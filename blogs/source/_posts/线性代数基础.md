---
title: 线性代数基础
categories: 数学
tags:
  - 线性代数
abbrlink: 74e95c64
date: 2019-06-03 20:13:14
---

参考[PCA数学原理](https://blog.csdn.net/u012005313/article/details/50877366)，小结`PCA`求解过程中相关的线性代数基础（*部分几何内容+概率论内容*）

* 内积
* 投影
* 向量的线性相关/线性无关
* 向量空间的基
* 线性变换和线性映射
* 矩阵降维
* 特征值和特征向量
* 正交向量组和正交矩阵
* 实对称矩阵

## 内积

参考：[点积](https://baike.baidu.com/item/%E7%82%B9%E7%A7%AF/9648528?fromtitle=%E5%86%85%E7%A7%AF&fromid=422863&fr=aladdin)

响亮的内积既可以由向量坐标的代数运算得出，也可以通过引入两个向量的长度和角度的几何概念来计算得到

### 代数运算

给定$n$个实向量$\alpha = (a_{1},a_{2},...,a_{n})^{T}, \beta = (b_{1},b_{2},...,b_{n})^{T}$，称实数

$$
[\alpha, \beta] = a_{1}b_{1} + a_{2}b_{2} + ... + a_{n}b_{n}
$$

为向量$\alpha$与$\beta$的内积

### 几何运算

给定$n$元实向量$\alpha = (a_{1}, a_{2}, ..., a_{n})^{T}$，称

$$
||\alpha|| = \sqrt{[\alpha, \alpha]}
= \sqrt{a_{1}^{2} + a_{2}^{2} + ... + a_{n}^{2}}
$$

为向量$\alpha$的长度（范数或模）。长度为$1$的向量称为**单位向量**，对任一非零向量$\alpha$，向量$\frac {\alpha}{||\alpha||}$为单位向量，这一过程称为**将向量$\alpha$单位化（或规范化/标准化）**

设$\alpha, \beta$为$n$元实非零向量，记

$$
< \alpha, \beta > = \arccos \frac {[\alpha, \beta]}{||\alpha|| ||\beta||}, 0\leq <\alpha, \beta> \leq \pi 
$$

称$<\alpha, \beta>$为向量$\alpha$和$\beta$的夹角

**设二维空间有两个向量$\alpha$和$\beta$，则内积定义如下：**

$$
\alpha\cdot \beta = ||\alpha|| ||\beta|| \cos \theta
$$

*该定义只对二维和三维空间有效*

## 投影

参考：[投影](https://baike.baidu.com/item/%E6%8A%95%E5%BD%B1/7565?fr=aladdin)

设两个非零向量$\alpha$和$\beta$的夹角为$\theta$，则将$||\beta||\cdot \cos \theta$叫做向量$\beta$在向量$\alpha$方向上的投影，也称为标投影（scalar projection），是一个标量

引入$\alpha$的单位矢量$\alpha(A)$，称$||\beta||\cdot \cos \theta\cdot \alpha(A)$为$\beta$在$\alpha$上的矢投影（vector projection），是一个向量

### 投影和内积关系

设向量$\beta$为$1$，则$\alpha$和$\beta$的内积等于$\alpha$向$\beta$所在直线投影的长度

$$
\alpha \cdot \beta = ||\alpha||\cdot \cos (\theta)
$$

## 向量的线性相关/线性无关

设向量组$\alpha_{1},\alpha_{2},...,\alpha_{m}\in R^{n}$，如果存在一组不全为零的数$k_{1},k_{2},...,k_{m}$，满足

$$
k_{1}\alpha_{1} + k_{2}\alpha_{2} + ... + k_{m}\alpha_{m} = 0
$$

则称向量组$\alpha_{1}, \alpha_{2},...,\alpha_{m}$ **线性相关**；当且仅当$k_{1}=k_{2}=...=k_{m}=0$时上式才成立，则称向量组$\alpha_{1},\alpha_{2},...,\alpha_{m}$ **线性无关**

**几何解释：在二维平面上，线性相关指向量在同一直线上，线性无关指向量不再同一直线上**

## 向量空间的基

设$V$是一个向量空间，$\alpha_{1},\alpha_{2},...,\alpha_{r}$是$V$中的**一组向量**，如果满足

1. $\alpha_{1},\alpha_{2},...,\alpha_{r}$线性无关
2. $V$中的任一向量都可由$\alpha_{1},\alpha_{2},...,\alpha_{r}$线性表示

则称$\alpha_{1},\alpha_{2},...,\alpha_{r}$是$V$中的一组**基**，数$r$称为$V$的维数，记作$dim(V)=r$，并称$V$是$r$维向量空间

### 正交基

参考：

[正交](https://baike.baidu.com/item/%E6%AD%A3%E4%BA%A4/36310)

[标准正交基](https://baike.baidu.com/item/%E6%A0%87%E5%87%86%E6%AD%A3%E4%BA%A4%E5%9F%BA/4729576?fr=aladdin)

称基中的向量为基向量，如果基向量两两正交（*向量内积为0*），则称基为正交基，如果正交基的基向量的模长都是单位长度$1$，则称正交基为标准正交基

**正交基中各基向量线性无关**

### 基变换与坐标变换

设$\alpha_{1}, \alpha_{2}, ..., \alpha_{r}$和$\beta_{1}, \beta_{2}, ..., \beta_{r}$为向量空间$V$的基，有

$$
(\beta_{1}, \beta_{2}, ..., \beta_{r})
= (\alpha_{1}, \alpha_{2}, ..., \alpha_{r}) P_{r\times r}
$$

称$r$阶矩阵$P$是由基$\alpha_{1}, \alpha_{2}, ..., \alpha_{r}$到基$\beta_{1}, \beta_{2}, ..., \beta_{r}$的过渡矩阵，称上式为**基变换公式**

*矩阵$P$是可逆矩阵*

设$V$是向量空间，$\alpha_{1}, \alpha_{2}, ..., \alpha_{r}$和$\beta_{1}, \beta_{2}, ..., \beta_{r}$分别为$V$的基，且

$$
X = (x_{1}, x_{2}, ..., x_{r})^{T}\\
Y = (y_{1}, y_{2}, ..., y_{r})^{T}
$$

分别是向量$a$在$\alpha_{1}, \alpha_{2}, ..., \alpha_{r}$和$\beta_{1}, \beta_{2}, ..., \beta_{r}$的坐标，则有

$$
X = PY \ 或\ Y = P^{-1}X
$$

其中$P$是由基$\alpha_{1}, \alpha_{2}, ..., \alpha_{r}$到基$\beta_{1}, \beta_{2}, ..., \beta_{r}$的过渡矩阵，称上式为**坐标变换公式**

## 线性变换和线性映射

参考：[线性变换](https://baike.baidu.com/item/%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/5904192?fr=aladdin)

线性变换（linear transformation）指线性空间$V$到其自身的线性映射，也就是坐标变换

线性映射（linear mapping）指从一个向量空间$V$到另一个向量空间$W$的映射且保持加法和数量乘法运算

## 矩阵降维

假设有$M$个$N$维向量组成的向量空间$P$，想要将其映射到由$R$个$N$维向量组成的向量空间$A$，则计算如下：

$$
PA=
\begin{pmatrix}
p_{1}\\ 
p_{2}\\ 
\vdots \\ 
p_{M}
\end{pmatrix}
(a_{1}, a_{2}, \cdots, a_{R})
\in R^{M\times R}
$$

其中$p_{i}$表示长度为$N$的行向量，$a_{j}$表示长度为$N$的列向量

**向量空间的矩阵乘法属于线性映射**

**如果$R$小于$M$，可以称线性映射为$P$到$A$的投影**

## 特征值和特征向量

设$A$是$n$阶方阵，若存在数$\lambda$和$n$维非零向量$X$，使得

$$
AX = \lambda X
$$

则称数$\lambda$为方阵$A$的**特征值**；非零向量$X$称为$A$的对应于特征值$\lambda$的**特征向量**

### 性质

定理一：设$A$是$n$阶矩阵，则$A^{T}$与$A$有相同的特征值

定理二：设$\lambda_{1}, \lambda_{2}, ..., \lambda_{n}$为$n$阶方阵$A=(a_{ij})$的$n$个特征值，则

$$
\sum_{i=1}^{n} \lambda_{i}
=\sum_{i=1}^{n} a_{ii}
$$

$$
\prod_{i=1}^{n} \lambda_{i}
=|A|
$$

**其中$\sum_{i=1}^{n} a_{ii}$是$A$的主对角线元素之和，称为方阵$A$的迹，记作$tr(A)$**

定理三：不同特征值对应的特征向量线性无关，也就是两两正交

### 求解

求解方阵$A$的特征值与特征向量:

1. 计算$A$的特征多项式：$f(\lambda) = | A - \lambda E |$，其根$\lambda_{1}, \lambda_{2}, ..., \lambda_{s}(\lambda_{i} \neq \lambda_{j})$就是$A$的$s$个不同的特征值

2. 对每个特征值$\lambda_{i}, i=1,2,...,s$，解方程组$(A-\lambda_{i}E)X=0$，其基础解系就是$A$的对应于特征值$\lambda_{i}$的线性无关的特征向量，其非零解就是$A$的对应于特征值$\lambda_{i}$的全部特征向量

### 特征值和投影关系

参考：[线性代数中，特征值与特征向量在代数和几何层面的实际意义是什么？](https://www.zhihu.com/question/20507061?sort=created)

矩阵乘法$AX$相当于矩阵$A$在向量$X$上的投影，$\lambda$表示投影大小（以$X$为基）

特征值越大表示数据分布越广，离散程度大，所以其方差越大

## 正交向量组和正交矩阵

**什么是正交向量?**

设$\alpha, \beta$是两个$n$元实向量，若$[\lambda, \beta]=0$，则称$\lambda$和$\beta$正交（或垂直），记为$\alpha \perp \beta $

向量$\alpha$和$\beta$正交的充分必要条件是$||\alpha + \beta||^{2} = ||\alpha||^{2} + ||\beta||^{2}$

**什么是正交向量组?**

若不含零向量的向量组中任意两个向量都正交，则称此向量组为**正交向量组**

由单位向量构成的正交向量组叫做**正交单位向量组（规范正交向量组或标准正交向量组）**

**什么是正交矩阵？**

设$A$为$n$阶矩阵，如果$AA^{T}=E$，则称$A$为正交矩阵

$A$为正交矩阵的充分必要条件是$A$的列（或行）向量组是单位正交向量组

### 正交向量组和基的关系

大小为$n$的正交向量组两两正交，比线性无关，可以视为$n$维空间的正交基

所以正交单位向量组可以视为标准正交基

## 实对称矩阵

定理一：设$A$为$n$阶实对称矩阵，$\lambda_{0}$是$A$的$r$重特征值，则$A$的属于特征值$\lambda_{0}$恰有$r$个线性无关的特征向量，即$R(A-\lambda_{0}E) = n-r$

定理二：设$A$为$n$阶实对称矩阵，则存在$n$阶正交矩阵$Q$，使得

$$
Q^{-1}AQ = Q^{T}AQ = \Lambda = diag(\lambda_{1}, \lambda_{2}, ..., \lambda_{n})
$$

其中$\lambda_{1}, \lambda_{2}, ..., \lambda_{n}$为$A$的特征值

正交矩阵$Q$由特征值对应的特征向量正交化且单位化后组成，$Q$的第$j$列对应特征值$\lambda_{j}$