---
title: 模型集成
categories:
  - [算法, 最优化]
tags:
  - 模型集成
abbrlink: e0761e53
date: 2019-08-04 16:47:11
---

训练多个独立模型，在测试阶段平均其预测结果，是一种有效的提高检测精度的方法，称为模型集成（`model ensemble`）

## 不同模型集成方式

检测精度通常与模型数量呈正比关系，不过其效果会逐渐降低。另外，控制不同变量得到的模型具有不一样的性能，`cs231n`中提出了几种模型集成方式：[Model Ensembles](http://cs231n.github.io/neural-networks-3/#ensemble)

* 同一套模型结构，不同的初始化

    使用交叉验证确定最好的超参数，然后使用不同随机初始化方式训练多个模型。其缺点在于该方法变量仅依赖于初始化
* 交叉验证过程中发现的最好一批超参数

    使用交叉验证确定最好的超参数，然后取检测效果最好的前一批（比如前`10`个）组成模型集成。这种方式提高了模型的多样性，但是有包含次优模型的危险。实际使用过程中，这种方式更容易实现，因为它不需要在交叉验证后再次训练
* 单个模型的不同检查点

    如果训练过程非常耗时，可以使用单个网络的不同检查点（`checkpoint`）进行模型集成。虽然这种方式缺乏多样性，取得的进步有限，但是在实际使用过程中仍旧有效，因为其实现方式很简单
* 在训练过程中运行参数平均值

    在内存中保持一个权重副本，其维持训练过程中权重的指数衰减和，这样能够得到前几次迭代过程中网络的平均状态，这种方式总能保证`1%-2%`的性能提高。其粗略的理解是损失对象是碗状的（`bowl-shaped`），训练过程中的网络不断的在其中跳跃，而平均权重方式能够更有机会跳入最低点

## 优缺点

模型集成方式能够进一步提高模型精度，减小误差率；不过在检测过程中需要花费更长时间