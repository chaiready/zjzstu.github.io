<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.0.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="alternate" href="/./atom.xml" title="做一个幸福的人" type="application/atom+xml"><meta name="google-site-verification" content="Qr_3yqLtyErDFKHW7mE8PJz4qDUX-bf_fMLpSRckQe4"><meta name="baidu-site-verification" content="zOwIvKMV7f"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Roboto:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="/lib/pace/pace-theme-center-atom.min.css"><script src="/lib/pace/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"7.5.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!1,pangu:!1,algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"搜索文章",hits_empty:"我们没有找到任何搜索结果: ${query}",hits_stats:"找到约${hits}条结果（用时${time}ms）"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},translation:{copy_button:"复制",copy_success:"复制成功",copy_failure:"复制失败"},sidebarPadding:40}</script><link href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap" rel="stylesheet"><meta name="description" content="文章very deep convolutional networks for large-scale image recognition对卷积网络深度进行了详细研究，证明了增加模型深度能够有效提高网络性能，其实现的VGGNet在2014年ImageNet的定位（localisation）和分类（classification）比赛中获得第一和第二名"><meta name="keywords" content="VGGNet"><meta property="og:type" content="article"><meta property="og:title" content="用于大尺度图像分类的极深卷积网络"><meta property="og:url" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;posts&#x2F;2738b55.html"><meta property="og:site_name" content="做一个幸福的人"><meta property="og:description" content="文章very deep convolutional networks for large-scale image recognition对卷积网络深度进行了详细研究，证明了增加模型深度能够有效提高网络性能，其实现的VGGNet在2014年ImageNet的定位（localisation）和分类（classification）比赛中获得第一和第二名"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;用于大尺度图像分类的极深卷积网络&#x2F;vggnet.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;用于大尺度图像分类的极深卷积网络&#x2F;params.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;用于大尺度图像分类的极深卷积网络&#x2F;single_scale.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;用于大尺度图像分类的极深卷积网络&#x2F;multi_scale.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;用于大尺度图像分类的极深卷积网络&#x2F;multi_crop.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;用于大尺度图像分类的极深卷积网络&#x2F;convnet_fusion.png"><meta property="og:updated_time" content="2020-02-15T05:36:35.875Z"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;用于大尺度图像分类的极深卷积网络&#x2F;vggnet.png"><link rel="canonical" href="https://www.zhujian.tech/posts/2738b55.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,isPage:!1,isArchive:!1}</script><title>用于大尺度图像分类的极深卷积网络 | 做一个幸福的人</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?e677aac1ac69b8826b9cfecb4e72e107";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">做一个幸福的人</span><span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">面朝大海，春暖花开</p></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i> 标签<span class="badge">129</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i> 分类<span class="badge">48</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i> 归档<span class="badge">169</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header> <a href="https://github.com/zjZSTU" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zhujian.tech/posts/2738b55.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.png"><meta itemprop="name" content="zhujian"><meta itemprop="description" content="one bite at a time"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="做一个幸福的人"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> 用于大尺度图像分类的极深卷积网络</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-06-21 19:45:19" itemprop="dateCreated datePublished" datetime="2019-06-21T19:45:19+00:00">2019-06-21</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-02-15 05:36:35" itemprop="dateModified" datetime="2020-02-15T05:36:35+00:00">2020-02-15</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/algorithm/" itemprop="url" rel="index"><span itemprop="name">算法</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/algorithm/deep-learning/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>2.9k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>5 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>文章<a href="https://arxiv.org/abs/1409.1556v6#" target="_blank" rel="noopener">very deep convolutional networks for large-scale image recognition</a>对<strong>卷积网络深度</strong>进行了详细研究，证明了增加模型深度能够有效提高网络性能，其实现的<code>VGGNet</code>在<code>2014</code>年<code>ImageNet</code>的定位（<code>localisation</code>）和分类（<code>classification</code>）比赛中获得第一和第二名</p><a id="more"></a><p><code>VGGNet</code>在<a href="https://www.zhujian.tech/posts/ca9994d1.html#more">AlexNet</a>模型配置和学习的基础上，参考<a href="https://zjzstu.github.io/posts/3f18ad9b.html#more" target="_blank" rel="noopener">ZFNet</a>使用更小的感受野和更小的步长，参考<a href="https://arxiv.org/abs/1312.6229" target="_blank" rel="noopener">OverFeat</a>在整个图像和多个尺度上对网络进行密集的训练和测试。最终，<code>VGGNet</code>使用$3\times 3$大小卷积核进行模型深度的研究，在学习过程中使用多尺度图像进行训练和测试</p><p>主要内容如下：</p><ol><li>卷积网络配置</li><li>训练和测试细节</li><li>分类实验</li><li>小结</li></ol><h2 id="卷积网络配置"><a href="#卷积网络配置" class="headerlink" title="卷积网络配置"></a>卷积网络配置</h2><h3 id="通用架构"><a href="#通用架构" class="headerlink" title="通用架构"></a>通用架构</h3><p><code>VGGNet</code>有多个版本，每个模型均包含以下内容</p><ul><li>输入数据固定为$224\times 224$大小的<code>RGB</code>图像</li><li>图像预处理仅执行均值零中心</li><li>使用$3\times 3$大小的卷积核，某些模型会额外配置$1\times 1$大小的卷积核，用于跨通道信息交互</li><li>步长固定为<code>1</code>，零填充用于保证卷积操作不改变输入数据体空间尺寸，$3\times 3$大小卷积核对应的零填充是<code>1</code></li><li>每个模型共有<code>5</code>个最大池化层，用于空间池化，滤波器大小为$2\times 2$，步长为<code>2</code></li><li>每个模型都包含<code>3</code>个全连接层，第一二个全连接层的神经元个数是<code>4096</code>，第三个神经元个数是类别数</li><li>模型输出结果使用<code>softmax</code>评分函数</li><li>所有隐藏层使用<code>ReLU</code>作为激活函数</li></ul><h3 id="模型配置"><a href="#模型配置" class="headerlink" title="模型配置"></a>模型配置</h3><p><code>VGGNet</code>共有<code>5</code>个版本，分别命名为<code>A-E</code></p><p><img src="/imgs/用于大尺度图像分类的极深卷积网络/vggnet.png" alt></p><p>每一列表示一个模型配置，不同列的区别在于增加的卷积层，卷积层命名规则为</p><blockquote><p>conv&lt;卷积核大小&gt;-&lt;滤波器个数&gt;</p></blockquote><p>由于参数主要集中在全连接层，所以<code>5</code>个模型的参数大体一致</p><p><img src="/imgs/用于大尺度图像分类的极深卷积网络/params.png" alt></p><h2 id="小卷积优势"><a href="#小卷积优势" class="headerlink" title="小卷积优势"></a>小卷积优势</h2><p><code>VGGNet</code>使用$3\times 3$大小卷积核进行特征提取，多个小卷积核操作的有效感受野等同于大卷积核一次操作。比如，两次$3\times 3$大小卷积操作（中间没有池化操作）等同于一次$5\times 5$大小卷积操作，三次$3\times 3$大小卷积操作的有效感受野等同于一次$7\times 7$大小卷积操作，参考<a href="https://www.zhujian.tech/posts/3b660279.html#more">感受野尺寸</a></p><p>$3\times 3$大小卷积操作还有如下优势：</p><ol><li>每个卷积层包含激活函数运算，堆叠小卷积网络能够集成更多的非线性函数，增强模型判别能力</li><li>假设每个卷积层滤波器个数均为$C$通道，那么3次$3\times 3$大小卷积操作共有$3\cdot 3\cdot 3\cdot C = 27C$个参数，而一次$7\times 7$大小卷积操作共有$49C$个参数。使用小卷积网络能够降低45%的参数（<em>此处和文章数据不太一致</em>）</li></ol><p>在模型<code>C</code>中还使用了$1\times 1$大小卷积核，参考<a href="https://zjzstu.github.io/posts/359ae103.html#more" target="_blank" rel="noopener">NIN</a>，其作用是进行跨通道的信息交互，同时能够集成激活函数，增加判别能力</p><h2 id="训练和测试细节"><a href="#训练和测试细节" class="headerlink" title="训练和测试细节"></a>训练和测试细节</h2><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><ul><li>批量大小为$256$</li><li>动量因子为$0.9$</li><li>权重惩罚因子为$5\cdot 10^{-4}$</li><li>第一二个全连接层进行随机失活（失活因子为<code>0.5</code>）</li><li>学习率初始化为$10^{-2}$，每当验证集精度停止提高时下降<code>10%</code></li></ul><p>整个训练过程共进行<code>370K</code>次（<code>74</code>次迭代），由于更小的卷积核滤波器、更深的深度以及某些层的预初始化，所以网络在较少的迭代次数后就能够拟合</p><p>首先对模型<code>A</code>进行训练，参数初始化为零均值，<code>0.01</code>方差；训练完成后使用其参数设置其他模型的<code>1-4</code>层卷积层和最后<code>3</code>个全连接层</p><h4 id="训练图像"><a href="#训练图像" class="headerlink" title="训练图像"></a>训练图像</h4><p>在每轮迭代中对图像进行随机采样$224\times 224$大小，并且进行随机水平翻转以及随机<code>RGB</code>颜色偏移</p><p>文章使用多种方法扩充数据集</p><p><strong>单尺度图像采样</strong>：假设最小边长度为$S$，将输入图像最小边缩放到$S=256或384$大小，随机采样$224\times 224$大小进行训练</p><p><strong>多尺度图像采样</strong>：将$S$随机缩放到尺度<code>[S_{min}, S_{max}]</code>之间（$S_{min}=256, S_{max}=512$），再随机采样$224\times 224$大小进行训练</p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>将模型全连接层转换成卷积层：第一二个全连接层的卷积核大小为$7\times 7$，第三个全连接层的卷积核大小为$1\times 1$，最后输出的通道数就是类别成绩</p><p>将测试图像最小边缩放至大小$Q$，直接应用到全卷积网络，对最后输出的激活图求均值得到类别成绩</p><p>同时使用水平翻转扩充测试集，使用最大类后验概率平均原始和翻转图像获得最终的成绩</p><h2 id="分类实验"><a href="#分类实验" class="headerlink" title="分类实验"></a>分类实验</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>使用<code>ILSVRC-2012</code>数据集，共<code>1000</code>类，分为<code>3</code>组图像：训练集（<code>130</code>万张）、验证集（<code>5</code>万张）和测试集（<code>10</code>万张）</p><p>下面的单尺度、多尺度和多裁剪相对于测试阶段</p><h3 id="单尺度评估"><a href="#单尺度评估" class="headerlink" title="单尺度评估"></a>单尺度评估</h3><p>对于固定$S$，设置$Q=S$，对于$S\in [S_{min}, S_{max}]$，设置$Q=0.5(S_{min}+S_{max})$</p><p><img src="/imgs/用于大尺度图像分类的极深卷积网络/single_scale.png" alt></p><ul><li><strong>比较模型<code>A</code>和<code>A-LRN</code>，增加<code>LRN</code>层不对实验结果有提高</strong></li><li>比较模型<code>A-E</code>，增加模型深度能够提高检测结果</li><li>比较模型<code>B、C和D</code>，<code>C</code>比<code>B</code>增加了$1\times 1$大小的卷积层，<code>D</code>比<code>B</code>增加了$3\times 3$大小的卷积层，实验结果表明虽然增加$1\times 1$卷积层能够提高判别能力，但是捕获更多的空间上下文信息更重要</li><li>文章用$5\times 5$大小卷积核替换模型<code>B</code>的每一对$3\times 3$大小卷积核，结果发现更浅的网络比模型<code>B</code>的<code>top-1</code>误差率提高了<code>7%</code>，证明小卷积的深网络比大卷积的浅网络更有效</li><li>训练阶段多尺度采样图像比单尺度采样图像的结果更好，表明尺度抖动（<code>scale jittering</code>）能够有效捕获多尺度图像信息</li></ul><h3 id="多尺度评估"><a href="#多尺度评估" class="headerlink" title="多尺度评估"></a>多尺度评估</h3><p>对于训练集固定$S$的情况，测试集采集<code>3</code>张测试图像：${S-32, S, S+32}$，平均其检测结果</p><p>对于训练集浮动$S$的情况，测试集采集更大范围的图像：${S_{min}, 0.5(S_{min}+S_{max}), S_{max}}$</p><p><img src="/imgs/用于大尺度图像分类的极深卷积网络/multi_scale.png" alt></p><p>测试集尺度抖动能够有效提升检测性能</p><h3 id="多裁剪评估"><a href="#多裁剪评估" class="headerlink" title="多裁剪评估"></a>多裁剪评估</h3><p>参考：<a href="https://blog.csdn.net/C_chuxin/article/details/82832229" target="_blank" rel="noopener">在VGG网络中dense evaluation 与multi-crop evaluation两种预测方法的区别以及效果</a></p><p>比较<code>dense evaluation</code>（密集评估）和<code>multi-crop evaluation</code>（多裁剪评估）</p><ul><li><p>密集评估指直接将原图输入全卷积网络（<code>FCN</code>），最后对每个特征图求均值得到类别成绩</p></li><li><p>多裁剪评估指对图像进行多次随机裁剪，最后平均每个类别值</p></li></ul><p>通过实验证明两者存在互补性（<code>complementarity</code>），</p><p><img src="/imgs/用于大尺度图像分类的极深卷积网络/multi_crop.png" alt></p><h3 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a>模型融合</h3><p>使用模型集成（<code>model ensemble</code>）的方法，组合多个网络进行测试，平均最后的检测结果，能够有效提高检测性能</p><p><img src="/imgs/用于大尺度图像分类的极深卷积网络/convnet_fusion.png" alt></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>参考：<a href="http://cs231n.github.io/convolutional-networks/#case" target="_blank" rel="noopener">VGGNet</a></p><p>文章对模型深度进行了详尽的评估，提出的共<code>5</code>个<code>VGGNet</code>模型从<code>11</code>层到<code>19</code>层，证明了堆叠深度能够有效提高网络性能</p><p>通过尺度抖动增加训练集，通过多裁剪评估和密集评估融合增加测试集，通过模型集成的方式来提高性能</p><p>虽然网络深度的增加能够提高网络性能，但是<code>VGGNet</code>的缺点在于参数多，占用内存大，运算时间长。所以后续的方向一方面在于<strong>是否能够减少网络参数，提高运算时间</strong>；另一方面在于<strong>是否能够堆叠更深的网络来得到更好的性能</strong></p></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';"> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/images/wechatpay.jpg" alt="zhujian 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/images/alipay.jpg" alt="zhujian 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zhujian</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zhujian.tech/posts/2738b55.html" title="用于大尺度图像分类的极深卷积网络">https://www.zhujian.tech/posts/2738b55.html</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/VGGNet/" rel="tag"># VGGNet</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/posts/cab4035.html" rel="next" title="NIN-pytorch"><i class="fa fa-chevron-left"></i> NIN-pytorch</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/posts/d3f167aa.html" rel="prev" title="GoogLeNet-numpy">GoogLeNet-numpy<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div><div class="comments" id="gitalk-container"></div></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#卷积网络配置"><span class="nav-number">1.</span> <span class="nav-text">卷积网络配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#通用架构"><span class="nav-number">1.1.</span> <span class="nav-text">通用架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型配置"><span class="nav-number">1.2.</span> <span class="nav-text">模型配置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#小卷积优势"><span class="nav-number">2.</span> <span class="nav-text">小卷积优势</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#训练和测试细节"><span class="nav-number">3.</span> <span class="nav-text">训练和测试细节</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#训练"><span class="nav-number">3.1.</span> <span class="nav-text">训练</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#训练图像"><span class="nav-number">3.1.1.</span> <span class="nav-text">训练图像</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测试"><span class="nav-number">3.2.</span> <span class="nav-text">测试</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分类实验"><span class="nav-number">4.</span> <span class="nav-text">分类实验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#数据集"><span class="nav-number">4.1.</span> <span class="nav-text">数据集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#单尺度评估"><span class="nav-number">4.2.</span> <span class="nav-text">单尺度评估</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多尺度评估"><span class="nav-number">4.3.</span> <span class="nav-text">多尺度评估</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多裁剪评估"><span class="nav-number">4.4.</span> <span class="nav-text">多裁剪评估</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型融合"><span class="nav-number">4.5.</span> <span class="nav-text">模型融合</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#小结"><span class="nav-number">5.</span> <span class="nav-text">小结</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zhujian" src="/images/avatar.png"><p class="site-author-name" itemprop="name">zhujian</p><div class="site-description" itemprop="description">one bite at a time</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">169</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">48</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">129</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="feed-link motion-element"><a href="/./atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zjZSTU" title="Github &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;zjZSTU" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/u012005313" title="CSDN &amp;rarr; https:&#x2F;&#x2F;blog.csdn.net&#x2F;u012005313" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i> CSDN</a></span><span class="links-of-author-item"><a href="/mailto:zjzstu@gmail.com" title="Gmail &amp;rarr; mailto:zjzstu@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> Gmail</a></span><span class="links-of-author-item"><a href="/mailto:505169307@gmail.com" title="QQmail &amp;rarr; mailto:505169307@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> QQmail</a></span></div><div class="cc-license motion-element" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://cloud.tencent.com/" title="https:&#x2F;&#x2F;cloud.tencent.com" rel="noopener" target="_blank">腾讯云</a></li><li class="links-of-blogroll-item"> <a href="https://www.aliyun.com/" title="https:&#x2F;&#x2F;www.aliyun.com" rel="noopener" target="_blank">阿里云</a></li><li class="links-of-blogroll-item"> <a href="https://developer.android.com/" title="https:&#x2F;&#x2F;developer.android.com&#x2F;" rel="noopener" target="_blank">Android Dev</a></li><li class="links-of-blogroll-item"> <a href="https://jenkins.io/" title="https:&#x2F;&#x2F;jenkins.io&#x2F;" rel="noopener" target="_blank">Jenkins</a></li><li class="links-of-blogroll-item"> <a href="http://cs231n.github.io/" title="http:&#x2F;&#x2F;cs231n.github.io&#x2F;" rel="noopener" target="_blank">cs231n</a></li><li class="links-of-blogroll-item"> <a href="https://pytorch.org/docs/stable/index.html" title="https:&#x2F;&#x2F;pytorch.org&#x2F;docs&#x2F;stable&#x2F;index.html" rel="noopener" target="_blank">pytorch</a></li><li class="links-of-blogroll-item"> <a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/" title="https:&#x2F;&#x2F;docs.docker.com&#x2F;install&#x2F;linux&#x2F;docker-ce&#x2F;ubuntu&#x2F;" rel="noopener" target="_blank">docker</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2020</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">zhujian</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span> <span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">948k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">26:20</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-bar-chart-o"></i></span> <a href="https://tongji.baidu.com/web/27249108/overview/index?siteId=13647183" rel="noopener" target="_blank">百度统计</a></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0</div> <span class="post-meta-divider">|</span><div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.5.0</div><div class="beian"> <a href="http://www.beian.miit.gov.cn/" rel="noopener" target="_blank">浙ICP备 19026415号</a> <span class="post-meta-divider">|</span> <img src="/images/beian_icon.png" style="display:inline-block;text-decoration:none;height:13px"> <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33011802001748" rel="noopener" target="_blank">浙公网安备 33011802001748号</a></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span> <span class="site-uv" title="总访客量">访客数：<span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="site-pv" title="总访问量">阅读量：<span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script color="17,63,61" opacity="1" zindex="-1" count="199" src="/lib/canvas-nest/canvas-nest.min.js"></script><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '8f22595c6dd29c94467d',
      clientSecret: 'e66bd90ebb9aa66c562c753dec6c90ceecbd51f2',
      repo: 'guestbook',
      owner: 'zjZSTU',
      admin: ['zjZSTU'],
      id: 'a0be31c1a3b195a50fd26ac3efa3dfb8',
        language: '',
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script></body></html>