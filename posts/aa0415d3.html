<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.0.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="alternate" href="/./atom.xml" title="做一个幸福的人" type="application/atom+xml"><meta name="google-site-verification" content="Qr_3yqLtyErDFKHW7mE8PJz4qDUX-bf_fMLpSRckQe4"><meta name="baidu-site-verification" content="zOwIvKMV7f"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Roboto:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="/lib/pace/pace-theme-center-atom.min.css"><script src="/lib/pace/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"7.5.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!1,pangu:!1,algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"搜索文章",hits_empty:"我们没有找到任何搜索结果: ${query}",hits_stats:"找到约${hits}条结果（用时${time}ms）"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},translation:{copy_button:"复制",copy_success:"复制成功",copy_failure:"复制失败"},sidebarPadding:40}</script><link href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap" rel="stylesheet"><meta name="description" content="PyTorch通过TorchVision工具包提供统一的数据加载、数据处理的接口，允许自定义类的方式加载数据集，通过DataLoader接口来批量处理"><meta name="keywords" content="python,pytorch,torchvision,numpy,matplotlib,pandas,skimage"><meta property="og:type" content="article"><meta property="og:title" content="[译]Writing Custom Datasets, DataLoaders and Transforms"><meta property="og:url" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;posts&#x2F;aa0415d3.html"><meta property="og:site_name" content="做一个幸福的人"><meta property="og:description" content="PyTorch通过TorchVision工具包提供统一的数据加载、数据处理的接口，允许自定义类的方式加载数据集，通过DataLoader接口来批量处理"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;pytorch-自定义数据集&#x2F;landmarked_face2.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;pytorch-自定义数据集&#x2F;sphx_glr_data_loading_tutorial_001.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;pytorch-自定义数据集&#x2F;sphx_glr_data_loading_tutorial_002.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;pytorch-自定义数据集&#x2F;sphx_glr_data_loading_tutorial_003.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;pytorch-自定义数据集&#x2F;sphx_glr_data_loading_tutorial_004.png"><meta property="og:updated_time" content="2020-02-15T05:36:35.879Z"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;pytorch-自定义数据集&#x2F;landmarked_face2.png"><link rel="canonical" href="https://www.zhujian.tech/posts/aa0415d3.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,isPage:!1,isArchive:!1}</script><title>[译]Writing Custom Datasets, DataLoaders and Transforms | 做一个幸福的人</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?e677aac1ac69b8826b9cfecb4e72e107";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">做一个幸福的人</span><span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">面朝大海，春暖花开</p></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i> 标签<span class="badge">129</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i> 分类<span class="badge">48</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i> 归档<span class="badge">169</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header> <a href="https://github.com/zjZSTU" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zhujian.tech/posts/aa0415d3.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.png"><meta itemprop="name" content="zhujian"><meta itemprop="description" content="one bite at a time"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="做一个幸福的人"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> [译]Writing Custom Datasets, DataLoaders and Transforms</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-12-08 14:52:55" itemprop="dateCreated datePublished" datetime="2019-12-08T14:52:55+00:00">2019-12-08</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-02-15 05:36:35" itemprop="dateModified" datetime="2020-02-15T05:36:35+00:00">2020-02-15</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programming/" itemprop="url" rel="index"><span itemprop="name">编程</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programming/programming-language/" itemprop="url" rel="index"><span itemprop="name">编程语言</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programming/codebase/" itemprop="url" rel="index"><span itemprop="name">代码库</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/translation/" itemprop="url" rel="index"><span itemprop="name">翻译</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>14k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>23 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>PyTorch通过TorchVision工具包提供统一的数据加载、数据处理的接口，允许自定义类的方式加载数据集，通过DataLoader接口来批量处理</p><a id="more"></a><p>原文地址：<a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html" target="_blank" rel="noopener">Writing Custom Datasets, DataLoaders and Transforms</a></p><blockquote><p>A lot of effort in solving any machine learning problem goes in to preparing the data. PyTorch provides many tools to make data loading easy and hopefully, to make your code more readable. In this tutorial, we will see how to load and preprocess/augment data from a non trivial dataset.</p></blockquote><p>在解决任何机器学习问题时，都要花很多精力准备数据。PyTorch提供了许多工具来使数据加载变得容易，并且有可能使您的代码更具可读性。在本教程中，我们将看到如何从一个自定义数据集中加载和预处理/扩充数据</p><blockquote><p>To run this tutorial, please make sure the following packages are installed:</p><ul><li>scikit-image: For image io and transforms</li><li>pandas: For easier csv parsing</li></ul></blockquote><p>运行本教程之前，确保以下包已安装：</p><ul><li>scikit-image: 用于图像输出和转换</li><li>pandas: 用于CSV文件解析</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from __future__ import print_function, division</span><br><span class="line">import os</span><br><span class="line">import torch</span><br><span class="line">import pandas as pd</span><br><span class="line">from skimage import io, transform</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from torch.utils.data import Dataset, DataLoader</span><br><span class="line">from torchvision import transforms, utils</span><br><span class="line"></span><br><span class="line"># Ignore warnings</span><br><span class="line">import warnings</span><br><span class="line">warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class="line"></span><br><span class="line">plt.ion()   # interactive mode</span><br></pre></td></tr></table></figure><blockquote><p>The dataset we are going to deal with is that of facial pose. This means that a face is annotated like this:</p></blockquote><p>我们将要处理的数据集是面部姿态数据集。这意味着一张脸被这样标注:</p><p><img src="/imgs/pytorch-自定义数据集/landmarked_face2.png" alt></p><blockquote><p>Over all, 68 different landmark points are annotated for each face.</p></blockquote><p>总的来说，为每张脸标注了68个不同的地点</p><blockquote><p>Download the dataset from <a href="https://download.pytorch.org/tutorial/faces.zip" target="_blank" rel="noopener">here</a> so that the images are in a directory named ‘data/faces/‘. This dataset was actually generated by applying excellent <a href="https://blog.dlib.net/2014/08/real-time-face-pose-estimation.html" target="_blank" rel="noopener">dlib’s pose estimation</a> on a few images from imagenet tagged as ‘face’</p></blockquote><p>从这里下载数据集，以便图像位于名为“data/faces/”的目录中（就是解压后放置在data/faces目录下）。这个数据集实际上是通过对标记为“人脸”的imagenet中的图像应用出色的dlib姿态估计方法生成的</p><blockquote><p>Dataset comes with a csv file with annotations which looks like this:</p></blockquote><p>数据集附带一个csv文件，其格式如下（第一行为注释信息，第二行开始是图像名及标注坐标）:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">image_name,part_0_x,part_0_y,part_1_x,part_1_y,part_2_x,part_2_y,part_3_x,part_3_y,...</span><br><span class="line">0805personali01.jpg,27,83,27,98,29,113,33,127,39,139,49,150,60,159,73,166,87,168,100,166,...</span><br><span class="line">10comm-decarlo.jpg,66,114,65,128,67,142,68,156,72,169,80,180,91,...</span><br></pre></td></tr></table></figure><blockquote><p>Let’s quickly read the CSV and get the annotations in an (N, 2) array where N is the number of landmarks.</p></blockquote><p>让我们快速阅读CSV并将标注地点保存在(N，2)大小数组，其中N是标注的数量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">landmarks_frame = pd.read_csv(&apos;data/faces/face_landmarks.csv&apos;)</span><br><span class="line"></span><br><span class="line">n = 65</span><br><span class="line">img_name = landmarks_frame.iloc[n, 0]</span><br><span class="line">landmarks = landmarks_frame.iloc[n, 1:].as_matrix()</span><br><span class="line">landmarks = landmarks.astype(&apos;float&apos;).reshape(-1, 2)</span><br><span class="line"></span><br><span class="line">print(&apos;Image name: &#123;&#125;&apos;.format(img_name))</span><br><span class="line">print(&apos;Landmarks shape: &#123;&#125;&apos;.format(landmarks.shape))</span><br><span class="line">print(&apos;First 4 Landmarks: &#123;&#125;&apos;.format(landmarks[:4]))</span><br></pre></td></tr></table></figure><p>输出</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Image name: person-7.jpg</span><br><span class="line">Landmarks shape: (68, 2)</span><br><span class="line">First 4 Landmarks: [[32. 65.]</span><br><span class="line"> [33. 76.]</span><br><span class="line"> [34. 86.]</span><br><span class="line"> [34. 97.]]</span><br></pre></td></tr></table></figure><blockquote><p>Let’s write a simple helper function to show an image and its landmarks and use it to show a sample.</p></blockquote><p>让我们编写一个简单的辅助函数来显示图像及其标注，并显示该结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def show_landmarks(image, landmarks):</span><br><span class="line">    &quot;&quot;&quot;Show image with landmarks&quot;&quot;&quot;</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker=&apos;.&apos;, c=&apos;r&apos;)</span><br><span class="line">    # 这一行代码需要去除 plt.pause(0.001)  # pause a bit so that plots are updated</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">show_landmarks(io.imread(os.path.join(&apos;data/faces/&apos;, img_name)),</span><br><span class="line">               landmarks)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/imgs/pytorch-自定义数据集/sphx_glr_data_loading_tutorial_001.png" alt></p><h2 id="Dataset-Class"><a href="#Dataset-Class" class="headerlink" title="Dataset Class"></a>Dataset Class</h2><blockquote><p>torch.utils.data.Dataset is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:</p><ul><li><code>__len__</code> so that len(dataset) returns the size of the dataset.</li><li><code>__getitem__</code> to support the indexing such that dataset[i] can be used to get ith sample</li></ul></blockquote><p>torch.util.data.Dataset是表示数据集的抽象类。自定义数据集类必须继承该类并重写以下方法：</p><ul><li><code>__len__</code>：返回数据集个数</li><li><code>__getitem__</code>：支持数据集检索，返回指定的图像</li></ul><blockquote><p>Let’s create a dataset class for our face landmarks dataset. We will read the csv in <code>__init__</code> but leave the reading of images to <code>__getitem__</code>. This is memory efficient because all the images are not stored in the memory at once but read as required.</p></blockquote><p>创建人脸标注数据集类。在<code>__init__</code>方法中读取CSV文件，在<code>__getItem__</code>方法中读取图像。这种方式更有效率，因为不需要一次性读取所有的图像</p><blockquote><p>Sample of our dataset will be a dict {‘image’: image, ‘landmarks’: landmarks}. Our dataset will take an optional argument transform so that any required processing can be applied on the sample. We will see the usefulness of transform in the next section.</p></blockquote><p>数据集中每个样本的格式为dict - {‘image’: image, ‘landmarks’: landmarks}。数据集类设置一个可选参数transform，作为参数转换，以便对样本应用任何所需的处理。我们将在下一节看到这个参数的操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">class FaceLandmarksDataset(Dataset):</span><br><span class="line">    &quot;&quot;&quot;Face Landmarks dataset.&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, csv_file, root_dir, transform=None):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Args:</span><br><span class="line">            csv_file (string): Path to the csv file with annotations.</span><br><span class="line">            root_dir (string): Directory with all the images.</span><br><span class="line">            transform (callable, optional): Optional transform to be applied</span><br><span class="line">                on a sample.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.landmarks_frame = pd.read_csv(csv_file)</span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return len(self.landmarks_frame)</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, idx):</span><br><span class="line">        if torch.is_tensor(idx):</span><br><span class="line">            idx = idx.tolist()</span><br><span class="line"></span><br><span class="line">        img_name = os.path.join(self.root_dir,</span><br><span class="line">                                self.landmarks_frame.iloc[idx, 0])</span><br><span class="line">        image = io.imread(img_name)</span><br><span class="line">        landmarks = self.landmarks_frame.iloc[idx, 1:]</span><br><span class="line">        landmarks = np.array([landmarks])</span><br><span class="line">        landmarks = landmarks.astype(&apos;float&apos;).reshape(-1, 2)</span><br><span class="line">        sample = &#123;&apos;image&apos;: image, &apos;landmarks&apos;: landmarks&#125;</span><br><span class="line"></span><br><span class="line">        if self.transform:</span><br><span class="line">            sample = self.transform(sample)</span><br><span class="line"></span><br><span class="line">        return sample</span><br></pre></td></tr></table></figure><blockquote><p>Let’s instantiate this class and iterate through the data samples. We will print the sizes of first 4 samples and show their landmarks.</p></blockquote><p>让我们实例化这个类并遍历数据样本。我们将打印前4个样本的尺寸，并显示它们的标注信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">face_dataset = FaceLandmarksDataset(csv_file=&apos;data/faces/face_landmarks.csv&apos;,</span><br><span class="line">                                    root_dir=&apos;data/faces/&apos;)</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">for i in range(len(face_dataset)):</span><br><span class="line">    sample = face_dataset[i]</span><br><span class="line"></span><br><span class="line">    print(i, sample[&apos;image&apos;].shape, sample[&apos;landmarks&apos;].shape)</span><br><span class="line"></span><br><span class="line">    ax = plt.subplot(1, 4, i + 1)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    ax.set_title(&apos;Sample #&#123;&#125;&apos;.format(i))</span><br><span class="line">    ax.axis(&apos;off&apos;)</span><br><span class="line">    show_landmarks(**sample)</span><br><span class="line"></span><br><span class="line">    if i == 3:</span><br><span class="line">        plt.show()</span><br><span class="line">        break</span><br></pre></td></tr></table></figure><p><img src="/imgs/pytorch-自定义数据集/sphx_glr_data_loading_tutorial_002.png" alt></p><p>输出</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0 (324, 215, 3) (68, 2)</span><br><span class="line">1 (500, 333, 3) (68, 2)</span><br><span class="line">2 (250, 258, 3) (68, 2)</span><br><span class="line">3 (434, 290, 3) (68, 2)</span><br></pre></td></tr></table></figure><h2 id="Transforms"><a href="#Transforms" class="headerlink" title="Transforms"></a>Transforms</h2><p>转换</p><blockquote><p>One issue we can see from the above is that the samples are not of the same size. Most neural networks expect the images of a fixed size. Therefore, we will need to write some prepocessing code. Let’s create three transforms:</p><ul><li>Rescale: to scale the image</li><li>RandomCrop: to crop from image randomly. This is data augmentation.</li><li>ToTensor: to convert the numpy images to torch images (we need to swap axes).</li></ul></blockquote><p>从上面我们可以看到的一个问题是样本的大小不同。大多数神经网络期望图像的大小是固定的。因此，我们需要编写一些预处理代码。让我们创建三个转换:</p><ul><li>Rescale：缩放图像</li><li>RandomCrop：随机裁剪。作用于数据扩充</li><li>ToTensor：转换numpy格式图像到torch格式</li></ul><blockquote><p>We will write them as callable classes instead of simple functions so that parameters of the transform need not be passed everytime it’s called. For this, we just need to implement <code>__call__</code> method and if required,<code>__init__</code> method. We can then use a transform like this:</p></blockquote><p>我们将把它们写成可调用的类，而不是简单的函数，这样就不需要每次调用时都传递转换的参数。为此，我们只需要实现<code>__call__</code>方法，如果需要的话，还可以实现<code>__init__</code>方法。然后我们可以使用如下转换:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tsfm = Transform(params)</span><br><span class="line">transformed_sample = tsfm(sample)</span><br></pre></td></tr></table></figure><blockquote><p>Observe below how these transforms had to be applied both on the image and landmarks.</p></blockquote><p>下面观察这些变换是如何应用于图像和标注信息的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">class Rescale(object):</span><br><span class="line">    &quot;&quot;&quot;Rescale the image in a sample to a given size.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        output_size (tuple or int): Desired output size. If tuple, output is</span><br><span class="line">            matched to output_size. If int, smaller of image edges is matched</span><br><span class="line">            to output_size keeping aspect ratio the same.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, output_size):</span><br><span class="line">        assert isinstance(output_size, (int, tuple))</span><br><span class="line">        self.output_size = output_size</span><br><span class="line"></span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        image, landmarks = sample[&apos;image&apos;], sample[&apos;landmarks&apos;]</span><br><span class="line"></span><br><span class="line">        h, w = image.shape[:2]</span><br><span class="line">        if isinstance(self.output_size, int):</span><br><span class="line">            if h &gt; w:</span><br><span class="line">                new_h, new_w = self.output_size * h / w, self.output_size</span><br><span class="line">            else:</span><br><span class="line">                new_h, new_w = self.output_size, self.output_size * w / h</span><br><span class="line">        else:</span><br><span class="line">            new_h, new_w = self.output_size</span><br><span class="line"></span><br><span class="line">        new_h, new_w = int(new_h), int(new_w)</span><br><span class="line"></span><br><span class="line">        img = transform.resize(image, (new_h, new_w))</span><br><span class="line"></span><br><span class="line">        # h and w are swapped for landmarks because for images,</span><br><span class="line">        # x and y axes are axis 1 and 0 respectively</span><br><span class="line">        landmarks = landmarks * [new_w / w, new_h / h]</span><br><span class="line"></span><br><span class="line">        return &#123;&apos;image&apos;: img, &apos;landmarks&apos;: landmarks&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class RandomCrop(object):</span><br><span class="line">    &quot;&quot;&quot;Crop randomly the image in a sample.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        output_size (tuple or int): Desired output size. If int, square crop</span><br><span class="line">            is made.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, output_size):</span><br><span class="line">        assert isinstance(output_size, (int, tuple))</span><br><span class="line">        if isinstance(output_size, int):</span><br><span class="line">            self.output_size = (output_size, output_size)</span><br><span class="line">        else:</span><br><span class="line">            assert len(output_size) == 2</span><br><span class="line">            self.output_size = output_size</span><br><span class="line"></span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        image, landmarks = sample[&apos;image&apos;], sample[&apos;landmarks&apos;]</span><br><span class="line"></span><br><span class="line">        h, w = image.shape[:2]</span><br><span class="line">        new_h, new_w = self.output_size</span><br><span class="line"></span><br><span class="line">        top = np.random.randint(0, h - new_h)</span><br><span class="line">        left = np.random.randint(0, w - new_w)</span><br><span class="line"></span><br><span class="line">        image = image[top: top + new_h,</span><br><span class="line">                      left: left + new_w]</span><br><span class="line"></span><br><span class="line">        landmarks = landmarks - [left, top]</span><br><span class="line"></span><br><span class="line">        return &#123;&apos;image&apos;: image, &apos;landmarks&apos;: landmarks&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ToTensor(object):</span><br><span class="line">    &quot;&quot;&quot;Convert ndarrays in sample to Tensors.&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        image, landmarks = sample[&apos;image&apos;], sample[&apos;landmarks&apos;]</span><br><span class="line"></span><br><span class="line">        # swap color axis because</span><br><span class="line">        # numpy image: H x W x C</span><br><span class="line">        # torch image: C X H X W</span><br><span class="line">        image = image.transpose((2, 0, 1))</span><br><span class="line">        return &#123;&apos;image&apos;: torch.from_numpy(image),</span><br><span class="line">                &apos;landmarks&apos;: torch.from_numpy(landmarks)&#125;</span><br></pre></td></tr></table></figure><h2 id="Compose-transforms"><a href="#Compose-transforms" class="headerlink" title="Compose transforms"></a>Compose transforms</h2><p>组合转换</p><blockquote><p>Now, we apply the transforms on a sample.</p></blockquote><p>现在将转换操作应用到样本中</p><blockquote><p>Let’s say we want to rescale the shorter side of the image to 256 and then randomly crop a square of size 224 from it. i.e, we want to compose Rescale and RandomCrop transforms. torchvision.transforms.Compose is a simple callable class which allows us to do this.</p></blockquote><p>假设我们想将图像的短边重新缩放到256，然后从中随机裁剪一个224大小的正方形。比如，我们想要组合Rescale和RandomCrop转换操作。可以通过torchvision.transforms.Compose实现</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">scale = Rescale(256)</span><br><span class="line">crop = RandomCrop(128)</span><br><span class="line">composed = transforms.Compose([Rescale(256),</span><br><span class="line">                               RandomCrop(224)])</span><br><span class="line"></span><br><span class="line"># Apply each of the above transforms on sample.</span><br><span class="line">fig = plt.figure()</span><br><span class="line">sample = face_dataset[65]</span><br><span class="line">for i, tsfrm in enumerate([scale, crop, composed]):</span><br><span class="line">    transformed_sample = tsfrm(sample)</span><br><span class="line"></span><br><span class="line">    ax = plt.subplot(1, 3, i + 1)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    ax.set_title(type(tsfrm).__name__)</span><br><span class="line">    show_landmarks(**transformed_sample)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/imgs/pytorch-自定义数据集/sphx_glr_data_loading_tutorial_003.png" alt></p><h2 id="Iterating-through-the-dataset"><a href="#Iterating-through-the-dataset" class="headerlink" title="Iterating through the dataset"></a>Iterating through the dataset</h2><p>数据集迭代</p><blockquote><p>Let’s put this all together to create a dataset with composed transforms. To summarize, every time this dataset is sampled:</p><ul><li>An image is read from the file on the fly</li><li>Transforms are applied on the read image</li><li>Since one of the transforms is random, data is augmentated on sampling</li></ul></blockquote><p>让我们把这些放在一起，创建一个具有组合转换的数据集。总而言之，每次对该数据集进行采样时:</p><ul><li>从文件中动态读取图像</li><li>对读取的图像应用变换</li><li>因为其中一个变换是随机的，所以数据在采样时被扩充了</li></ul><blockquote><p>We can iterate over the created dataset with a for i in range loop as before.</p></blockquote><p>之前我们可以通过for i in range方式来完成</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">transformed_dataset = FaceLandmarksDataset(csv_file=&apos;data/faces/face_landmarks.csv&apos;,</span><br><span class="line">                                           root_dir=&apos;data/faces/&apos;,</span><br><span class="line">                                           transform=transforms.Compose([</span><br><span class="line">                                               Rescale(256),</span><br><span class="line">                                               RandomCrop(224),</span><br><span class="line">                                               ToTensor()</span><br><span class="line">                                           ]))</span><br><span class="line"></span><br><span class="line">for i in range(len(transformed_dataset)):</span><br><span class="line">    sample = transformed_dataset[i]</span><br><span class="line"></span><br><span class="line">    print(i, sample[&apos;image&apos;].size(), sample[&apos;landmarks&apos;].size())</span><br><span class="line"></span><br><span class="line">    if i == 3:</span><br><span class="line">        break</span><br></pre></td></tr></table></figure><p>输出</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0 torch.Size([3, 224, 224]) torch.Size([68, 2])</span><br><span class="line">1 torch.Size([3, 224, 224]) torch.Size([68, 2])</span><br><span class="line">2 torch.Size([3, 224, 224]) torch.Size([68, 2])</span><br><span class="line">3 torch.Size([3, 224, 224]) torch.Size([68, 2])</span><br></pre></td></tr></table></figure><blockquote><p>However, we are losing a lot of features by using a simple for loop to iterate over the data. In particular, we are missing out on:</p><ul><li>Batching the data</li><li>Shuffling the data</li><li>Load the data in parallel using multiprocessing workers.</li></ul></blockquote><p>然而，通过使用一个简单的for循环来迭代数据会丢失很多特性。特别是我们错过了:</p><ul><li>批量处理数据</li><li>打乱数据</li><li>使用多处理器并行加载数据</li></ul><blockquote><p>torch.utils.data.DataLoader is an iterator which provides all these features. Parameters used below should be clear. One parameter of interest is collate_fn. You can specify how exactly the samples need to be batched using collate_fn. However, default collate should work fine for most use cases.</p></blockquote><p>torch.utils.data.DataLoader是一个迭代器，能够提供上述所有的特性。感兴趣的一个参数是collate_fn。您可以使用collate_fn指定如何批量化样本集，默认设置已经能够很好的作用于大多数情况了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">dataloader = DataLoader(transformed_dataset, batch_size=4,</span><br><span class="line">                        shuffle=True, num_workers=4)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Helper function to show a batch</span><br><span class="line">def show_landmarks_batch(sample_batched):</span><br><span class="line">    &quot;&quot;&quot;Show image with landmarks for a batch of samples.&quot;&quot;&quot;</span><br><span class="line">    images_batch, landmarks_batch = \</span><br><span class="line">            sample_batched[&apos;image&apos;], sample_batched[&apos;landmarks&apos;]</span><br><span class="line">    batch_size = len(images_batch)</span><br><span class="line">    im_size = images_batch.size(2)</span><br><span class="line">    grid_border_size = 2</span><br><span class="line"></span><br><span class="line">    grid = utils.make_grid(images_batch)</span><br><span class="line">    plt.imshow(grid.numpy().transpose((1, 2, 0)))</span><br><span class="line"></span><br><span class="line">    for i in range(batch_size):</span><br><span class="line">        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size + (i + 1) * grid_border_size,</span><br><span class="line">                    landmarks_batch[i, :, 1].numpy() + grid_border_size,</span><br><span class="line">                    s=10, marker=&apos;.&apos;, c=&apos;r&apos;)</span><br><span class="line"></span><br><span class="line">        plt.title(&apos;Batch from dataloader&apos;)</span><br><span class="line"></span><br><span class="line">for i_batch, sample_batched in enumerate(dataloader):</span><br><span class="line">    print(i_batch, sample_batched[&apos;image&apos;].size(),</span><br><span class="line">          sample_batched[&apos;landmarks&apos;].size())</span><br><span class="line"></span><br><span class="line">    # observe 4th batch and stop.</span><br><span class="line">    if i_batch == 3:</span><br><span class="line">        plt.figure()</span><br><span class="line">        show_landmarks_batch(sample_batched)</span><br><span class="line">        plt.axis(&apos;off&apos;)</span><br><span class="line">        plt.ioff()</span><br><span class="line">        plt.show()</span><br><span class="line">        break</span><br></pre></td></tr></table></figure><p><img src="/imgs/pytorch-自定义数据集/sphx_glr_data_loading_tutorial_004.png" alt></p><p>输出</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])</span><br><span class="line">1 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])</span><br><span class="line">2 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])</span><br><span class="line">3 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])</span><br></pre></td></tr></table></figure><h2 id="Afterword-torchvision"><a href="#Afterword-torchvision" class="headerlink" title="Afterword: torchvision"></a>Afterword: torchvision</h2><p>后记：torchvision</p><blockquote><p>In this tutorial, we have seen how to write and use datasets, transforms and dataloader. torchvision package provides some common datasets and transforms. You might not even have to write custom classes. One of the more generic datasets available in torchvision is ImageFolder. It assumes that images are organized in the following way:</p></blockquote><p>在本教程中，我们已经看到了如何编写和使用数据集、转换和数据加载器。torchvision包提供了一些常见的数据集和转换。你甚至不必编写自定义类。在torchvision中最通用的数据集之一是ImageFolder。它假设图像以下列方式组织:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root/ants/xxx.png</span><br><span class="line">root/ants/xxy.jpeg</span><br><span class="line">root/ants/xxz.png</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">root/bees/123.jpg</span><br><span class="line">root/bees/nsdf3.png</span><br><span class="line">root/bees/asd932_.png</span><br></pre></td></tr></table></figure><blockquote><p>where ‘ants’, ‘bees’ etc. are class labels. Similarly generic transforms which operate on PIL.Image like RandomHorizontalFlip, Scale, are also available. You can use these to write a dataloader like this:</p></blockquote><p>其中<code>ants</code>、<code>bees</code>是类标签。里面集成了通用的转换操作，比如RandomHorizontalFlip/Scale等等。您可以使用这些来编写如下数据加载器:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torchvision import transforms, datasets</span><br><span class="line"></span><br><span class="line">data_transform = transforms.Compose([</span><br><span class="line">        transforms.RandomSizedCrop(224),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=[0.485, 0.456, 0.406],</span><br><span class="line">                             std=[0.229, 0.224, 0.225])</span><br><span class="line">    ])</span><br><span class="line">hymenoptera_dataset = datasets.ImageFolder(root=&apos;hymenoptera_data/train&apos;,</span><br><span class="line">                                           transform=data_transform)</span><br><span class="line">dataset_loader = torch.utils.data.DataLoader(hymenoptera_dataset,</span><br><span class="line">                                             batch_size=4, shuffle=True,</span><br><span class="line">                                             num_workers=4)</span><br></pre></td></tr></table></figure></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';"> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/images/wechatpay.jpg" alt="zhujian 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/images/alipay.jpg" alt="zhujian 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zhujian</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zhujian.tech/posts/aa0415d3.html" title="[译]Writing Custom Datasets, DataLoaders and Transforms">https://www.zhujian.tech/posts/aa0415d3.html</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/python/" rel="tag"># python</a> <a href="/tags/pytorch/" rel="tag"># pytorch</a> <a href="/tags/torchvision/" rel="tag"># torchvision</a> <a href="/tags/numpy/" rel="tag"># numpy</a> <a href="/tags/matplotlib/" rel="tag"># matplotlib</a> <a href="/tags/pandas/" rel="tag"># pandas</a> <a href="/tags/skimage/" rel="tag"># skimage</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/posts/5a56cd45.html" rel="next" title="[数据集]PASCAL VOC 2007"><i class="fa fa-chevron-left"></i> [数据集]PASCAL VOC 2007</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/posts/631c599a.html" rel="prev" title="[数据集]Fashion-MNIST">[数据集]Fashion-MNIST<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div><div class="comments" id="gitalk-container"></div></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Dataset-Class"><span class="nav-number">1.</span> <span class="nav-text">Dataset Class</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Transforms"><span class="nav-number">2.</span> <span class="nav-text">Transforms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Compose-transforms"><span class="nav-number">3.</span> <span class="nav-text">Compose transforms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Iterating-through-the-dataset"><span class="nav-number">4.</span> <span class="nav-text">Iterating through the dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Afterword-torchvision"><span class="nav-number">5.</span> <span class="nav-text">Afterword: torchvision</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zhujian" src="/images/avatar.png"><p class="site-author-name" itemprop="name">zhujian</p><div class="site-description" itemprop="description">one bite at a time</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">169</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">48</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">129</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="feed-link motion-element"><a href="/./atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zjZSTU" title="Github &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;zjZSTU" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/u012005313" title="CSDN &amp;rarr; https:&#x2F;&#x2F;blog.csdn.net&#x2F;u012005313" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i> CSDN</a></span><span class="links-of-author-item"><a href="/mailto:zjzstu@gmail.com" title="Gmail &amp;rarr; mailto:zjzstu@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> Gmail</a></span><span class="links-of-author-item"><a href="/mailto:505169307@gmail.com" title="QQmail &amp;rarr; mailto:505169307@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> QQmail</a></span></div><div class="cc-license motion-element" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://cloud.tencent.com/" title="https:&#x2F;&#x2F;cloud.tencent.com" rel="noopener" target="_blank">腾讯云</a></li><li class="links-of-blogroll-item"> <a href="https://www.aliyun.com/" title="https:&#x2F;&#x2F;www.aliyun.com" rel="noopener" target="_blank">阿里云</a></li><li class="links-of-blogroll-item"> <a href="https://developer.android.com/" title="https:&#x2F;&#x2F;developer.android.com&#x2F;" rel="noopener" target="_blank">Android Dev</a></li><li class="links-of-blogroll-item"> <a href="https://jenkins.io/" title="https:&#x2F;&#x2F;jenkins.io&#x2F;" rel="noopener" target="_blank">Jenkins</a></li><li class="links-of-blogroll-item"> <a href="http://cs231n.github.io/" title="http:&#x2F;&#x2F;cs231n.github.io&#x2F;" rel="noopener" target="_blank">cs231n</a></li><li class="links-of-blogroll-item"> <a href="https://pytorch.org/docs/stable/index.html" title="https:&#x2F;&#x2F;pytorch.org&#x2F;docs&#x2F;stable&#x2F;index.html" rel="noopener" target="_blank">pytorch</a></li><li class="links-of-blogroll-item"> <a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/" title="https:&#x2F;&#x2F;docs.docker.com&#x2F;install&#x2F;linux&#x2F;docker-ce&#x2F;ubuntu&#x2F;" rel="noopener" target="_blank">docker</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2020</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">zhujian</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span> <span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">948k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">26:20</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-bar-chart-o"></i></span> <a href="https://tongji.baidu.com/web/27249108/overview/index?siteId=13647183" rel="noopener" target="_blank">百度统计</a></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0</div> <span class="post-meta-divider">|</span><div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.5.0</div><div class="beian"> <a href="http://www.beian.miit.gov.cn/" rel="noopener" target="_blank">浙ICP备 19026415号</a> <span class="post-meta-divider">|</span> <img src="/images/beian_icon.png" style="display:inline-block;text-decoration:none;height:13px"> <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33011802001748" rel="noopener" target="_blank">浙公网安备 33011802001748号</a></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span> <span class="site-uv" title="总访客量">访客数：<span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="site-pv" title="总访问量">阅读量：<span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script color="17,63,61" opacity="1" zindex="-1" count="199" src="/lib/canvas-nest/canvas-nest.min.js"></script><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '8f22595c6dd29c94467d',
      clientSecret: 'e66bd90ebb9aa66c562c753dec6c90ceecbd51f2',
      repo: 'guestbook',
      owner: 'zjZSTU',
      admin: ['zjZSTU'],
      id: 'd30e9e02ffdcd715b1719662cb4fd77d',
        language: '',
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script></body></html>