<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.0.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="alternate" href="/./atom.xml" title="做一个幸福的人" type="application/atom+xml"><meta name="google-site-verification" content="Qr_3yqLtyErDFKHW7mE8PJz4qDUX-bf_fMLpSRckQe4"><meta name="baidu-site-verification" content="zOwIvKMV7f"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Roboto:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="/lib/pace/pace-theme-center-atom.min.css"><script src="/lib/pace/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"7.5.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!1,pangu:!1,algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"搜索文章",hits_empty:"我们没有找到任何搜索结果: ${query}",hits_stats:"找到约${hits}条结果（用时${time}ms）"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},translation:{copy_button:"复制",copy_success:"复制成功",copy_failure:"复制失败"},sidebarPadding:40}</script><link href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap" rel="stylesheet"><meta name="description" content="参考：Understanding AlexNetAlexNet在ImageNet LSVRC-2010的1000类分类比赛上实现了37.5% top-1和17.0% top-5的最小误差率，在LSVRC-2012上实现了15.3% top-5的最小误差率，这些数据是当时最好的识别结果，其实现代码也在google code上公开：cuda-convnet"><meta name="keywords" content="AlexNet"><meta property="og:type" content="article"><meta property="og:title" content="AlexNet"><meta property="og:url" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;posts&#x2F;ca9994d1.html"><meta property="og:site_name" content="做一个幸福的人"><meta property="og:description" content="参考：Understanding AlexNetAlexNet在ImageNet LSVRC-2010的1000类分类比赛上实现了37.5% top-1和17.0% top-5的最小误差率，在LSVRC-2012上实现了15.3% top-5的最小误差率，这些数据是当时最好的识别结果，其实现代码也在google code上公开：cuda-convnet"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;AlexNet&#x2F;AlexNet.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;AlexNet&#x2F;relu.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;AlexNet&#x2F;lrn.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;AlexNet&#x2F;pca.png"><meta property="og:updated_time" content="2020-02-15T05:36:35.867Z"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;AlexNet&#x2F;AlexNet.png"><link rel="canonical" href="https://www.zhujian.tech/posts/ca9994d1.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,isPage:!1,isArchive:!1}</script><title>AlexNet | 做一个幸福的人</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?e677aac1ac69b8826b9cfecb4e72e107";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">做一个幸福的人</span><span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">面朝大海，春暖花开</p></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i> 标签<span class="badge">129</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i> 分类<span class="badge">48</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i> 归档<span class="badge">169</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header> <a href="https://github.com/zjZSTU" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zhujian.tech/posts/ca9994d1.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.png"><meta itemprop="name" content="zhujian"><meta itemprop="description" content="one bite at a time"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="做一个幸福的人"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> AlexNet</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-06-08 10:53:31" itemprop="dateCreated datePublished" datetime="2019-06-08T10:53:31+00:00">2019-06-08</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-02-15 05:36:35" itemprop="dateModified" datetime="2020-02-15T05:36:35+00:00">2020-02-15</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/algorithm/" itemprop="url" rel="index"><span itemprop="name">算法</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/algorithm/deep-learning/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>4k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>7 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>参考：<a href="https://www.learnopencv.com/understanding-alexnet/" target="_blank" rel="noopener">Understanding AlexNet</a></p><p><code>AlexNet</code>在<code>ImageNet LSVRC-2010</code>的<code>1000</code>类分类比赛上实现了<code>37.5% top-1</code>和<code>17.0% top-5</code>的最小误差率，在<code>LSVRC-2012</code>上实现了<code>15.3% top-5</code>的最小误差率，这些数据是当时最好的识别结果，其实现代码也在<code>google code</code>上公开：<a href="https://code.google.com/archive/p/cuda-convnet/" target="_blank" rel="noopener">cuda-convnet</a></p><a id="more"></a><p>本文学习<code>AlexNet</code>网络结构及其训练方法</p><h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p><code>AlexNet</code>除了减去均值以外，没有执行任何预处理操作</p><h2 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h2><p>首先介绍最初的双<code>GPU AlexNet</code>架构，再介绍单<code>GPU</code>的<code>AlexNet</code>架构</p><h3 id="双GPU-AlexNet"><a href="#双GPU-AlexNet" class="headerlink" title="双GPU AlexNet"></a>双GPU AlexNet</h3><p>在文章<a href="http://xueshu.baidu.com/usercenter/paper/show?paperid=bfdf67dfdf8cea0c47038f63e91b9df1&amp;site=xueshu_se" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a>中，<code>AlexNet</code>使用双<code>GPU</code>进行训练，其结构如下所示：</p><p><img src="/imgs/AlexNet/AlexNet.png" alt></p><p><code>AlexNet</code>包含<code>8</code>个可学习层：<code>5</code>个卷积层 + <code>3</code>个全连接层组成</p><ul><li>第二/四/五个卷积层的核仅与同一GPU的前一层进行连接</li><li>第三个卷积层的核与第二层全部连接</li><li>全连接层的核与前一层全部连接</li><li>局部归一化层跟随在第一二个卷积层后</li><li>重叠池化层跟随在局部归一化层后以及第<code>5</code>个卷积层后</li><li>第三、第四和第五个卷积层直接连接</li><li>卷积层和全连接层都使用<code>ReLU</code>作为激活函数</li></ul><h3 id="单GPU-AlexNet"><a href="#单GPU-AlexNet" class="headerlink" title="单GPU AlexNet"></a>单GPU AlexNet</h3><p><strong>单<code>GPU</code>训练的<code>AlexNet</code>模型如下（<em>已去除LRN</em>）：</strong></p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">输入大小</th><th style="text-align:center">滤波器大小</th><th style="text-align:center">步长</th><th style="text-align:center">零填充</th><th style="text-align:center">滤波器个数</th><th style="text-align:center">输出大小</th></tr></thead><tbody><tr><td style="text-align:center">CONV1</td><td style="text-align:center">227x227x3</td><td style="text-align:center">11x11x3</td><td style="text-align:center">4</td><td style="text-align:center">0</td><td style="text-align:center">96</td><td style="text-align:center">55x55x96</td></tr><tr><td style="text-align:center">POOL2</td><td style="text-align:center">55x55x96</td><td style="text-align:center">3x3</td><td style="text-align:center">2</td><td style="text-align:center">/</td><td style="text-align:center">96</td><td style="text-align:center">27x27x96</td></tr><tr><td style="text-align:center">CONV3</td><td style="text-align:center">27x27x96</td><td style="text-align:center">5x5x96</td><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">256</td><td style="text-align:center">27x27x256</td></tr><tr><td style="text-align:center">POOL4</td><td style="text-align:center">27x27x256</td><td style="text-align:center">3x3</td><td style="text-align:center">2</td><td style="text-align:center">/</td><td style="text-align:center">256</td><td style="text-align:center">13x13x256</td></tr><tr><td style="text-align:center">CONV5</td><td style="text-align:center">13x13x256</td><td style="text-align:center">3x3x256</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">384</td><td style="text-align:center">13x13x384</td></tr><tr><td style="text-align:center">CONV6</td><td style="text-align:center">13x13x384</td><td style="text-align:center">3x3x384</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">384</td><td style="text-align:center">13x13x384</td></tr><tr><td style="text-align:center">CONV7</td><td style="text-align:center">13x13x384</td><td style="text-align:center">3x3x384</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">256</td><td style="text-align:center">13x13x256</td></tr><tr><td style="text-align:center">POOL8</td><td style="text-align:center">13x13x256</td><td style="text-align:center">3x3</td><td style="text-align:center">2</td><td style="text-align:center">/</td><td style="text-align:center">256</td><td style="text-align:center">6x6x256</td></tr><tr><td style="text-align:center">FC9</td><td style="text-align:center">1x1x9216</td><td style="text-align:center">1x1</td><td style="text-align:center">/</td><td style="text-align:center">/</td><td style="text-align:center">4096</td><td style="text-align:center">1x1x4096</td></tr><tr><td style="text-align:center">FC10</td><td style="text-align:center">1x1x4096</td><td style="text-align:center">1x1</td><td style="text-align:center">/</td><td style="text-align:center">/</td><td style="text-align:center">4096</td><td style="text-align:center">1x1x4096</td></tr><tr><td style="text-align:center">FC11</td><td style="text-align:center">1x1x4096</td><td style="text-align:center">1x1</td><td style="text-align:center">/</td><td style="text-align:center">/</td><td style="text-align:center">1000</td><td style="text-align:center">1x1x1000</td></tr></tbody></table></div><h3 id="224还是227"><a href="#224还是227" class="headerlink" title="224还是227"></a><code>224</code>还是<code>227</code></h3><p>在原文中作者输入图像大小为<code>224x224</code>，不过经过推算不符合网络计算，应该使用<code>227x227</code>作为输入图像大小</p><h3 id="神经元和参数个数"><a href="#神经元和参数个数" class="headerlink" title="神经元和参数个数"></a>神经元和参数个数</h3><p>参考：</p><p><a href="https://vimsky.com/article/3664.html" target="_blank" rel="noopener">AlexNet中的参数数量</a></p><p><a href="https://stackoverflow.com/questions/40060949/how-to-calculate-the-number-of-parameters-of-alexnet" target="_blank" rel="noopener">How to calculate the number of parameters of AlexNet?</a></p><p>整个网络约有<code>6</code>千万个参数和<code>65</code>万个神经元，计算如下：</p><ul><li><p>输入层大小<code>227x227x3</code>，输入维数是<code>15,4587</code></p></li><li><p>第一层卷积层卷积核大小为<code>11x11x3</code>，步长<code>4</code>，滤波器个数<code>96</code>，所以参数个数是<code>(11x11x3)x96+96=3,4944</code>，输出大小为<code>55x55x96=29,0400</code></p><ul><li>池化层滤波器大小为<code>3x3</code>，步长<code>2</code>，所以输出大小为<code>27x27x96</code></li></ul></li><li><p>第二层卷积层卷积核大小为<code>5x5x96</code>，零填充<code>2</code>，滤波器个数<code>256</code>，所以参数个数是<code>(5x5x96)x256+256=61,4656</code>，输出大小为<code>27x27x256=18,6624</code></p><ul><li>池化层滤波器大小为<code>3x3</code>，步长<code>2</code>，所以输出大小为<code>13x13x256</code></li></ul></li><li><p>第三层卷积层卷积核大小为<code>3x3x256</code>，零填充<code>1</code>，滤波器个数是<code>384</code>个，所以参数个数是<code>(3x3x256)x384+384=88,5120</code>，输出大小为<code>13x13x384=6,4896</code></p></li><li><p>第四层卷积层卷积核大小为<code>3x3x384</code>，零填充<code>1</code>，滤波器个数是<code>384</code>个，所以参数个数是<code>(3x3x384)x384+384=132,7488</code>，输出大小为<code>13x13x384=6,4896</code></p></li><li><p>第五层卷积层卷积核大小为<code>3x3x384</code>，零填充<code>1</code>，滤波器个数是<code>256</code>，所以参数个数是<code>(3x3x384)x256+256=88,4992</code>，输出大小为<code>13x13x256=4,3264</code></p><ul><li>池化层滤波器大小为<code>3x3</code>，步长<code>2</code>，所以输出大小为<code>6x6x256</code></li></ul></li><li><p>第一层全连接层大小为<code>4096</code>，所以参数个数是<code>(6x6x256)x4096+4096=3775,2832</code>，输出大小为<code>4096</code></p></li><li><p>第二层全连接层大小为<code>4096</code>，所以参数个数是<code>4096x4096+4096=1678,1312</code>，输出大小为<code>4096</code></p></li><li><p>输出层大小为<code>1000</code>，所以参数个数是<code>4096x1000+1000=409,7000</code></p></li></ul><p>神经元总个数是<code>15,4587+29,0400+18,6624+6,4896+6,4896+4,3264+4096+4096+1000=81,3859</code>（<em>不包括输入层就是<code>65,9272</code></em>）</p><p>参数总个数是<code>3,4944+61,4656+88,5120+132,7488+88,4992+3775,2832+1678,1312+409,7000=6237,8344</code></p><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><p>主要有<code>4</code>点：</p><ol><li>使用<code>ReLU</code>作为激活函数提高训练速度</li><li>多<code>GPU</code>训练</li><li>使用局部响应归一化(<code>LRN</code>)方法增加泛化能力</li><li>使用重叠池化层（<code>Overlapping Pool</code>）提高泛化能力</li></ol><h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p>之前标准的激活函数是<code>tanh()</code>和<code>sigmoid()</code>函数，文章中使用<code>ReLU(Rectified Linear Units，修正线性单元)</code>作为神经元激活函数</p><p>使用4层卷积神经网络训练<code>CIFAR-10</code>数据集，比较达到<code>25%</code>训练误差率的时间，使用<code>ReLU</code>能够比<code>tanh</code>快<code>6</code>倍</p><p><img src="/imgs/AlexNet/relu.png" alt></p><h3 id="多GPU训练"><a href="#多GPU训练" class="headerlink" title="多GPU训练"></a>多GPU训练</h3><p><code>AlexNet</code>使用两块<code>GTX 580 GPU</code>，在深度上进行切分，将每层一半神经元分别放置在不同<code>GPU</code>上进行训练</p><h3 id="局部响应归一化"><a href="#局部响应归一化" class="headerlink" title="局部响应归一化"></a>局部响应归一化</h3><p>参考：<a href="https://cloud.tencent.com/developer/article/1347792" target="_blank" rel="noopener">深度学习: 局部响应归一化 (Local Response Normalization，LRN)</a></p><p>数学实现如下：</p><p><img src="/imgs/AlexNet/lrn.png" alt></p><p>经过<code>ReLU</code>激活后的卷积图，第i层上的位置为<code>(x,y)</code>的神经元值<code>a</code>，需要除以其相邻<code>n</code>个层相同位置的神经元值之和。常量k，n，$\alpha$，$\beta$都是超参数，需要通过验证集设定，当前设定为$k=2，n=5，\alpha=10^{-4}，beta=0.75$</p><p>其目的是<strong>实现神经元的侧抑制</strong>（<code>lateral inhibition</code>），在不同层之间进行竞争，使响应值大的神经元变得更大，并抑制其他较小的神经元</p><p><code>LRN（Local Response Normalization，局部响应归一化）</code>能够提高泛化能力：在<code>ImageNet 1000</code>类分类任务中，<code>LRN</code>减少了<code>1.4% top-1</code>和<code>1.2% top5</code>的错误率；在<code>cifar-10</code>数据集测试中，一个<code>4</code>层神经网络能达到<code>13%</code>测试误差率（没有<code>LRN</code>）和<code>11%</code>测试误差率（有<code>LRN</code>）</p><p><strong><em>在之后其他网络的测试中发现<code>LRN</code>对训练结果提高几乎没有影响，所以不再使用</em></strong></p><h3 id="重叠池化层"><a href="#重叠池化层" class="headerlink" title="重叠池化层"></a>重叠池化层</h3><p>传统的池化层步长和滤波器大小相同（<code>s=z=2</code>），所以滤波器操作不会重叠</p><p><code>alexnet</code>使用重叠池化（<code>Overlapping Pool</code>）操作，步长小于滤波器大小（<code>s=2,x=3,s&lt;z</code>），这在<code>1000</code>类分类任务上能够实现<code>0.4% top-1</code>和<code>0.3% top-5</code>的提高。在训练过程中能够发现重叠池化模型更难以过拟合</p><h2 id="避免过拟合手段"><a href="#避免过拟合手段" class="headerlink" title="避免过拟合手段"></a>避免过拟合手段</h2><ol><li>数据扩充（<code>data augmentation</code>）</li><li>随机失活（<code>dropout</code>）</li></ol><h3 id="数据扩充"><a href="#数据扩充" class="headerlink" title="数据扩充"></a>数据扩充</h3><p>文章中提到了两种方式</p><p>第一种方式是生成图像转换和水平映射。在训练阶段，获取<code>256x256</code>大小的数据集，再从中随机获取<code>227x227</code>大小的训练图像，同时通过水平映像(<code>horizontal reflection</code>)操作来扩大数据集；在测试阶段，使用同样方式裁剪5个$227\times 227$大小图像，并进行水平翻转，平均这10个图像预测结果作为输出</p><p>第二种方式是改变训练数据的通道强度，对于每个<code>RGB</code>图像像素$I_{xy}=[I_{xy}^{B},I_{xy}^{G},I_{xy}^{B}]^{T}$，添加如下值：</p><p><img src="/imgs/AlexNet/pca.png" alt></p><p>其中$p_{i}$是第i个特征向量（<code>eigenvector</code>），$\lambda_{i}$是RGB像素值3x3协方差矩阵（<code>covariance matrix</code>）的特征值，$\alpha_{i}$是符合零均值(<code>mean zero</code>)和<code>0.1</code>标准方差(<code>standard deviation</code>)的服从高斯分布的随机变量，特定训练图像上的每个像素使用的$\alpha_{i}$都不相同，再次训练时需要重新设置$\alpha_{i}$</p><p>使用<code>PCA</code>改变图像强度的理论基础是自然图像的一个重要特性：物体同一性不随照明强度和颜色的变化而变化</p><p>这种方法减少了至少<code>1% top-1</code>误差率</p><h3 id="随机失活"><a href="#随机失活" class="headerlink" title="随机失活"></a>随机失活</h3><p>集合不同网络模型进行预测能够很好的减少测试误差，但是对于大网络而言需要耗费很多时间进行训练。随机失活（<code>dropout</code>）操作对中间隐含层进行操作，以<code>0.5</code>的概率判断该神经元是否失效，即这个神经元不进行前向操作，也不进行反向更新</p><p>有两点优势：</p><ol><li>每次进行训练都是在不同的网络架构上，与此同时这些不同的网络架构共享同一套权重</li><li>减少神经元复杂的共适应性（<code>co-adaptation</code>），神经元不能依赖于某个特定的神经元</li></ol><p>在测试阶段，对所有神经元的输出都乘以<code>0.5</code>，以获取指数多个<code>dropout</code>网络产生的预测分布的几何平均值</p><p><strong>在<code>alexnet</code>模型中，对前两个全连接层进行<code>dropout</code>操作</strong>。如果没有<code>dropout</code>，整个网络会严重过拟合，并且训练过程达到收敛的时间大致增加了一倍</p><h2 id="学习细节"><a href="#学习细节" class="headerlink" title="学习细节"></a>学习细节</h2><p>批量大小为<code>128</code>，使用动量值为<code>0.9</code>，权重衰减率为<code>5e-4</code>，权重更新公式如下：</p><script type="math/tex;mode=display">
v_{i+1} = 0.9\cdot v_{i} - 0.0005\cdot lr\cdot w_{i} - lr \triangledown w_{i}\\
w_{i+1} = w_{i} + v_{i+1}</script><p>权重初始化为<code>0</code>均值，<code>0.01</code>标准差的高斯分布</p><p>第二、第四、第五个卷积层层和全连接层的偏置值初始化为$1$，其他层的偏置值初始化为$0$</p><p>学习率初始化为<code>0.01</code>，在终止之前共减少了<code>3</code>次</p></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';"> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/images/wechatpay.jpg" alt="zhujian 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/images/alipay.jpg" alt="zhujian 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zhujian</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zhujian.tech/posts/ca9994d1.html" title="AlexNet">https://www.zhujian.tech/posts/ca9994d1.html</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/AlexNet/" rel="tag"># AlexNet</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/posts/2bee4fce.html" rel="next" title="随机失活-pytorch"><i class="fa fa-chevron-left"></i> 随机失活-pytorch</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/posts/ba337bfa.html" rel="prev" title="AlexNet-pytorch">AlexNet-pytorch<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div><div class="comments" id="gitalk-container"></div></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#预处理"><span class="nav-number">1.</span> <span class="nav-text">预处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网络架构"><span class="nav-number">2.</span> <span class="nav-text">网络架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#双GPU-AlexNet"><span class="nav-number">2.1.</span> <span class="nav-text">双GPU AlexNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#单GPU-AlexNet"><span class="nav-number">2.2.</span> <span class="nav-text">单GPU AlexNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#224还是227"><span class="nav-number">2.3.</span> <span class="nav-text">224还是227</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#神经元和参数个数"><span class="nav-number">2.4.</span> <span class="nav-text">神经元和参数个数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#特性"><span class="nav-number">3.</span> <span class="nav-text">特性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ReLU"><span class="nav-number">3.1.</span> <span class="nav-text">ReLU</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多GPU训练"><span class="nav-number">3.2.</span> <span class="nav-text">多GPU训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#局部响应归一化"><span class="nav-number">3.3.</span> <span class="nav-text">局部响应归一化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#重叠池化层"><span class="nav-number">3.4.</span> <span class="nav-text">重叠池化层</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#避免过拟合手段"><span class="nav-number">4.</span> <span class="nav-text">避免过拟合手段</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#数据扩充"><span class="nav-number">4.1.</span> <span class="nav-text">数据扩充</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#随机失活"><span class="nav-number">4.2.</span> <span class="nav-text">随机失活</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#学习细节"><span class="nav-number">5.</span> <span class="nav-text">学习细节</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zhujian" src="/images/avatar.png"><p class="site-author-name" itemprop="name">zhujian</p><div class="site-description" itemprop="description">one bite at a time</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">169</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">48</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">129</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="feed-link motion-element"><a href="/./atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zjZSTU" title="Github &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;zjZSTU" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/u012005313" title="CSDN &amp;rarr; https:&#x2F;&#x2F;blog.csdn.net&#x2F;u012005313" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i> CSDN</a></span><span class="links-of-author-item"><a href="/mailto:zjzstu@gmail.com" title="Gmail &amp;rarr; mailto:zjzstu@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> Gmail</a></span><span class="links-of-author-item"><a href="/mailto:505169307@gmail.com" title="QQmail &amp;rarr; mailto:505169307@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> QQmail</a></span></div><div class="cc-license motion-element" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://cloud.tencent.com/" title="https:&#x2F;&#x2F;cloud.tencent.com" rel="noopener" target="_blank">腾讯云</a></li><li class="links-of-blogroll-item"> <a href="https://www.aliyun.com/" title="https:&#x2F;&#x2F;www.aliyun.com" rel="noopener" target="_blank">阿里云</a></li><li class="links-of-blogroll-item"> <a href="https://developer.android.com/" title="https:&#x2F;&#x2F;developer.android.com&#x2F;" rel="noopener" target="_blank">Android Dev</a></li><li class="links-of-blogroll-item"> <a href="https://jenkins.io/" title="https:&#x2F;&#x2F;jenkins.io&#x2F;" rel="noopener" target="_blank">Jenkins</a></li><li class="links-of-blogroll-item"> <a href="http://cs231n.github.io/" title="http:&#x2F;&#x2F;cs231n.github.io&#x2F;" rel="noopener" target="_blank">cs231n</a></li><li class="links-of-blogroll-item"> <a href="https://pytorch.org/docs/stable/index.html" title="https:&#x2F;&#x2F;pytorch.org&#x2F;docs&#x2F;stable&#x2F;index.html" rel="noopener" target="_blank">pytorch</a></li><li class="links-of-blogroll-item"> <a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/" title="https:&#x2F;&#x2F;docs.docker.com&#x2F;install&#x2F;linux&#x2F;docker-ce&#x2F;ubuntu&#x2F;" rel="noopener" target="_blank">docker</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2020</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">zhujian</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span> <span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">948k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">26:20</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-bar-chart-o"></i></span> <a href="https://tongji.baidu.com/web/27249108/overview/index?siteId=13647183" rel="noopener" target="_blank">百度统计</a></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0</div> <span class="post-meta-divider">|</span><div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.5.0</div><div class="beian"> <a href="http://www.beian.miit.gov.cn/" rel="noopener" target="_blank">浙ICP备 19026415号</a> <span class="post-meta-divider">|</span> <img src="/images/beian_icon.png" style="display:inline-block;text-decoration:none;height:13px"> <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33011802001748" rel="noopener" target="_blank">浙公网安备 33011802001748号</a></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span> <span class="site-uv" title="总访客量">访客数：<span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="site-pv" title="总访问量">阅读量：<span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script color="17,63,61" opacity="1" zindex="-1" count="199" src="/lib/canvas-nest/canvas-nest.min.js"></script><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '8f22595c6dd29c94467d',
      clientSecret: 'e66bd90ebb9aa66c562c753dec6c90ceecbd51f2',
      repo: 'guestbook',
      owner: 'zjZSTU',
      admin: ['zjZSTU'],
      id: '0548262b4f669603e9f8f39899d17f1b',
        language: '',
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script></body></html>