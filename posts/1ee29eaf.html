<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.0.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="alternate" href="/./atom.xml" title="做一个幸福的人" type="application/atom+xml"><meta name="google-site-verification" content="Qr_3yqLtyErDFKHW7mE8PJz4qDUX-bf_fMLpSRckQe4"><meta name="baidu-site-verification" content="zOwIvKMV7f"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Roboto:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="/lib/pace/pace-theme-center-atom.min.css"><script src="/lib/pace/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"7.5.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!1,pangu:!1,algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"搜索文章",hits_empty:"我们没有找到任何搜索结果: ${query}",hits_stats:"找到约${hits}条结果（用时${time}ms）"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},translation:{copy_button:"复制",copy_success:"复制成功",copy_failure:"复制失败"},sidebarPadding:40}</script><link href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap" rel="stylesheet"><meta name="description" content="参考：Image Classification: Data-driven Approach, k-Nearest Neighbor, train&#x2F;val&#x2F;test splits"><meta name="keywords" content="python,K近邻,numpy,matplotlib,sklearn,pandas"><meta property="og:type" content="article"><meta property="og:title" content="KNN分类器"><meta property="og:url" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;posts&#x2F;1ee29eaf.html"><meta property="og:site_name" content="做一个幸福的人"><meta property="og:description" content="参考：Image Classification: Data-driven Approach, k-Nearest Neighbor, train&#x2F;val&#x2F;test splits"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;KNN&#x2F;iris.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;KNN&#x2F;german_data.png"><meta property="og:updated_time" content="2020-02-15T05:36:35.871Z"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;KNN&#x2F;iris.png"><link rel="canonical" href="https://www.zhujian.tech/posts/1ee29eaf.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,isPage:!1,isArchive:!1}</script><title>KNN分类器 | 做一个幸福的人</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?e677aac1ac69b8826b9cfecb4e72e107";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">做一个幸福的人</span><span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">面朝大海，春暖花开</p></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i> 标签<span class="badge">129</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i> 分类<span class="badge">48</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i> 归档<span class="badge">169</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header> <a href="https://github.com/zjZSTU" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zhujian.tech/posts/1ee29eaf.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.png"><meta itemprop="name" content="zhujian"><meta itemprop="description" content="one bite at a time"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="做一个幸福的人"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> KNN分类器</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-07-11 19:34:29" itemprop="dateCreated datePublished" datetime="2019-07-11T19:34:29+00:00">2019-07-11</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-02-15 05:36:35" itemprop="dateModified" datetime="2020-02-15T05:36:35+00:00">2020-02-15</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/algorithm/" itemprop="url" rel="index"><span itemprop="name">算法</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programming/" itemprop="url" rel="index"><span itemprop="name">编程</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programming/programming-language/" itemprop="url" rel="index"><span itemprop="name">编程语言</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/algorithm/data-learning/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programming/codebase/" itemprop="url" rel="index"><span itemprop="name">代码库</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/algorithm/classifier/" itemprop="url" rel="index"><span itemprop="name">分类器</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>8.9k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>15 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>参考：</p><p><a href="http://cs231n.github.io/classification/" target="_blank" rel="noopener">Image Classification: Data-driven Approach, k-Nearest Neighbor, train/val/test splits</a></p><a id="more"></a><p>最近重温<code>cs231n</code>课程，完成了课堂作业<a href="http://cs231n.github.io/assignments2019/assignment1/" target="_blank" rel="noopener">assignment1</a>，记录一下<code>KNN</code>分类器相关的概念以及实现，包括通用的分类器训练及测试过程</p><h2 id="什么是KNN分类器"><a href="#什么是KNN分类器" class="headerlink" title="什么是KNN分类器"></a>什么是KNN分类器</h2><p>参考：<a href="https://www.devtalking.com/articles/machine-learning-11/" target="_blank" rel="noopener">机器学习笔记十一之决策边界</a></p><p><code>KNN(K-Nearest Neighbor)</code>分类器是最简单的分类器实现之一，其决策边界是非线性的。它通过比较测试图像和样本图像的像素差异，按差异值从低到高排序对应样本图像标签，选择前<code>K</code>个标签中出现次数最多的标签作为分类结果</p><p>常用的比较像素差异的方法有<code>L1/L2</code>范数，参考<a href="https://www.zhujian.tech/posts/ce0afb50.html">范数</a></p><h3 id="优势和劣势"><a href="#优势和劣势" class="headerlink" title="优势和劣势"></a>优势和劣势</h3><p>主要有<code>2</code>点优势：</p><ol><li>易于理解和实现</li><li>不需要花费时间训练</li></ol><p>主要有<code>3</code>点缺陷：</p><ol><li>分类器需要保存所有的训练数据，空间效率低下</li><li>测试过程中测试图像需要和所有的训练图像进行比较，时间效率低下</li><li>通过像素差异进行分类，对于偏移（<code>shift</code>）、遮挡（<code>messed up</code>）和亮度调节的泛化效果不高</li></ol><h2 id="KNN分类器实现"><a href="#KNN分类器实现" class="headerlink" title="KNN分类器实现"></a>KNN分类器实现</h2><p>实现<code>KNN</code>分类器，使用<code>L2</code>范数进行像素差异计算，默认执行最近邻分类（<em>K=1</em>）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-11 下午8:02</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">from builtins import range</span><br><span class="line">from builtins import object</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class KNN(object):</span><br><span class="line">    &quot;&quot;&quot; a kNN classifier with L2 distance &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.X_train = None</span><br><span class="line">        self.y_train = None</span><br><span class="line"></span><br><span class="line">    def train(self, X, y):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Train the classifier. For k-nearest neighbors this is just</span><br><span class="line">        memorizing the training data.</span><br><span class="line">        Inputs:</span><br><span class="line">        - X: A numpy array of shape (num_train, D) containing the training data</span><br><span class="line">          consisting of num_train samples each of dimension D.</span><br><span class="line">        - y: A numpy array of shape (N,) containing the training labels, where</span><br><span class="line">             y[i] is the label for X[i].</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.X_train = X</span><br><span class="line">        self.y_train = y</span><br><span class="line"></span><br><span class="line">    def predict(self, X, k=1):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Predict labels for test data using this classifier.</span><br><span class="line">        Inputs:</span><br><span class="line">        - X: A numpy array of shape (num_test, D) containing test data consisting</span><br><span class="line">             of num_test samples each of dimension D.</span><br><span class="line">        - k: The number of nearest neighbors that vote for the predicted labels.</span><br><span class="line">        Returns:</span><br><span class="line">        - y: A numpy array of shape (num_test,) containing predicted labels for the</span><br><span class="line">          test data, where y[i] is the predicted label for the test point X[i].</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        dists = self._compute_distances(X)</span><br><span class="line"></span><br><span class="line">        return self._predict_labels(dists, k=k)</span><br><span class="line"></span><br><span class="line">    def _compute_distances(self, X):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Compute the distance between each test point in X and each training point</span><br><span class="line">        in self.X_train using no explicit loops.</span><br><span class="line">        Input / Output: Same as compute_distances_two_loops</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        num_test = X.shape[0]</span><br><span class="line">        num_train = self.X_train.shape[0]</span><br><span class="line">        dists = np.zeros((num_test, num_train))</span><br><span class="line"></span><br><span class="line">        temp_test = np.atleast_2d(np.sum(X ** 2, axis=1)).T</span><br><span class="line">        temp_train = np.atleast_2d(np.sum(self.X_train ** 2, axis=1))</span><br><span class="line">        temp_test_train = -2 * X.dot(self.X_train.T)</span><br><span class="line"></span><br><span class="line">        dists = np.sqrt(temp_test + temp_train + temp_test_train)</span><br><span class="line">        return dists</span><br><span class="line"></span><br><span class="line">    def _predict_labels(self, dists, k=1):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Given a matrix of distances between test points and training points,</span><br><span class="line">        predict a label for each test point.</span><br><span class="line">        Inputs:</span><br><span class="line">        - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</span><br><span class="line">          gives the distance betwen the ith test point and the jth training point.</span><br><span class="line">        Returns:</span><br><span class="line">        - y: A numpy array of shape (num_test,) containing predicted labels for the</span><br><span class="line">          test data, where y[i] is the predicted label for the test point X[i].</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        num_test = dists.shape[0]</span><br><span class="line">        y_pred = np.zeros(num_test)</span><br><span class="line">        for i in range(num_test):</span><br><span class="line">            idxes = np.argsort(dists[i])</span><br><span class="line">            closest_y = list(self.y_train[idxes][:k])</span><br><span class="line"></span><br><span class="line">            nums = np.array([closest_y.count(m) for m in closest_y])</span><br><span class="line">            y_pred[i] = closest_y[np.argmax(nums)]</span><br><span class="line"></span><br><span class="line">        return y_pred</span><br></pre></td></tr></table></figure><h2 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h2><p>交叉验证（<code>cross-validation</code>）是模型训练过程中调试超参数$k$的很有效的手段，训练过程如下：</p><ol><li>将训练数据等分为$N$份</li><li>按序取出其中一份作为验证集，其余数据重新作为训练集</li><li>计算超参数$k$为某一值时的预测精度。这样，每个超参数$k$都会得到$N$个精度值</li><li>平均$N$个精度值作为当前超参数$k$值的检测结果，比较不同$k$值下的检测精度，选取最好的$k$值</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">num_folds = 5</span><br><span class="line">k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]</span><br><span class="line"></span><br><span class="line">X_train_folds = []</span><br><span class="line">y_train_folds = []</span><br><span class="line"></span><br><span class="line">X_train_folds = np.array_split(X_train, num_folds)</span><br><span class="line">y_train_folds = np.array_split(y_train, num_folds)</span><br><span class="line"></span><br><span class="line"># A dictionary holding the accuracies for different values of k that we find</span><br><span class="line"># when running cross-validation. After running cross-validation,</span><br><span class="line"># k_to_accuracies[k] should be a list of length num_folds giving the different</span><br><span class="line"># accuracy values that we found when using that value of k.</span><br><span class="line">k_to_accuracies = &#123;&#125;</span><br><span class="line"></span><br><span class="line"># 计算预测标签和验证集标签的精度</span><br><span class="line">def compute_accuracy(y_test, y_test_pred):</span><br><span class="line">    num_test = y_test.shape[0]</span><br><span class="line">    num_correct = np.sum(y_test_pred == y_test)</span><br><span class="line">    accuracy = float(num_correct) / num_test</span><br><span class="line">    return accuracy</span><br><span class="line"></span><br><span class="line">for k in k_choices:</span><br><span class="line">    k_accuracies = []</span><br><span class="line">    # 随机选取其中一份为验证集，其余为测试集</span><br><span class="line">    for i in range(num_folds):</span><br><span class="line">        x_folds = X_train_folds.copy()</span><br><span class="line">        y_folds = y_train_folds.copy()</span><br><span class="line">        </span><br><span class="line">        x_vals = x_folds.pop(i)</span><br><span class="line">        x_trains = np.vstack(x_folds)</span><br><span class="line">        </span><br><span class="line">        y_vals = y_folds.pop(i)</span><br><span class="line">        y_trains = np.hstack(y_folds)</span><br><span class="line">        </span><br><span class="line">        classifier = KNearestNeighbor()</span><br><span class="line">#         print(x_trains.shape)</span><br><span class="line">#         print(y_trains.shape)</span><br><span class="line">        classifier.train(x_trains, y_trains)</span><br><span class="line">        </span><br><span class="line">#         print(x_vals.shape)</span><br><span class="line">        y_val_pred = classifier.predict(x_vals, k=k, num_loops=0)</span><br><span class="line">        k_accuracies.append(compute_accuracy(y_vals, y_val_pred))</span><br><span class="line">    k_to_accuracies[k] = k_accuracies</span><br><span class="line"></span><br><span class="line"># print(k_to_accuracies)</span><br><span class="line"># Print out the computed accuracies</span><br><span class="line">for k in sorted(k_to_accuracies):</span><br><span class="line">    for accuracy in k_to_accuracies[k]:</span><br><span class="line">        print(&apos;k = %d, accuracy = %f&apos; % (k, accuracy))</span><br></pre></td></tr></table></figure><p><em>通常设置训练集为$5$等分或$10$等分</em></p><p>交叉验证方法的优点在于其得到的超参数具有最好的泛化效果，缺点在于训练时间长</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>使用两个数据集分别测试<code>KNN</code>分类器，使用交叉验证方法训练最好的<code>KNN</code>分类器</p><p>完整代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-15 上午11:33</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">from builtins import range</span><br><span class="line">from classifier.knn_classifier import KNN</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn import utils</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_iris(iris_path, shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(iris_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        data = utils.shuffle(data)</span><br><span class="line"></span><br><span class="line">    species_dict = &#123;</span><br><span class="line">        &apos;Iris-setosa&apos;: 0,</span><br><span class="line">        &apos;Iris-versicolor&apos;: 1,</span><br><span class="line">        &apos;Iris-virginica&apos;: 2</span><br><span class="line">    &#125;</span><br><span class="line">    data[&apos;Species&apos;] = data[&apos;Species&apos;].map(species_dict)</span><br><span class="line"></span><br><span class="line">    data_x = np.array(</span><br><span class="line">        [data[&apos;SepalLengthCm&apos;], data[&apos;SepalWidthCm&apos;], data[&apos;PetalLengthCm&apos;], data[&apos;PetalWidthCm&apos;]]).T</span><br><span class="line">    data_y = data[&apos;Species&apos;]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=False)</span><br><span class="line"></span><br><span class="line">    return x_train, x_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_german_data(data_path, shuffle=True, tsize=0.8):</span><br><span class="line">    data_list = pd.read_csv(data_path, header=None, sep=&apos;\s+&apos;)</span><br><span class="line"></span><br><span class="line">    data_array = data_list.values</span><br><span class="line">    height, width = data_array.shape[:2]</span><br><span class="line">    data_x = data_array[:, :(width - 1)]</span><br><span class="line">    data_y = data_array[:, (width - 1)]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    y_train = np.array(list(map(lambda x: 1 if x == 2 else 0, y_train)))</span><br><span class="line">    y_test = np.array(list(map(lambda x: 1 if x == 2 else 0, y_test)))</span><br><span class="line"></span><br><span class="line">    return x_train, x_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(y, y_pred):</span><br><span class="line">    num = y.shape[0]</span><br><span class="line">    num_correct = np.sum(y_pred == y)</span><br><span class="line">    acc = float(num_correct) / num</span><br><span class="line">    return acc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def cross_validation(x_train, y_train, k_choices, num_folds=5, Classifier=KNN):</span><br><span class="line">    X_train_folds = np.array_split(x_train, num_folds)</span><br><span class="line">    y_train_folds = np.array_split(y_train, num_folds)</span><br><span class="line"></span><br><span class="line">    # 计算预测标签和验证集标签的精度</span><br><span class="line">    k_to_accuracies = &#123;&#125;</span><br><span class="line">    for k in k_choices:</span><br><span class="line">        k_accuracies = []</span><br><span class="line">        # 随机选取其中一份为验证集，其余为测试集</span><br><span class="line">        for i in range(num_folds):</span><br><span class="line">            x_folds = X_train_folds.copy()</span><br><span class="line">            y_folds = y_train_folds.copy()</span><br><span class="line"></span><br><span class="line">            x_vals = x_folds.pop(i)</span><br><span class="line">            x_trains = np.vstack(x_folds)</span><br><span class="line"></span><br><span class="line">            y_vals = y_folds.pop(i)</span><br><span class="line">            y_trains = np.hstack(y_folds)</span><br><span class="line"></span><br><span class="line">            classifier = Classifier()</span><br><span class="line">            classifier.train(x_trains, y_trains)</span><br><span class="line"></span><br><span class="line">            y_val_pred = classifier.predict(x_vals, k=k)</span><br><span class="line">            k_accuracies.append(compute_accuracy(y_vals, y_val_pred))</span><br><span class="line">        k_to_accuracies[k] = k_accuracies</span><br><span class="line"></span><br><span class="line">    return k_to_accuracies</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(k_choices, k_to_accuracies):</span><br><span class="line">    # plot the raw observations</span><br><span class="line">    for k in k_choices:</span><br><span class="line">        accuracies = k_to_accuracies[k]</span><br><span class="line">        plt.scatter([k] * len(accuracies), accuracies)</span><br><span class="line"></span><br><span class="line">    # plot the trend line with error bars that correspond to standard deviation</span><br><span class="line">    accuracies_mean = np.array([np.mean(v) for k, v in sorted(k_to_accuracies.items())])</span><br><span class="line">    accuracies_std = np.array([np.std(v) for k, v in sorted(k_to_accuracies.items())])</span><br><span class="line">    plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)</span><br><span class="line">    plt.title(&apos;Cross-validation on k&apos;)</span><br><span class="line">    plt.xlabel(&apos;k&apos;)</span><br><span class="line">    plt.ylabel(&apos;Cross-validation accuracy&apos;)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # iris_path = &apos;/home/zj/data/iris-species/Iris.csv&apos;</span><br><span class="line">    # x_train, x_test, y_train, y_test = load_iris(iris_path, shuffle=True, tsize=0.8)</span><br><span class="line"></span><br><span class="line">    data_path = &apos;/home/zj/data/german/german.data-numeric&apos;</span><br><span class="line">    x_train, x_test, y_train, y_test = load_german_data(data_path, shuffle=True, tsize=0.8)</span><br><span class="line"></span><br><span class="line">    x_train = x_train.astype(np.double)</span><br><span class="line">    x_test = x_test.astype(np.double)</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-8</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(var + eps)</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(var + eps)</span><br><span class="line"></span><br><span class="line">    k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 30, 50, 100]</span><br><span class="line">    k_to_accuracies = cross_validation(x_train, y_train, k_choices)</span><br><span class="line"></span><br><span class="line">    # print(k_to_accuracies)</span><br><span class="line">    # Print out the computed accuracies</span><br><span class="line">    for k in sorted(k_to_accuracies):</span><br><span class="line">        for accuracy in k_to_accuracies[k]:</span><br><span class="line">            print(&apos;k = %d, accuracy = %f&apos; % (k, accuracy))</span><br><span class="line"></span><br><span class="line">    plot(k_choices, k_to_accuracies)</span><br><span class="line"></span><br><span class="line">    accuracies_mean = np.array([np.mean(v) for k, v in sorted(k_to_accuracies.items())])</span><br><span class="line">    k = k_choices[np.argmax(accuracies_mean)]</span><br><span class="line">    print(&apos;最好的k值是：%d&apos; % k)</span><br><span class="line"></span><br><span class="line">    # 测试集测试</span><br><span class="line">    classifier = KNN()</span><br><span class="line">    classifier.train(x_train, y_train)</span><br><span class="line"></span><br><span class="line">    y_test_pred = classifier.predict(x_test, k=k)</span><br><span class="line">    y_test_acc = compute_accuracy(y_test, y_test_pred)</span><br><span class="line">    print(&apos;测试集精度为：%f&apos; % y_test_acc)</span><br></pre></td></tr></table></figure><p>数据集一：<code>Iris</code>数据集，共<code>4</code>个变量，<code>3</code>个类别。参考：<a href="https://www.zhujian.tech/posts/2626bec3.html">鸢尾数据集</a></p><p>测试结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">最好的k值是：12</span><br><span class="line">测试集精度为：0.933333</span><br></pre></td></tr></table></figure><p><img src="/imgs/KNN/iris.png" alt></p><p>数据集二：德国信用卡数据集，共<code>24</code>个变量，<code>2</code>个类别。参考：<a href="https://download.csdn.net/download/u012005313/11351036" target="_blank" rel="noopener">german data</a></p><p>测试结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">最好的k值是：20</span><br><span class="line">测试集精度为：0.735000</span><br></pre></td></tr></table></figure><p><img src="/imgs/KNN/german_data.png" alt></p><p><em>由于数据集过小，进行多次交叉验证才能得到比较好的结果</em></p></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';"> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/images/wechatpay.jpg" alt="zhujian 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/images/alipay.jpg" alt="zhujian 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zhujian</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zhujian.tech/posts/1ee29eaf.html" title="KNN分类器">https://www.zhujian.tech/posts/1ee29eaf.html</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/python/" rel="tag"># python</a> <a href="/tags/k-nearest-neighbor/" rel="tag"># K近邻</a> <a href="/tags/numpy/" rel="tag"># numpy</a> <a href="/tags/matplotlib/" rel="tag"># matplotlib</a> <a href="/tags/sklearn/" rel="tag"># sklearn</a> <a href="/tags/pandas/" rel="tag"># pandas</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/posts/2bdd8f16.html" rel="next" title="AdaGrad、RMSProp和Adam"><i class="fa fa-chevron-left"></i> AdaGrad、RMSProp和Adam</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/posts/ebe205e.html" rel="prev" title="线性SVM分类器">线性SVM分类器<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div><div class="comments" id="gitalk-container"></div></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是KNN分类器"><span class="nav-number">1.</span> <span class="nav-text">什么是KNN分类器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#优势和劣势"><span class="nav-number">1.1.</span> <span class="nav-text">优势和劣势</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#KNN分类器实现"><span class="nav-number">2.</span> <span class="nav-text">KNN分类器实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#交叉验证"><span class="nav-number">3.</span> <span class="nav-text">交叉验证</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实验"><span class="nav-number">4.</span> <span class="nav-text">实验</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zhujian" src="/images/avatar.png"><p class="site-author-name" itemprop="name">zhujian</p><div class="site-description" itemprop="description">one bite at a time</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">169</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">48</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">129</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="feed-link motion-element"><a href="/./atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zjZSTU" title="Github &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;zjZSTU" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/u012005313" title="CSDN &amp;rarr; https:&#x2F;&#x2F;blog.csdn.net&#x2F;u012005313" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i> CSDN</a></span><span class="links-of-author-item"><a href="/mailto:zjzstu@gmail.com" title="Gmail &amp;rarr; mailto:zjzstu@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> Gmail</a></span><span class="links-of-author-item"><a href="/mailto:505169307@gmail.com" title="QQmail &amp;rarr; mailto:505169307@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> QQmail</a></span></div><div class="cc-license motion-element" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://cloud.tencent.com/" title="https:&#x2F;&#x2F;cloud.tencent.com" rel="noopener" target="_blank">腾讯云</a></li><li class="links-of-blogroll-item"> <a href="https://www.aliyun.com/" title="https:&#x2F;&#x2F;www.aliyun.com" rel="noopener" target="_blank">阿里云</a></li><li class="links-of-blogroll-item"> <a href="https://developer.android.com/" title="https:&#x2F;&#x2F;developer.android.com&#x2F;" rel="noopener" target="_blank">Android Dev</a></li><li class="links-of-blogroll-item"> <a href="https://jenkins.io/" title="https:&#x2F;&#x2F;jenkins.io&#x2F;" rel="noopener" target="_blank">Jenkins</a></li><li class="links-of-blogroll-item"> <a href="http://cs231n.github.io/" title="http:&#x2F;&#x2F;cs231n.github.io&#x2F;" rel="noopener" target="_blank">cs231n</a></li><li class="links-of-blogroll-item"> <a href="https://pytorch.org/docs/stable/index.html" title="https:&#x2F;&#x2F;pytorch.org&#x2F;docs&#x2F;stable&#x2F;index.html" rel="noopener" target="_blank">pytorch</a></li><li class="links-of-blogroll-item"> <a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/" title="https:&#x2F;&#x2F;docs.docker.com&#x2F;install&#x2F;linux&#x2F;docker-ce&#x2F;ubuntu&#x2F;" rel="noopener" target="_blank">docker</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2020</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">zhujian</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span> <span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">948k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">26:20</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-bar-chart-o"></i></span> <a href="https://tongji.baidu.com/web/27249108/overview/index?siteId=13647183" rel="noopener" target="_blank">百度统计</a></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0</div> <span class="post-meta-divider">|</span><div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.5.0</div><div class="beian"> <a href="http://www.beian.miit.gov.cn/" rel="noopener" target="_blank">浙ICP备 19026415号</a> <span class="post-meta-divider">|</span> <img src="/images/beian_icon.png" style="display:inline-block;text-decoration:none;height:13px"> <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33011802001748" rel="noopener" target="_blank">浙公网安备 33011802001748号</a></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span> <span class="site-uv" title="总访客量">访客数：<span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="site-pv" title="总访问量">阅读量：<span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script color="17,63,61" opacity="1" zindex="-1" count="199" src="/lib/canvas-nest/canvas-nest.min.js"></script><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '8f22595c6dd29c94467d',
      clientSecret: 'e66bd90ebb9aa66c562c753dec6c90ceecbd51f2',
      repo: 'guestbook',
      owner: 'zjZSTU',
      admin: ['zjZSTU'],
      id: '0b28392fe8d1aea695a7cc6a7aebb70c',
        language: '',
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script></body></html>