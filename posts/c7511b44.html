<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.0.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="alternate" href="/./atom.xml" title="做一个幸福的人" type="application/atom+xml"><meta name="google-site-verification" content="Qr_3yqLtyErDFKHW7mE8PJz4qDUX-bf_fMLpSRckQe4"><meta name="baidu-site-verification" content="zOwIvKMV7f"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Roboto:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="/lib/pace/pace-theme-center-atom.min.css"><script src="/lib/pace/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"7.5.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!1,pangu:!1,algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"搜索文章",hits_empty:"我们没有找到任何搜索结果: ${query}",hits_stats:"找到约${hits}条结果（用时${time}ms）"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},translation:{copy_button:"复制",copy_success:"复制成功",copy_failure:"复制失败"},sidebarPadding:40}</script><link href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap" rel="stylesheet"><meta name="description" content="参考：Transfer Learning实际训练中很少有网络能够拥有足够大的数据集进行训练，所以迁移学习是实际卷积网络训练过程中非常重要的步骤"><meta name="keywords" content="python,pytorch,torchvision,numpy,matplotlib,迁移学习"><meta property="og:type" content="article"><meta property="og:title" content="迁移学习"><meta property="og:url" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;posts&#x2F;c7511b44.html"><meta property="og:site_name" content="做一个幸福的人"><meta property="og:description" content="参考：Transfer Learning实际训练中很少有网络能够拥有足够大的数据集进行训练，所以迁移学习是实际卷积网络训练过程中非常重要的步骤"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;transfer-learning&#x2F;data.png"><meta property="og:updated_time" content="2020-02-28T11:43:49.836Z"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;transfer-learning&#x2F;data.png"><link rel="canonical" href="https://www.zhujian.tech/posts/c7511b44.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,isPage:!1,isArchive:!1}</script><title>迁移学习 | 做一个幸福的人</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?e677aac1ac69b8826b9cfecb4e72e107";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">做一个幸福的人</span><span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">面朝大海，春暖花开</p></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i> 标签<span class="badge">129</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i> 分类<span class="badge">48</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i> 归档<span class="badge">169</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header> <a href="https://github.com/zjZSTU" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zhujian.tech/posts/c7511b44.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.png"><meta itemprop="name" content="zhujian"><meta itemprop="description" content="one bite at a time"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="做一个幸福的人"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> 迁移学习</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-02-28 14:30:55 / 修改时间：11:43:49" itemprop="dateCreated datePublished" datetime="2020-02-28T14:30:55+00:00">2020-02-28</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/algorithm/" itemprop="url" rel="index"><span itemprop="name">算法</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programming/" itemprop="url" rel="index"><span itemprop="name">编程</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/algorithm/optimization/" itemprop="url" rel="index"><span itemprop="name">最优化</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programming/programming-language/" itemprop="url" rel="index"><span itemprop="name">编程语言</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programming/codebase/" itemprop="url" rel="index"><span itemprop="name">代码库</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>8.1k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>14 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>参考：<a href="http://cs231n.github.io/transfer-learning/" target="_blank" rel="noopener">Transfer Learning</a></p><p>实际训练中很少有网络能够拥有足够大的数据集进行训练，所以迁移学习是实际卷积网络训练过程中非常重要的步骤</p><a id="more"></a><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>首先将模型在大数据集（比如<code>ImageNet</code>，包含<code>120</code>万张共<code>1000</code>类的图像）上进行预训练，然后将训练后的模型作为指定数据集的初始化或者固定特征提取器，这一操作称为迁移学习（<code>Transfer Learning</code>）</p><h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><p>迁移学习主要有<code>2</code>个适用场景：</p><ol><li>将卷积网络作为<strong>固定特征提取器</strong>。除了最后的全连接层外，将会冻结所有网络的权重。最后的全连接层将会被一个新的随机初始化的全连接层替代，并且仅训练该层</li><li><strong>微调</strong>卷积网络。不使用随机初始化而是用一个预训练网络来初始化网络，就像在<code>ImageNet 1000</code>数据集上训练网络一样，剩下的训练和往常一样。可以微调卷积网络的所有层，或者可以保持一些早期的层固定不变(由于过度拟合的问题)，并且只微调网络的一些较高层部分。这是因为观察到卷积网络的早期特征包含更多通用特征(例如，边缘检测器或颜色斑点检测器)，这些特征对许多任务都很有用，但是卷积网络的顶层对于原始数据集中包含的类的细节变得越来越具体。例如，在包含许多犬种的<code>ImageNet</code>的情况下，卷积网络的很大一部分表示能力可以用于区分犬种的特定特性</li></ol><h2 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h2><ul><li><code>Caffe</code>训练的卷积网络可以在<a href="https://github.com/BVLC/caffe/wiki/Model-Zoo" target="_blank" rel="noopener">Model Zoo</a>上进行分享</li><li><code>PyTorch</code>在<code>torchvision.models</code>中提供了多个网络及其预训练模型</li></ul><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>参考：<a href="https://zhujian.tech/posts/c8566254.html" target="_blank" rel="noopener">[译]Transfer Learning for Computer Vision Tutorial</a></p><p>使用网络<code>ResNet18</code>对小数据集（只有蚂蚁和蜜蜂两类，每类有约<code>120</code>张训练图片和<code>75</code>张测试图片）进行识别，比较随机初始化参数、使用预训练模型作为固定特征提取器以及微调网络的差异</p><p><img src="/imgs/transfer-learning/data.png" alt></p><h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><p>下载<a href="https://download.pytorch.org/tutorial/hymenoptera_data.zip" target="_blank" rel="noopener">数据集</a>，保存并解压到<code>data</code>文件夹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">├── data</span><br><span class="line">│   ├── hymenoptera_data</span><br><span class="line">│   └── hymenoptera_data.zip</span><br></pre></td></tr></table></figure><ul><li>训练阶段。随机裁剪图片并缩放至<code>224x224</code>大小，同时进行随机水平翻转，最后进行数据标准化操作</li><li>测试阶段。缩放图片至<code>256x256</code>大小，从中心裁剪<code>224x224</code>大小，最后进行数据标准化操作</li><li>批量大小：<code>4</code></li></ul><h3 id="训练参数"><a href="#训练参数" class="headerlink" title="训练参数"></a>训练参数</h3><ul><li>网络：<code>ResNet18</code></li><li>反向传播：随机梯度下降（<code>SGD</code>）</li><li>学习率：<code>1e-3</code></li><li>动量：<code>0.9</code></li><li>学习率调度器：随步长衰减，每<code>7</code>轮迭代衰减一次，<code>gamma=0.1</code></li></ul><h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   finetune.py</span><br><span class="line">@time:   2020-02-26</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import time</span><br><span class="line">import copy</span><br><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import torchvision</span><br><span class="line">import torchvision.datasets as datasets</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">import torchvision.models as models</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def imshow(inp, title=None):</span><br><span class="line">    &quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;</span><br><span class="line">    inp = inp.numpy().transpose((1, 2, 0))</span><br><span class="line">    mean = np.array([0.485, 0.456, 0.406])</span><br><span class="line">    std = np.array([0.229, 0.224, 0.225])</span><br><span class="line">    inp = std * inp + mean</span><br><span class="line">    inp = np.clip(inp, 0, 1)</span><br><span class="line">    plt.imshow(inp)</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    plt.pause(0.001)  # pause a bit so that plots are updated</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data():</span><br><span class="line">    # Data augmentation and normalization for training</span><br><span class="line">    # Just normalization for validation</span><br><span class="line">    # 进行数据扩充</span><br><span class="line">    data_transforms = &#123;</span><br><span class="line">        &apos;train&apos;: transforms.Compose([</span><br><span class="line">            transforms.RandomResizedCrop(224),</span><br><span class="line">            transforms.RandomHorizontalFlip(),</span><br><span class="line">            transforms.ToTensor(),</span><br><span class="line">            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])</span><br><span class="line">        ]),</span><br><span class="line">        &apos;val&apos;: transforms.Compose([</span><br><span class="line">            transforms.Resize(256),</span><br><span class="line">            transforms.CenterCrop(224),</span><br><span class="line">            transforms.ToTensor(),</span><br><span class="line">            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])</span><br><span class="line">        ]),</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    data_dir = &apos;data/hymenoptera_data&apos;</span><br><span class="line">    image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])</span><br><span class="line">                      for x in [&apos;train&apos;, &apos;val&apos;]&#125;</span><br><span class="line">    dataloaders = &#123;x: DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4)</span><br><span class="line">                   for x in [&apos;train&apos;, &apos;val&apos;]&#125;</span><br><span class="line">    dataset_sizes = &#123;x: len(image_datasets[x]) for x in [&apos;train&apos;, &apos;val&apos;]&#125;</span><br><span class="line">    class_names = image_datasets[&apos;train&apos;].classes</span><br><span class="line"></span><br><span class="line">    return dataloaders, dataset_sizes, class_names</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def show_data(dataloaders):</span><br><span class="line">    # 可视化数据集</span><br><span class="line">    # Get a batch of training data</span><br><span class="line">    inputs, classes = next(iter(dataloaders[&apos;train&apos;]))</span><br><span class="line">    # Make a grid from batch</span><br><span class="line">    # 制作图像网格</span><br><span class="line">    out = torchvision.utils.make_grid(inputs)</span><br><span class="line">    imshow(out, title=[class_names[x] for x in classes])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def visualize_model(model, dataloaders, class_names, num_images=6):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    可视化模型训练结果</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    was_training = model.training</span><br><span class="line">    model.eval()</span><br><span class="line">    images_so_far = 0</span><br><span class="line">    fig = plt.figure()</span><br><span class="line"></span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for i, (inputs, labels) in enumerate(dataloaders[&apos;val&apos;]):</span><br><span class="line">            inputs = inputs.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            _, preds = torch.max(outputs, 1)</span><br><span class="line"></span><br><span class="line">            for j in range(inputs.size()[0]):</span><br><span class="line">                images_so_far += 1</span><br><span class="line">                ax = plt.subplot(num_images // 2, 2, images_so_far)</span><br><span class="line">                ax.axis(&apos;off&apos;)</span><br><span class="line">                ax.set_title(&apos;predicted: &#123;&#125;&apos;.format(class_names[preds[j]]))</span><br><span class="line">                imshow(inputs.cpu().data[j])</span><br><span class="line"></span><br><span class="line">                if images_so_far == num_images:</span><br><span class="line">                    model.train(mode=was_training)</span><br><span class="line">                    return</span><br><span class="line">        model.train(mode=was_training)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def visualize_train():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    可视化训练损失和精度</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_model(mode=&apos;ri&apos;):</span><br><span class="line">    if mode == &apos;fixed&apos;:</span><br><span class="line">        model_conv = torchvision.models.resnet18(pretrained=True)</span><br><span class="line">        for param in model_conv.parameters():</span><br><span class="line">            param.requires_grad = False</span><br><span class="line">        return model_conv</span><br><span class="line">    elif mode == &apos;ft&apos;:</span><br><span class="line">        return models.resnet18(pretrained=True)</span><br><span class="line">    else:</span><br><span class="line">        return models.resnet18()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def train_model(model, criterion, optimizer, scheduler, dataset_sizes, dataloaders, num_epochs=25):</span><br><span class="line">    since = time.time()</span><br><span class="line"></span><br><span class="line">    best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line">    best_acc = 0.0</span><br><span class="line"></span><br><span class="line">    for epoch in range(num_epochs):</span><br><span class="line">        print(&apos;Epoch &#123;&#125;/&#123;&#125;&apos;.format(epoch, num_epochs - 1))</span><br><span class="line">        print(&apos;-&apos; * 10)</span><br><span class="line"></span><br><span class="line">        # Each epoch has a training and validation phase</span><br><span class="line">        for phase in [&apos;train&apos;, &apos;val&apos;]:</span><br><span class="line">            if phase == &apos;train&apos;:</span><br><span class="line">                model.train()  # Set model to training mode</span><br><span class="line">            else:</span><br><span class="line">                model.eval()  # Set model to evaluate mode</span><br><span class="line"></span><br><span class="line">            running_loss = 0.0</span><br><span class="line">            running_corrects = 0</span><br><span class="line"></span><br><span class="line">            # Iterate over data.</span><br><span class="line">            for inputs, labels in dataloaders[phase]:</span><br><span class="line">                inputs = inputs.to(device)</span><br><span class="line">                labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">                # zero the parameter gradients</span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">                # forward</span><br><span class="line">                # track history if only in train</span><br><span class="line">                with torch.set_grad_enabled(phase == &apos;train&apos;):</span><br><span class="line">                    outputs = model(inputs)</span><br><span class="line">                    _, preds = torch.max(outputs, 1)</span><br><span class="line">                    loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">                    # backward + optimize only if in training phase</span><br><span class="line">                    if phase == &apos;train&apos;:</span><br><span class="line">                        loss.backward()</span><br><span class="line">                        optimizer.step()</span><br><span class="line"></span><br><span class="line">                # statistics</span><br><span class="line">                running_loss += loss.item() * inputs.size(0)</span><br><span class="line">                running_corrects += torch.sum(preds == labels.data)</span><br><span class="line">            if phase == &apos;train&apos;:</span><br><span class="line">                scheduler.step()</span><br><span class="line"></span><br><span class="line">            epoch_loss = running_loss / dataset_sizes[phase]</span><br><span class="line">            epoch_acc = running_corrects.double() / dataset_sizes[phase]</span><br><span class="line"></span><br><span class="line">            print(&apos;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&apos;.format(</span><br><span class="line">                phase, epoch_loss, epoch_acc))</span><br><span class="line"></span><br><span class="line">            # deep copy the model</span><br><span class="line">            if phase == &apos;val&apos; and epoch_acc &gt; best_acc:</span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line"></span><br><span class="line">        print()</span><br><span class="line"></span><br><span class="line">    time_elapsed = time.time() - since</span><br><span class="line">    print(&apos;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&apos;.format(</span><br><span class="line">        time_elapsed // 60, time_elapsed % 60))</span><br><span class="line">    print(&apos;Best val Acc: &#123;:4f&#125;&apos;.format(best_acc))</span><br><span class="line"></span><br><span class="line">    # load best model weights</span><br><span class="line">    model.load_state_dict(best_model_wts)</span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line"></span><br><span class="line">    dataloaders, dataset_sizes, class_names = load_data()</span><br><span class="line">    show_data(dataloaders)</span><br><span class="line"></span><br><span class="line">    for mode_name in &#123;&apos;ri&apos;, &apos;ft&apos;, &apos;fixed&apos;&#125;:</span><br><span class="line">        print(&apos;begin mode: %s&apos; % mode_name)</span><br><span class="line">        print(&apos;#&apos; * 20)</span><br><span class="line">        # 创建网络模型，指定参数初始化方式</span><br><span class="line">        model = create_model(mode=mode_name)</span><br><span class="line">        # model = create_model(mode=&apos;ri&apos;)</span><br><span class="line">        # model = create_model(mode=&apos;ft&apos;)</span><br><span class="line">        # model = create_model(mode=&apos;fixed&apos;)</span><br><span class="line"></span><br><span class="line">        num_ftrs = model.fc.in_features</span><br><span class="line">        # Here the size of each output sample is set to 2.</span><br><span class="line">        # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).</span><br><span class="line">        model.fc = nn.Linear(num_ftrs, 2)</span><br><span class="line"></span><br><span class="line">        model_conv = model.to(device)</span><br><span class="line">        criterion = nn.CrossEntropyLoss()</span><br><span class="line">        # Observe that all parameters are being optimized</span><br><span class="line">        # 随机梯度下降</span><br><span class="line">        optimizer_conv = optim.SGD(model_conv.parameters(), lr=0.001, momentum=0.9)</span><br><span class="line">        # Decay LR by a factor of 0.1 every 7 epochs</span><br><span class="line">        # 随步长衰减</span><br><span class="line">        exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)</span><br><span class="line"></span><br><span class="line">        model_conv = train_model(model_conv, criterion,</span><br><span class="line">                                 optimizer_conv,</span><br><span class="line">                                 exp_lr_scheduler,</span><br><span class="line">                                 dataset_sizes,</span><br><span class="line">                                 dataloaders,</span><br><span class="line">                                 num_epochs=25)</span><br><span class="line"></span><br><span class="line">        # visualize_model(model_conv, dataloaders, class_names, num_images=6)</span><br></pre></td></tr></table></figure><h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><p>分别用<code>3</code>种不同的权重处理方式（随机初始化、微调、固定特征提取器）进行训练，共迭代<code>25</code>次，结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">begin mode: ri</span><br><span class="line">####################</span><br><span class="line">...</span><br><span class="line">Training complete in 0m 39s</span><br><span class="line">Best val Acc: 0.725490</span><br><span class="line">begin mode: ft</span><br><span class="line">####################</span><br><span class="line">...</span><br><span class="line">Training complete in 0m 40s</span><br><span class="line">Best val Acc: 0.941176</span><br><span class="line">begin mode: fixed</span><br><span class="line">####################</span><br><span class="line">...</span><br><span class="line">Training complete in 0m 26s</span><br><span class="line">Best val Acc: 0.960784</span><br></pre></td></tr></table></figure><p>从训练结果中发现，使用迁移学习后的网络模型能够得到更好的训练结果</p><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><p>在何种情况下进行迁移学习的使用，最大的因素有两个：</p><ul><li>新数据集的规模</li><li>新数据集与原先数据集的相似程度</li></ul><p>根据以上两个因素共分为<code>4</code>个使用场景：</p><ol><li>新数据集很小，与原始数据集相似。由于数据集很小，存在过拟合的问题，所以微调卷积网络不是一个好主意；由于数据与原始数据相似，卷积网络中的高级特征也与此数据集相关。最好的办法就是<strong>使用固定特征提取器的方式，再训练一个线性分类器</strong></li><li>新数据集很大，与原始数据集相似。因为有更多的数据，所以对整个网络进行<strong>微调</strong>也不会产生过拟合</li><li>新数据集很小，与原始数据集非常不同。因为数据很小，所以使用固定特征提取器的方式，再训练一个线性分类器。由于数据集有很大的不同，所以不能从包含更多数据集特定特征的网络顶部来训练分类器，而是<strong>固定网络早期权重，微调网络顶部权重的方式来训练线性分类器</strong></li><li>新数据集很大，与原始数据集非常不同。由于数据集非常大，能够从头开始训练一个卷积网络。但是在实践中，用来自预训练模型的权重初始化仍然非常有效。在这种情况下，将有足够的数据和信心通过整个网络进行<strong>微调</strong></li></ol></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';"> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/images/wechatpay.jpg" alt="zhujian 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/images/alipay.jpg" alt="zhujian 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zhujian</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zhujian.tech/posts/c7511b44.html" title="迁移学习">https://www.zhujian.tech/posts/c7511b44.html</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/python/" rel="tag"># python</a> <a href="/tags/pytorch/" rel="tag"># pytorch</a> <a href="/tags/torchvision/" rel="tag"># torchvision</a> <a href="/tags/numpy/" rel="tag"># numpy</a> <a href="/tags/matplotlib/" rel="tag"># matplotlib</a> <a href="/tags/transfer-learning/" rel="tag"># 迁移学习</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/posts/c8566254.html" rel="next" title="[译]Transfer Learning for Computer Vision Tutorial"><i class="fa fa-chevron-left"></i> [译]Transfer Learning for Computer Vision Tutorial</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"></div></div></footer></article></div></div><div class="comments" id="gitalk-container"></div></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#简介"><span class="nav-number">1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#适用场景"><span class="nav-number">2.</span> <span class="nav-text">适用场景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#预训练模型"><span class="nav-number">3.</span> <span class="nav-text">预训练模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#示例"><span class="nav-number">4.</span> <span class="nav-text">示例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#加载数据"><span class="nav-number">4.1.</span> <span class="nav-text">加载数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练参数"><span class="nav-number">4.2.</span> <span class="nav-text">训练参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实现代码"><span class="nav-number">4.3.</span> <span class="nav-text">实现代码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#比较"><span class="nav-number">4.4.</span> <span class="nav-text">比较</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用场景"><span class="nav-number">5.</span> <span class="nav-text">使用场景</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zhujian" src="/images/avatar.png"><p class="site-author-name" itemprop="name">zhujian</p><div class="site-description" itemprop="description">one bite at a time</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">169</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">48</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">129</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="feed-link motion-element"><a href="/./atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zjZSTU" title="Github &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;zjZSTU" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/u012005313" title="CSDN &amp;rarr; https:&#x2F;&#x2F;blog.csdn.net&#x2F;u012005313" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i> CSDN</a></span><span class="links-of-author-item"><a href="/mailto:zjzstu@gmail.com" title="Gmail &amp;rarr; mailto:zjzstu@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> Gmail</a></span><span class="links-of-author-item"><a href="/mailto:505169307@gmail.com" title="QQmail &amp;rarr; mailto:505169307@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> QQmail</a></span></div><div class="cc-license motion-element" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://cloud.tencent.com/" title="https:&#x2F;&#x2F;cloud.tencent.com" rel="noopener" target="_blank">腾讯云</a></li><li class="links-of-blogroll-item"> <a href="https://www.aliyun.com/" title="https:&#x2F;&#x2F;www.aliyun.com" rel="noopener" target="_blank">阿里云</a></li><li class="links-of-blogroll-item"> <a href="https://developer.android.com/" title="https:&#x2F;&#x2F;developer.android.com&#x2F;" rel="noopener" target="_blank">Android Dev</a></li><li class="links-of-blogroll-item"> <a href="https://jenkins.io/" title="https:&#x2F;&#x2F;jenkins.io&#x2F;" rel="noopener" target="_blank">Jenkins</a></li><li class="links-of-blogroll-item"> <a href="http://cs231n.github.io/" title="http:&#x2F;&#x2F;cs231n.github.io&#x2F;" rel="noopener" target="_blank">cs231n</a></li><li class="links-of-blogroll-item"> <a href="https://pytorch.org/docs/stable/index.html" title="https:&#x2F;&#x2F;pytorch.org&#x2F;docs&#x2F;stable&#x2F;index.html" rel="noopener" target="_blank">pytorch</a></li><li class="links-of-blogroll-item"> <a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/" title="https:&#x2F;&#x2F;docs.docker.com&#x2F;install&#x2F;linux&#x2F;docker-ce&#x2F;ubuntu&#x2F;" rel="noopener" target="_blank">docker</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2020</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">zhujian</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span> <span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">948k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">26:20</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-bar-chart-o"></i></span> <a href="https://tongji.baidu.com/web/27249108/overview/index?siteId=13647183" rel="noopener" target="_blank">百度统计</a></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0</div> <span class="post-meta-divider">|</span><div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.5.0</div><div class="beian"> <a href="http://www.beian.miit.gov.cn/" rel="noopener" target="_blank">浙ICP备 19026415号</a> <span class="post-meta-divider">|</span> <img src="/images/beian_icon.png" style="display:inline-block;text-decoration:none;height:13px"> <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33011802001748" rel="noopener" target="_blank">浙公网安备 33011802001748号</a></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span> <span class="site-uv" title="总访客量">访客数：<span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="site-pv" title="总访问量">阅读量：<span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script color="17,63,61" opacity="1" zindex="-1" count="199" src="/lib/canvas-nest/canvas-nest.min.js"></script><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '8f22595c6dd29c94467d',
      clientSecret: 'e66bd90ebb9aa66c562c753dec6c90ceecbd51f2',
      repo: 'guestbook',
      owner: 'zjZSTU',
      admin: ['zjZSTU'],
      id: '4370b05e7ac479d678203eaedd4fe1a6',
        language: '',
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script></body></html>