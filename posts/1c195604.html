<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.0.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="alternate" href="/./atom.xml" title="做一个幸福的人" type="application/atom+xml"><meta name="google-site-verification" content="Qr_3yqLtyErDFKHW7mE8PJz4qDUX-bf_fMLpSRckQe4"><meta name="baidu-site-verification" content="zOwIvKMV7f"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Roboto:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="/lib/pace/pace-theme-center-atom.min.css"><script src="/lib/pace/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"7.5.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!1,pangu:!1,algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"搜索文章",hits_empty:"我们没有找到任何搜索结果: ${query}",hits_stats:"找到约${hits}条结果（用时${time}ms）"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},translation:{copy_button:"复制",copy_success:"复制成功",copy_failure:"复制失败"},sidebarPadding:40}</script><link href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap" rel="stylesheet"><meta name="description" content="使用pytorch实现softmax回归，首先使用基本数学运算函数实现，然后逐步使用各种封装函数和优化包进行替换"><meta name="keywords" content="python,pytorch,numpy,matplotlib,sklearn,pandas,softmax"><meta property="og:type" content="article"><meta property="og:title" content="从numpy到pytorch实现softmax回归"><meta property="og:url" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;posts&#x2F;1c195604.html"><meta property="og:site_name" content="做一个幸福的人"><meta property="og:description" content="使用pytorch实现softmax回归，首先使用基本数学运算函数实现，然后逐步使用各种封装函数和优化包进行替换"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;从numpy到pytorch实现softmax回归&#x2F;pytorch_basic_softmax_loss.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;从numpy到pytorch实现softmax回归&#x2F;pytorch_basic_softmax_accuracy.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;从numpy到pytorch实现softmax回归&#x2F;pytorch_advanced_softmax_loss.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;从numpy到pytorch实现softmax回归&#x2F;pytorch_advanced_softmax_accuracy.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;从numpy到pytorch实现softmax回归&#x2F;pytorch_advanced_softmax_loss_v2.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;从numpy到pytorch实现softmax回归&#x2F;pytorch_advanced_softmax_accuracy_v2.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;从numpy到pytorch实现softmax回归&#x2F;pytorch_advanced_softmax_loss_v3.png"><meta property="og:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;从numpy到pytorch实现softmax回归&#x2F;pytorch_advanced_softmax_accuracy_v3.png"><meta property="og:updated_time" content="2020-02-15T05:36:35.871Z"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https:&#x2F;&#x2F;www.zhujian.tech&#x2F;imgs&#x2F;从numpy到pytorch实现softmax回归&#x2F;pytorch_basic_softmax_loss.png"><link rel="canonical" href="https://www.zhujian.tech/posts/1c195604.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,isPage:!1,isArchive:!1}</script><title>从numpy到pytorch实现softmax回归 | 做一个幸福的人</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?e677aac1ac69b8826b9cfecb4e72e107";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">做一个幸福的人</span><span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">面朝大海，春暖花开</p></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i> 标签<span class="badge">129</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i> 分类<span class="badge">48</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i> 归档<span class="badge">169</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header> <a href="https://github.com/zjZSTU" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zhujian.tech/posts/1c195604.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.png"><meta itemprop="name" content="zhujian"><meta itemprop="description" content="one bite at a time"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="做一个幸福的人"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> 从numpy到pytorch实现softmax回归</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-04-28 11:13:16" itemprop="dateCreated datePublished" datetime="2019-04-28T11:13:16+00:00">2019-04-28</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-02-15 05:36:35" itemprop="dateModified" datetime="2020-02-15T05:36:35+00:00">2020-02-15</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/algorithm/" itemprop="url" rel="index"><span itemprop="name">算法</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programming/" itemprop="url" rel="index"><span itemprop="name">编程</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programming/programming-language/" itemprop="url" rel="index"><span itemprop="name">编程语言</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/algorithm/data-learning/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programming/codebase/" itemprop="url" rel="index"><span itemprop="name">代码库</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>16k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>27 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>使用<code>pytorch</code>实现<code>softmax</code>回归，首先使用基本数学运算函数实现，然后逐步使用各种封装函数和优化包进行替换</p><a id="more"></a><p>超参数如下：</p><ul><li>batch_size = 8</li><li>lambda = 2e-4</li><li>alpha = 2e-4</li></ul><p>使用数据库</p><ul><li><a href="https://www.kaggle.com/uciml/iris" target="_blank" rel="noopener">Iris Species</a></li></ul><h2 id="numpy实现"><a href="#numpy实现" class="headerlink" title="numpy实现"></a><code>numpy</code>实现</h2><p>参考<a href="https://www.zhujian.tech/posts/2626bec3.html#more">softmax回归</a></p><h2 id="pytorch实现-基本数学运算函数"><a href="#pytorch实现-基本数学运算函数" class="headerlink" title="pytorch实现 - 基本数学运算函数"></a><code>pytorch</code>实现 - 基本数学运算函数</h2><p>先利用<code>numpy</code>获取<code>iris</code>数据，再转换<code>为torch.Tensor</code>结构</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x_train, x_test, y_train, y_test, y_train_indicator = load_data()</span><br><span class="line"></span><br><span class="line">x_train = torch.FloatTensor(x_train)</span><br><span class="line">x_test = torch.FloatTensor(x_test)</span><br><span class="line">y_train = torch.LongTensor(y_train)</span><br><span class="line">y_test = torch.LongTensor(y_test)</span><br><span class="line">y_train_indicator = torch.FloatTensor(y_train_indicator)</span><br></pre></td></tr></table></figure><p>初始化权重，生成标准正态分布随机数组</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def init_weights(inputs, outputs, requires_grad=False):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    初始化权重</span><br><span class="line">    使用torch.randn生成标准正态分布</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    w = 0.01 * torch.randn(inputs, outputs, requires_grad=requires_grad, dtype=torch.float)</span><br><span class="line">    b = 0.01 * torch.randn(1, requires_grad=requires_grad, dtype=torch.float)</span><br><span class="line">    return w, b</span><br></pre></td></tr></table></figure><p>执行线性运算和<code>softmax</code>运算</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def linear(x, w, b):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    线性操作</span><br><span class="line">    :param x: 大小为(m,n)</span><br><span class="line">    :param w: 大小为(k,n)</span><br><span class="line">    :return: 大小为(m,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return x.mm(w) + b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def softmax(x):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    softmax归一化计算</span><br><span class="line">    :param x: 大小为(m, k)</span><br><span class="line">    :return: 大小为(m, k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x -= torch.unsqueeze(torch.max(x, 1)[0], 1)</span><br><span class="line">    exps = torch.exp(x)</span><br><span class="line">    return exps / torch.unsqueeze(torch.sum(exps, dim=1), 1)</span><br></pre></td></tr></table></figure><p>计算预测结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def compute_scores(W, b, X):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param X: 大小为(m,n)</span><br><span class="line">    :param W: 大小为(k,n)</span><br><span class="line">    :param b: 1</span><br><span class="line">    :return: (m,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return softmax(linear(X, W, b))</span><br></pre></td></tr></table></figure><p>计算损失值和梯度值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def compute_loss(scores, indicator, W, b, la=2e-4):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算损失值</span><br><span class="line">    :param scores: 大小为(m, n)</span><br><span class="line">    :param indicator: 大小为(m, n)</span><br><span class="line">    :param W: (n, k)</span><br><span class="line">    :return: (m,1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    loss = -1 / scores.size()[0] * torch.sum(torch.log(scores) * indicator)</span><br><span class="line">    reg = la / 2 * (torch.sum(W ** 2) + b ** 2)</span><br><span class="line"></span><br><span class="line">    return (loss + reg).item()</span><br><span class="line"></span><br><span class="line">def compute_gradient(indicator, scores, x, W, la=2e-4):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算梯度</span><br><span class="line">    :param indicator: 大小为(m,k)</span><br><span class="line">    :param scores: 大小为(m,k)</span><br><span class="line">    :param x: 大小为(m,n)</span><br><span class="line">    :param W: (n, k)</span><br><span class="line">    :return: (n,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    dloss = -1 / scores.size()[0] * x.t().mm(torch.sub(indicator, scores))</span><br><span class="line">    dreg = la * W</span><br><span class="line">    return dloss + dreg</span><br></pre></td></tr></table></figure><p>最后计算精度</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def compute_accuracy(scores, Y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param scores: (m,k)</span><br><span class="line">    :param Y: (m,1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    predictions = torch.argmax(scores, dim=1)</span><br><span class="line">    res = (predictions == Y.squeeze())</span><br><span class="line">    return 1.0 * torch.sum(res).item() / scores.size()[0]</span><br></pre></td></tr></table></figure><p>完整代码如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-4-27 下午3:05</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn import utils</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/iris-species/Iris.csv&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(data_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        data = utils.shuffle(data)</span><br><span class="line"></span><br><span class="line">    # 示性函数</span><br><span class="line">    pd_indicator = pd.get_dummies(data[&apos;Species&apos;])</span><br><span class="line">    indicator = np.array(</span><br><span class="line">        [pd_indicator[&apos;Iris-setosa&apos;], pd_indicator[&apos;Iris-versicolor&apos;], pd_indicator[&apos;Iris-virginica&apos;]]).T</span><br><span class="line"></span><br><span class="line">    species_dict = &#123;</span><br><span class="line">        &apos;Iris-setosa&apos;: 0,</span><br><span class="line">        &apos;Iris-versicolor&apos;: 1,</span><br><span class="line">        &apos;Iris-virginica&apos;: 2</span><br><span class="line">    &#125;</span><br><span class="line">    data[&apos;Species&apos;] = data[&apos;Species&apos;].map(species_dict)</span><br><span class="line"></span><br><span class="line">    data_x = np.array(</span><br><span class="line">        [data[&apos;SepalLengthCm&apos;], data[&apos;SepalWidthCm&apos;], data[&apos;PetalLengthCm&apos;], data[&apos;PetalWidthCm&apos;]]).T</span><br><span class="line">    data_y = data[&apos;Species&apos;]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=False)</span><br><span class="line"></span><br><span class="line">    y_train = np.atleast_2d(y_train).T</span><br><span class="line">    y_test = np.atleast_2d(y_test).T</span><br><span class="line"></span><br><span class="line">    y_train_indicator = np.atleast_2d(indicator[:y_train.shape[0]])</span><br><span class="line"></span><br><span class="line">    return torch.from_numpy(x_train).float(), torch.from_numpy(x_test).float(), torch.from_numpy(</span><br><span class="line">        y_train), torch.from_numpy(y_test), torch.from_numpy(y_train_indicator).float()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def linear(x, w):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    线性操作</span><br><span class="line">    :param x: 大小为(m,n+1)</span><br><span class="line">    :param w: 大小为(n+1,k)</span><br><span class="line">    :return: 大小为(m,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return x.mm(w)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def softmax(x):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    softmax归一化计算</span><br><span class="line">    :param x: 大小为(m, k)</span><br><span class="line">    :return: 大小为(m, k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x -= torch.unsqueeze(torch.max(x, 1)[0], 1)</span><br><span class="line">    exps = torch.exp(x)</span><br><span class="line">    return exps / torch.unsqueeze(torch.sum(exps, dim=1), 1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_scores(X, W):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param X: 大小为(m,n)</span><br><span class="line">    :param W: 大小为(k,n)</span><br><span class="line">    :return: (m,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return softmax(linear(X, W))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_loss(scores, indicator, W, la=2e-4):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算损失值</span><br><span class="line">    :param scores: 大小为(m, k)</span><br><span class="line">    :param indicator: 大小为(m, k)</span><br><span class="line">    :param W: (n+1, k)</span><br><span class="line">    :return: (1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    loss = -1 / scores.size()[0] * torch.sum(torch.log(scores) * indicator)</span><br><span class="line">    reg = la / 2 * torch.sum(W ** 2)</span><br><span class="line"></span><br><span class="line">    return (loss + reg).item()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient(indicator, scores, x, W, la=2e-4):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算梯度</span><br><span class="line">    :param indicator: 大小为(m,k)</span><br><span class="line">    :param scores: 大小为(m,k)</span><br><span class="line">    :param x: 大小为(m,n+1)</span><br><span class="line">    :param W: (n+1, k)</span><br><span class="line">    :return: (n+1,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    dloss = -1 / scores.size()[0] * x.t().mm(torch.sub(indicator, scores))</span><br><span class="line">    dreg = la * W</span><br><span class="line">    return dloss + dreg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(scores, Y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param scores: (m,k)</span><br><span class="line">    :param Y: (m,1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    predictions = torch.argmax(scores, dim=1)</span><br><span class="line">    res = (predictions == Y.squeeze())</span><br><span class="line">    return 1.0 * torch.sum(res).item() / scores.size()[0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(res_list, title=None, xlabel=None):</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    if xlabel is not None:</span><br><span class="line">        plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(res_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient_descent(batch_size=8, epoches=2000, alpha=2e-4):</span><br><span class="line">    x_train, x_test, y_train, y_test, y_train_indicator = load_data()</span><br><span class="line"></span><br><span class="line">    m, n = x_train.size()[:2]</span><br><span class="line">    k = 3</span><br><span class="line">    # print(m, n, k)</span><br><span class="line"></span><br><span class="line">    W = 0.01 * torch.randn(n + 1, k, requires_grad=False, dtype=torch.float)</span><br><span class="line">    # print(w)</span><br><span class="line">    # 插入一列</span><br><span class="line">    x_train = torch.from_numpy(np.insert(x_train.numpy(), 0, np.ones(m), axis=1))</span><br><span class="line">    x_test = torch.from_numpy(np.insert(x_test.numpy(), 0, np.ones(x_test.size()[0]), axis=1))</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestW = None</span><br><span class="line">    bestA = 0</span><br><span class="line">    range_list = list(range(0, m - batch_size, batch_size))</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j in range_list:</span><br><span class="line">            data = x_train[j:j + batch_size]</span><br><span class="line">            labels = y_train_indicator[j:j + batch_size]</span><br><span class="line"></span><br><span class="line">            scores = compute_scores(data, W)</span><br><span class="line">            tempW = W - alpha * compute_gradient(labels, scores, data, W)</span><br><span class="line">            W = tempW</span><br><span class="line"></span><br><span class="line">            if j == range_list[-1]:</span><br><span class="line">                loss = compute_loss(scores, labels, W)</span><br><span class="line">                loss_list.append(loss)</span><br><span class="line"></span><br><span class="line">                accuracy = compute_accuracy(compute_scores(x_train, W), y_train)</span><br><span class="line">                accuracy_list.append(accuracy)</span><br><span class="line">                if accuracy &gt;= bestA:</span><br><span class="line">                    bestA = accuracy</span><br><span class="line">                    bestW = W.clone()</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度&apos;)</span><br><span class="line"></span><br><span class="line">    print(bestA)</span><br><span class="line">    print(compute_accuracy(compute_scores(x_test, bestW), y_test))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    compute_gradient_descent(batch_size=8, epoches=100000)</span><br></pre></td></tr></table></figure><p>测试结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 测试集精度</span><br><span class="line">0.975</span><br><span class="line"># 验证集精度</span><br><span class="line">1.0</span><br></pre></td></tr></table></figure><p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_basic_softmax_loss.png" alt></p><p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_basic_softmax_accuracy.png" alt></p><h2 id="pytorch实现-使用nn包优化softmax回归模型和损失函数"><a href="#pytorch实现-使用nn包优化softmax回归模型和损失函数" class="headerlink" title="pytorch实现 - 使用nn包优化softmax回归模型和损失函数"></a><code>pytorch</code>实现 - 使用<code>nn</code>包优化<code>softmax</code>回归模型和损失函数</h2><p><code>pytorch</code>在包<code>nn</code>中提供了大量算法和损失函数实现，并且能够自动计算梯度</p><p>使用线性模型和<code>softmax</code>回归模型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># softmax回归模型和权重</span><br><span class="line">linearModel = nn.Linear(n, k)</span><br><span class="line">softmaxModel = nn.LogSoftmax()</span><br><span class="line">w = linearModel.weight</span><br><span class="line">b = linearModel.bias</span><br><span class="line"></span><br><span class="line">scores = softmaxModel.forward(linearModel.forward(data))</span><br></pre></td></tr></table></figure><p>使用交叉熵损失类计算损失和计算梯度</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 损失函数</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">loss = criterion(scores, labels.squeeze())</span><br><span class="line"># 反向传播</span><br><span class="line">loss.backward()</span><br><span class="line"># 梯度更新</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    w -= w.grad * alpha</span><br><span class="line">    w.grad.zero_()</span><br><span class="line">    b -= b.grad * alpha</span><br><span class="line">    b.grad.zero_()</span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn import utils</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/iris-species/Iris.csv&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(data_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        data = utils.shuffle(data)</span><br><span class="line"></span><br><span class="line">    # 示性函数</span><br><span class="line">    pd_indicator = pd.get_dummies(data[&apos;Species&apos;])</span><br><span class="line">    indicator = np.array(</span><br><span class="line">        [pd_indicator[&apos;Iris-setosa&apos;], pd_indicator[&apos;Iris-versicolor&apos;], pd_indicator[&apos;Iris-virginica&apos;]]).T</span><br><span class="line"></span><br><span class="line">    species_dict = &#123;</span><br><span class="line">        &apos;Iris-setosa&apos;: 0,</span><br><span class="line">        &apos;Iris-versicolor&apos;: 1,</span><br><span class="line">        &apos;Iris-virginica&apos;: 2</span><br><span class="line">    &#125;</span><br><span class="line">    data[&apos;Species&apos;] = data[&apos;Species&apos;].map(species_dict)</span><br><span class="line"></span><br><span class="line">    data_x = np.array(</span><br><span class="line">        [data[&apos;SepalLengthCm&apos;], data[&apos;SepalWidthCm&apos;], data[&apos;PetalLengthCm&apos;], data[&apos;PetalWidthCm&apos;]]).T</span><br><span class="line">    data_y = data[&apos;Species&apos;]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=False)</span><br><span class="line"></span><br><span class="line">    y_train = np.atleast_2d(y_train).T</span><br><span class="line">    y_test = np.atleast_2d(y_test).T</span><br><span class="line"></span><br><span class="line">    y_train_indicator = np.atleast_2d(indicator[:y_train.shape[0]])</span><br><span class="line"></span><br><span class="line">    return torch.from_numpy(x_train).float(), torch.from_numpy(x_test).float(), torch.from_numpy(</span><br><span class="line">        y_train), torch.from_numpy(y_test), torch.from_numpy(y_train_indicator).float()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(scores, Y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param scores: (m,k)</span><br><span class="line">    :param Y: (m,1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    predictions = torch.argmax(scores, dim=1)</span><br><span class="line">    res = (predictions == Y.squeeze())</span><br><span class="line">    return 1.0 * torch.sum(res).item() / scores.size()[0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(res_list, title=None, xlabel=None):</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    if xlabel is not None:</span><br><span class="line">        plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(res_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient_descent(batch_size=8, epoches=2000, alpha=2e-4):</span><br><span class="line">    x_train, x_test, y_train, y_test, y_train_indicator = load_data()</span><br><span class="line"></span><br><span class="line">    m, n = x_train.size()[:2]</span><br><span class="line">    k = 3</span><br><span class="line">    # print(m, n, k)</span><br><span class="line"></span><br><span class="line">    # softmax回归模型和权重</span><br><span class="line">    linearModel = nn.Linear(n, k)</span><br><span class="line">    softmaxModel = nn.LogSoftmax()</span><br><span class="line">    w = linearModel.weight</span><br><span class="line">    b = linearModel.bias</span><br><span class="line">    # 损失函数</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestW = None</span><br><span class="line">    bestB = None</span><br><span class="line">    bestA = 0</span><br><span class="line">    range_list = list(range(0, m - batch_size, batch_size))</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j in range_list:</span><br><span class="line">            data = x_train[j:j + batch_size]</span><br><span class="line">            labels = y_train[j:j + batch_size]</span><br><span class="line"></span><br><span class="line">            scores = softmaxModel.forward(linearModel.forward(data))</span><br><span class="line">            loss = criterion(scores, labels.squeeze())</span><br><span class="line">            # 反向传播</span><br><span class="line">            loss.backward()</span><br><span class="line">            # 梯度更新</span><br><span class="line">            with torch.no_grad():</span><br><span class="line">                w -= w.grad * alpha</span><br><span class="line">                w.grad.zero_()</span><br><span class="line">                b -= b.grad * alpha</span><br><span class="line">                b.grad.zero_()</span><br><span class="line"></span><br><span class="line">            if j == range_list[-1]:</span><br><span class="line">                loss_list.append(loss.item())</span><br><span class="line"></span><br><span class="line">                accuracy = compute_accuracy(softmaxModel(linearModel(x_train)), y_train)</span><br><span class="line">                accuracy_list.append(accuracy)</span><br><span class="line">                if accuracy &gt;= bestA:</span><br><span class="line">                    bestA = accuracy</span><br><span class="line">                    bestW = w.clone()</span><br><span class="line">                    bestB = b.clone()</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度&apos;)</span><br><span class="line"></span><br><span class="line">    linearModel.weight = nn.Parameter(bestW)</span><br><span class="line">    linearModel.bias = nn.Parameter(bestB)</span><br><span class="line">    print(bestA)</span><br><span class="line">    print(compute_accuracy(softmaxModel.forward(linearModel.forward(x_test)), y_test))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    compute_gradient_descent(batch_size=8, epoches=50000)</span><br></pre></td></tr></table></figure><p>测试结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 测试集精度</span><br><span class="line">0.9833333333333333</span><br><span class="line"># 验证集精度</span><br><span class="line">1.0</span><br></pre></td></tr></table></figure><p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_advanced_softmax_loss.png" alt></p><p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_advanced_softmax_accuracy.png" alt></p><h2 id="pytorch实现-使用优化器和自定义softmax实现类"><a href="#pytorch实现-使用优化器和自定义softmax实现类" class="headerlink" title="pytorch实现 - 使用优化器和自定义softmax实现类"></a><code>pytorch</code>实现 - 使用优化器和自定义<code>softmax</code>实现类</h2><p>自定义类，实现<code>softmax</code>运算以及参数设置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">class SoftmaxModule(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, inputs, outputs):</span><br><span class="line">        super(SoftmaxModule, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(inputs, outputs)</span><br><span class="line">        self.softmax = nn.LogSoftmax()</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        x = self.linear.forward(input)</span><br><span class="line">        x = self.softmax.forward(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def getParameter(self):</span><br><span class="line">        return self.linear.weight, self.linear.bias</span><br><span class="line"></span><br><span class="line">    def setParameter(self, weight, bias):</span><br><span class="line">        self.linear.weight = nn.Parameter(weight)</span><br><span class="line">        self.linear.bias = nn.Parameter(bias)</span><br></pre></td></tr></table></figure><p><code>pytorch</code>提供了优化器包<code>torch.optim</code>来辅助进行梯度更新</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 优化器</span><br><span class="line">optimizer = optim.SGD(module.parameters(), lr=alpha)</span><br><span class="line"></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"># 反向传播</span><br><span class="line">loss.backward()</span><br><span class="line"># 梯度更新</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure><p>更新代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">class SoftmaxModule(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, inputs, outputs):</span><br><span class="line">        super(SoftmaxModule, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(inputs, outputs)</span><br><span class="line">        self.softmax = nn.LogSoftmax()</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        x = self.linear.forward(input)</span><br><span class="line">        x = self.softmax.forward(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def getParameter(self):</span><br><span class="line">        return self.linear.weight, self.linear.bias</span><br><span class="line"></span><br><span class="line">    def setParameter(self, weight, bias):</span><br><span class="line">        self.linear.weight = nn.Parameter(weight)</span><br><span class="line">        self.linear.bias = nn.Parameter(bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient_descent(batch_size=8, epoches=2000, alpha=2e-4):</span><br><span class="line">    x_train, x_test, y_train, y_test, y_train_indicator = load_data()</span><br><span class="line"></span><br><span class="line">    m, n = x_train.size()[:2]</span><br><span class="line">    k = 3</span><br><span class="line">    # print(m, n, k)</span><br><span class="line"></span><br><span class="line">    # softmax模型</span><br><span class="line">    module = SoftmaxModule(n, k)</span><br><span class="line">    # 损失函数</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    # 优化器</span><br><span class="line">    optimizer = optim.SGD(module.parameters(), lr=alpha)</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestW = None</span><br><span class="line">    bestB = None</span><br><span class="line">    bestA = 0</span><br><span class="line">    range_list = list(range(0, m - batch_size, batch_size))</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j in range_list:</span><br><span class="line">            data = x_train[j:j + batch_size]</span><br><span class="line">            labels = y_train[j:j + batch_size]</span><br><span class="line"></span><br><span class="line">            scores = module.forward(data)</span><br><span class="line">            loss = criterion(scores, labels.squeeze())</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            # 反向传播</span><br><span class="line">            loss.backward()</span><br><span class="line">            # 梯度更新</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            if j == range_list[-1]:</span><br><span class="line">                loss_list.append(loss.item())</span><br><span class="line"></span><br><span class="line">                accuracy = compute_accuracy(module.forward(x_train), y_train)</span><br><span class="line">                accuracy_list.append(accuracy)</span><br><span class="line">                if accuracy &gt;= bestA:</span><br><span class="line">                    bestA = accuracy</span><br><span class="line">                    bestW, bestB = module.getParameter()</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度&apos;)</span><br><span class="line"></span><br><span class="line">    module.setParameter(bestW, bestB)</span><br><span class="line">    print(bestA)</span><br><span class="line">    print(compute_accuracy(module.forward(x_test), y_test))</span><br></pre></td></tr></table></figure><p>测试结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 测试集精度</span><br><span class="line">0.975</span><br><span class="line"># 验证集精度</span><br><span class="line">1.0</span><br></pre></td></tr></table></figure><p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_advanced_softmax_loss_v2.png" alt></p><p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_advanced_softmax_accuracy_v2.png" alt></p><h2 id="pytorch实现-使用TensorDataset和DataLoader简化批量数据操作"><a href="#pytorch实现-使用TensorDataset和DataLoader简化批量数据操作" class="headerlink" title="pytorch实现 - 使用TensorDataset和DataLoader简化批量数据操作"></a><code>pytorch</code>实现 - 使用<code>TensorDataset</code>和<code>DataLoader</code>简化批量数据操作</h2><p><code>pytorch.util.data</code>包提供了类<code>TensorDataset</code>和<code>DataLoader</code>，用于批量加载数据</p><p><code>TensorDataset</code>是一个数据集包装类；<code>DataLoader</code>是一个数据加载类，能够实现批量采样、数据打乱</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 包装数据集和标记</span><br><span class="line">dataset = TensorDataset(x_train, y_train)</span><br><span class="line"># 加载包装类，设置批量和打乱数据</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)</span><br><span class="line"># 获取批量数据个数</span><br><span class="line">batch_len = dataloader.__len__()</span><br><span class="line"># 依次获取批量数据</span><br><span class="line">for j, items in enumerate(dataloader, 0):</span><br><span class="line">    data, labels = items</span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from torch.utils.data import TensorDataset</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn import utils</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/iris-species/Iris.csv&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(data_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        data = utils.shuffle(data)</span><br><span class="line"></span><br><span class="line">    species_dict = &#123;</span><br><span class="line">        &apos;Iris-setosa&apos;: 0,</span><br><span class="line">        &apos;Iris-versicolor&apos;: 1,</span><br><span class="line">        &apos;Iris-virginica&apos;: 2</span><br><span class="line">    &#125;</span><br><span class="line">    data[&apos;Species&apos;] = data[&apos;Species&apos;].map(species_dict)</span><br><span class="line"></span><br><span class="line">    data_x = np.array(</span><br><span class="line">        [data[&apos;SepalLengthCm&apos;], data[&apos;SepalWidthCm&apos;], data[&apos;PetalLengthCm&apos;], data[&apos;PetalWidthCm&apos;]]).T</span><br><span class="line">    data_y = data[&apos;Species&apos;]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=False)</span><br><span class="line"></span><br><span class="line">    y_train = np.atleast_2d(y_train).T</span><br><span class="line">    y_test = np.atleast_2d(y_test).T</span><br><span class="line"></span><br><span class="line">    return torch.from_numpy(x_train).float(), torch.from_numpy(x_test).float(), torch.from_numpy(</span><br><span class="line">        y_train), torch.from_numpy(y_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(scores, Y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param scores: (m,k)</span><br><span class="line">    :param Y: (m,1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    predictions = torch.argmax(scores, dim=1)</span><br><span class="line">    res = (predictions == Y.squeeze())</span><br><span class="line">    return 1.0 * torch.sum(res).item() / scores.size()[0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(res_list, title=None, xlabel=None):</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    if xlabel is not None:</span><br><span class="line">        plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(res_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class SoftmaxModule(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, inputs, outputs):</span><br><span class="line">        super(SoftmaxModule, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(inputs, outputs)</span><br><span class="line">        self.softmax = nn.LogSoftmax()</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        x = self.linear.forward(input)</span><br><span class="line">        x = self.softmax.forward(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def getParameter(self):</span><br><span class="line">        return self.linear.weight, self.linear.bias</span><br><span class="line"></span><br><span class="line">    def setParameter(self, weight, bias):</span><br><span class="line">        self.linear.weight = nn.Parameter(weight)</span><br><span class="line">        self.linear.bias = nn.Parameter(bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient_descent(batch_size=8, epoches=2000, alpha=2e-4):</span><br><span class="line">    x_train, x_test, y_train, y_test = load_data()</span><br><span class="line"></span><br><span class="line">    m, n = x_train.size()[:2]</span><br><span class="line">    k = 3</span><br><span class="line">    # print(m, n, k)</span><br><span class="line"></span><br><span class="line">    # softmax模型</span><br><span class="line">    module = SoftmaxModule(n, k)</span><br><span class="line">    # 损失函数</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    # 优化器</span><br><span class="line">    optimizer = optim.SGD(module.parameters(), lr=alpha)</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestW = None</span><br><span class="line">    bestB = None</span><br><span class="line">    bestA = 0</span><br><span class="line"></span><br><span class="line">    dataset = TensorDataset(x_train, y_train)</span><br><span class="line">    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)</span><br><span class="line">    batch_len = dataloader.__len__()</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j, items in enumerate(dataloader, 0):</span><br><span class="line">            data, labels = items</span><br><span class="line"></span><br><span class="line">            scores = module.forward(data)</span><br><span class="line">            loss = criterion(scores, labels.squeeze())</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            # 反向传播</span><br><span class="line">            loss.backward()</span><br><span class="line">            # 梯度更新</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            if j == (batch_len - 1):</span><br><span class="line">                loss_list.append(loss.item())</span><br><span class="line">                accuracy = compute_accuracy(module.forward(x_train), y_train)</span><br><span class="line">                accuracy_list.append(accuracy)</span><br><span class="line">                if accuracy &gt;= bestA:</span><br><span class="line">                    bestA = accuracy</span><br><span class="line">                    bestW, bestB = module.getParameter()</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度&apos;)</span><br><span class="line"></span><br><span class="line">    module.setParameter(bestW, bestB)</span><br><span class="line">    print(bestA)</span><br><span class="line">    print(compute_accuracy(module.forward(x_test), y_test))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    compute_gradient_descent(batch_size=8, epoches=50000)</span><br></pre></td></tr></table></figure><p>测试结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 测试集精度</span><br><span class="line">0.975</span><br><span class="line"># 验证集精度</span><br><span class="line">1.0</span><br></pre></td></tr></table></figure><p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_advanced_softmax_loss_v3.png" alt></p><p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_advanced_softmax_accuracy_v3.png" alt></p></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';"> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/images/wechatpay.jpg" alt="zhujian 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/images/alipay.jpg" alt="zhujian 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zhujian</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zhujian.tech/posts/1c195604.html" title="从numpy到pytorch实现softmax回归">https://www.zhujian.tech/posts/1c195604.html</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/python/" rel="tag"># python</a> <a href="/tags/pytorch/" rel="tag"># pytorch</a> <a href="/tags/numpy/" rel="tag"># numpy</a> <a href="/tags/matplotlib/" rel="tag"># matplotlib</a> <a href="/tags/sklearn/" rel="tag"># sklearn</a> <a href="/tags/pandas/" rel="tag"># pandas</a> <a href="/tags/softmax/" rel="tag"># softmax</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/posts/2626bec3.html" rel="next" title="softmax回归"><i class="fa fa-chevron-left"></i> softmax回归</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/posts/dd673751.html" rel="prev" title="使用softmax回归进行mnist分类">使用softmax回归进行mnist分类<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div><div class="comments" id="gitalk-container"></div></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#numpy实现"><span class="nav-number">1.</span> <span class="nav-text">numpy实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pytorch实现-基本数学运算函数"><span class="nav-number">2.</span> <span class="nav-text">pytorch实现 - 基本数学运算函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pytorch实现-使用nn包优化softmax回归模型和损失函数"><span class="nav-number">3.</span> <span class="nav-text">pytorch实现 - 使用nn包优化softmax回归模型和损失函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pytorch实现-使用优化器和自定义softmax实现类"><span class="nav-number">4.</span> <span class="nav-text">pytorch实现 - 使用优化器和自定义softmax实现类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pytorch实现-使用TensorDataset和DataLoader简化批量数据操作"><span class="nav-number">5.</span> <span class="nav-text">pytorch实现 - 使用TensorDataset和DataLoader简化批量数据操作</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zhujian" src="/images/avatar.png"><p class="site-author-name" itemprop="name">zhujian</p><div class="site-description" itemprop="description">one bite at a time</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">169</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">48</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">129</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="feed-link motion-element"><a href="/./atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zjZSTU" title="Github &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;zjZSTU" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/u012005313" title="CSDN &amp;rarr; https:&#x2F;&#x2F;blog.csdn.net&#x2F;u012005313" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i> CSDN</a></span><span class="links-of-author-item"><a href="/mailto:zjzstu@gmail.com" title="Gmail &amp;rarr; mailto:zjzstu@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> Gmail</a></span><span class="links-of-author-item"><a href="/mailto:505169307@gmail.com" title="QQmail &amp;rarr; mailto:505169307@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> QQmail</a></span></div><div class="cc-license motion-element" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://cloud.tencent.com/" title="https:&#x2F;&#x2F;cloud.tencent.com" rel="noopener" target="_blank">腾讯云</a></li><li class="links-of-blogroll-item"> <a href="https://www.aliyun.com/" title="https:&#x2F;&#x2F;www.aliyun.com" rel="noopener" target="_blank">阿里云</a></li><li class="links-of-blogroll-item"> <a href="https://developer.android.com/" title="https:&#x2F;&#x2F;developer.android.com&#x2F;" rel="noopener" target="_blank">Android Dev</a></li><li class="links-of-blogroll-item"> <a href="https://jenkins.io/" title="https:&#x2F;&#x2F;jenkins.io&#x2F;" rel="noopener" target="_blank">Jenkins</a></li><li class="links-of-blogroll-item"> <a href="http://cs231n.github.io/" title="http:&#x2F;&#x2F;cs231n.github.io&#x2F;" rel="noopener" target="_blank">cs231n</a></li><li class="links-of-blogroll-item"> <a href="https://pytorch.org/docs/stable/index.html" title="https:&#x2F;&#x2F;pytorch.org&#x2F;docs&#x2F;stable&#x2F;index.html" rel="noopener" target="_blank">pytorch</a></li><li class="links-of-blogroll-item"> <a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/" title="https:&#x2F;&#x2F;docs.docker.com&#x2F;install&#x2F;linux&#x2F;docker-ce&#x2F;ubuntu&#x2F;" rel="noopener" target="_blank">docker</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2020</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">zhujian</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span> <span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">948k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">26:20</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-bar-chart-o"></i></span> <a href="https://tongji.baidu.com/web/27249108/overview/index?siteId=13647183" rel="noopener" target="_blank">百度统计</a></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0</div> <span class="post-meta-divider">|</span><div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.5.0</div><div class="beian"> <a href="http://www.beian.miit.gov.cn/" rel="noopener" target="_blank">浙ICP备 19026415号</a> <span class="post-meta-divider">|</span> <img src="/images/beian_icon.png" style="display:inline-block;text-decoration:none;height:13px"> <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33011802001748" rel="noopener" target="_blank">浙公网安备 33011802001748号</a></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span> <span class="site-uv" title="总访客量">访客数：<span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="site-pv" title="总访问量">阅读量：<span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script color="17,63,61" opacity="1" zindex="-1" count="199" src="/lib/canvas-nest/canvas-nest.min.js"></script><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '8f22595c6dd29c94467d',
      clientSecret: 'e66bd90ebb9aa66c562c753dec6c90ceecbd51f2',
      repo: 'guestbook',
      owner: 'zjZSTU',
      admin: ['zjZSTU'],
      id: '255b446b09529354e2a508f65bdc0b2d',
        language: '',
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script></body></html>