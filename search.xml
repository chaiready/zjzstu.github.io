<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>迁移学习</title>
    <url>/posts/c7511b44.html</url>
    <content><![CDATA[<p>参考：<a href="http://cs231n.github.io/transfer-learning/" target="_blank" rel="noopener">Transfer Learning</a></p><p>实际训练中很少有网络能够拥有足够大的数据集进行训练，所以迁移学习是实际卷积网络训练过程中非常重要的步骤</p><a id="more"></a>

<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>首先将模型在大数据集（比如<code>ImageNet</code>，包含<code>120</code>万张共<code>1000</code>类的图像）上进行预训练，然后将训练后的模型作为指定数据集的初始化或者固定特征提取器，这一操作称为迁移学习（<code>Transfer Learning</code>）</p>
<h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><p>迁移学习主要有<code>2</code>个适用场景：</p>
<ol>
<li>将卷积网络作为<strong>固定特征提取器</strong>。除了最后的全连接层外，将会冻结所有网络的权重。最后的全连接层将会被一个新的随机初始化的全连接层替代，并且仅训练该层</li>
<li><strong>微调</strong>卷积网络。不使用随机初始化而是用一个预训练网络来初始化网络，就像在<code>ImageNet 1000</code>数据集上训练网络一样，剩下的训练和往常一样。可以微调卷积网络的所有层，或者可以保持一些早期的层固定不变(由于过度拟合的问题)，并且只微调网络的一些较高层部分。这是因为观察到卷积网络的早期特征包含更多通用特征(例如，边缘检测器或颜色斑点检测器)，这些特征对许多任务都很有用，但是卷积网络的顶层对于原始数据集中包含的类的细节变得越来越具体。例如，在包含许多犬种的<code>ImageNet</code>的情况下，卷积网络的很大一部分表示能力可以用于区分犬种的特定特性</li>
</ol>
<h2 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h2><ul>
<li><code>Caffe</code>训练的卷积网络可以在<a href="https://github.com/BVLC/caffe/wiki/Model-Zoo" target="_blank" rel="noopener">Model Zoo</a>上进行分享</li>
<li><code>PyTorch</code>在<code>torchvision.models</code>中提供了多个网络及其预训练模型</li>
</ul>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>参考：<a href="https://zhujian.tech/posts/c8566254.html" target="_blank" rel="noopener">[译]Transfer Learning for Computer Vision Tutorial</a></p>
<p>使用网络<code>ResNet18</code>对小数据集（只有蚂蚁和蜜蜂两类，每类有约<code>120</code>张训练图片和<code>75</code>张测试图片）进行识别，比较随机初始化参数、使用预训练模型作为固定特征提取器以及微调网络的差异</p>
<p><img src="/imgs/transfer-learning/data.png" alt></p>
<h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><p>下载<a href="https://download.pytorch.org/tutorial/hymenoptera_data.zip" target="_blank" rel="noopener">数据集</a>，保存并解压到<code>data</code>文件夹</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">├── data</span><br><span class="line">│   ├── hymenoptera_data</span><br><span class="line">│   └── hymenoptera_data.zip</span><br></pre></td></tr></table></figure>
<ul>
<li>训练阶段。随机裁剪图片并缩放至<code>224x224</code>大小，同时进行随机水平翻转，最后进行数据标准化操作</li>
<li>测试阶段。缩放图片至<code>256x256</code>大小，从中心裁剪<code>224x224</code>大小，最后进行数据标准化操作</li>
<li>批量大小：<code>4</code></li>
</ul>
<h3 id="训练参数"><a href="#训练参数" class="headerlink" title="训练参数"></a>训练参数</h3><ul>
<li>网络：<code>ResNet18</code></li>
<li>反向传播：随机梯度下降（<code>SGD</code>）</li>
<li>学习率：<code>1e-3</code></li>
<li>动量：<code>0.9</code></li>
<li>学习率调度器：随步长衰减，每<code>7</code>轮迭代衰减一次，<code>gamma=0.1</code></li>
</ul>
<h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   finetune.py</span><br><span class="line">@time:   2020-02-26</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import time</span><br><span class="line">import copy</span><br><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import torchvision</span><br><span class="line">import torchvision.datasets as datasets</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">import torchvision.models as models</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def imshow(inp, title=None):</span><br><span class="line">    &quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;</span><br><span class="line">    inp = inp.numpy().transpose((1, 2, 0))</span><br><span class="line">    mean = np.array([0.485, 0.456, 0.406])</span><br><span class="line">    std = np.array([0.229, 0.224, 0.225])</span><br><span class="line">    inp = std * inp + mean</span><br><span class="line">    inp = np.clip(inp, 0, 1)</span><br><span class="line">    plt.imshow(inp)</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    plt.pause(0.001)  # pause a bit so that plots are updated</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data():</span><br><span class="line">    # Data augmentation and normalization for training</span><br><span class="line">    # Just normalization for validation</span><br><span class="line">    # 进行数据扩充</span><br><span class="line">    data_transforms = &#123;</span><br><span class="line">        &apos;train&apos;: transforms.Compose([</span><br><span class="line">            transforms.RandomResizedCrop(224),</span><br><span class="line">            transforms.RandomHorizontalFlip(),</span><br><span class="line">            transforms.ToTensor(),</span><br><span class="line">            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])</span><br><span class="line">        ]),</span><br><span class="line">        &apos;val&apos;: transforms.Compose([</span><br><span class="line">            transforms.Resize(256),</span><br><span class="line">            transforms.CenterCrop(224),</span><br><span class="line">            transforms.ToTensor(),</span><br><span class="line">            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])</span><br><span class="line">        ]),</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    data_dir = &apos;data/hymenoptera_data&apos;</span><br><span class="line">    image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])</span><br><span class="line">                      for x in [&apos;train&apos;, &apos;val&apos;]&#125;</span><br><span class="line">    dataloaders = &#123;x: DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4)</span><br><span class="line">                   for x in [&apos;train&apos;, &apos;val&apos;]&#125;</span><br><span class="line">    dataset_sizes = &#123;x: len(image_datasets[x]) for x in [&apos;train&apos;, &apos;val&apos;]&#125;</span><br><span class="line">    class_names = image_datasets[&apos;train&apos;].classes</span><br><span class="line"></span><br><span class="line">    return dataloaders, dataset_sizes, class_names</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def show_data(dataloaders):</span><br><span class="line">    # 可视化数据集</span><br><span class="line">    # Get a batch of training data</span><br><span class="line">    inputs, classes = next(iter(dataloaders[&apos;train&apos;]))</span><br><span class="line">    # Make a grid from batch</span><br><span class="line">    # 制作图像网格</span><br><span class="line">    out = torchvision.utils.make_grid(inputs)</span><br><span class="line">    imshow(out, title=[class_names[x] for x in classes])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def visualize_model(model, dataloaders, class_names, num_images=6):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    可视化模型训练结果</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    was_training = model.training</span><br><span class="line">    model.eval()</span><br><span class="line">    images_so_far = 0</span><br><span class="line">    fig = plt.figure()</span><br><span class="line"></span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for i, (inputs, labels) in enumerate(dataloaders[&apos;val&apos;]):</span><br><span class="line">            inputs = inputs.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            _, preds = torch.max(outputs, 1)</span><br><span class="line"></span><br><span class="line">            for j in range(inputs.size()[0]):</span><br><span class="line">                images_so_far += 1</span><br><span class="line">                ax = plt.subplot(num_images // 2, 2, images_so_far)</span><br><span class="line">                ax.axis(&apos;off&apos;)</span><br><span class="line">                ax.set_title(&apos;predicted: &#123;&#125;&apos;.format(class_names[preds[j]]))</span><br><span class="line">                imshow(inputs.cpu().data[j])</span><br><span class="line"></span><br><span class="line">                if images_so_far == num_images:</span><br><span class="line">                    model.train(mode=was_training)</span><br><span class="line">                    return</span><br><span class="line">        model.train(mode=was_training)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def visualize_train():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    可视化训练损失和精度</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_model(mode=&apos;ri&apos;):</span><br><span class="line">    if mode == &apos;fixed&apos;:</span><br><span class="line">        model_conv = torchvision.models.resnet18(pretrained=True)</span><br><span class="line">        for param in model_conv.parameters():</span><br><span class="line">            param.requires_grad = False</span><br><span class="line">        return model_conv</span><br><span class="line">    elif mode == &apos;ft&apos;:</span><br><span class="line">        return models.resnet18(pretrained=True)</span><br><span class="line">    else:</span><br><span class="line">        return models.resnet18()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def train_model(model, criterion, optimizer, scheduler, dataset_sizes, dataloaders, num_epochs=25):</span><br><span class="line">    since = time.time()</span><br><span class="line"></span><br><span class="line">    best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line">    best_acc = 0.0</span><br><span class="line"></span><br><span class="line">    for epoch in range(num_epochs):</span><br><span class="line">        print(&apos;Epoch &#123;&#125;/&#123;&#125;&apos;.format(epoch, num_epochs - 1))</span><br><span class="line">        print(&apos;-&apos; * 10)</span><br><span class="line"></span><br><span class="line">        # Each epoch has a training and validation phase</span><br><span class="line">        for phase in [&apos;train&apos;, &apos;val&apos;]:</span><br><span class="line">            if phase == &apos;train&apos;:</span><br><span class="line">                model.train()  # Set model to training mode</span><br><span class="line">            else:</span><br><span class="line">                model.eval()  # Set model to evaluate mode</span><br><span class="line"></span><br><span class="line">            running_loss = 0.0</span><br><span class="line">            running_corrects = 0</span><br><span class="line"></span><br><span class="line">            # Iterate over data.</span><br><span class="line">            for inputs, labels in dataloaders[phase]:</span><br><span class="line">                inputs = inputs.to(device)</span><br><span class="line">                labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">                # zero the parameter gradients</span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">                # forward</span><br><span class="line">                # track history if only in train</span><br><span class="line">                with torch.set_grad_enabled(phase == &apos;train&apos;):</span><br><span class="line">                    outputs = model(inputs)</span><br><span class="line">                    _, preds = torch.max(outputs, 1)</span><br><span class="line">                    loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">                    # backward + optimize only if in training phase</span><br><span class="line">                    if phase == &apos;train&apos;:</span><br><span class="line">                        loss.backward()</span><br><span class="line">                        optimizer.step()</span><br><span class="line"></span><br><span class="line">                # statistics</span><br><span class="line">                running_loss += loss.item() * inputs.size(0)</span><br><span class="line">                running_corrects += torch.sum(preds == labels.data)</span><br><span class="line">            if phase == &apos;train&apos;:</span><br><span class="line">                scheduler.step()</span><br><span class="line"></span><br><span class="line">            epoch_loss = running_loss / dataset_sizes[phase]</span><br><span class="line">            epoch_acc = running_corrects.double() / dataset_sizes[phase]</span><br><span class="line"></span><br><span class="line">            print(&apos;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&apos;.format(</span><br><span class="line">                phase, epoch_loss, epoch_acc))</span><br><span class="line"></span><br><span class="line">            # deep copy the model</span><br><span class="line">            if phase == &apos;val&apos; and epoch_acc &gt; best_acc:</span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line"></span><br><span class="line">        print()</span><br><span class="line"></span><br><span class="line">    time_elapsed = time.time() - since</span><br><span class="line">    print(&apos;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&apos;.format(</span><br><span class="line">        time_elapsed // 60, time_elapsed % 60))</span><br><span class="line">    print(&apos;Best val Acc: &#123;:4f&#125;&apos;.format(best_acc))</span><br><span class="line"></span><br><span class="line">    # load best model weights</span><br><span class="line">    model.load_state_dict(best_model_wts)</span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line"></span><br><span class="line">    dataloaders, dataset_sizes, class_names = load_data()</span><br><span class="line">    show_data(dataloaders)</span><br><span class="line"></span><br><span class="line">    for mode_name in &#123;&apos;ri&apos;, &apos;ft&apos;, &apos;fixed&apos;&#125;:</span><br><span class="line">        print(&apos;begin mode: %s&apos; % mode_name)</span><br><span class="line">        print(&apos;#&apos; * 20)</span><br><span class="line">        # 创建网络模型，指定参数初始化方式</span><br><span class="line">        model = create_model(mode=mode_name)</span><br><span class="line">        # model = create_model(mode=&apos;ri&apos;)</span><br><span class="line">        # model = create_model(mode=&apos;ft&apos;)</span><br><span class="line">        # model = create_model(mode=&apos;fixed&apos;)</span><br><span class="line"></span><br><span class="line">        num_ftrs = model.fc.in_features</span><br><span class="line">        # Here the size of each output sample is set to 2.</span><br><span class="line">        # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).</span><br><span class="line">        model.fc = nn.Linear(num_ftrs, 2)</span><br><span class="line"></span><br><span class="line">        model_conv = model.to(device)</span><br><span class="line">        criterion = nn.CrossEntropyLoss()</span><br><span class="line">        # Observe that all parameters are being optimized</span><br><span class="line">        # 随机梯度下降</span><br><span class="line">        optimizer_conv = optim.SGD(model_conv.parameters(), lr=0.001, momentum=0.9)</span><br><span class="line">        # Decay LR by a factor of 0.1 every 7 epochs</span><br><span class="line">        # 随步长衰减</span><br><span class="line">        exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)</span><br><span class="line"></span><br><span class="line">        model_conv = train_model(model_conv, criterion,</span><br><span class="line">                                 optimizer_conv,</span><br><span class="line">                                 exp_lr_scheduler,</span><br><span class="line">                                 dataset_sizes,</span><br><span class="line">                                 dataloaders,</span><br><span class="line">                                 num_epochs=25)</span><br><span class="line"></span><br><span class="line">        # visualize_model(model_conv, dataloaders, class_names, num_images=6)</span><br></pre></td></tr></table></figure>
<h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><p>分别用<code>3</code>种不同的权重处理方式（随机初始化、微调、固定特征提取器）进行训练，共迭代<code>25</code>次，结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">begin mode: ri</span><br><span class="line">####################</span><br><span class="line">...</span><br><span class="line">Training complete in 0m 39s</span><br><span class="line">Best val Acc: 0.725490</span><br><span class="line">begin mode: ft</span><br><span class="line">####################</span><br><span class="line">...</span><br><span class="line">Training complete in 0m 40s</span><br><span class="line">Best val Acc: 0.941176</span><br><span class="line">begin mode: fixed</span><br><span class="line">####################</span><br><span class="line">...</span><br><span class="line">Training complete in 0m 26s</span><br><span class="line">Best val Acc: 0.960784</span><br></pre></td></tr></table></figure>
<p>从训练结果中发现，使用迁移学习后的网络模型能够得到更好的训练结果</p>
<h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><p>在何种情况下进行迁移学习的使用，最大的因素有两个：</p>
<ul>
<li>新数据集的规模</li>
<li>新数据集与原先数据集的相似程度</li>
</ul>
<p>根据以上两个因素共分为<code>4</code>个使用场景：</p>
<ol>
<li>新数据集很小，与原始数据集相似。由于数据集很小，存在过拟合的问题，所以微调卷积网络不是一个好主意；由于数据与原始数据相似，卷积网络中的高级特征也与此数据集相关。最好的办法就是<strong>使用固定特征提取器的方式，再训练一个线性分类器</strong></li>
<li>新数据集很大，与原始数据集相似。因为有更多的数据，所以对整个网络进行<strong>微调</strong>也不会产生过拟合</li>
<li>新数据集很小，与原始数据集非常不同。因为数据很小，所以使用固定特征提取器的方式，再训练一个线性分类器。由于数据集有很大的不同，所以不能从包含更多数据集特定特征的网络顶部来训练分类器，而是<strong>固定网络早期权重，微调网络顶部权重的方式来训练线性分类器</strong></li>
<li>新数据集很大，与原始数据集非常不同。由于数据集非常大，能够从头开始训练一个卷积网络。但是在实践中，用来自预训练模型的权重初始化仍然非常有效。在这种情况下，将有足够的数据和信心通过整个网络进行<strong>微调</strong></li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>最优化</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>torchvision</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]Transfer Learning for Computer Vision Tutorial</title>
    <url>/posts/c8566254.html</url>
    <content><![CDATA[<blockquote>
<p>In this tutorial, you will learn how to train a convolutional neural network for image classification using transfer learning. You can read more about the transfer learning at cs231n notes</p>
</blockquote><a id="more"></a>
<p>在本教程中，您将学习如何使用迁移学习来训练用于图像分类的卷积神经网络。您可以在<a href="https://cs231n.github.io/transfer-learning/" target="_blank" rel="noopener">cs231n notes</a>上阅读更多关于迁移学习的信息</p>
<blockquote>
<p>Quoting these notes,</p>
<blockquote>
<p>In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.</p>
</blockquote>
</blockquote>
<p>引用</p>
<p>实际上，很少有人从头开始训练整个卷积网络(随机初始化)，因为拥有足够大的数据集是相对罕见的。相反，通常在非常大的数据集(例如，包含120万张1000个类别的图像的ImageNet)上预处理ConvNet，然后将ConvNet用作感兴趣任务的初始化或固定特征提取器</p>
<blockquote>
<p>These two major transfer learning scenarios look as follows:</p>
<ul>
<li>Finetuning the convnet: Instead of random initializaion, we initialize the network with a pretrained network, like the one that is trained on imagenet 1000 dataset. Rest of the training looks as usual.</li>
<li>ConvNet as fixed feature extractor: Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained.</li>
</ul>
</blockquote>
<p>这两个主要的迁移学习场景如下:</p>
<ul>
<li>微调网络：不使用随机初始化而是用一个预训练网络来初始化网络，就像在imagenet 1000数据集上训练的网络一样。剩下的训练看起来和往常一样</li>
<li>卷积网络作为固定的特征提取器：除了最后的全连接层外，将会冻结所有网络的权重。最后的全连接层将会被一个新的随机初始化的全连接层替代，并且仅训练该层</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># License: BSD</span><br><span class="line"># Author: Sasank Chilamkurthy</span><br><span class="line"></span><br><span class="line">from __future__ import print_function, division</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from torch.optim import lr_scheduler</span><br><span class="line">import numpy as np</span><br><span class="line">import torchvision</span><br><span class="line">from torchvision import datasets, models, transforms</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import time</span><br><span class="line">import os</span><br><span class="line">import copy</span><br><span class="line"></span><br><span class="line">plt.ion()   # interactive mode</span><br></pre></td></tr></table></figure>
<h2 id="Load-Data"><a href="#Load-Data" class="headerlink" title="Load Data"></a>Load Data</h2><p>加载数据</p>
<blockquote>
<p>We will use torchvision and torch.utils.data packages for loading the data.</p>
</blockquote>
<p>我们使用torchvision和torch.util.data包来加载数据</p>
<blockquote>
<p>The problem we’re going to solve today is to train a model to classify ants and bees. We have about 120 training images each for ants and bees. There are 75 validation images for each class. Usually, this is a very small dataset to generalize upon, if trained from scratch. Since we are using transfer learning, we should be able to generalize reasonably well.</p>
</blockquote>
<p>要解决的问题是训练一个分类蚂蚁和蜜蜂的模型，分别有大约120张蚂蚁和蜜蜂的训练图片，并且每个类还有75张验证图像。通常来说这是一个非常小的数据集，如果从零开始训练的话会导致无法收敛。而使用迁移学习，应该能够得到相当好的泛化结果</p>
<blockquote>
<p>This dataset is a very small subset of imagenet.</p>
</blockquote>
<p>本数据集是imagenet的一个非常小的子集</p>
<blockquote>
<p>Note: Download the data from here and extract it to the current directory.</p>
</blockquote>
<p>注意：下载<a href="https://download.pytorch.org/tutorial/hymenoptera_data.zip" target="_blank" rel="noopener">数据</a>并提取到当前文件夹</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Data augmentation and normalization for training</span><br><span class="line"># Just normalization for validation</span><br><span class="line">data_transforms = &#123;</span><br><span class="line">    &apos;train&apos;: transforms.Compose([</span><br><span class="line">        transforms.RandomResizedCrop(224),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])</span><br><span class="line">    ]),</span><br><span class="line">    &apos;val&apos;: transforms.Compose([</span><br><span class="line">        transforms.Resize(256),</span><br><span class="line">        transforms.CenterCrop(224),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])</span><br><span class="line">    ]),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data_dir = &apos;data/hymenoptera_data&apos;</span><br><span class="line">image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x),</span><br><span class="line">                                          data_transforms[x])</span><br><span class="line">                  for x in [&apos;train&apos;, &apos;val&apos;]&#125;</span><br><span class="line">dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,</span><br><span class="line">                                             shuffle=True, num_workers=4)</span><br><span class="line">              for x in [&apos;train&apos;, &apos;val&apos;]&#125;</span><br><span class="line">dataset_sizes = &#123;x: len(image_datasets[x]) for x in [&apos;train&apos;, &apos;val&apos;]&#125;</span><br><span class="line">class_names = image_datasets[&apos;train&apos;].classes</span><br><span class="line"></span><br><span class="line">device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br></pre></td></tr></table></figure>
<h2 id="Visualize-a-few-images"><a href="#Visualize-a-few-images" class="headerlink" title="Visualize a few images"></a>Visualize a few images</h2><p>可视化图像</p>
<blockquote>
<p>Let’s visualize a few training images so as to understand the data augmentations.</p>
</blockquote>
<p>可视化小部分训练图像，以便理解数据扩充</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def imshow(inp, title=None):</span><br><span class="line">    &quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;</span><br><span class="line">    inp = inp.numpy().transpose((1, 2, 0))</span><br><span class="line">    mean = np.array([0.485, 0.456, 0.406])</span><br><span class="line">    std = np.array([0.229, 0.224, 0.225])</span><br><span class="line">    inp = std * inp + mean</span><br><span class="line">    inp = np.clip(inp, 0, 1)</span><br><span class="line">    plt.imshow(inp)</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    plt.pause(0.001)  # pause a bit so that plots are updated</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Get a batch of training data</span><br><span class="line">inputs, classes = next(iter(dataloaders[&apos;train&apos;]))</span><br><span class="line"></span><br><span class="line"># Make a grid from batch</span><br><span class="line">out = torchvision.utils.make_grid(inputs)</span><br><span class="line"></span><br><span class="line">imshow(out, title=[class_names[x] for x in classes])</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/译-transfer-learning/sphx_glr_transfer_learning_tutorial_001.png" alt></p>
<h2 id="Training-the-model"><a href="#Training-the-model" class="headerlink" title="Training the model"></a>Training the model</h2><p>训练模型</p>
<blockquote>
<p>Now, let’s write a general function to train a model. Here, we will illustrate:</p>
<ul>
<li>Scheduling the learning rate</li>
<li>Saving the best model</li>
</ul>
</blockquote>
<p>现在，让我们编写一个通用函数来训练一个模型。将实现以下功能：</p>
<ul>
<li>调度学习率</li>
<li>保存最佳模型</li>
</ul>
<blockquote>
<p>In the following, parameter scheduler is an LR scheduler object from torch.optim.lr_scheduler.</p>
</blockquote>
<p>下面代码中，参数scheduler是来自于包torch.optim.lr_scheduler的学习率调度器对象</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def train_model(model, criterion, optimizer, scheduler, num_epochs=25):</span><br><span class="line">    since = time.time()</span><br><span class="line"></span><br><span class="line">    best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line">    best_acc = 0.0</span><br><span class="line"></span><br><span class="line">    for epoch in range(num_epochs):</span><br><span class="line">        print(&apos;Epoch &#123;&#125;/&#123;&#125;&apos;.format(epoch, num_epochs - 1))</span><br><span class="line">        print(&apos;-&apos; * 10)</span><br><span class="line"></span><br><span class="line">        # Each epoch has a training and validation phase</span><br><span class="line">        for phase in [&apos;train&apos;, &apos;val&apos;]:</span><br><span class="line">            if phase == &apos;train&apos;:</span><br><span class="line">                model.train()  # Set model to training mode</span><br><span class="line">            else:</span><br><span class="line">                model.eval()   # Set model to evaluate mode</span><br><span class="line"></span><br><span class="line">            running_loss = 0.0</span><br><span class="line">            running_corrects = 0</span><br><span class="line"></span><br><span class="line">            # Iterate over data.</span><br><span class="line">            for inputs, labels in dataloaders[phase]:</span><br><span class="line">                inputs = inputs.to(device)</span><br><span class="line">                labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">                # zero the parameter gradients</span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">                # forward</span><br><span class="line">                # track history if only in train</span><br><span class="line">                with torch.set_grad_enabled(phase == &apos;train&apos;):</span><br><span class="line">                    outputs = model(inputs)</span><br><span class="line">                    _, preds = torch.max(outputs, 1)</span><br><span class="line">                    loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">                    # backward + optimize only if in training phase</span><br><span class="line">                    if phase == &apos;train&apos;:</span><br><span class="line">                        loss.backward()</span><br><span class="line">                        optimizer.step()</span><br><span class="line"></span><br><span class="line">                # statistics</span><br><span class="line">                running_loss += loss.item() * inputs.size(0)</span><br><span class="line">                running_corrects += torch.sum(preds == labels.data)</span><br><span class="line">            if phase == &apos;train&apos;:</span><br><span class="line">                scheduler.step()</span><br><span class="line"></span><br><span class="line">            epoch_loss = running_loss / dataset_sizes[phase]</span><br><span class="line">            epoch_acc = running_corrects.double() / dataset_sizes[phase]</span><br><span class="line"></span><br><span class="line">            print(&apos;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&apos;.format(</span><br><span class="line">                phase, epoch_loss, epoch_acc))</span><br><span class="line"></span><br><span class="line">            # deep copy the model</span><br><span class="line">            if phase == &apos;val&apos; and epoch_acc &gt; best_acc:</span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line"></span><br><span class="line">        print()</span><br><span class="line"></span><br><span class="line">    time_elapsed = time.time() - since</span><br><span class="line">    print(&apos;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&apos;.format(</span><br><span class="line">        time_elapsed // 60, time_elapsed % 60))</span><br><span class="line">    print(&apos;Best val Acc: &#123;:4f&#125;&apos;.format(best_acc))</span><br><span class="line"></span><br><span class="line">    # load best model weights</span><br><span class="line">    model.load_state_dict(best_model_wts)</span><br><span class="line">    return model</span><br></pre></td></tr></table></figure>
<h2 id="Visualizing-the-model-predictions"><a href="#Visualizing-the-model-predictions" class="headerlink" title="Visualizing the model predictions"></a>Visualizing the model predictions</h2><p>可视化模型预测</p>
<blockquote>
<p>Generic function to display predictions for a few images</p>
</blockquote>
<p>显示图像预测的通用函数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def visualize_model(model, num_images=6):</span><br><span class="line">    was_training = model.training</span><br><span class="line">    model.eval()</span><br><span class="line">    images_so_far = 0</span><br><span class="line">    fig = plt.figure()</span><br><span class="line"></span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for i, (inputs, labels) in enumerate(dataloaders[&apos;val&apos;]):</span><br><span class="line">            inputs = inputs.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            _, preds = torch.max(outputs, 1)</span><br><span class="line"></span><br><span class="line">            for j in range(inputs.size()[0]):</span><br><span class="line">                images_so_far += 1</span><br><span class="line">                ax = plt.subplot(num_images//2, 2, images_so_far)</span><br><span class="line">                ax.axis(&apos;off&apos;)</span><br><span class="line">                ax.set_title(&apos;predicted: &#123;&#125;&apos;.format(class_names[preds[j]]))</span><br><span class="line">                imshow(inputs.cpu().data[j])</span><br><span class="line"></span><br><span class="line">                if images_so_far == num_images:</span><br><span class="line">                    model.train(mode=was_training)</span><br><span class="line">                    return</span><br><span class="line">        model.train(mode=was_training)</span><br></pre></td></tr></table></figure>
<h2 id="Finetuning-the-convnet"><a href="#Finetuning-the-convnet" class="headerlink" title="Finetuning the convnet"></a>Finetuning the convnet</h2><p>微调网络</p>
<blockquote>
<p>Load a pretrained model and reset final fully connected layer.</p>
</blockquote>
<p>加载预处理模型并重置最后的全连接层</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">model_ft = models.resnet18(pretrained=True)</span><br><span class="line">num_ftrs = model_ft.fc.in_features</span><br><span class="line"># Here the size of each output sample is set to 2.</span><br><span class="line"># Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).</span><br><span class="line">model_ft.fc = nn.Linear(num_ftrs, 2)</span><br><span class="line"></span><br><span class="line">model_ft = model_ft.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"># Observe that all parameters are being optimized</span><br><span class="line">optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)</span><br><span class="line"></span><br><span class="line"># Decay LR by a factor of 0.1 every 7 epochs</span><br><span class="line">exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)</span><br></pre></td></tr></table></figure>
<h2 id="Train-and-evaluate"><a href="#Train-and-evaluate" class="headerlink" title="Train and evaluate"></a>Train and evaluate</h2><p>训练和评估</p>
<blockquote>
<p>It should take around 15-25 min on CPU. On GPU though, it takes less than a minute.</p>
</blockquote>
<p>在CPU上大约需要15-25分钟。但是在GPU上只需要不到一分钟的时间</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,</span><br><span class="line">                       num_epochs=25)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Out</p>
</blockquote>
<p>输出</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Epoch 0/24</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.5952 Acc: 0.7172</span><br><span class="line">val Loss: 0.2687 Acc: 0.9150</span><br><span class="line"></span><br><span class="line">Epoch 1/24</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.7011 Acc: 0.7172</span><br><span class="line">val Loss: 0.2945 Acc: 0.9216</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">Epoch 23/24</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.2068 Acc: 0.9139</span><br><span class="line">val Loss: 0.2128 Acc: 0.9150</span><br><span class="line"></span><br><span class="line">Epoch 24/24</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.3255 Acc: 0.8443</span><br><span class="line">val Loss: 0.2181 Acc: 0.9085</span><br><span class="line"></span><br><span class="line">Training complete in 1m 7s</span><br><span class="line">Best val Acc: 0.921569</span><br></pre></td></tr></table></figure>
<p>可视化模型</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">visualize_model(model_ft)</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/译-transfer-learning/sphx_glr_transfer_learning_tutorial_002.png" alt></p>
<h2 id="ConvNet-as-fixed-feature-extractor"><a href="#ConvNet-as-fixed-feature-extractor" class="headerlink" title="ConvNet as fixed feature extractor"></a>ConvNet as fixed feature extractor</h2><p>使用卷积网络作为固定的特征提取器</p>
<blockquote>
<p>Here, we need to freeze all the network except the final layer. We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward().</p>
</blockquote>
<p>下面操作中将冻结除最后一层以外的所有网络。通过设置requires_grad == False来冻结参数，这样梯度就不会向后计算</p>
<blockquote>
<p>Here, we need to freeze all the network except the final layer. We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward().</p>
<p>You can read more about this in the documentation here.</p>
</blockquote>
<p>更多关于梯度计算的可参考<a href="https://pytorch.org/docs/master/notes/autograd.html" target="_blank" rel="noopener">Autograd mechanics</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">model_conv = torchvision.models.resnet18(pretrained=True)</span><br><span class="line">for param in model_conv.parameters():</span><br><span class="line">    param.requires_grad = False</span><br><span class="line"></span><br><span class="line"># Parameters of newly constructed modules have requires_grad=True by default</span><br><span class="line">num_ftrs = model_conv.fc.in_features</span><br><span class="line">model_conv.fc = nn.Linear(num_ftrs, 2)</span><br><span class="line"></span><br><span class="line">model_conv = model_conv.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"># Observe that only parameters of final layer are being optimized as</span><br><span class="line"># opposed to before.</span><br><span class="line">optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)</span><br><span class="line"></span><br><span class="line"># Decay LR by a factor of 0.1 every 7 epochs</span><br><span class="line">exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)</span><br></pre></td></tr></table></figure>
<h2 id="Train-and-evaluate-1"><a href="#Train-and-evaluate-1" class="headerlink" title="Train and evaluate"></a>Train and evaluate</h2><p>训练和评估</p>
<blockquote>
<p>On CPU this will take about half the time compared to previous scenario. This is expected as gradients don’t need to be computed for most of the network. However, forward does need to be computed.</p>
</blockquote>
<p>与之前的场景相比，在CPU上这将花费大约一半的时间。这是可预期的，虽然大多数网络不需要计算梯度，但是向前操作确实需要计算</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">model_conv = train_model(model_conv, criterion, optimizer_conv,</span><br><span class="line">                         exp_lr_scheduler, num_epochs=25)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Out:</p>
</blockquote>
<p>输出：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Epoch 0/24</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.5803 Acc: 0.6680</span><br><span class="line">val Loss: 0.3703 Acc: 0.8235</span><br><span class="line"></span><br><span class="line">Epoch 1/24</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.4522 Acc: 0.7869</span><br><span class="line">val Loss: 0.1773 Acc: 0.9346</span><br><span class="line"></span><br><span class="line">Epoch 2/24</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.4594 Acc: 0.8197</span><br><span class="line">val Loss: 0.2089 Acc: 0.9216</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">Epoch 23/24</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.2957 Acc: 0.8525</span><br><span class="line">val Loss: 0.2206 Acc: 0.9281</span><br><span class="line"></span><br><span class="line">Epoch 24/24</span><br><span class="line">----------</span><br><span class="line">train Loss: 0.3527 Acc: 0.8443</span><br><span class="line">val Loss: 0.2230 Acc: 0.9477</span><br><span class="line"></span><br><span class="line">Training complete in 0m 34s</span><br><span class="line">Best val Acc: 0.954248</span><br></pre></td></tr></table></figure>
<p>可视化模型</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">visualize_model(model_conv)</span><br><span class="line"></span><br><span class="line">plt.ioff()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/译-transfer-learning/sphx_glr_transfer_learning_tutorial_003.png" alt></p>
<h2 id="Further-Learning"><a href="#Further-Learning" class="headerlink" title="Further Learning"></a>Further Learning</h2><p>进一步学习</p>
<blockquote>
<p>If you would like to learn more about the applications of transfer learning, checkout our Quantized Transfer Learning for Computer Vision Tutorial.</p>
</blockquote>
<p>如果想要学习更多关于迁移学习，参考<a href="https://pytorch.org/tutorials/intermediate/quantized_transfer_learning_tutorial.html" target="_blank" rel="noopener">Quantized Transfer Learning for Computer Vision Tutorial</a></p>
]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据</category>
        <category>代码库</category>
        <category>数据集</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>torchvision</tag>
      </tags>
  </entry>
  <entry>
    <title>[数据集]Penn-Fudan</title>
    <url>/posts/6c61a203.html</url>
    <content><![CDATA[<p>数据集<a href="https://www.cis.upenn.edu/~jshi/ped_html/" target="_blank" rel="noopener">Penn-Fudan</a>可用于行人检测和分割任务</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><code>Penn-Fudan</code>数据集包含了<code>170</code>张图像共<code>345</code>个标注行人，其中<code>96</code>张来自于宾夕法尼亚大学，<code>74</code>张来自于复旦大学。这些图片表示校园和城市街道周围的场景，每个图像中至少有一个行人</p><a id="more"></a>

<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>行人及其对应的分割掩码如下：</p>
<p><img src="/imgs/penn-fudan/penn-fudan.png" alt></p>
<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>下载地址：<a href="https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip" target="_blank" rel="noopener">Penn-Fudan.zip</a></p>
<p>其标注格式使用<a href="http://www.pascal-network.org/challenges/VOC/PAScode.tar.gz" target="_blank" rel="noopener">PASCAL Version 1.0.0</a></p>
]]></content>
      <categories>
        <category>数据</category>
        <category>数据集</category>
      </categories>
      <tags>
        <tag>Penn-Fudan</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]TorchVision Object Detection Finetuning Tutorial</title>
    <url>/posts/1a1c504e.html</url>
    <content><![CDATA[<p>本文是PyTorch中关于微调CNN的一篇教程，里面利用预训练的Mask R-CNN模型，在PennFudan数据集上进行微调实现</p><a id="more"></a>
<p>原文地址：<a href="https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html" target="_blank" rel="noopener">TorchVision Object Detection Finetuning Tutorial</a></p>
<p>本文章涉及脚本位于仓库<a href="https://github.com/pytorch/vision" target="_blank" rel="noopener">pytorch/vision</a></p>
<blockquote>
<p>For this tutorial, we will be finetuning a pre-trained Mask R-CNN model in the Penn-Fudan Database for Pedestrian Detection and Segmentation. It contains 170 images with 345 instances of pedestrians, and we will use it to illustrate how to use the new features in torchvision in order to train an instance segmentation model on a custom dataset.</p>
</blockquote>
<p>在本教程中，我们将在Penn-Fudan的行人检测和分割数据库中微调一个预先训练好的Mask R-CNN模型。数据库包含170幅共345个行人实例的图像，我们将用它来演示如何使用torchvision的新特性，以便在自定义数据集上训练一个实例分割模型</p>
<h2 id="Defining-the-Dataset"><a href="#Defining-the-Dataset" class="headerlink" title="Defining the Dataset"></a>Defining the Dataset</h2><p>定义数据集</p>
<blockquote>
<p>The reference scripts for training object detection, instance segmentation and person keypoint detection allows for easily supporting adding new custom datasets. The dataset should inherit from the standard <code>torch.utils.data.Dataset</code> class, and implement <code>__len__</code> and <code>__getitem__</code>.</p>
</blockquote>
<p>用于训练目标检测、实例分割和人物关键点检测的参考脚本能够很容易的添加新的定制数据集。数据集应该继承自标准的<code>torch.utils.data.Dataset</code>类，并实现方法<code>__len__</code>和<code>__getitem__</code></p>
<blockquote>
<p>The only specificity that we require is that the dataset <code>__getitem__</code> should return:</p>
<ul>
<li><code>image</code>: a PIL Image of size <code>(H, W)</code></li>
<li><code>target</code>: a dict containing the following fields<ul>
<li><code>boxes (FloatTensor[N, 4])</code>: the coordinates of the N bounding boxes in [x0, y0, x1, y1] format, ranging from 0 to W and 0 to H</li>
<li><code>labels (Int64Tensor[N])</code>: the label for each bounding box</li>
<li><code>image_id (Int64Tensor[1])</code>: an image identifier. It should be unique between all the images in the dataset, and is used during evaluation</li>
<li><code>area (Tensor[N])</code>: The area of the bounding box. This is used during evaluation with the COCO metric, to separate the metric scores between small, medium and large boxes.</li>
<li><code>iscrowd (UInt8Tensor[N])</code>: instances with iscrowd=True will be ignored during evaluation.</li>
<li><code>(optionally) masks (UInt8Tensor[N, H, W])</code>: The segmentation masks for each one of the objects</li>
<li><code>(optionally) keypoints (FloatTensor[N, K, 3])</code>: For each one of the N objects, it contains the K keypoints in [x, y, visibility] format, defining the object. visibility=0 means that the keypoint is not visible. Note that for data augmentation, the notion of flipping a keypoint is dependent on the data representation, and you should probably adapt references/detection/transforms.py for your new keypoint representation</li>
</ul>
</li>
</ul>
</blockquote>
<p>我们唯一需要的特性是数据集<code>__getitem__</code>应该返回:</p>
<ul>
<li><code>image</code>：大小为<code>(H, W)</code>的PIL Image</li>
<li><code>target</code>：包含以下字段的dict<ul>
<li><code>boxes (FloatTensor[N, 4])</code>：N表示边界框数目，4表示边界框格式，分别为[x0, y0, x1, y1]，宽度取值为[0, W]，长度取值为[0, H]</li>
<li><code>labels (Int64Tensor[N])</code>：每个边界框的标签</li>
<li><code>image_id (Int64Tensor[1])</code>：图像标识符</li>
<li><code>area (Tensor[N])</code>：边界框面积。这在使用COCO指标进行评估时使用，用于区分小、中、大框之间的指标得分</li>
<li><code>iscrowd (UInt8Tensor[N])</code>：iscrowd=True的实例将在评估期间被忽略</li>
<li>(可选) <code>masks (UInt8Tensor[N, H, W])</code>：每个目标的分割掩码</li>
<li>(可选) <code>keypoints (FloatTensor[N, K, 3])</code>：对于N个对象中的每一个，它包含[x, y, visibility]格式的K个关键点，用于定义对象。visibility=0表示关键点不可见。注意，对于数据扩充，翻转关键点的概念取决于数据表示，你应该为新的关键点表示调整references/detection/transforms.py</li>
</ul>
</li>
</ul>
<blockquote>
<p>If your model returns the above methods, they will make it work for both training and evaluation, and will use the evaluation scripts from pycocotools.</p>
</blockquote>
<p>自定义的上述方法能够既适用于训练也适用于评估，其中评估使用的是来自pycocotools的评估脚本</p>
<blockquote>
<p>Additionally, if you want to use aspect ratio grouping during training (so that each batch only contains images with similar aspect ratio), then it is recommended to also implement a get_height_and_width method, which returns the height and the width of the image. If this method is not provided, we query all elements of the dataset via <code>__getitem__</code> , which loads the image in memory and is slower than if a custom method is provided.</p>
</blockquote>
<p>此外，如果你希望在训练过程中使用纵横比分组(以便每一批只包含具有相似纵横比的图像)，那么最好实现方法get_height_and_width，该方法返回图像的高度和宽度。如果不提供此方法，我们通过<code>__getitem__</code>查询数据集的所有元素，这会将图像加载到内存中，比自定义方法还要慢</p>
<h2 id="Writing-a-custom-dataset-for-PennFudan"><a href="#Writing-a-custom-dataset-for-PennFudan" class="headerlink" title="Writing a custom dataset for PennFudan"></a>Writing a custom dataset for PennFudan</h2><p>自定义PennFudan数据集类</p>
<blockquote>
<p>Let’s write a dataset for the PennFudan dataset. After downloading and extracting the zip file, we have the following folder structure:</p>
</blockquote>
<p>实现PennFudan数据类，先<a href="https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip" target="_blank" rel="noopener">下载和解压zip文件</a>，其文件结构如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PennFudanPed/</span><br><span class="line">  PedMasks/</span><br><span class="line">    FudanPed00001_mask.png</span><br><span class="line">    FudanPed00002_mask.png</span><br><span class="line">    FudanPed00003_mask.png</span><br><span class="line">    FudanPed00004_mask.png</span><br><span class="line">    ...</span><br><span class="line">  PNGImages/</span><br><span class="line">    FudanPed00001.png</span><br><span class="line">    FudanPed00002.png</span><br><span class="line">    FudanPed00003.png</span><br><span class="line">    FudanPed00004.png</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Here is one example of a pair of images and segmentation masks</p>
</blockquote>
<p>下面是一对图像和分割掩码的示例</p>
<p><img src="/imgs/译-finetune/tv_image02.png" alt></p>
<blockquote>
<p>So each image has a corresponding segmentation mask, where each color correspond to a different instance. Let’s write a torch.utils.data.Dataset class for this dataset.</p>
</blockquote>
<p>每个图像有一个对应的分割掩码，其中不同的颜色表示不同的实例。实现数据类（继承自torch.utils.data.Dataset）如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line">from PIL import Image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class PennFudanDataset(object):</span><br><span class="line">    def __init__(self, root, transforms):</span><br><span class="line">        self.root = root</span><br><span class="line">        self.transforms = transforms</span><br><span class="line"></span><br><span class="line">        # load all image files, sorting them to</span><br><span class="line">        # ensure that they are aligned</span><br><span class="line">        # 通过排序确保图像和掩码文件一一对应</span><br><span class="line">        self.imgs = list(sorted(os.listdir(os.path.join(root, &quot;PNGImages&quot;))))</span><br><span class="line">        self.masks = list(sorted(os.listdir(os.path.join(root, &quot;PedMasks&quot;))))</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, idx):</span><br><span class="line">        # load images ad masks</span><br><span class="line">        # 加载图像和掩码</span><br><span class="line">        img_path = os.path.join(self.root, &quot;PNGImages&quot;, self.imgs[idx])</span><br><span class="line">        mask_path = os.path.join(self.root, &quot;PedMasks&quot;, self.masks[idx])</span><br><span class="line">        img = Image.open(img_path).convert(&quot;RGB&quot;)</span><br><span class="line">        # note that we haven&apos;t converted the mask to RGB,</span><br><span class="line">        # because each color corresponds to a different instance</span><br><span class="line">        # with 0 being background</span><br><span class="line">        # 其实也可以使用cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">        mask = Image.open(mask_path)</span><br><span class="line">        # convert the PIL Image into a numpy array</span><br><span class="line">        mask = np.array(mask)</span><br><span class="line">        # instances are encoded as different colors</span><br><span class="line">        obj_ids = np.unique(mask)</span><br><span class="line">        # first id is the background, so remove it</span><br><span class="line">        # 第一个表示</span><br><span class="line">        obj_ids = obj_ids[1:]</span><br><span class="line"></span><br><span class="line">        # split the color-encoded mask into a set</span><br><span class="line">        # of binary masks</span><br><span class="line">        # 针对不同的行人实例创建对应的掩码</span><br><span class="line">        masks = mask == obj_ids[:, None, None]</span><br><span class="line"></span><br><span class="line">        # get bounding box coordinates for each mask</span><br><span class="line">        # 计算每个掩码的边界框坐标</span><br><span class="line">        num_objs = len(obj_ids)</span><br><span class="line">        boxes = []</span><br><span class="line">        for i in range(num_objs):</span><br><span class="line">            pos = np.where(masks[i])</span><br><span class="line">            xmin = np.min(pos[1])</span><br><span class="line">            xmax = np.max(pos[1])</span><br><span class="line">            ymin = np.min(pos[0])</span><br><span class="line">            ymax = np.max(pos[0])</span><br><span class="line">            boxes.append([xmin, ymin, xmax, ymax])</span><br><span class="line"></span><br><span class="line">        # convert everything into a torch.Tensor</span><br><span class="line">        boxes = torch.as_tensor(boxes, dtype=torch.float32)</span><br><span class="line">        # there is only one class</span><br><span class="line">        labels = torch.ones((num_objs,), dtype=torch.int64)</span><br><span class="line">        masks = torch.as_tensor(masks, dtype=torch.uint8)</span><br><span class="line"></span><br><span class="line">        image_id = torch.tensor([idx])</span><br><span class="line">        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])</span><br><span class="line">        # suppose all instances are not crowd</span><br><span class="line">        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)</span><br><span class="line"></span><br><span class="line">        target = &#123;&#125;</span><br><span class="line">        target[&quot;boxes&quot;] = boxes</span><br><span class="line">        target[&quot;labels&quot;] = labels</span><br><span class="line">        target[&quot;masks&quot;] = masks</span><br><span class="line">        target[&quot;image_id&quot;] = image_id</span><br><span class="line">        target[&quot;area&quot;] = area</span><br><span class="line">        target[&quot;iscrowd&quot;] = iscrowd</span><br><span class="line"></span><br><span class="line">        if self.transforms is not None:</span><br><span class="line">            img, target = self.transforms(img, target)</span><br><span class="line"></span><br><span class="line">        return img, target</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return len(self.imgs)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>That’s all for the dataset. Now let’s define a model that can perform predictions on this dataset.</p>
</blockquote>
<p>上述就是自定义数据类。下面定义一个模型，在上述数据集上进行预测</p>
<h2 id="Defining-your-model"><a href="#Defining-your-model" class="headerlink" title="Defining your model"></a>Defining your model</h2><p>定义模型</p>
<blockquote>
<p>In this tutorial, we will be using Mask R-CNN, which is based on top of Faster R-CNN. Faster R-CNN is a model that predicts both bounding boxes and class scores for potential objects in the image.</p>
</blockquote>
<p>本教材使用<a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="noopener">Mask R-CNN</a>，该模型基于<a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">Faster R-CNN</a>。Faster R-CNN能够同时预测图像中潜在目标的预测框和类成绩</p>
<p><img src="/imgs/译-finetune/tv_image03.png" alt></p>
<blockquote>
<p>Mask R-CNN adds an extra branch into Faster R-CNN, which also predicts segmentation masks for each instance.</p>
</blockquote>
<p>Mask R-CNN在Faster R-CNN的基础上增加了一个额外的功能，就是同时能够预测每个实例的分割掩码</p>
<p><img src="/imgs/译-finetune/tv_image04.png" alt></p>
<blockquote>
<p>There are two common situations where one might want to modify one of the available models in torchvision modelzoo. The first is when we want to start from a pre-trained model, and just finetune the last layer. The other is when we want to replace the backbone of the model with a different one (for faster predictions, for example).</p>
</blockquote>
<p>当人们想要修改torchvision modelzoo中的可用模型时，有两种常见的情况。第一种是当我们想要使用一个预训练模型时，只需要微调最后一层。第二种是我们想用一个不同的模型来替换这个模型的主干（比如为了更快的预测）</p>
<blockquote>
<p>Let’s go see how we would do one or another in the following sections.</p>
</blockquote>
<p>让我们来看看在接下来的几节中会如何做</p>
<h3 id="1-Finetuning-from-a-pretrained-model"><a href="#1-Finetuning-from-a-pretrained-model" class="headerlink" title="1 - Finetuning from a pretrained model"></a>1 - Finetuning from a pretrained model</h3><p>1 - 对预处理模型进行微调</p>
<blockquote>
<p>Let’s suppose that you want to start from a model pre-trained on COCO and want to finetune it for your particular classes. Here is a possible way of doing it:</p>
</blockquote>
<p>假设您想从一个在COCO上预训练的模型开始，并想针对特定类对其进行微调。这里有一个可行的方法:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import torchvision</span><br><span class="line">from torchvision.models.detection.faster_rcnn import FastRCNNPredictor</span><br><span class="line"></span><br><span class="line"># load a model pre-trained pre-trained on COCO</span><br><span class="line"># 加载在COCO上预训练的模型</span><br><span class="line">model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)</span><br><span class="line"></span><br><span class="line"># replace the classifier with a new one, that has</span><br><span class="line"># num_classes which is user-defined</span><br><span class="line"># 替换新的分类器</span><br><span class="line">num_classes = 2  # 1 class (person) + background</span><br><span class="line"># get number of input features for the classifier</span><br><span class="line"># 获取分类器的输入特征数</span><br><span class="line">in_features = model.roi_heads.box_predictor.cls_score.in_features</span><br><span class="line"># replace the pre-trained head with a new one</span><br><span class="line">model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)</span><br></pre></td></tr></table></figure>
<h3 id="2-Modifying-the-model-to-add-a-different-backbone"><a href="#2-Modifying-the-model-to-add-a-different-backbone" class="headerlink" title="2 - Modifying the model to add a different backbone"></a>2 - Modifying the model to add a different backbone</h3><p>2 - 通过添加不同的主干来修改模型</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import torchvision</span><br><span class="line">from torchvision.models.detection import FasterRCNN</span><br><span class="line">from torchvision.models.detection.rpn import AnchorGenerator</span><br><span class="line"></span><br><span class="line"># load a pre-trained model for classification and return</span><br><span class="line"># only the features</span><br><span class="line">backbone = torchvision.models.mobilenet_v2(pretrained=True).features</span><br><span class="line"># FasterRCNN needs to know the number of</span><br><span class="line"># output channels in a backbone. For mobilenet_v2, it&apos;s 1280</span><br><span class="line"># so we need to add it here</span><br><span class="line">backbone.out_channels = 1280</span><br><span class="line"></span><br><span class="line"># let&apos;s make the RPN generate 5 x 3 anchors per spatial</span><br><span class="line"># location, with 5 different sizes and 3 different aspect</span><br><span class="line"># ratios. We have a Tuple[Tuple[int]] because each feature</span><br><span class="line"># map could potentially have different sizes and</span><br><span class="line"># aspect ratios</span><br><span class="line">anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),</span><br><span class="line">                                   aspect_ratios=((0.5, 1.0, 2.0),))</span><br><span class="line"></span><br><span class="line"># let&apos;s define what are the feature maps that we will</span><br><span class="line"># use to perform the region of interest cropping, as well as</span><br><span class="line"># the size of the crop after rescaling.</span><br><span class="line"># if your backbone returns a Tensor, featmap_names is expected to</span><br><span class="line"># be [0]. More generally, the backbone should return an</span><br><span class="line"># OrderedDict[Tensor], and in featmap_names you can choose which</span><br><span class="line"># feature maps to use.</span><br><span class="line">roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],</span><br><span class="line">                                                output_size=7,</span><br><span class="line">                                                sampling_ratio=2)</span><br><span class="line"></span><br><span class="line"># put the pieces together inside a FasterRCNN model</span><br><span class="line">model = FasterRCNN(backbone,</span><br><span class="line">                   num_classes=2,</span><br><span class="line">                   rpn_anchor_generator=anchor_generator,</span><br><span class="line">                   box_roi_pool=roi_pooler)</span><br></pre></td></tr></table></figure>
<h3 id="An-Instance-segmentation-model-for-PennFudan-Dataset"><a href="#An-Instance-segmentation-model-for-PennFudan-Dataset" class="headerlink" title="An Instance segmentation model for PennFudan Dataset"></a>An Instance segmentation model for PennFudan Dataset</h3><p>PennFudan数据集的实例分割模型</p>
<blockquote>
<p>In our case, we want to fine-tune from a pre-trained model, given that our dataset is very small, so we will be following approach number 1.</p>
</blockquote>
<p>在我们的例子中，我们希望从预先训练好的模型中进行微调，因为我们的数据集非常小，所以我们将遵循方法1</p>
<blockquote>
<p>Here we want to also compute the instance segmentation masks, so we will be using Mask R-CNN:</p>
</blockquote>
<p>为了能够同时计算实例分割掩码，所以使用Mask R-CNN：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import torchvision</span><br><span class="line">from torchvision.models.detection.faster_rcnn import FastRCNNPredictor</span><br><span class="line">from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_model_instance_segmentation(num_classes):</span><br><span class="line">    # load an instance segmentation model pre-trained pre-trained on COCO</span><br><span class="line">    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)</span><br><span class="line"></span><br><span class="line">    # get number of input features for the classifier</span><br><span class="line">    in_features = model.roi_heads.box_predictor.cls_score.in_features</span><br><span class="line">    # replace the pre-trained head with a new one</span><br><span class="line">    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)</span><br><span class="line"></span><br><span class="line">    # now get the number of input features for the mask classifier</span><br><span class="line">    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels</span><br><span class="line">    hidden_layer = 256</span><br><span class="line">    # and replace the mask predictor with a new one</span><br><span class="line">    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,</span><br><span class="line">                                                       hidden_layer,</span><br><span class="line">                                                       num_classes)</span><br><span class="line"></span><br><span class="line">    return model</span><br></pre></td></tr></table></figure>
<blockquote>
<p>That’s it, this will make model be ready to be trained and evaluated on your custom dataset.</p>
</blockquote>
<p>上述代码就能够实现自定义数据集的训练和评估</p>
<h2 id="Putting-everything-together"><a href="#Putting-everything-together" class="headerlink" title="Putting everything together"></a>Putting everything together</h2><p>完整实现</p>
<blockquote>
<p>In references/detection/, we have a number of helper functions to simplify training and evaluating detection models. Here, we will use references/detection/engine.py, references/detection/utils.py and references/detection/transforms.py. Just copy them to your folder and use them here.</p>
</blockquote>
<p>在references/detection/目录中提供了许多能够简化训练和评估检测模型的辅助函数。在本次实验中，使用了references/detection/engine.py、references/detection/utils.py和references/detection/transforms.py</p>
<blockquote>
<p>Let’s write some helper functions for data augmentation / transformation:</p>
</blockquote>
<p>实现一些用于数据扩充/转换的辅助函数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import transforms as T</span><br><span class="line"></span><br><span class="line">def get_transform(train):</span><br><span class="line">    transforms = []</span><br><span class="line">    transforms.append(T.ToTensor())</span><br><span class="line">    if train:</span><br><span class="line">        transforms.append(T.RandomHorizontalFlip(0.5))</span><br><span class="line">    return T.Compose(transforms)</span><br></pre></td></tr></table></figure>
<h2 id="Testing-forward-method-Optional"><a href="#Testing-forward-method-Optional" class="headerlink" title="Testing forward() method (Optional)"></a>Testing forward() method (Optional)</h2><blockquote>
<p>Before iterating over the dataset, it’s good to see what the model expects during training and inference time on sample data.</p>
</blockquote>
<p>在迭代数据集之前，最好能知道模型在样本数据的训练和推理时中需要什么</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)</span><br><span class="line">dataset = PennFudanDataset(&apos;PennFudanPed&apos;, get_transform(train=True))</span><br><span class="line">data_loader = torch.utils.data.DataLoader(</span><br><span class="line"> dataset, batch_size=2, shuffle=True, num_workers=4,</span><br><span class="line"> collate_fn=utils.collate_fn)</span><br><span class="line"># For Training</span><br><span class="line">images,targets = next(iter(data_loader))</span><br><span class="line">images = list(image for image in images)</span><br><span class="line">targets = [&#123;k: v for k, v in t.items()&#125; for t in targets]</span><br><span class="line">output = model(images,targets)   # Returns losses and detections</span><br><span class="line"># For inference</span><br><span class="line">model.eval()</span><br><span class="line">x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]</span><br><span class="line">predictions = model(x)           # Returns predictions</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Let’s now write the main function which performs the training and the validation:</p>
</blockquote>
<p>下面编写执行训练和验证的主函数:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from engine import train_one_epoch, evaluate</span><br><span class="line">import utils</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    # train on the GPU or on the CPU, if a GPU is not available</span><br><span class="line">    device = torch.device(&apos;cuda&apos;) if torch.cuda.is_available() else torch.device(&apos;cpu&apos;)</span><br><span class="line"></span><br><span class="line">    # our dataset has two classes only - background and person</span><br><span class="line">    num_classes = 2</span><br><span class="line">    # use our dataset and defined transformations</span><br><span class="line">    dataset = PennFudanDataset(&apos;PennFudanPed&apos;, get_transform(train=True))</span><br><span class="line">    dataset_test = PennFudanDataset(&apos;PennFudanPed&apos;, get_transform(train=False))</span><br><span class="line"></span><br><span class="line">    # split the dataset in train and test set</span><br><span class="line">    indices = torch.randperm(len(dataset)).tolist()</span><br><span class="line">    dataset = torch.utils.data.Subset(dataset, indices[:-50])</span><br><span class="line">    dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])</span><br><span class="line"></span><br><span class="line">    # define training and validation data loaders</span><br><span class="line">    data_loader = torch.utils.data.DataLoader(</span><br><span class="line">        dataset, batch_size=2, shuffle=True, num_workers=4,</span><br><span class="line">        collate_fn=utils.collate_fn)</span><br><span class="line"></span><br><span class="line">    data_loader_test = torch.utils.data.DataLoader(</span><br><span class="line">        dataset_test, batch_size=1, shuffle=False, num_workers=4,</span><br><span class="line">        collate_fn=utils.collate_fn)</span><br><span class="line"></span><br><span class="line">    # get the model using our helper function</span><br><span class="line">    model = get_model_instance_segmentation(num_classes)</span><br><span class="line"></span><br><span class="line">    # move model to the right device</span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    # construct an optimizer</span><br><span class="line">    params = [p for p in model.parameters() if p.requires_grad]</span><br><span class="line">    optimizer = torch.optim.SGD(params, lr=0.005,</span><br><span class="line">                                momentum=0.9, weight_decay=0.0005)</span><br><span class="line">    # and a learning rate scheduler</span><br><span class="line">    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,</span><br><span class="line">                                                   step_size=3,</span><br><span class="line">                                                   gamma=0.1)</span><br><span class="line"></span><br><span class="line">    # let&apos;s train it for 10 epochs</span><br><span class="line">    num_epochs = 10</span><br><span class="line"></span><br><span class="line">    for epoch in range(num_epochs):</span><br><span class="line">        # train for one epoch, printing every 10 iterations</span><br><span class="line">        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)</span><br><span class="line">        # update the learning rate</span><br><span class="line">        lr_scheduler.step()</span><br><span class="line">        # evaluate on the test dataset</span><br><span class="line">        evaluate(model, data_loader_test, device=device)</span><br><span class="line"></span><br><span class="line">    print(&quot;That&apos;s it!&quot;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>You should get as output for the first epoch:</p>
</blockquote>
<p>第一轮预期输出如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Epoch: [0]  [ 0/60]  eta: 0:01:18  lr: 0.000090  loss: 2.5213 (2.5213)  loss_classifier: 0.8025 (0.8025)  loss_box_reg: 0.2634 (0.2634)  loss_mask: 1.4265 (1.4265)  loss_objectness: 0.0190 (0.0190)  loss_rpn_box_reg: 0.0099 (0.0099)  time: 1.3121  data: 0.3024  max mem: 3485</span><br><span class="line">Epoch: [0]  [10/60]  eta: 0:00:20  lr: 0.000936  loss: 1.3007 (1.5313)  loss_classifier: 0.3979 (0.4719)  loss_box_reg: 0.2454 (0.2272)  loss_mask: 0.6089 (0.7953)  loss_objectness: 0.0197 (0.0228)  loss_rpn_box_reg: 0.0121 (0.0141)  time: 0.4198  data: 0.0298  max mem: 5081</span><br><span class="line">Epoch: [0]  [20/60]  eta: 0:00:15  lr: 0.001783  loss: 0.7567 (1.1056)  loss_classifier: 0.2221 (0.3319)  loss_box_reg: 0.2002 (0.2106)  loss_mask: 0.2904 (0.5332)  loss_objectness: 0.0146 (0.0176)  loss_rpn_box_reg: 0.0094 (0.0123)  time: 0.3293  data: 0.0035  max mem: 5081</span><br><span class="line">Epoch: [0]  [30/60]  eta: 0:00:11  lr: 0.002629  loss: 0.4705 (0.8935)  loss_classifier: 0.0991 (0.2517)  loss_box_reg: 0.1578 (0.1957)  loss_mask: 0.1970 (0.4204)  loss_objectness: 0.0061 (0.0140)  loss_rpn_box_reg: 0.0075 (0.0118)  time: 0.3403  data: 0.0044  max mem: 5081</span><br><span class="line">Epoch: [0]  [40/60]  eta: 0:00:07  lr: 0.003476  loss: 0.3901 (0.7568)  loss_classifier: 0.0648 (0.2022)  loss_box_reg: 0.1207 (0.1736)  loss_mask: 0.1705 (0.3585)  loss_objectness: 0.0018 (0.0113)  loss_rpn_box_reg: 0.0075 (0.0112)  time: 0.3407  data: 0.0044  max mem: 5081</span><br><span class="line">Epoch: [0]  [50/60]  eta: 0:00:03  lr: 0.004323  loss: 0.3237 (0.6703)  loss_classifier: 0.0474 (0.1731)  loss_box_reg: 0.1109 (0.1561)  loss_mask: 0.1658 (0.3201)  loss_objectness: 0.0015 (0.0093)  loss_rpn_box_reg: 0.0093 (0.0116)  time: 0.3379  data: 0.0043  max mem: 5081</span><br><span class="line">Epoch: [0]  [59/60]  eta: 0:00:00  lr: 0.005000  loss: 0.2540 (0.6082)  loss_classifier: 0.0309 (0.1526)  loss_box_reg: 0.0463 (0.1405)  loss_mask: 0.1568 (0.2945)  loss_objectness: 0.0012 (0.0083)  loss_rpn_box_reg: 0.0093 (0.0123)  time: 0.3489  data: 0.0042  max mem: 5081</span><br><span class="line">Epoch: [0] Total time: 0:00:21 (0.3570 s / it)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">Test:  [ 0/50]  eta: 0:00:19  model_time: 0.2152 (0.2152)  evaluator_time: 0.0133 (0.0133)  time: 0.4000  data: 0.1701  max mem: 5081</span><br><span class="line">Test:  [49/50]  eta: 0:00:00  model_time: 0.0628 (0.0687)  evaluator_time: 0.0039 (0.0064)  time: 0.0735  data: 0.0022  max mem: 5081</span><br><span class="line">Test: Total time: 0:00:04 (0.0828 s / it)</span><br><span class="line">Averaged stats: model_time: 0.0628 (0.0687)  evaluator_time: 0.0039 (0.0064)</span><br><span class="line">Accumulating evaluation results...</span><br><span class="line">DONE (t=0.01s).</span><br><span class="line">Accumulating evaluation results...</span><br><span class="line">DONE (t=0.01s).</span><br><span class="line">IoU metric: bbox</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.606</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.984</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.780</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.582</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.612</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.270</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.672</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.650</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.755</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664</span><br><span class="line">IoU metric: segm</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.704</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.979</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.871</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.488</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.316</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.748</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.749</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.650</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.673</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758</span><br></pre></td></tr></table></figure>
<blockquote>
<p>So after one epoch of training, we obtain a COCO-style mAP of 60.6, and a mask mAP of 70.4.</p>
</blockquote>
<p>经过一个周期的训练后，获得了60.6的COCO风格mAP和70.4的掩码mAP</p>
<blockquote>
<p>After training for 10 epochs, I got the following metrics</p>
</blockquote>
<p>经过10个周期的训练后，得到以下指标</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">IoU metric: bbox</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.799</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.969</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.935</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.831</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.844</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.844</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.777</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.870</span><br><span class="line">IoU metric: segm</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.761</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.969</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.919</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.341</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.464</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.303</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.799</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.799</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.769</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.818</span><br></pre></td></tr></table></figure>
<blockquote>
<p>But what do the predictions look like? Let’s take one image in the dataset and verify</p>
</blockquote>
<p>实际预测是什么样的呢？使用一张图像进行验证</p>
<p><img src="/imgs/译-finetune/tv_image05.png" alt></p>
<blockquote>
<p>The trained model predicts 9 instances of person in this image, let’s see a couple of them:</p>
</blockquote>
<p>经过训练的模型预测了该图像中的9个人物实例，让我们来看看其中的几个:</p>
<p><img src="/imgs/译-finetune/tv_image07.png" alt></p>
<blockquote>
<p>The results look pretty good!</p>
</blockquote>
<p>结果确实很好！</p>
<h2 id="Wrapping-up"><a href="#Wrapping-up" class="headerlink" title="Wrapping up"></a>Wrapping up</h2><p>小结</p>
<blockquote>
<p>In this tutorial, you have learned how to create your own training pipeline for instance segmentation models, on a custom dataset. For that, you wrote a torch.utils.data.Dataset class that returns the images and the ground truth boxes and segmentation masks. You also leveraged a Mask R-CNN model pre-trained on COCO train2017 in order to perform transfer learning on this new dataset.</p>
</blockquote>
<p>在本教程中，您已经学习了如何在自定义数据集上为实例分割模型创建自己的训练流程。为此需要编写了一个torch.utils.data.Dataset类，该类返回image、标注边界框和分割掩码。您还利用了在COCO 2017 上预训练的一个Mask R-CNN模型，以便在这个新数据集上执行迁移学习</p>
<blockquote>
<p>For a more complete example, which includes multi-machine / multi-gpu training, check references/detection/train.py, which is present in the torchvision repo.</p>
</blockquote>
<p>更完整的例子，包括多机器/多gpu训练，check references/detection/train.py，均在torchvision仓库中存在</p>
<blockquote>
<p>You can download a full source file for this tutorial here.</p>
</blockquote>
<p>本教材完整程序下载：<a href="https://pytorch.org/tutorials/_static/tv-training-code.py" target="_blank" rel="noopener">tv-training-code.py</a></p>
]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据</category>
        <category>代码库</category>
        <category>数据集</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>torchvision</tag>
        <tag>PennFudan</tag>
      </tags>
  </entry>
  <entry>
    <title>C++11实践</title>
    <url>/posts/b738146b.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://www.zhujian.tech/posts/be56146c.html">[译]欢迎回到C++(现代C++)</a></p><p><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/%E5%AD%A6%E4%B9%A0C++%E4%B9%8B%E8%B7%AF/" target="_blank" rel="noopener">学习c++之路</a></p><p>最开始学习编程的时候接触的是<code>C</code>语言，之后自然的过渡到<code>C++</code>语言，所以很长时间内会使用<code>C</code>语言风格编写<code>C++</code>代码（<em>用的还挺顺</em>）。后来随着学习的深入，逐渐发现更应该用面向对象的思想来学习和使用<code>C++</code></p><a id="more"></a>



<p>编译<code>OpenCV 4.0</code>时发现其<code>C++</code>代码已全面符合<code>C++ 11</code>规范，忽然发现之前学习的<code>C++</code>已经过了多个版本，经过查询后发现从<code>C++ 11</code>开始，<code>C++</code>语言完成了极大的转变，提供了足够多的数据结构和算法来替代<code>C</code>语言风格的编写</p>
<p>经过一段时间的<code>C++ 11</code>规范的学习和实践，小结常用的语法以及新增的规范：</p>
<ul>
<li>关键字<ul>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/get-started/keywords/nullptr/" target="_blank" rel="noopener">nullptr</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/get-started/type-cast-deduce/auto/" target="_blank" rel="noopener">auto</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/get-started/type-cast-deduce/decltype/" target="_blank" rel="noopener">decltype</a></li>
</ul>
</li>
<li>智能指针<ul>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/smart-pointer/unique_ptr/" target="_blank" rel="noopener">unique_ptr</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/smart-pointer/shared_ptr/" target="_blank" rel="noopener">shared_ptr</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/smart-pointer/weak_ptr/" target="_blank" rel="noopener">weak_ptr</a></li>
</ul>
</li>
<li>类型转换<ul>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/get-started/type-cast-deduce/%E7%8E%B0%E4%BB%A3%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/#dynamic_cast" target="_blank" rel="noopener">dynmaic_cast</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/get-started/type-cast-deduce/%E7%8E%B0%E4%BB%A3%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/#static_cast" target="_blank" rel="noopener">static_cast</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/get-started/type-cast-deduce/%E7%8E%B0%E4%BB%A3%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/#const_cast" target="_blank" rel="noopener">const_cast</a></li>
</ul>
</li>
<li>字符串<ul>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/get-started/type-cast-deduce/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%B1%BB%E5%9E%8B/" target="_blank" rel="noopener">string</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/faq/ISO%20C++%20forbids%20converting%20a%20string%20constant%20to%20char*/" target="_blank" rel="noopener">ISO C++ forbids converting a string constant to ‘char*’</a></li>
</ul>
</li>
<li>类<ul>
<li>关键字<ul>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/class/%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E6%A6%82%E8%BF%B0/#virtual" target="_blank" rel="noopener">virtual</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/class/%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E6%A6%82%E8%BF%B0/#override" target="_blank" rel="noopener">override</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/class/%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E6%A6%82%E8%BF%B0/#final" target="_blank" rel="noopener">final</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/class/%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E6%A6%82%E8%BF%B0/#inline" target="_blank" rel="noopener">inline</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/class/%E6%88%90%E5%91%98%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/#_4" target="_blank" rel="noopener">friend</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/class/static%E6%88%90%E5%91%98/" target="_blank" rel="noopener">static</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/template/%E6%A8%A1%E6%9D%BF%E6%A6%82%E8%BF%B0/" target="_blank" rel="noopener">模板</a></li>
<li>标准库容器<ul>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/stl/vector/" target="_blank" rel="noopener">vector</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/stl/map/" target="_blank" rel="noopener">map</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/stl/queue/" target="_blank" rel="noopener">queue</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/stl/stack/" target="_blank" rel="noopener">stack</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/stl/array/" target="_blank" rel="noopener">array</a></li>
</ul>
</li>
<li>标准库算法<ul>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/stl/for_each/" target="_blank" rel="noopener">for_each</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/stl/find/" target="_blank" rel="noopener">find</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/stl/sort/" target="_blank" rel="noopener">sort</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/advanced/stl/STL%E6%A6%82%E8%BF%B0/" target="_blank" rel="noopener">shuffle</a></li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>编程</category>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title>[peek]录屏工具使用</title>
    <url>/posts/32ab76c9.html</url>
    <content><![CDATA[<p>之前使用过<code>GifCam</code>进行录屏，操作效果一般，后来重装系统就没有再安装。最近偶然机会下发现一个好用的录屏工具 - <a href="https://github.com/phw/peek" target="_blank" rel="noopener">peek</a>，界面简洁同时操作简单</p><a id="more"></a>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><code>Ubuntu 18.04</code>下通过<code>PPA</code>方式安装：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo add-apt-repository ppa:peek-developers/stable</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install peek</span><br></pre></td></tr></table></figure>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>从菜单栏点击<code>peek</code>图标或者在命令行输入<code>peek</code>，启动应用后设置peek屏幕大小，匹配要录制的内容后输入快捷键<code>Ctrl + Alt + R</code>即可开始录屏</p>
<p><img src="/imgs/peek/peek.gif" alt></p>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>peek</tag>
      </tags>
  </entry>
  <entry>
    <title>选择性搜索算法小结</title>
    <url>/posts/58ff6dae.html</url>
    <content><![CDATA[<p>研究了好久的选择性搜索算法，终于把它搞定!!!</p><h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><p>选择性搜索算法的实现包含了两部分，一是图分割算法，二是选择性搜索算法，分别由两篇论文组成：</p><a id="more"></a>

<ol>
<li><a href="https://zhujian.tech/posts/44a20d07.html" target="_blank" rel="noopener">[译]高效的基于图的图像分割</a></li>
<li><a href="https://zhujian.tech/posts/1cb6a408.html" target="_blank" rel="noopener">[译]作用于目标识别的选择性搜索</a></li>
</ol>
<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><h3 id="图分割"><a href="#图分割" class="headerlink" title="图分割"></a>图分割</h3><p>图分割论文提供了<code>C++</code>实现，同时<code>OpenCV</code>也实现了图分割算法</p>
<ol>
<li><a href="https://zhujian.tech/posts/a4b1a6d9.html" target="_blank" rel="noopener">基于图的图像分割-工程源码</a></li>
<li><a href="https://zhujian.tech/posts/18052054.html" target="_blank" rel="noopener">基于图的图像分割-OpenCV源码</a></li>
</ol>
<p><img src="/imgs/选择性搜索小结/graphseg.png" alt></p>
<h3 id="选择性搜索"><a href="#选择性搜索" class="headerlink" title="选择性搜索"></a>选择性搜索</h3><p>选择性搜索算法在<code>OpenCV</code>中已有实现。为了进一步理解选择性搜索算法的实现，从<code>OpenCV</code>中抽取了相应的源码进行学习：<a href="https://github.com/zjZSTU/selectivesearch" target="_blank" rel="noopener">zjZSTU/selectivesearch</a></p>
<p><img src="/imgs/选择性搜索小结/selectivesearch.png" alt></p>
<p><img src="/imgs/选择性搜索小结/selectivesearchsegmentationstrategy.png" alt></p>
<h2 id="OpenCV-bug"><a href="#OpenCV-bug" class="headerlink" title="OpenCV bug"></a>OpenCV bug</h2><p>当前使用<code>OpenCV 4.2.0</code>，之前使用过<code>OpenCV 4.0.0/4.1.0</code>，发现使用<code>selectivesearch</code>进行目标检测时，如果输入的图像长宽比过大就会出错。在<code>Github</code>的<code>opencv/opencv_contrib</code>仓库的<code>Issues</code>上找到不少的讨论</p>
<ul>
<li><a href="https://github.com/opencv/opencv_contrib/issues/705" target="_blank" rel="noopener">Bug in SelectiveSearchSegmentation #705</a></li>
<li><a href="https://github.com/opencv/opencv_contrib/issues/1707" target="_blank" rel="noopener">SelectiveSearchSegmentation crashes with some image #1707</a></li>
<li><a href="https://github.com/opencv/opencv_contrib/issues/2102" target="_blank" rel="noopener">Selective Search crashes on images with a width:height or height:width ratio greater than about 2.43 #2102</a></li>
</ul>
<p>这个问题已经得到了解决：</p>
<ul>
<li><a href="https://github.com/opencv/opencv_contrib/pull/2103" target="_blank" rel="noopener">Added a fix for issue 2102. #2103</a></li>
<li><a href="https://github.com/opencv/opencv_contrib/pull/2132" target="_blank" rel="noopener">Fix 2102 redux #2132</a></li>
</ul>
<p>其原因是计算方向导数时，需要对图像进行旋转操作，计算梯度后重新旋转回原来的方向，并进行剪切操作。如果图像宽高比过大，会导致裁剪出错</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">During one of the stages of selective search, the image is rotated 45 degrees and gradients are computed along the X and Y directions in the rotated image. The gradient image is then rotated back to the original orientation and cropped to remove surrounding empty space, leaving it with the same shape as the original image. However, the implementation of the crop will specify an ROI with negative x or y values if the image&apos;s native aspect ratio is too high or too low (basically, if the image is far from square).</span><br><span class="line"></span><br><span class="line">This is because the bounding box of the rotated image is strictly bigger than the original image if the original is sufficiently close to square; but if the original is too &quot;skinny&quot;, the bounding box of its rotation will be less tall or wide than the original.</span><br><span class="line"></span><br><span class="line">The fix is to threshold the x and y computed for the ROI at 0.</span><br></pre></td></tr></table></figure>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>选择性搜索算法将目标检测转换成图像分割</p>
<ul>
<li>图分割算法将图像分割的过程转换成图分量合并的过程</li>
<li>选择性搜索算法对初始分割集进行分层分组算法，进一步合并得到更多的候选区域</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>图像处理</category>
        <category>随笔</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>基于图的图像分割</tag>
        <tag>选择性搜索</tag>
        <tag>目标检测</tag>
        <tag>目标分割</tag>
      </tags>
  </entry>
  <entry>
    <title>[OKR]2020年2月份</title>
    <url>/posts/921c65be.html</url>
    <content><![CDATA[<p>经过上个月的<code>OKR</code>实践，发现并没有合理的设置关键任务，并且没有考虑到实际学习时间（比如一月份的春节），所以<code>2</code>月份的<code>OKR</code>应该在一月份的<code>OKR</code>实践的基础上，继续之前未完成的事情，有效的设置关键任务</p><a id="more"></a>
<h2 id="目标及关键结果"><a href="#目标及关键结果" class="headerlink" title="目标及关键结果"></a>目标及关键结果</h2><ul>
<li><code>OKR</code>当前的状态<ul>
<li>目标：找到图像相关的研发工作</li>
<li>关键结果：选择性搜索算法小结(<code>8/10</code>)</li>
<li>关键结果：<code>C++11</code>实践小结(<code>5/10</code>)</li>
<li>关键结果：<code>R-CNN/Fast R-CNN</code>实现(<code>5/10</code>)</li>
</ul>
</li>
</ul>
<h2 id="01-09"><a href="#01-09" class="headerlink" title="01-09"></a>01-09</h2><p><img src="/okr/2020-2/2020-02-01-09.png" alt></p>
<ul>
<li>本周关注的任务<ul>
<li><code>P1</code>：<code>SelectiveSearch</code>目标检测实现</li>
<li><code>P1</code>：<code>SelectiveSearch</code>实践小结</li>
<li><code>P2</code>：<code>C++11</code>实践小结</li>
</ul>
</li>
<li>未来四周的计划<ul>
<li><code>PyNet</code>库整理</li>
<li><code>GraphLib</code>库整理</li>
<li><code>GoogLeNet</code>算法实现</li>
<li><code>Fast R-CNN</code>算法实现</li>
</ul>
</li>
<li>状态指标<ul>
<li>在过年时找到学习状态</li>
<li><code>R-CNN/Fast R-CNN</code>理论学习</li>
</ul>
</li>
</ul>
<h2 id="10-22"><a href="#10-22" class="headerlink" title="10-22"></a>10-22</h2><p>上一个<code>OKR</code>计划啥也没有完成！！！在老家太安逸了，没有动力撒 </p>
<p><img src="/okr/2020-2/sad-cry.svg" alt></p>
<p>从<code>10</code>号开始，慢慢恢复了学习的节奏，截止到22号为止，完成了以下工作：</p>
<ol>
<li><code>selectivesearch</code>算法原理、源码解析：<a href="https://github.com/zjZSTU/selectivesearch" target="_blank" rel="noopener">zjZSTU/selectivesearch</a></li>
<li>学习了<code>UML</code>类图，在<code>PlantUML</code>上实现类图绘制</li>
<li><code>C++11</code>实践小结</li>
</ol>
<h2 id="23-29"><a href="#23-29" class="headerlink" title="23-29"></a>23-29</h2><p><img src="/okr/2020-2/2020-02-23-29.png" alt></p>
<ul>
<li>本周关注的任务<ul>
<li><code>P1</code>：<code>R-CNN</code>算法实现</li>
<li><code>P1</code>：<code>R-CNN</code>实践小结</li>
<li><code>P2</code>：<code>Fast R-CNN</code>算法实现</li>
</ul>
</li>
<li>未来四周的计划<ul>
<li><code>PyNet</code>库整理</li>
<li><code>GraphLib</code>库整理</li>
<li><code>GoogLeNet</code>算法实现</li>
</ul>
</li>
<li>状态指标<ul>
<li>找回平日工作状态</li>
<li><code>R-CNN/Fast R-CNN</code>理论学习</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>随笔</category>
        <category>软件工程</category>
        <category>开发流程</category>
      </categories>
      <tags>
        <tag>OKR</tag>
      </tags>
  </entry>
  <entry>
    <title>[pytorch]训练一个简单的检测器</title>
    <url>/posts/5bfa4e56.html</url>
    <content><![CDATA[<p>学习边框回归的概念时，发现一篇自定义检测器的文章</p><ul>
<li>原文：<a href="https://towardsdatascience.com/getting-started-with-bounding-box-regression-in-tensorflow-743e22d0ccb3" target="_blank" rel="noopener">Getting Started With Bounding Box Regression In TensorFlow</a></li>
<li>中文：<a href="http://blog.hubwiz.com/2019/09/16/bounding-box-regression/" target="_blank" rel="noopener">目标检测之边框回归入门【Tensorflow】</a></li>
</ul><a id="more"></a>

<p>虽然题目写的是边框回归，但是里面没有讲解相关的概念，而是自定义了一个边框检测器，实现原理比较简单。看完之后感觉挺有趣的，之前也没有自己实现过检测器，原文使用<code>TensorFlow</code>实现，当前使用<code>PyTorch</code>进行复现</p>
<h2 id="操作流程"><a href="#操作流程" class="headerlink" title="操作流程"></a>操作流程</h2><ol>
<li>定位数据集</li>
<li>自定义损失函数</li>
<li>训练</li>
<li>检测</li>
</ol>
<h2 id="定位数据集"><a href="#定位数据集" class="headerlink" title="定位数据集"></a>定位数据集</h2><p>使用一个简单的<a href="https://zhujian.tech/posts/a2d65e1.html" target="_blank" rel="noopener">图像定位数据集</a>：</p>
<blockquote>
<ul>
<li>包含<code>3</code>类：<code>Cucumber</code>（黄瓜）、<code>Eggplant</code>（茄子）、<code>Mushroom</code>（蘑菇）</li>
<li>每类共有超过<code>60</code>张的图像，大小固定为<code>(227, 277, 3)</code>，每张图像里有一个物体</li>
<li>每张图像有一个对应的<code>xml</code>文件，格式和<code>PASCAL VOC</code>数据集一致，包含图像信息以及标注信息</li>
</ul>
</blockquote>
<h2 id="自定义损失函数"><a href="#自定义损失函数" class="headerlink" title="自定义损失函数"></a>自定义损失函数</h2><p>使用<code>MSE(Mean Squared Error)</code>和<a href="https://zhujian.tech/posts/796ebd4e.html" target="_blank" rel="noopener">IoU(Intersection over Union)</a>作为损失函数</p>
<script type="math/tex; mode=display">
loss(x, x^{'}) = MSE(x, x^{'}) + (1 - IoU(x, x^{'}))</script><p><code>MSE</code>计算的是预测标签和真值标签之间的损失，<code>1- IoU</code>计算的是预测边框和真值边框之间的损失，这样能够保证模型计算结果能够检测指定类别以及得到相应的标注信息。所以训练标签包含了边框标注数据和类别信息（<code>one-hot</code>编码形式）</p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><ul>
<li>自定义了数据集类<code>LocationDataSet</code>用于图像定位数据集的加载</li>
<li>自定义了损失函数类<code>MSE_IoU</code>用于损失函数的计算和求导</li>
<li>分别使用<code>LeNet-5</code>和<code>AlexNet</code>进行训练</li>
<li>使用随机梯度下降进行模型优化，初始学习率为<code>1e-3</code>，动量大小为<code>0.9</code>，使用<code>Nesterov</code>加速，共训练<code>100</code>轮</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   bounding.py</span><br><span class="line">@time:   2020-01-15</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import logging</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">import xmltodict</span><br><span class="line">import torch</span><br><span class="line">from torch.utils.data import Dataset</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">from torchvision.models import alexnet</span><br><span class="line"></span><br><span class="line">logging.basicConfig(format=&apos;%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s&apos;, level=logging.DEBUG)</span><br><span class="line"></span><br><span class="line"># LeNet-5</span><br><span class="line"># input_dim = 32</span><br><span class="line"># AlexNet</span><br><span class="line">input_dim = 227</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class LocationDataSet(Dataset):</span><br><span class="line"></span><br><span class="line">    def __init__(self, root_dir, train=True, transform=None, input_dim=1):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        自定义数据集类，加载定位数据集</span><br><span class="line">        1. 训练部分，加载编码前50图像和标记数据</span><br><span class="line">        2. 测试部分，加载编码50之后图像和标记数据</span><br><span class="line">        :param root_dir:</span><br><span class="line">        :param train:</span><br><span class="line">        :param transform:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        cates = [&apos;cucumber&apos;, &apos;eggplant&apos;, &apos;mushroom&apos;]</span><br><span class="line">        class_binary_label = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]</span><br><span class="line">        self.train = train</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">        self.imgs = []</span><br><span class="line">        self.bboxes = []</span><br><span class="line">        self.classes = []</span><br><span class="line"></span><br><span class="line">        for cate_idx in range(3):</span><br><span class="line">            if self.train:</span><br><span class="line">                for i in range(1, 51):</span><br><span class="line">                    img, bndbox, class_name = self._get_item(root_dir, cates[cate_idx], i)</span><br><span class="line">                    bndbox = bndbox / input_dim</span><br><span class="line"></span><br><span class="line">                    self.imgs.append(img)</span><br><span class="line">                    self.bboxes.append(np.hstack((bndbox, class_binary_label[cate_idx])))</span><br><span class="line">                    self.classes.append(class_name)</span><br><span class="line">            else:</span><br><span class="line">                for i in range(51, 61):</span><br><span class="line">                    img, bndbox, class_name = self._get_item(root_dir, cates[cate_idx], i)</span><br><span class="line">                    bndbox = bndbox / input_dim</span><br><span class="line"></span><br><span class="line">                    self.imgs.append(img)</span><br><span class="line">                    self.bboxes.append(np.hstack((bndbox, class_binary_label[cate_idx])))</span><br><span class="line">                    self.classes.append(class_name)</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, idx):</span><br><span class="line">        img = self.imgs[idx]</span><br><span class="line">        if self.transform:</span><br><span class="line">            sample = self.transform(img)</span><br><span class="line">        else:</span><br><span class="line">            sample = img</span><br><span class="line">        return sample, torch.Tensor(self.bboxes[idx]).float()</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return len(self.imgs)</span><br><span class="line"></span><br><span class="line">    def _get_item(self, root_dir, cate, i):</span><br><span class="line">        img_path = os.path.join(root_dir, &apos;%s_%d.jpg&apos; % (cate, i))</span><br><span class="line">        img = cv2.imread(img_path)</span><br><span class="line"></span><br><span class="line">        xml_path = os.path.join(root_dir, &apos;%s_%d.xml&apos; % (cate, i))</span><br><span class="line">        x = xmltodict.parse(open(xml_path, &apos;rb&apos;))</span><br><span class="line">        bndbox = x[&apos;annotation&apos;][&apos;object&apos;][&apos;bndbox&apos;]</span><br><span class="line">        bndbox = np.array(</span><br><span class="line">            [float(bndbox[&apos;xmin&apos;]), float(bndbox[&apos;ymin&apos;]), float(bndbox[&apos;xmax&apos;]), float(bndbox[&apos;ymax&apos;])])</span><br><span class="line"></span><br><span class="line">        return img, bndbox, x[&apos;annotation&apos;][&apos;object&apos;][&apos;name&apos;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data():</span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.ToPILImage(),</span><br><span class="line">        transforms.Resize(input_dim),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    root_dir = &apos;./data/image-localization-dataset/training_images/&apos;</span><br><span class="line">    train_dataset = LocationDataSet(root_dir, train=True, transform=transform, input_dim=input_dim)</span><br><span class="line">    test_dataset = LocationDataSet(root_dir, train=False, transform=transform, input_dim=input_dim)</span><br><span class="line"></span><br><span class="line">    train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)</span><br><span class="line">    test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, num_workers=4)</span><br><span class="line"></span><br><span class="line">    return train_dataloader, test_dataloader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MSE_IoU(nn.Module):</span><br><span class="line"></span><br><span class="line">    def calculate_iou(self, target_boxes, pred_boxes):</span><br><span class="line">        # 计算重叠区域的左上角和右下角坐标</span><br><span class="line">        x_min = torch.max(target_boxes[:, 0], pred_boxes[:, 0])</span><br><span class="line">        y_min = torch.max(target_boxes[:, 1], pred_boxes[:, 1])</span><br><span class="line">        x_max = torch.min(target_boxes[:, 2], pred_boxes[:, 2])</span><br><span class="line">        y_max = torch.min(target_boxes[:, 3], pred_boxes[:, 3])</span><br><span class="line">        # 计算交集面积</span><br><span class="line">        intersection = torch.max(torch.zeros(x_max.shape).cuda(), x_max - x_min) \</span><br><span class="line">                       * torch.max(torch.zeros(y_max.shape).cuda(), y_max - y_min)</span><br><span class="line"></span><br><span class="line">        # 计算两个边界框面积</span><br><span class="line">        boxAArea = (target_boxes[:, 2] - target_boxes[:, 0]) * (target_boxes[:, 3] - target_boxes[:, 1])</span><br><span class="line">        boxBArea = (pred_boxes[:, 2] - pred_boxes[:, 0]) * (pred_boxes[:, 3] - pred_boxes[:, 1])</span><br><span class="line"></span><br><span class="line">        iou = intersection / (boxAArea + boxBArea - intersection)</span><br><span class="line">        return iou</span><br><span class="line"></span><br><span class="line">    def forward(self, target_boxes, pred_boxes):</span><br><span class="line">        mseloss = nn.MSELoss().forward(target_boxes, pred_boxes)</span><br><span class="line">        iouloss = torch.mean(1 - self.calculate_iou(target_boxes, pred_boxes))</span><br><span class="line"></span><br><span class="line">        return mseloss + iouloss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class LeNet5(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, in_channels=1, num_classes=10):</span><br><span class="line">        super(LeNet5, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5, stride=1, padding=0, bias=True)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)</span><br><span class="line">        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1, padding=0, bias=True)</span><br><span class="line"></span><br><span class="line">        self.pool = nn.MaxPool2d((2, 2), stride=2)</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(in_features=120, out_features=84, bias=True)</span><br><span class="line">        self.fc2 = nn.Linear(84, num_classes, bias=True)</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        x = self.pool(F.relu(self.conv1(input)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line"></span><br><span class="line">        x = x.view(-1, self.num_flat_features(x))</span><br><span class="line"></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        return self.fc2(x)</span><br><span class="line"></span><br><span class="line">    def num_flat_features(self, x):</span><br><span class="line">        size = x.size()[1:]  # all dimensions except the batch dimension</span><br><span class="line">        num_features = 1</span><br><span class="line">        for s in size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        return num_features</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(loader, net, device):</span><br><span class="line">    total_accuracy = 0</span><br><span class="line">    num = 0</span><br><span class="line">    for item in loader:</span><br><span class="line">        data, labels = item</span><br><span class="line">        data = data.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        scores = net.forward(data)</span><br><span class="line">        predicted = torch.nn.functional.one_hot(torch.argmax(scores[:, 4:7], dim=1), num_classes=3)</span><br><span class="line">        total_accuracy += torch.mean((predicted == labels[:, 4:7]).float()).item()</span><br><span class="line">        num += 1</span><br><span class="line">    return total_accuracy / num</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    train_dataloader, test_dataloader = load_data()</span><br><span class="line"></span><br><span class="line">    device = &quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;</span><br><span class="line"></span><br><span class="line">    num_classes = 7</span><br><span class="line">    # net = LeNet5(in_channels=3, num_classes=num_classes).to(device)</span><br><span class="line">    net = alexnet(num_classes=num_classes).to(device)</span><br><span class="line">    criterion = MSE_IoU().to(device)</span><br><span class="line">    # optimer = optim.Adam(net.parameters(), lr=1e-3)</span><br><span class="line">    optimer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, nesterov=True)</span><br><span class="line"></span><br><span class="line">    logging.info(&quot;开始训练&quot;)</span><br><span class="line">    epoches = 100</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        num = 0</span><br><span class="line">        total_loss = 0</span><br><span class="line">        for j, item in enumerate(train_dataloader, 0):</span><br><span class="line">            data, labels = item</span><br><span class="line">            data = data.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">            scores = net.forward(data)</span><br><span class="line">            loss = criterion.forward(scores, labels)</span><br><span class="line">            total_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            optimer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimer.step()</span><br><span class="line">            num += 1</span><br><span class="line">        avg_loss = total_loss / num</span><br><span class="line">        logging.info(&apos;epoch: %d loss: %.6f&apos; % (i + 1, total_loss / num))</span><br><span class="line">        train_accuracy = compute_accuracy(train_dataloader, net, device)</span><br><span class="line">        test_accuracy = compute_accuracy(test_dataloader, net, device)</span><br><span class="line">        logging.info(&apos;train accuracy: %f test accuracy: %f&apos; % (train_accuracy, test_accuracy))</span><br><span class="line"></span><br><span class="line">    # torch.save(net.state_dict(), &apos;./model/LeNet-5.pth&apos;)</span><br><span class="line">    torch.save(net.state_dict(), &apos;./model/AlexNet.pth&apos;)</span><br><span class="line"></span><br><span class="line">    img, label = test_dataloader.dataset.__getitem__(10)</span><br><span class="line">    img = img.unsqueeze(0).to(device)</span><br><span class="line">    print(img.shape)</span><br><span class="line">    print(label)</span><br><span class="line">    scores = net.forward(img)</span><br><span class="line">    print(scores)</span><br></pre></td></tr></table></figure>
<p>使用<code>AlexNet</code>训练日志如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-01-18 21:03:25,738 box-detector.py[line:230] INFO epoch: 98 loss: 0.225710</span><br><span class="line">2020-01-18 21:03:26,068 box-detector.py[line:234] INFO train accuracy: 0.894737 test accuracy: 0.854167</span><br><span class="line">2020-01-18 21:03:26,737 box-detector.py[line:230] INFO epoch: 99 loss: 0.224704</span><br><span class="line">2020-01-18 21:03:27,065 box-detector.py[line:234] INFO train accuracy: 0.903509 test accuracy: 0.833333</span><br><span class="line">2020-01-18 21:03:27,747 box-detector.py[line:230] INFO epoch: 100 loss: 0.230456</span><br><span class="line">2020-01-18 21:03:28,076 box-detector.py[line:234] INFO train accuracy: 0.899123 test accuracy: 0.854167</span><br><span class="line">torch.Size([1, 3, 227, 227])</span><br><span class="line">tensor([0.2247, 0.2599, 0.8414, 0.7225, 0.0000, 1.0000, 0.0000])</span><br><span class="line">tensor([[0.2072, 0.2580, 0.7714, 0.6773, 0.3503, 0.4326, 0.1010]],</span><br><span class="line">       device=&apos;cuda:0&apos;, grad_fn=&lt;AddmmBackward&gt;)</span><br></pre></td></tr></table></figure>
<p>模型保存在<code>./model/AlexNet.pth</code>中</p>
<h2 id="检测"><a href="#检测" class="headerlink" title="检测"></a>检测</h2><p>调用保存的模型进行标注检测，并比较相应的检测类别</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   draw_box.py</span><br><span class="line">@time:   2020-01-18</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">from torchvision.models import alexnet</span><br><span class="line"></span><br><span class="line">from box_detector import load_data</span><br><span class="line">from box_detector import input_dim</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    train_loader, test_loader = load_data()</span><br><span class="line">    device = &quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;</span><br><span class="line"></span><br><span class="line">    dataset = test_loader.dataset</span><br><span class="line">    img, label = dataset.__getitem__(0)</span><br><span class="line">    image = img.unsqueeze(0).to(device)</span><br><span class="line">    label = label.unsqueeze(0)</span><br><span class="line"></span><br><span class="line">    num_classes = 7</span><br><span class="line">    # net = LeNet5(in_channels=3, num_classes=num_classes).to(device)</span><br><span class="line">    net = alexnet(num_classes=num_classes).to(device)</span><br><span class="line">    # net.load_state_dict(torch.load(&apos;./model/LeNet-5.pth&apos;))</span><br><span class="line">    net.load_state_dict(torch.load(&apos;./model/AlexNet.pth&apos;))</span><br><span class="line">    net.eval()</span><br><span class="line"></span><br><span class="line">    scores = net.forward(image)</span><br><span class="line">    print(scores)</span><br><span class="line">    print(label)</span><br><span class="line"></span><br><span class="line">    predict_cate = torch.argmax(scores[:, 4:7], dim=1)</span><br><span class="line">    truth_cate = torch.argmax(label[:, 4:7], dim=1)</span><br><span class="line">    print(&apos;predict: &apos; + str(predict_cate) + &apos; truth: &apos; + str(truth_cate))</span><br><span class="line"></span><br><span class="line">    img = img * 0.5 + 0.5</span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.ToPILImage(),</span><br><span class="line">        transforms.Resize(227)</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    truth_rect = label[:, :4] * input_dim</span><br><span class="line">    predict_rect = scores[:, :4] * input_dim</span><br><span class="line">    print(truth_rect)</span><br><span class="line">    print(predict_rect)</span><br><span class="line"></span><br><span class="line">    origin = np.array(transform(img), dtype=np.uint8)</span><br><span class="line"></span><br><span class="line">    x_min, y_min, x_max, y_max = truth_rect.squeeze()[:4]</span><br><span class="line">    cv2.rectangle(origin, (x_min, y_min), (x_max, y_max),</span><br><span class="line">                  (0, 255, 0), thickness=2)</span><br><span class="line">    x_min, y_min, x_max, y_max = predict_rect.squeeze()[:4]</span><br><span class="line">    cv2.rectangle(origin, (x_min, y_min), (x_max, y_max),</span><br><span class="line">                  (0, 0, 255), thickness=2)</span><br><span class="line">    cv2.imwrite(&apos;box_detector.png&apos;, origin)</span><br><span class="line">    # cv2.imshow(&apos;img&apos;, origin)</span><br><span class="line">    # cv2.waitKey(0)</span><br></pre></td></tr></table></figure>
<p>输出结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tensor([[  7.,  17., 220., 199.]])</span><br><span class="line">tensor([[  2.9428,  16.3437, 221.9320, 199.8142]], device=&apos;cuda:0&apos;,</span><br><span class="line">       grad_fn=&lt;MulBackward0&gt;)</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/detector-location/box_detector.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>数据</category>
        <category>卷积神经网络</category>
        <category>代码库</category>
        <category>数据集</category>
      </categories>
      <tags>
        <tag>AlexNet</tag>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>LeNet-5</tag>
        <tag>image localization dataset</tag>
      </tags>
  </entry>
  <entry>
    <title>[数据集]Image Localization Dataset</title>
    <url>/posts/a2d65e1.html</url>
    <content><![CDATA[<p>图像定位数据集（<code>image localization dataset</code>）是一个简单的用于图像定位实验的数据集，参考<a href="https://www.kaggle.com/mbkinaci/image-localization-dataset/data" target="_blank" rel="noopener">Image Localization Dataset</a></p><a id="more"></a>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ul>
<li>包含<code>3</code>类：<code>Cucumber</code>（黄瓜）、<code>Eggplant</code>（茄子）、<code>Mushroom</code>（蘑菇）</li>
<li>每类共有超过<code>60</code>张的图像，大小固定为<code>(227, 277, 3)</code>，每张图像里有一个物体</li>
<li>每张图像有一个对应的<code>xml</code>文件，格式和<code>PASCAL VOC</code>数据集一致，包含图像信息以及标注信息</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   show_img.py</span><br><span class="line">@time:   2020-01-18</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import xmltodict</span><br><span class="line"></span><br><span class="line">from matplotlib.font_manager import _rebuild</span><br><span class="line"></span><br><span class="line">_rebuild()  # reload一下</span><br><span class="line"></span><br><span class="line">plt.rcParams[&apos;font.sans-serif&apos;] = [&apos;simhei&apos;]  # 用来正常显示中文标签</span><br><span class="line">plt.rcParams[&apos;axes.unicode_minus&apos;] = False  # 用来正常显示负号</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw_rect(img_path, xml_path):</span><br><span class="line">    img = cv2.imread(img_path)</span><br><span class="line">    xml_data = xmltodict.parse(open(xml_path, &apos;rb&apos;))</span><br><span class="line"></span><br><span class="line">    bndbox = xml_data[&apos;annotation&apos;][&apos;object&apos;][&apos;bndbox&apos;]</span><br><span class="line">    bndbox = np.array([int(bndbox[&apos;xmin&apos;]), int(bndbox[&apos;ymin&apos;]), int(bndbox[&apos;xmax&apos;]), int(bndbox[&apos;ymax&apos;])])</span><br><span class="line">    x_min, y_min, x_max, y_max = bndbox</span><br><span class="line">    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 255, 0), thickness=2)</span><br><span class="line"></span><br><span class="line">    return img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_img():</span><br><span class="line">    root_dir = &apos;./data/image-localization-dataset/training_images/&apos;</span><br><span class="line">    img_cucumber = os.path.join(root_dir, &apos;cucumber_1.jpg&apos;)</span><br><span class="line">    img_eggplant = os.path.join(root_dir, &apos;eggplant_1.jpg&apos;)</span><br><span class="line">    img_mushroom = os.path.join(root_dir, &apos;mushroom_1.jpg&apos;)</span><br><span class="line"></span><br><span class="line">    xml_cucumber = os.path.join(root_dir, &apos;cucumber_1.xml&apos;)</span><br><span class="line">    xml_eggplant = os.path.join(root_dir, &apos;eggplant_1.xml&apos;)</span><br><span class="line">    xml_mushroom = os.path.join(root_dir, &apos;mushroom_1.xml&apos;)</span><br><span class="line"></span><br><span class="line">    img_cucumber = draw_rect(img_cucumber, xml_cucumber)</span><br><span class="line">    img_eggplant = draw_rect(img_eggplant, xml_eggplant)</span><br><span class="line">    img_mushroom = draw_rect(img_mushroom, xml_mushroom)</span><br><span class="line"></span><br><span class="line">    return img_cucumber, img_eggplant, img_mushroom</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    img_cucumber, img_eggplant, img_mushroom = load_img()</span><br><span class="line"></span><br><span class="line">    plt.style.use(&apos;dark_background&apos;)</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(10, 5))  # 设置窗口大小</span><br><span class="line">    plt.suptitle(&apos;图像定位数据集&apos;)  # 图片名称</span><br><span class="line"></span><br><span class="line">    plt.subplot(1, 3, 1)</span><br><span class="line">    plt.title(&apos;cucumber&apos;)</span><br><span class="line">    plt.imshow(img_cucumber), plt.axis(&apos;off&apos;)</span><br><span class="line"></span><br><span class="line">    plt.subplot(1, 3, 2)</span><br><span class="line">    plt.title(&apos;eggplant&apos;)</span><br><span class="line">    plt.imshow(img_eggplant), plt.axis(&apos;off&apos;)</span><br><span class="line"></span><br><span class="line">    plt.subplot(1, 3, 3)</span><br><span class="line">    plt.title(&apos;mushroom&apos;)</span><br><span class="line">    plt.imshow(img_mushroom), plt.axis(&apos;off&apos;)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/dataset-localization/img_location.png" alt></p>
<h2 id="sklearn加载"><a href="#sklearn加载" class="headerlink" title="sklearn加载"></a>sklearn加载</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   localization_test.py</span><br><span class="line">@time:   2020-01-18</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import cv2</span><br><span class="line">import glob</span><br><span class="line">import numpy as np</span><br><span class="line">import xmltodict</span><br><span class="line">from sklearn.preprocessing import LabelBinarizer</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">input_dim = 227</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_image():</span><br><span class="line">    image_paths = glob.glob(&apos;./data/image-localization-dataset/training_images/*.jpg&apos;)</span><br><span class="line">    images = []</span><br><span class="line">    for image_path in image_paths:</span><br><span class="line">        img = cv2.imread(image_path)</span><br><span class="line">        # 缩放图像到固定大小</span><br><span class="line">        img = cv2.resize(img, (input_dim, input_dim))</span><br><span class="line">        # 缩放像素值到[0,1]</span><br><span class="line">        images.append(img / 255.0)</span><br><span class="line">    return images</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_labels():</span><br><span class="line">    bboxes = []</span><br><span class="line">    classes_raw = []</span><br><span class="line">    annotations_paths = glob.glob(&apos;./data/image-localization-dataset/training_images/*.xml&apos;)</span><br><span class="line">    for xmlfile in annotations_paths:</span><br><span class="line">        x = xmltodict.parse(open(xmlfile, &apos;rb&apos;))</span><br><span class="line">        bndbox = x[&apos;annotation&apos;][&apos;object&apos;][&apos;bndbox&apos;]</span><br><span class="line">        bndbox = np.array([int(bndbox[&apos;xmin&apos;]), int(bndbox[&apos;ymin&apos;]), int(bndbox[&apos;xmax&apos;]), int(bndbox[&apos;ymax&apos;])])</span><br><span class="line">        # 同等比例缩放边界框坐标</span><br><span class="line">        bboxes.append(bndbox * (input_dim / float(x[&apos;annotation&apos;][&apos;size&apos;][&apos;width&apos;])))</span><br><span class="line">        classes_raw.append(x[&apos;annotation&apos;][&apos;object&apos;][&apos;name&apos;])</span><br><span class="line">    return bboxes, classes_raw</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data():</span><br><span class="line">    images = load_image()</span><br><span class="line">    bboxes, classes_raw = load_labels()</span><br><span class="line"></span><br><span class="line">    # 标签信息自定义</span><br><span class="line">    # 当前等于 标注信息 + one-hot编码</span><br><span class="line">    boxes = np.array(bboxes)</span><br><span class="line">    encoder = LabelBinarizer()</span><br><span class="line">    classes_onehot = encoder.fit_transform(classes_raw)</span><br><span class="line"></span><br><span class="line">    Y = np.concatenate([boxes, classes_onehot], axis=1)</span><br><span class="line">    X = np.array(images)</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)</span><br><span class="line">    return np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    x_train, x_test, y_train, y_test = load_data()</span><br><span class="line"></span><br><span class="line">    print(x_train.shape)</span><br><span class="line">    print(y_train.shape)</span><br><span class="line">    print(x_test.shape)</span><br><span class="line">    print(y_test.shape)</span><br><span class="line"># 输出</span><br><span class="line">(167, 227, 227, 3)</span><br><span class="line">(167, 7)</span><br><span class="line">(19, 227, 227, 3)</span><br><span class="line">(19, 7)</span><br></pre></td></tr></table></figure>
<h2 id="pytorch加载"><a href="#pytorch加载" class="headerlink" title="pytorch加载"></a>pytorch加载</h2><p>参考<a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/pytorch/[torchvision]%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86%E6%93%8D%E4%BD%9C/" target="_blank" rel="noopener">[torchvision]自定义数据集和预处理操作</a>实现自定义数据集</p>
<p>继承自类<code>torch.utils.data.Dataset</code>，重写了函数<code>__getitem__</code>和<code>__len__</code>。如果是训练部分，加载编号前<code>50</code>个图像；如果是测试部分，加载<code>50</code>之后的图像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class LocationDataSet(Dataset):</span><br><span class="line"></span><br><span class="line">    def __init__(self, root_dir, train=True, transform=None, input_dim=1):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        自定义数据集类，加载定位数据集</span><br><span class="line">        1. 训练部分，加载编码前50图像和标记数据</span><br><span class="line">        2. 测试部分，加载编码50之后图像和标记数据</span><br><span class="line">        :param root_dir:</span><br><span class="line">        :param train:</span><br><span class="line">        :param transform:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        cates = [&apos;cucumber&apos;, &apos;eggplant&apos;, &apos;mushroom&apos;]</span><br><span class="line">        class_binary_label = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]</span><br><span class="line">        self.train = train</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">        self.imgs = []</span><br><span class="line">        self.bboxes = []</span><br><span class="line">        self.classes = []</span><br><span class="line"></span><br><span class="line">        for cate_idx in range(3):</span><br><span class="line">            if self.train:</span><br><span class="line">                for i in range(1, 51):</span><br><span class="line">                    img, bndbox, class_name = self._get_item(root_dir, cates[cate_idx], i)</span><br><span class="line">                    bndbox = bndbox / input_dim</span><br><span class="line"></span><br><span class="line">                    self.imgs.append(img)</span><br><span class="line">                    self.bboxes.append(np.hstack((bndbox, class_binary_label[cate_idx])))</span><br><span class="line">                    self.classes.append(class_name)</span><br><span class="line">            else:</span><br><span class="line">                for i in range(51, 61):</span><br><span class="line">                    img, bndbox, class_name = self._get_item(root_dir, cates[cate_idx], i)</span><br><span class="line">                    bndbox = bndbox / input_dim</span><br><span class="line"></span><br><span class="line">                    self.imgs.append(img)</span><br><span class="line">                    self.bboxes.append(np.hstack((bndbox, class_binary_label[cate_idx])))</span><br><span class="line">                    self.classes.append(class_name)</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, idx):</span><br><span class="line">        img = self.imgs[idx]</span><br><span class="line">        if self.transform:</span><br><span class="line">            sample = self.transform(img)</span><br><span class="line">        else:</span><br><span class="line">            sample = img</span><br><span class="line">        return sample, torch.Tensor(self.bboxes[idx]).float()</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return len(self.imgs)</span><br><span class="line"></span><br><span class="line">    def _get_item(self, root_dir, cate, i):</span><br><span class="line">        img_path = os.path.join(root_dir, &apos;%s_%d.jpg&apos; % (cate, i))</span><br><span class="line">        img = cv2.imread(img_path)</span><br><span class="line"></span><br><span class="line">        xml_path = os.path.join(root_dir, &apos;%s_%d.xml&apos; % (cate, i))</span><br><span class="line">        x = xmltodict.parse(open(xml_path, &apos;rb&apos;))</span><br><span class="line">        bndbox = x[&apos;annotation&apos;][&apos;object&apos;][&apos;bndbox&apos;]</span><br><span class="line">        bndbox = np.array(</span><br><span class="line">            [float(bndbox[&apos;xmin&apos;]), float(bndbox[&apos;ymin&apos;]), float(bndbox[&apos;xmax&apos;]), float(bndbox[&apos;ymax&apos;])])</span><br><span class="line"></span><br><span class="line">        return img, bndbox, x[&apos;annotation&apos;][&apos;object&apos;][&apos;name&apos;]</span><br></pre></td></tr></table></figure>
<p>实现自定义类后，通过加载器进行数据处理</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch.utils.data import Dataset</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line"></span><br><span class="line">def load_data():</span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.ToPILImage(),</span><br><span class="line">        transforms.Resize(input_dim),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    root_dir = &apos;./data/image-localization-dataset/training_images/&apos;</span><br><span class="line">    train_dataset = LocationDataSet(root_dir, train=True, transform=transform, input_dim=input_dim)</span><br><span class="line">    test_dataset = LocationDataSet(root_dir, train=False, transform=transform, input_dim=input_dim)</span><br><span class="line"></span><br><span class="line">    train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)</span><br><span class="line">    test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, num_workers=4)</span><br><span class="line"></span><br><span class="line">    return train_dataloader, test_dataloader</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    train_dataloader, test_dataloader = load_data()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据</category>
        <category>代码库</category>
        <category>数据集</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
        <tag>numpy</tag>
        <tag>sklearn</tag>
        <tag>image localization dataset</tag>
        <tag>xmltodict</tag>
        <tag>glob</tag>
      </tags>
  </entry>
  <entry>
    <title>[目标检测]IoU</title>
    <url>/posts/796ebd4e.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/" target="_blank" rel="noopener">Intersection over Union (IoU) for object detection</a></p><a id="more"></a>

<p><a href="https://en.wikipedia.org/wiki/Jaccard_index" target="_blank" rel="noopener">Jaccard index</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/36303642" target="_blank" rel="noopener">一分钟的CNN：如何理解IoU(Intersection over Union)和NMS(non-maximum suppression)算法？</a></p>
<p><code>IoU(Intersection over union, 交集并集比)</code>是目标检测领域常用的评价标准，通过比较真值边界框（<code>the ground-truth bounding box</code>，手动标记）和预测边界框（<code>the predicted bounding box</code>）的重合度来判定算法检测性能</p>
<p><img src="/imgs/iou/450px-Intersection_over_Union_-_object_detection_bounding_boxes.jpg" alt></p>
<h2 id="原理解析"><a href="#原理解析" class="headerlink" title="原理解析"></a>原理解析</h2><p>在上图中，绿色边框是真值边界框，红色边框是算法检测得到的预测边界框，<code>IoU</code>需要计算两个边界框的重叠面积和并集面积的比率</p>
<script type="math/tex; mode=display">
IoU = \frac {Area\ of\ Overlap}{Area\ of\ Union}</script><p><img src="/imgs/iou/Intersection_over_Union_-_visual_equation.png" alt></p>
<p>更多情况下，分母计算的是由预测边界框和真值边界框所包围的区域</p>
<p><code>IoU</code>的取值范围在<code>[0,1]</code>之间，当<code>IoU&gt;0.5</code>时通常认为是好的预测</p>
<p><img src="/imgs/iou/Intersection_over_Union_-_poor,_good_and_excellent_score.png" alt></p>
<h2 id="python实现"><a href="#python实现" class="headerlink" title="python实现"></a>python实现</h2><p>分别使用<code>numpy</code>和<code>pytorch</code>计算两个边界框的<code>IoU</code>，分为<code>3</code>种情况：</p>
<ol>
<li>完全重叠</li>
<li>部分重叠</li>
<li>没有重叠</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   iou-compute.py</span><br><span class="line">@time:   2020-01-19</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def numpy_iou(target_boxes, pred_boxes):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    target_boxes和pred_boxes大小相同:[N, 4]，其中N表示边框数目，4表示保存的是[xmin, ymin, xmax, ymax]</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    xA = np.maximum(target_boxes[:, 0], pred_boxes[:, 0])</span><br><span class="line">    yA = np.maximum(target_boxes[:, 1], pred_boxes[:, 1])</span><br><span class="line">    xB = np.minimum(target_boxes[:, 2], pred_boxes[:, 2])</span><br><span class="line">    yB = np.minimum(target_boxes[:, 3], pred_boxes[:, 3])</span><br><span class="line">    # 计算交集面积</span><br><span class="line">    intersection = np.maximum(0.0, xB - xA) * np.maximum(0.0, yB - yA)</span><br><span class="line">    # 计算两个边界框面积</span><br><span class="line">    boxAArea = (target_boxes[:, 2] - target_boxes[:, 0]) * (target_boxes[:, 3] - target_boxes[:, 1])</span><br><span class="line">    boxBArea = (pred_boxes[:, 2] - pred_boxes[:, 0]) * (pred_boxes[:, 3] - pred_boxes[:, 1])</span><br><span class="line"></span><br><span class="line">    iou = intersection / (boxAArea + boxBArea - intersection)</span><br><span class="line">    return iou</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def pytorch_iou(target_boxes, pred_boxes):</span><br><span class="line">    x_min = torch.max(target_boxes[:, 0], pred_boxes[:, 0])</span><br><span class="line">    y_min = torch.max(target_boxes[:, 1], pred_boxes[:, 1])</span><br><span class="line">    x_max = torch.min(target_boxes[:, 2], pred_boxes[:, 2])</span><br><span class="line">    y_max = torch.min(target_boxes[:, 3], pred_boxes[:, 3])</span><br><span class="line">    # 计算交集面积</span><br><span class="line">    intersection = torch.max(torch.zeros(x_max.shape), x_max - x_min) \</span><br><span class="line">                   * torch.max(torch.zeros(y_max.shape), y_max - y_min)</span><br><span class="line"></span><br><span class="line">    # 计算两个边界框面积</span><br><span class="line">    boxAArea = (target_boxes[:, 2] - target_boxes[:, 0]) * (target_boxes[:, 3] - target_boxes[:, 1])</span><br><span class="line">    boxBArea = (pred_boxes[:, 2] - pred_boxes[:, 0]) * (pred_boxes[:, 3] - pred_boxes[:, 1])</span><br><span class="line"></span><br><span class="line">    iou = intersection / (boxAArea + boxBArea - intersection)</span><br><span class="line">    return iou</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    target_boxes = np.array([[10, 10, 50, 50], [40, 270, 100, 380], [450, 300, 500, 500]])</span><br><span class="line">    pred_boxes = np.array([[20, 20, 40, 40], [30, 280, 200, 300], [400, 200, 450, 250]])</span><br><span class="line"></span><br><span class="line">    iou1 = numpy_iou(target_boxes, pred_boxes)</span><br><span class="line">    iou2 = pytorch_iou(torch.Tensor(target_boxes), torch.Tensor(pred_boxes))</span><br><span class="line"></span><br><span class="line">    print(&apos;numpy:&apos;, iou1)</span><br><span class="line">    print(&apos;pytorch:&apos;, iou2)</span><br><span class="line"></span><br><span class="line">    img = np.ones((650, 650, 3)) * 255</span><br><span class="line">    for item in target_boxes:</span><br><span class="line">        xmin, ymin, xmax, ymax = item</span><br><span class="line">        cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 0, 255), thickness=2)</span><br><span class="line">    for item in pred_boxes:</span><br><span class="line">        xmin, ymin, xmax, ymax = item</span><br><span class="line">        cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), thickness=2)</span><br><span class="line"></span><br><span class="line">    cv2.imshow(&apos;img&apos;, img)</span><br><span class="line">    cv2.waitKey(0)</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/iou/IoU.png" alt></p>
<p>计算结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">numpy: [0.25       0.13636364 0.        ]</span><br><span class="line">pytorch: tensor([0.2500, 0.1364, 0.0000])</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>算法</category>
        <category>评价标准</category>
      </categories>
      <tags>
        <tag>IoU</tag>
      </tags>
  </entry>
  <entry>
    <title>[多分类]PR曲线</title>
    <url>/posts/2bbcad17.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://zhujian.tech/posts/bca792b4.html" target="_blank" rel="noopener"> [二分类]PR曲线</a></p><p><a href="https://zhujian.tech/posts/48526d13.html" target="_blank" rel="noopener">[多分类]ROC曲线</a></p><p>计算多分类任务的<code>PR</code>曲线</p><h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><p>参考：<a href="https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;oldid=793358396#Average_precision" target="_blank" rel="noopener">Mean average precision</a></p><a id="more"></a>




<p>计算多分类任务的<code>PR</code>曲线面积<code>AP</code>，通常使用微平均方式（<code>micro</code>），即累加所有的标签的混淆矩阵，统一计算精确度和召回率</p>
<h2 id="python"><a href="#python" class="headerlink" title="python"></a>python</h2><p><code>sklearn</code>库提供了函数<a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" target="_blank" rel="noopener">sklearn.metrics.average_precision_score</a>计算<code>AP</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def average_precision_score(y_true, y_score, average=&quot;macro&quot;, pos_label=1, sample_weight=None):</span><br></pre></td></tr></table></figure>
<p>利用函数<a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" target="_blank" rel="noopener">sklearn.metrics.precision_recall_curve</a>计算微平均方式的精确度和召回率</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">precision[&quot;micro&quot;], recall[&quot;micro&quot;], _ = precision_recall_curve(y_test.ravel(), y_score.ravel())</span><br></pre></td></tr></table></figure>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>参考：<a href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html?highlight=precision%20recall#precision-recall" target="_blank" rel="noopener">Precision-Recall</a></p>
<p>使用<code>iris</code>数据集和单层神经网络进行<code>PR</code>曲线绘制</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   multi-pr-nn.py</span><br><span class="line">@time:   2020-01-11</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from nn_classifier import NN</span><br><span class="line">from sklearn.preprocessing import label_binarize</span><br><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import precision_recall_curve</span><br><span class="line">from sklearn.metrics import average_precision_score</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data():</span><br><span class="line">    # Import some data to play with</span><br><span class="line">    iris = datasets.load_iris()</span><br><span class="line">    X = iris.data</span><br><span class="line">    y = iris.target</span><br><span class="line"></span><br><span class="line">    # shuffle and split training and test sets</span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)</span><br><span class="line"></span><br><span class="line">    return X_train, X_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">    n_classes = 3</span><br><span class="line"></span><br><span class="line">    # 数据标准化</span><br><span class="line">    x_train = X_train.astype(np.float64)</span><br><span class="line">    x_test = X_test.astype(np.float64)</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-8</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(np.maximum(var, eps))</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(np.maximum(var, eps))</span><br><span class="line"></span><br><span class="line">    # 定义分类器，训练和预测</span><br><span class="line">    classifier = NN(None, input_dim=4, num_classes=3)</span><br><span class="line">    classifier.train(x_train, y_train, num_iters=100, batch_size=8, verbose=True)</span><br><span class="line">    res_labels, y_score = classifier.predict(x_test)</span><br><span class="line"></span><br><span class="line">    # For each class</span><br><span class="line">    precision = dict()</span><br><span class="line">    recall = dict()</span><br><span class="line">    average_precision = dict()</span><br><span class="line"></span><br><span class="line">    # Binarize the output 将类别标签二值化</span><br><span class="line">    y_test = label_binarize(y_test, classes=[0, 1, 2])</span><br><span class="line">    for i in range(n_classes):</span><br><span class="line">        precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_score[:, i])</span><br><span class="line">        average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])</span><br><span class="line"></span><br><span class="line">    # 计算微定义AP</span><br><span class="line">    # A &quot;micro-average&quot;: quantifying score on all classes jointly</span><br><span class="line">    precision[&quot;micro&quot;], recall[&quot;micro&quot;], _ = precision_recall_curve(y_test.ravel(), y_score.ravel())</span><br><span class="line">    average_precision[&quot;micro&quot;] = average_precision_score(y_test, y_score, average=&quot;micro&quot;)</span><br><span class="line">    print(&apos;Average precision score, micro-averaged over all classes: &#123;0:0.2f&#125;&apos;.format(average_precision[&quot;micro&quot;]))</span><br><span class="line"></span><br><span class="line">    # plt.figure()</span><br><span class="line">    # plt.step(recall[&apos;micro&apos;], precision[&apos;micro&apos;], where=&apos;post&apos;)</span><br><span class="line">    # plt.xlabel(&apos;Recall&apos;)</span><br><span class="line">    # plt.ylabel(&apos;Precision&apos;)</span><br><span class="line">    # plt.ylim([0.0, 1.05])</span><br><span class="line">    # plt.xlim([0.0, 1.0])</span><br><span class="line">    # plt.title(&apos;Average precision score, micro-averaged over all classes: AP=&#123;0:0.2f&#125;&apos;.format(average_precision[&quot;micro&quot;]))</span><br><span class="line">    # plt.show()</span><br><span class="line"></span><br><span class="line">    # setup plot details</span><br><span class="line">    colors = [&apos;navy&apos;, &apos;turquoise&apos;, &apos;darkorange&apos;, &apos;cornflowerblue&apos;, &apos;teal&apos;]</span><br><span class="line">    plt.figure(figsize=(7, 8))</span><br><span class="line">    f_scores = np.linspace(0.2, 0.8, num=4)</span><br><span class="line">    lines = []</span><br><span class="line">    labels = []</span><br><span class="line"></span><br><span class="line">    l, = plt.plot(recall[&quot;micro&quot;], precision[&quot;micro&quot;], color=&apos;gold&apos;, lw=2)</span><br><span class="line">    lines.append(l)</span><br><span class="line">    labels.append(&apos;micro-average Precision-recall (area = &#123;0:0.2f&#125;)&apos;.format(average_precision[&quot;micro&quot;]))</span><br><span class="line"></span><br><span class="line">    for i, color in zip(range(n_classes), colors):</span><br><span class="line">        l, = plt.plot(recall[i], precision[i], color=color, lw=2)</span><br><span class="line">        lines.append(l)</span><br><span class="line">        labels.append(&apos;Precision-recall for class &#123;0&#125; (area = &#123;1:0.2f&#125;)&apos;</span><br><span class="line">                      &apos;&apos;.format(i, average_precision[i]))</span><br><span class="line"></span><br><span class="line">    fig = plt.gcf()</span><br><span class="line">    fig.subplots_adjust(bottom=0.15)</span><br><span class="line">    plt.xlim([0.0, 1.0])</span><br><span class="line">    plt.ylim([0.0, 1.05])</span><br><span class="line">    plt.xlabel(&apos;Recall&apos;)</span><br><span class="line">    plt.ylabel(&apos;Precision&apos;)</span><br><span class="line">    plt.title(&apos;Extension of Precision-Recall curve to multi-class&apos;)</span><br><span class="line">    plt.legend(lines, labels, loc=(0, -.38), prop=dict(size=14))</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>实现结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iteration 0 / 100: loss 1.080253</span><br><span class="line">iteration 10 / 100: loss 0.848652</span><br><span class="line">iteration 20 / 100: loss 0.703864</span><br><span class="line">iteration 30 / 100: loss 0.611669</span><br><span class="line">iteration 40 / 100: loss 0.549452</span><br><span class="line">iteration 50 / 100: loss 0.504679</span><br><span class="line">iteration 60 / 100: loss 0.470638</span><br><span class="line">iteration 70 / 100: loss 0.443626</span><br><span class="line">iteration 80 / 100: loss 0.421484</span><br><span class="line">iteration 90 / 100: loss 0.402878</span><br><span class="line">Average precision score, micro-averaged over all classes: 0.92</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/multi-pr/multi-pr.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>评价标准</category>
        <category>代码库</category>
        <category>PR曲线</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>sklearn</tag>
        <tag>AP</tag>
      </tags>
  </entry>
  <entry>
    <title>[多分类]ROC曲线</title>
    <url>/posts/48526d13.html</url>
    <content><![CDATA[<p>参考：<a href="https://zhujian.tech/posts/71a847e.html" target="_blank" rel="noopener">[二分类]ROC曲线</a></p><p>学习和使用多分类任务的<code>ROC</code>曲线</p><h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><p>参考：[<a href="https://scikit-learn.org/stable/modules/model_evaluation.html#from-binary-to-multiclass-and-multilabel" target="_blank" rel="noopener">3.3.2.1. From binary to multiclass and multilabel</a>]</p><a id="more"></a>


<p>通过<code>ROC</code>曲线能够有效评估算法的性能，默认情况下适用于二分类任务，在多分类任务中利用<code>one vs rest</code>方式计算各个类别的混淆矩阵，使用如下平均方式</p>
<ol>
<li><code>macro</code>：分别求出每个类，再进行算术平均<ul>
<li>优点：直观、易懂，并且方便实现</li>
<li>缺点：实际情况下可能不同类别拥有不同的重要性，宏平均会导致计算结果受不常用类别的影响</li>
</ul>
</li>
<li><code>weighted</code>：加权累加每个类别</li>
<li><code>micro</code>：全局计算。将所有混淆矩阵累加在一起，然后计算<code>TPR/FPR/AUC</code></li>
<li><code>samples</code>：适用于样本不平衡的情况，参考<a href="https://zhuanlan.zhihu.com/p/59862986" target="_blank" rel="noopener">详解sklearn的多分类模型评价指标</a></li>
</ol>
<h2 id="python"><a href="#python" class="headerlink" title="python"></a>python</h2><p><code>sklearn</code>库提供了函数<a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" target="_blank" rel="noopener">sklearn.metrics.roc_auc_score</a>计算<code>ROC</code>曲线的<code>AUC</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def roc_auc_score(y_true, y_score, average=&quot;macro&quot;, sample_weight=None, max_fpr=None):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>y_true</code>：大小为[n_samples]（仅表示正样本标签）或者<code>[n_samples, n_classes]</code></li>
<li><code>y_score</code>：大小和<code>y_true</code>一致，表示预测成绩</li>
<li><code>average</code>：适用于多分类任务的平均方式<ul>
<li><code>micro</code>：微平均方式。求和所有类别的混淆矩阵，再计算<code>TPR/FPR</code></li>
<li><code>macro</code>：宏平均方式。计算各个类别的混淆矩阵，再计算平均值</li>
<li><code>weighted</code>：加权平均</li>
<li><code>samples</code></li>
</ul>
</li>
</ul>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>参考：<a href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py" target="_blank" rel="noopener">Receiver Operating Characteristic (ROC)</a></p>
<h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>使用<code>sklearn</code>库提供的<code>iris</code>数据集，每类<code>50</code>个样本，每个样本包含<code>4</code>个特征，共<code>3</code>类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def load_data():</span><br><span class="line">    # Import some data to play with</span><br><span class="line">    iris = datasets.load_iris()</span><br><span class="line">    X = iris.data</span><br><span class="line">    y = iris.target</span><br><span class="line"></span><br><span class="line">    # shuffle and split training and test sets</span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)</span><br><span class="line"></span><br><span class="line">    return X_train, X_test, y_train, y_test</span><br></pre></td></tr></table></figure>
<h2 id="分类器"><a href="#分类器" class="headerlink" title="分类器"></a>分类器</h2><p>参考<a href="https://zhujian.tech/posts/81a57a7.html" target="_blank" rel="noopener">神经网络分类器</a>使用单层神经网络</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>通过两种方式计算多分类任务的<code>macro AUC</code>和<code>micro AUC</code>，一是通过分别计算每类的<code>TRP/FPR</code>，再计算最后的<code>AUC</code>；二是直接调用函数<code>roc_auc_score</code>计算</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   multi-roc-nn.py</span><br><span class="line">@time:   2020-01-11</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   2-roc.py</span><br><span class="line">@time:   2020-01-10</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">from mnist_reader import load_mnist</span><br><span class="line">from nn_classifier import NN</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from scipy import interp</span><br><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import label_binarize</span><br><span class="line">from sklearn.metrics import auc</span><br><span class="line">from sklearn.metrics import roc_curve</span><br><span class="line">from sklearn.metrics import roc_auc_score</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data():</span><br><span class="line">    # Import some data to play with</span><br><span class="line">    iris = datasets.load_iris()</span><br><span class="line">    X = iris.data</span><br><span class="line">    y = iris.target</span><br><span class="line"></span><br><span class="line">    # shuffle and split training and test sets</span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)</span><br><span class="line"></span><br><span class="line">    return X_train, X_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    X_train, X_test, y_train, y_test = load_data()</span><br><span class="line">    n_classes = 3</span><br><span class="line"></span><br><span class="line">    # 数据标准化</span><br><span class="line">    x_train = X_train.astype(np.float64)</span><br><span class="line">    x_test = X_test.astype(np.float64)</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-8</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(np.maximum(var, eps))</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(np.maximum(var, eps))</span><br><span class="line"></span><br><span class="line">    # 定义分类器，训练和预测</span><br><span class="line">    classifier = NN(None, input_dim=4, num_classes=3)</span><br><span class="line">    classifier.train(x_train, y_train, num_iters=100, batch_size=8, verbose=True)</span><br><span class="line">    res_labels, y_score = classifier.predict(x_test)</span><br><span class="line">    # print(y_score)</span><br><span class="line"></span><br><span class="line">    # Compute ROC curve and ROC area for each class</span><br><span class="line">    fpr = dict()</span><br><span class="line">    tpr = dict()</span><br><span class="line">    roc_auc = dict()</span><br><span class="line"></span><br><span class="line">    # Binarize the output 将类别标签二值化</span><br><span class="line">    y_test = label_binarize(y_test, classes=[0, 1, 2])</span><br><span class="line">    # one vs rest方式计算每个类别的TPR/FPR以及AUC</span><br><span class="line">    for i in range(n_classes):</span><br><span class="line">        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])</span><br><span class="line">        roc_auc[i] = auc(fpr[i], tpr[i])</span><br><span class="line"></span><br><span class="line">    # Compute micro-average ROC curve and ROC area</span><br><span class="line">    # 微平均方式计算TPR/FPR，最后得到AUC</span><br><span class="line">    fpr[&quot;micro&quot;], tpr[&quot;micro&quot;], _ = roc_curve(y_test.ravel(), y_score.ravel())</span><br><span class="line">    roc_auc[&quot;micro&quot;] = auc(fpr[&quot;micro&quot;], tpr[&quot;micro&quot;])</span><br><span class="line">    # 直接调用函数计算</span><br><span class="line">    micro_auc = roc_auc_score(y_test, y_score, average=&apos;micro&apos;)</span><br><span class="line"></span><br><span class="line">    lw = 2</span><br><span class="line">    # plt.figure()</span><br><span class="line">    # plt.plot(fpr[2], tpr[2], color=&apos;darkorange&apos;, lw=lw, label=&apos;ROC curve (area = %0.2f)&apos; % roc_auc[2])</span><br><span class="line">    # plt.plot([0, 1], [0, 1], color=&apos;navy&apos;, lw=lw, linestyle=&apos;--&apos;)</span><br><span class="line">    # plt.xlim([0.0, 1.0])</span><br><span class="line">    # plt.ylim([0.0, 1.05])</span><br><span class="line">    # plt.xlabel(&apos;False Positive Rate&apos;)</span><br><span class="line">    # plt.ylabel(&apos;True Positive Rate&apos;)</span><br><span class="line">    # plt.title(&apos;Receiver operating characteristic example&apos;)</span><br><span class="line">    # plt.legend(loc=&quot;lower right&quot;)</span><br><span class="line">    # plt.show()</span><br><span class="line"></span><br><span class="line">    # First aggregate all false positive rates</span><br><span class="line">    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))</span><br><span class="line"></span><br><span class="line">    # Then interpolate all ROC curves at this points</span><br><span class="line">    mean_tpr = np.zeros_like(all_fpr)</span><br><span class="line">    for i in range(n_classes):</span><br><span class="line">        mean_tpr += interp(all_fpr, fpr[i], tpr[i])</span><br><span class="line"></span><br><span class="line">    # Finally average it and compute AUC</span><br><span class="line">    mean_tpr /= n_classes</span><br><span class="line"></span><br><span class="line">    fpr[&quot;macro&quot;] = all_fpr</span><br><span class="line">    tpr[&quot;macro&quot;] = mean_tpr</span><br><span class="line">    roc_auc[&quot;macro&quot;] = auc(fpr[&quot;macro&quot;], tpr[&quot;macro&quot;])</span><br><span class="line">    # 直接调用函数计算</span><br><span class="line">    macro_auc = roc_auc_score(y_test, y_score, average=&apos;macro&apos;)</span><br><span class="line"></span><br><span class="line">    print(roc_auc)</span><br><span class="line">    print(&apos;micro auc:&apos;, micro_auc)</span><br><span class="line">    print(&apos;macro auc:&apos;, macro_auc)</span><br><span class="line"></span><br><span class="line">    # Plot all ROC curves</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(fpr[&quot;micro&quot;], tpr[&quot;micro&quot;],</span><br><span class="line">             label=&apos;micro-average ROC curve (area = &#123;0:0.2f&#125;)&apos;.format(roc_auc[&quot;micro&quot;]),</span><br><span class="line">             color=&apos;deeppink&apos;, linestyle=&apos;:&apos;, linewidth=4)</span><br><span class="line"></span><br><span class="line">    plt.plot(fpr[&quot;macro&quot;], tpr[&quot;macro&quot;],</span><br><span class="line">             label=&apos;macro-average ROC curve (area = &#123;0:0.2f&#125;)&apos;.format(roc_auc[&quot;macro&quot;]),</span><br><span class="line">             color=&apos;navy&apos;, linestyle=&apos;:&apos;, linewidth=4)</span><br><span class="line"></span><br><span class="line">    colors = [&apos;aqua&apos;, &apos;darkorange&apos;, &apos;cornflowerblue&apos;]</span><br><span class="line">    for i, color in zip(range(n_classes), colors):</span><br><span class="line">        plt.plot(fpr[i], tpr[i], color=color, lw=lw,</span><br><span class="line">                 label=&apos;ROC curve of class &#123;0&#125; (area = &#123;1:0.2f&#125;)&apos;.format(i, roc_auc[i]))</span><br><span class="line"></span><br><span class="line">    plt.plot([0, 1], [0, 1], &apos;k--&apos;, lw=lw)</span><br><span class="line">    plt.xlim([0.0, 1.0])</span><br><span class="line">    plt.ylim([0.0, 1.05])</span><br><span class="line">    plt.xlabel(&apos;False Positive Rate&apos;)</span><br><span class="line">    plt.ylabel(&apos;True Positive Rate&apos;)</span><br><span class="line">    plt.title(&apos;Some extension of Receiver operating characteristic to multi-class&apos;)</span><br><span class="line">    plt.legend(loc=&quot;lower right&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iteration 0 / 100: loss 1.078953</span><br><span class="line">iteration 10 / 100: loss 0.822893</span><br><span class="line">iteration 20 / 100: loss 0.663991</span><br><span class="line">iteration 30 / 100: loss 0.563895</span><br><span class="line">iteration 40 / 100: loss 0.497447</span><br><span class="line">iteration 50 / 100: loss 0.450596</span><br><span class="line">iteration 60 / 100: loss 0.415750</span><br><span class="line">iteration 70 / 100: loss 0.388712</span><br><span class="line">iteration 80 / 100: loss 0.367034</span><br><span class="line">iteration 90 / 100: loss 0.349197</span><br><span class="line">&#123;0: 1.0, 1: 0.8764534883720929, 2: 0.9312, &apos;micro&apos;: 0.9399111111111111, &apos;macro&apos;: 0.9408812015503877&#125;</span><br><span class="line">micro auc: 0.9399111111111111</span><br><span class="line">macro auc: 0.935884496124031</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/multi-roc/multi-roc.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>评价标准</category>
        <category>代码库</category>
        <category>ROC曲线</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>sklearn</tag>
        <tag>AUC</tag>
      </tags>
  </entry>
  <entry>
    <title>[多分类]混淆矩阵</title>
    <url>/posts/c35edb41.html</url>
    <content><![CDATA[<p>参考：<a href="https://www.zhujian.tech/posts/74ea027a.html">[二分类]混淆矩阵</a></p><p>学习多分类任务的混淆矩阵计算，共有两种方式：</p><ol>
<li><code>one VS rest</code></li>
<li><code>one VS one</code></li>
</ol><a id="more"></a>


<h2 id="one-VS-rest"><a href="#one-VS-rest" class="headerlink" title="one VS rest"></a>one VS rest</h2><p>指定其中一个类别为正样本，将其他类别统统归类为负样本，然后进行混淆矩阵的计算</p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><p><code>sklearn</code>提供了实现函数：<a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.multilabel_confusion_matrix.html?highlight=multilabel_confusion_matrix#sklearn-metrics-multilabel-confusion-matrix" target="_blank" rel="noopener">sklearn.metrics.multilabel_confusion_matrix</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def multilabel_confusion_matrix(y_true, y_pred, sample_weight=None, labels=None, samplewise=False):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>y_true</code>：一维数组（仅输出正样本标签）或者多维矩阵（<code>n_samples, n_outputs</code>）</li>
<li><code>y_pred</code>：和<code>y_true</code>的格式一样</li>
<li><code>labels</code>：列表形式，指定正样本的顺序，否则函数将按排序顺序进行计算</li>
</ul>
<p>该函数计算基于每个类别的混淆矩阵，输出大小为<code>(n_outputs, 2, 2)</code>，每个混淆矩阵的排列如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">TN</th>
<th style="text-align:center">FP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">FN</td>
<td style="text-align:center">TP</td>
</tr>
</tbody>
</table>
</div>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>对<code>3</code>类任务进行计算，输入标签如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[&apos;cat&apos;, &apos;ant&apos;, &apos;cat&apos;, &apos;cat&apos;, &apos;ant&apos;, &apos;bird&apos;]</span><br></pre></td></tr></table></figure>
<p>预测标签如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[&apos;ant&apos;, &apos;ant&apos;, &apos;cat&apos;, &apos;cat&apos;, &apos;ant&apos;, &apos;cat&apos;]</span><br></pre></td></tr></table></figure>
<p>计算每类的混淆矩阵，并指定计算顺序：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">res = multilabel_confusion_matrix(y_true, y_pred, labels=[&quot;ant&quot;, &quot;bird&quot;, &quot;cat&quot;])</span><br></pre></td></tr></table></figure>
<p>输出大小为<code>(3, 2, 2)</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[[[3 1]</span><br><span class="line">  [0 2]]</span><br><span class="line"></span><br><span class="line"> [[5 0]</span><br><span class="line">  [1 0]]</span><br><span class="line"></span><br><span class="line"> [[2 1]</span><br><span class="line">  [1 2]]]</span><br></pre></td></tr></table></figure>
<h2 id="one-VS-one"><a href="#one-VS-one" class="headerlink" title="one VS one"></a>one VS one</h2><p>在多分类任务中，还可以对每两个类别进行混淆矩阵的计算</p>
<h3 id="python-1"><a href="#python-1" class="headerlink" title="python"></a>python</h3><p><code>sklearn</code>提供了实现函数：<a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix" target="_blank" rel="noopener">sklearn.metrics.confusion_matrix</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def confusion_matrix(y_true, y_pred, labels=None, sample_weight=None):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>y_true</code>：一维数组，指定正样本</li>
<li><code>y_pred</code>：一维数组，输出预测标签</li>
<li><code>labels</code>：指定正样本顺序</li>
</ul>
<p>函数返回一个<code>(n_classes, n_classes)</code>大小的混淆矩阵</p>
<h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>如果是二分类，其混淆矩阵排列为：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">TN</th>
<th style="text-align:center">FP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">FN</td>
<td style="text-align:center">TP</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()</span><br><span class="line">    print(tn, fp, fn, tp)</span><br><span class="line"># 输出</span><br><span class="line">0 2 1 1</span><br></pre></td></tr></table></figure>
<p>如果是多分类，其输出如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    y_true = [&quot;cat&quot;, &quot;ant&quot;, &quot;cat&quot;, &quot;cat&quot;, &quot;ant&quot;, &quot;bird&quot;]</span><br><span class="line">    y_pred = [&quot;ant&quot;, &quot;ant&quot;, &quot;cat&quot;, &quot;cat&quot;, &quot;ant&quot;, &quot;cat&quot;]</span><br><span class="line">    res = confusion_matrix(y_true, y_pred, labels=[&quot;ant&quot;, &quot;bird&quot;, &quot;cat&quot;])</span><br><span class="line">    print(res)</span><br><span class="line"># 输出</span><br><span class="line">[[2 0 0]</span><br><span class="line"> [0 0 1]</span><br><span class="line"> [1 0 2]]</span><br></pre></td></tr></table></figure>
<ul>
<li>点$(i,i)$的值表示第$i$类正确分类的数目</li>
<li>点$(i,j)$的值表示第$i$类错误分类为$j$类的数目</li>
</ul>
<h2 id="利用混淆矩阵查看错误分类"><a href="#利用混淆矩阵查看错误分类" class="headerlink" title="利用混淆矩阵查看错误分类"></a>利用混淆矩阵查看错误分类</h2><p>参考：<a href="https://www.cnblogs.com/shuai-long/p/11649896.html" target="_blank" rel="noopener">分类算法-3.多分类中的混淆矩阵</a></p>
<p>利用<code>one vs one</code>的方式计算多分类任务，能够理清具体的错误分类场景</p>
<h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>参考<a href="https://www.zhujian.tech/posts/631c599a.html">Fashion-MNIST数据集解析</a></p>
<h3 id="分类器"><a href="#分类器" class="headerlink" title="分类器"></a>分类器</h3><p>参考<a href="https://www.zhujian.tech/posts/81a57a7.html">神经网络分类器</a></p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   confusion-matrix.py</span><br><span class="line">@time:   2020-01-11</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">from nn_classifier import NN</span><br><span class="line">from mnist_reader import load_mnist</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2</span><br><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data():</span><br><span class="line">    path = &quot;/home/zj/data/fashion-mnist/fashion-mnist/data/fashion/&quot;</span><br><span class="line">    train_images, train_labels = load_mnist(path, kind=&apos;train&apos;)</span><br><span class="line">    test_images, test_labels = load_mnist(path, kind=&apos;t10k&apos;)</span><br><span class="line"></span><br><span class="line">    return train_images, train_labels, test_images, test_labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    train_images, train_labels, test_images, test_labels = load_data()</span><br><span class="line">    print(train_images.shape)</span><br><span class="line">    print(train_labels.shape)</span><br><span class="line"></span><br><span class="line">    x_train = train_images.astype(np.float64)</span><br><span class="line">    x_test = test_images.astype(np.float64)</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-8</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(np.maximum(var, eps))</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(np.maximum(var, eps))</span><br><span class="line"></span><br><span class="line">    classifier = NN([100, 20], input_dim=28 * 28, num_classes=10)</span><br><span class="line">    classifier.train(x_train, train_labels, verbose=True)</span><br><span class="line">    y_pred = classifier.predict(x_test)</span><br><span class="line"></span><br><span class="line">    cm = confusion_matrix(test_labels, y_pred)</span><br><span class="line">    print(cm)</span><br><span class="line"></span><br><span class="line">    plt.matshow(cm)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>使用神经网络分类<code>Fashion-MNIST</code>，结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[[852   1  21  25   4   0  86   0  11   0]</span><br><span class="line"> [  7 967   3  16   5   0   1   0   1   0]</span><br><span class="line"> [ 25   1 833  12  70   1  55   0   3   0]</span><br><span class="line"> [ 38   5  14 888  30   2  20   0   3   0]</span><br><span class="line"> [  6   1 118  44 776   1  52   0   2   0]</span><br><span class="line"> [  0   0   0   0   1 955   0  23   2  19]</span><br><span class="line"> [167   1  93  38  75   4 608   0  14   0]</span><br><span class="line"> [  0   0   0   0   0  28   0 921   0  51]</span><br><span class="line"> [ 12   2   2   8   5   7  12   3 948   1]</span><br><span class="line"> [  0   0   1   0   0  14   1  16   0 968]]</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/multi-cm/cm-mnist.png" alt></p>
<p>从混淆矩阵中可以发现，标签<code>0</code>（就是<code>T</code>恤）最容易错误分类为标签<code>6</code>（就是衬衫）；标签<code>4</code>（就是外套）最容易错误分类为标签<code>２</code>（就是套衫）</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>评价标准</category>
        <category>代码库</category>
        <category>混淆矩阵</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title>[二分类]F1-score</title>
    <url>/posts/50c7d392.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://en.wikipedia.org/wiki/F1_score" target="_blank" rel="noopener">F1 score</a></p><p><a href="https://en.wikipedia.org/wiki/Confusion_matrix" target="_blank" rel="noopener">Confusion matrix</a></p><p>$F_{1} score$可以解释为精确性和召回率的加权平均值，相当于精确率和召回率的综合评价指标</p><a id="more"></a>



<p><strong><em>当前着重于二分类<code>F1 score</code></em></strong></p>
<h2 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h2><p>精确率和召回率的计算参考<a href="https://zhujian.tech/posts/bca792b4.html" target="_blank" rel="noopener">[二分类]PR曲线</a>。$F_{1} score$的计算公式如下：</p>
<script type="math/tex; mode=display">
F_{1} = \frac {2}{recall^{-1} + precision^{-1}} = 2\cdot \frac {precision\cdot recall}{precision + recall}</script><p>$F_{1}$取值为<code>[0, 1]</code>，其中数值为<code>1</code>表示实现了最好的精确率和召回率，数值为<code>0</code>表示性能最差</p>
<h2 id="python"><a href="#python" class="headerlink" title="python"></a>python</h2><p>参考：<a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html?highlight=f1%20score#sklearn.metrics.f1_score" target="_blank" rel="noopener">sklearn.metrics.f1_score</a></p>
<p><code>Python</code>库<code>Sklearn</code>实现了$F_{1} score$的计算</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def f1_score(y_true, y_pred, labels=None, pos_label=1, average=&apos;binary&apos;, sample_weight=None):</span><br></pre></td></tr></table></figure>
<p>该函数返回二元分类中正样本的<code>F1 score</code>值</p>
<ul>
<li><code>y_true</code>：一维数组，表示正样本标签</li>
<li><code>y_pred</code>：一维数组，表示分类器预测类别</li>
<li><code>pos_label</code>：字符串或者数值，表示正样本类标签，默认为<code>1</code></li>
</ul>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>参考<a href="https://zhujian.tech/posts/bca792b4.html" target="_blank" rel="noopener">[二分类]PR曲线</a>实现二元数据集的提取，分类器的训练和预测。<code>F1-score</code>计算如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import f1_score</span><br><span class="line"></span><br><span class="line">classifier = LogisticClassifier()</span><br><span class="line">classifier.train(x_train, train_labels)</span><br><span class="line">res_labels, scores = classifier.predict(x_test)</span><br><span class="line"></span><br><span class="line">f1 = f1_score(test_labels, res_labels)</span><br><span class="line">print(f1)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>算法</category>
        <category>评价标准</category>
        <category>PR曲线</category>
      </categories>
      <tags>
        <tag>F1 score</tag>
      </tags>
  </entry>
  <entry>
    <title>准确率 vs. 精确率</title>
    <url>/posts/5b516f3c.html</url>
    <content><![CDATA[<p>参考：<a href="https://en.wikipedia.org/wiki/Confusion_matrix" target="_blank" rel="noopener">Confusion matrix</a></p><p>准确率和精确率是常用的算法评价标准，但是其定义略有差别</p><ul>
<li>准确率（<code>Accuracy</code>）：预测正确的样本占所有样本的比率</li>
</ul><a id="more"></a>


<script type="math/tex; mode=display">
ACC = \frac {TP + TN}{P+N} = \frac {TP+TN}{TP+TN+FP+FN}</script><ul>
<li>精度率（<code>Precision</code>，也称为<code>PPV,  positive predictive value</code>）：预测正确的正样本占原先正样本集的比率</li>
</ul>
<script type="math/tex; mode=display">
PPV=\frac {TP}{TP+FP}</script>]]></content>
      <categories>
        <category>算法</category>
        <category>评价标准</category>
      </categories>
      <tags>
        <tag>精确率</tag>
        <tag>准确率</tag>
      </tags>
  </entry>
  <entry>
    <title>[OKR]2020年1月份</title>
    <url>/posts/a3f47f23.html</url>
    <content><![CDATA[<p><code>2020</code>年<code>1</code>月份<code>OKR</code>实现</p><h2 id="目标及关键结果"><a href="#目标及关键结果" class="headerlink" title="目标及关键结果"></a>目标及关键结果</h2><ul>
<li><code>OKR</code>当前的状态<ul>
<li>目标：找到图像相关的研发工作</li>
<li>关键结果：理清检测/分类算法的评判标准(<code>5/10</code>)</li>
<li>关键结果：实现<code>RCNN</code>模型(<code>5/10</code>)</li>
<li>关键结果：<code>C++11</code>实践小结(<code>5/10</code>)</li>
</ul>
</li>
</ul><a id="more"></a>

<h2 id="06-12"><a href="#06-12" class="headerlink" title="06-12"></a>06-12</h2><p><img src="/okr/2020-1/2020-01-06-12.png" alt></p>
<ul>
<li>本周关注的任务<ul>
<li><code>P1</code>：二分类算法的混淆矩阵/<code>ROC</code>曲线/<code>PR</code>曲线/<code>F1-score</code>实现</li>
<li><code>P1</code>：多分类算法的混淆矩阵/<code>ROC</code>曲线/<code>PR</code>曲线/<code>F1-score</code>实现</li>
<li><code>P1</code>：检测算法的<code>mAP/IoU/FPS/mABO</code>实现</li>
</ul>
</li>
<li>未来四周的计划<ul>
<li><code>SelectiveSearch</code>算法实现</li>
<li><code>R-CNN</code>算法实现</li>
<li><code>C++11</code>实践小结</li>
</ul>
</li>
<li>状态指标<ul>
<li>编程语言和代码库的使用熟悉度</li>
<li>对评判标准的理论学习能力</li>
</ul>
</li>
</ul>
<h2 id="13-19"><a href="#13-19" class="headerlink" title="13-19"></a>13-19</h2><p>上周实现了分类任务的评判标准（混淆矩阵/<code>ROC</code>曲线/<code>PR</code>曲线）学习，也学习了目标检测任务的<code>IoU</code>概念，不过并没有学习目标检测的<code>AP/ABO</code>，其原因是这两个概念和具体数据集使用密切联系，所以打算等到之后实际使用时再进一步研究</p>
<p><img src="/okr/2020-1/2020-01-13-19.png" alt></p>
<ul>
<li>本周关注的任务<ul>
<li><code>P1</code>：<code>SelectiveSearch</code>算法实现</li>
<li><code>P2</code>：<code>C++11</code>实践小结</li>
<li><code>P2</code>：<code>PyNet</code>库文档编辑</li>
</ul>
</li>
<li>未来四周的计划<ul>
<li><code>R-CNN</code>算法实现</li>
<li><code>GoogLeNet</code>算法实现</li>
<li><code>Fast R-CNN</code>算法实现</li>
</ul>
</li>
<li>状态指标<ul>
<li><code>SelectiveSearch</code>理论学习</li>
<li>卷积神经网络学习</li>
</ul>
</li>
</ul>
<h2 id="20-26"><a href="#20-26" class="headerlink" title="20-26"></a>20-26</h2><p>上周测试了<code>SelectiveSearch C++/Python</code>算法，同时使用<code>PyTorch</code>完成了一个简单的目标检测器，但是并没有完成<code>C++</code>实践小结和<code>PyNet</code>库文档整理。其原因在于没有很好的设置任务，导致学习的重心和任务产生了偏移，同时目标检测算法的实现、训练和测试需要花费很多时间</p>
<p><img src="/okr/2020-1/2020-01-20-26.png" alt></p>
<ul>
<li>本周关注的任务<ul>
<li><code>P1</code>：<code>SelectiveSearch</code>目标检测实现</li>
<li><code>P1</code>：<code>SelectiveSearch</code>实践小结</li>
<li><code>P2</code>：<code>R-CNN</code>目标检测实现</li>
<li><code>P2</code>：<code>R-CNN</code>实践小结</li>
</ul>
</li>
<li>未来四周的计划<ul>
<li><code>C++</code>实践小结</li>
<li><code>PyNet</code>库整理</li>
<li><code>GraphLib</code>库整理</li>
<li><code>GoogLeNet</code>算法实现</li>
<li><code>Fast R-CNN</code>算法实现</li>
</ul>
</li>
<li>状态指标<ul>
<li><code>SelectiveSearch</code>理论学习</li>
<li><code>R-CNN</code>理论学习</li>
</ul>
</li>
</ul>
<h2 id="27-31"><a href="#27-31" class="headerlink" title="27-31"></a>27-31</h2><p>上周实现了目标检测的数据集采集和训练，不过从<code>25</code>号开始就是春节，并没有完成其余的操作</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>最终的<code>OKR</code>状态如下：</p>
<ul>
<li><code>OKR</code>当前的状态<ul>
<li>目标：找到图像相关的研发工作</li>
<li>关键结果：理清检测/分类算法的评判标准(<code>8/10</code>)</li>
<li>关键结果：实现<code>RCNN</code>模型(<code>6/10</code>)</li>
<li>关键结果：<code>C++11</code>实践小结(<code>5/10</code>)</li>
</ul>
</li>
</ul>
<p>第一个月的<code>OKR</code>没有很好的完成，因为发现并没有很好的理清任务的难度和步骤。后续改进：减少任务量，争取能够完成每月<code>OKR</code></p>
]]></content>
      <categories>
        <category>随笔</category>
        <category>软件工程</category>
        <category>开发流程</category>
      </categories>
      <tags>
        <tag>OKR</tag>
      </tags>
  </entry>
  <entry>
    <title>2019年小结</title>
    <url>/posts/f4cf1e23.html</url>
    <content><![CDATA[<p>在网上看到很多<code>vloger</code>都发布了自己的<code>2019</code>年小结，想想自己的<code>2019</code>年也发生了很多事情，记录一下</p><a id="more"></a>
<h2 id="学业"><a href="#学业" class="headerlink" title="学业"></a>学业</h2><p>今年<code>6</code>月份终于毕业了!!! 虽然毕业证书晚来了一年，但是还是很兴奋，作为人生的一个里程碑吧。另外还有一种解脱感，研究生学习和本科生还是不一样，会有更大的压力和期待，尤其当现实的毕业要求和未来的工作要求不协调的时候，更有一种前所未有的迷茫。拿到毕业证书的那一刻，才能够真正放下学校的事情，进一步向未来前进</p>
<h2 id="专业"><a href="#专业" class="headerlink" title="专业"></a>专业</h2><p>一直把学习分为<code>3</code>个部分：读书、实践和总结。读万卷书，行万里路，当然还要不时总结和回顾</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>研究生期间在老师指导下参与过多个项目，同时也在公司实习过。细细算下来，使用过的编程语言包括了<code>C、C++、Java、Python、Lua</code>，完成的项目有<code>Android app</code>、嵌入式系统工具和桌面系统工具。做的东西越多，当然也能够学习到越多的知识，但是随着实践的增多，对很多知识点并没有进行深入的研究和理解，常常出现重复学习的迹象，这会让我对学习产生烦躁</p>
<p>为了维护内心世界的平静，必须好好的将学习的知识整理成文档和代码仓库</p>
<h4 id="博客和文档"><a href="#博客和文档" class="headerlink" title="博客和文档"></a>博客和文档</h4><p>在大四结束时开通了<code>CSDN</code>博客，在<code>2015-2018</code>年研究生期间一直坚持更新博客内容，记录下所学所用的知识和技能。从2019年开始，为了更加灵活的编辑和发布，利用<a href="https://blog-website-building-guide.readthedocs.io/zh_CN/latest/?badge=latest" target="_blank" rel="noopener">Hexo</a>搭建了个人博客</p>
<p>对于系列文档的编辑，使用<code>Sphinx+Github+Readthedocs</code>方式进行集成，经过近一年的使用后，发现文档生成工具<a href="https://zj-sphinx-github-readthedocs.readthedocs.io/en/latest/" target="_blank" rel="noopener">MkDocs</a>比<code>Sphinx</code>更加实用</p>
<p>博客地址：</p>
<ul>
<li><a href="https://blog.csdn.net/u012005313" target="_blank" rel="noopener">编号1993</a></li>
<li><a href="https://zhujian.tech/posts/bd2847bc.html" target="_blank" rel="noopener">做一个幸福的人</a></li>
</ul>
<h4 id="代码仓库"><a href="#代码仓库" class="headerlink" title="代码仓库"></a>代码仓库</h4><p>本科时期就接触了<code>git</code>工具，虽然能够使用其进行版本管理，但因为缺乏足够的使用规范，导致代码仓库的维护没有持续性。在<code>2019</code>年，我整理出<code>4</code>个版本相关的规范：</p>
<ul>
<li><a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/message/%E5%BC%95%E8%A8%80/" target="_blank" rel="noopener">消息提交规范</a></li>
<li><a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/version/[SEMVER]%E8%AF%AD%E4%B9%89%E7%89%88%E6%9C%AC%E8%A7%84%E8%8C%83/" target="_blank" rel="noopener">语义版本规范</a></li>
<li><a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/readme/%E5%BC%95%E8%A8%80/" target="_blank" rel="noopener">README编写规范</a></li>
<li><a href="https://www.zhujian.tech/posts/c7ee2f15.html">GIT工作流实践</a></li>
</ul>
<p>仓库地址：<a href="https://github.com/zjZSTU" target="_blank" rel="noopener">https://github.com/zjZSTU</a></p>
<h3 id="读书"><a href="#读书" class="headerlink" title="读书"></a>读书</h3><p>因为之前的项目实践经历，让我发现程序员的工作不仅仅是代码的编辑，还需要参与整个软件的开发，包括最开始的提出需求以及后续的测试和发布。在<code>2019</code>年，好好的复习了软件工程相关的内容</p>
<p>另一方面，由于之前的开发针对网络处理的内容不多，所以比较缺乏计算机网络的知识和使用，所以在<code>2019</code>年复习了计算机网络相关的内容</p>
<p>之前的学习经历都与图像领域相关，所以在<code>2019</code>年，我打算好好的巩固一下基于图像处理的深度学习知识，包括了数学逻辑推导、网络构成及其优化方法；算法开发最好的利器就是<code>C++</code>和<code>Python</code>，其中<code>C++11</code>新增了许多新的智能特性，我在<code>2019</code>年重新学习了<code>C++11</code>规范</p>
<ul>
<li><a href="https://www.zhujian.tech/posts/fe7e69f4.html">数学</a></li>
<li><a href="https://www.zhujian.tech/posts/ee5b0da5.html">软件工程</a></li>
<li><a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/basic/ip%E5%9C%B0%E5%9D%80/" target="_blank" rel="noopener">计算机网络</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/algorithm/machine-learning/" target="_blank" rel="noopener">机器学习</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/algorithm/deep-learning/" target="_blank" rel="noopener">深度学习</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/algorithm/optimization/" target="_blank" rel="noopener">最优化</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/%E5%AD%A6%E4%B9%A0C++%E4%B9%8B%E8%B7%AF/" target="_blank" rel="noopener">C++11 Specification</a></li>
</ul>
<h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><ul>
<li>首先，程序员必需解决的就是如何访问海外网络的问题。之前使用的都是别人搭建好的<code>VPN</code>服务，在<code>2019</code>年，自己开始尝试购买服务器进行搭建，先后尝试使用了<code>SS/SSR/Brook/V2ray</code>，最后发现<a href="https://wall-guide.readthedocs.io/zh/latest/?badge=latest" target="_blank" rel="noopener">Trojan</a>是一个很好的选择</li>
<li>其次，结合自己之前的开发经历，发现<code>CI</code>工具和容器化工具是未来必备的开发利器。最开始使用的<code>CI</code>工具是<code>Travis-CI</code>，后来自己搭建<a href="https://containerization-automation.readthedocs.io/zh_CN/latest/jenkins/" target="_blank" rel="noopener">Jenkins</a>进行操作；而对于容器化工具，使用<a href="https://containerization-automation.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">Docker</a>进行容器操作</li>
<li>最后，结合深度学习和版本控制，练习了斯坦福的<a href="https://github.com/zjZSTU/cs231n" target="_blank" rel="noopener">CS231n</a>课程作业，并且使用<code>python numpy</code>开发了自己的深度网络库<a href="https://github.com/zjZSTU/PyNet" target="_blank" rel="noopener">PyNet</a></li>
</ul>
<h2 id="工作和展望"><a href="#工作和展望" class="headerlink" title="工作和展望"></a>工作和展望</h2><p>之前的工作和学习经历让我有一种盲目的自信，觉得没啥工作不能找到的，但是实际找工作时发现处处碰壁。主要原因是学习和工作不聚焦，现在打算寻求图像处理相关的工作，但是之前的工作经历并不支撑这一想法，所以在下半年没有找工作，留在学校学习相关的知识，希望<code>2020</code>年有一个新的开始</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>OKR工作法</title>
    <url>/posts/b85d3c6c.html</url>
    <content><![CDATA[<p><code>OKR</code>（<code>Objectives and Key Results</code>，目标与关键结果）工作法是最近非常热门的管理和实践模型，在公司实习的时候接触了这个概念，后来回学校后就没有去深入研究。买了一本书<code>《OKR工作法》</code>进行学习，里面通过一个创业案例来说明<code>OKR</code>工作法的使用。从我个人观点来看，<code>OKR</code>的概念非常抽象，整个模型可以说很简单，不过确实能够通过实践它得到不一样的进步</p><a id="more"></a>
<p><em>以下内容更多的关注于个人的OKR学习和实践</em></p>
<h2 id="内容列表"><a href="#内容列表" class="headerlink" title="内容列表"></a>内容列表</h2><ul>
<li>重要-紧急矩阵</li>
<li><code>OKR</code>工作法</li>
<li>实践</li>
<li>小结</li>
</ul>
<h2 id="重要-紧急矩阵"><a href="#重要-紧急矩阵" class="headerlink" title="重要-紧急矩阵"></a>重要-紧急矩阵</h2><p>重要-紧急矩阵是有别于<code>OKR</code>工作法的开发模型，它将事情按<strong>重要</strong>和<strong>紧急</strong>两个维度进行划分，其中一个维度是<code>重要 - 不重要</code>，另一个维度是<code>紧急 - 不紧急</code>。通过重要 - 紧急矩阵能够有效的将待完成的事情进行优先级划分，将事情映射到坐标系后，依次处理：</p>
<ol>
<li>重要紧急的事情</li>
<li>重要不紧急的事情</li>
<li>紧急不重要的事情</li>
<li>不重要不紧急的事情</li>
</ol>
<p>模型也存在着缺陷：理论上应该优先处理重要事情，也就是当处理完重要紧急事情后，应该优先于重要不紧急的事情，但是往往紧急不重要的事情会影响实际的处理流程，最后导致重要不紧急的事情无法得到实践</p>
<h2 id="OKR工作法"><a href="#OKR工作法" class="headerlink" title="OKR工作法"></a>OKR工作法</h2><p><code>OKR</code>工作法更加着重于重要事情的判断和处理，制定<code>OKR</code>是爲了聚焦最重要的事情，防止重要但不紧急的事情没有完成。也就是說<code>OKR</code>的目的<strong>不是设置一件你需要做的事情，而是设置一件你必须做的事情</strong></p>
<p><code>OKR</code>工作法包含三个步骤：</p>
<ul>
<li>首先，设置有挑战、可衡量的阶段性目标</li>
<li>其次，确保你和你的团队一直朝着这个目标前进，不要被其他事情干扰</li>
<li>最后，把握节奏，所有成员一直明确需要努力达成的目标，并相互支持、相互鼓励</li>
</ul>
<p>所以<code>OKR</code>工作法的核心就是<strong>聚焦</strong>，<code>O</code>指的是目标（<code>objective</code>），用于明确方向；<code>KR</code>指的是关键结果（<code>Key Result</code>），用于量化目标。对公司或者个人而言，都应该有一个使命或者愿景，它可以长时间的引导你前进的方向，而目标就是对愿景的细化（足够抽象），关键结果就是对目标的评判（足够具体，能够适用于数值评估）</p>
<p>制订<code>OKR</code>时需要遵循以下<code>3</code>个原则：</p>
<ol>
<li>目标要明确方向并且鼓舞人心</li>
<li>目标要有时间期限</li>
<li>由独立的团队来执行目标。目标必须真正属于设立目标的人</li>
</ol>
<h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p>从<code>3</code>个方面阐述<code>OKR</code>工作法的使用：</p>
<ol>
<li><code>OKR</code>的展示形式</li>
<li>每周/每月/季度的实践</li>
<li>工具的使用</li>
</ol>
<h3 id="OKR的展示形式"><a href="#OKR的展示形式" class="headerlink" title="OKR的展示形式"></a>OKR的展示形式</h3><p>通过一个<code>4</code>象限的形式展示<code>OKR</code></p>
<p><img src="/imgs/okr/OKR.png" alt></p>
<ul>
<li>本周关注的任务：列出<code>3-4</code>件最重要的事情，只有本周完成了这几件事情，团队的目标才能向前推进；明确这些事情的优先级</li>
<li><code>OKR</code>当前的状态：基础信心指数是<code>5/10</code>（就是<code>50%</code>，一半一半），每周根据上周完成情况进行修改，并讨论为什么会更高或更低</li>
<li>未来四周的计划：有哪些事情需要其他团队成员做好准备或支持，都列在这个象限里</li>
<li>状态指标：列出两个影响目标达成的其他因素，团队需要额外关注，比如客户关系、团队状态、系统状况等。当这些地方发生意外时，马上讨论找出应对方案，确保<code>OKR</code>不受影响</li>
</ul>
<p><strong>注意 1：使用<code>P1/P2</code>标明事情优先级，<code>P1</code>是必须做的，<code>P2</code>是应该做的</strong></p>
<p><strong>注意 2：在矩形的左下方列出后续计划中要做的重要工作（为后续实现关键结果做准备）</strong></p>
<h3 id="每周-每月-季度的实践"><a href="#每周-每月-季度的实践" class="headerlink" title="每周/每月/季度的实践"></a>每周/每月/季度的实践</h3><ul>
<li>通常仅设置一个目标，保证任务足够聚焦</li>
<li>通常目标设定时间为一个季度，使用关键结果来判定到期时目标是否达成</li>
</ul>
<p>使用周报辅助<code>OKR</code>实现。周报包含以下内容：</p>
<ol>
<li>把团队的<code>OKR</code>作为开始，并标注目标的信心指数</li>
<li>列出上周的优先任务，并标注完成情况</li>
<li>列出下周的优先任务</li>
<li>列出风险或阻碍</li>
<li>备注</li>
</ol>
<h3 id="工具的使用"><a href="#工具的使用" class="headerlink" title="工具的使用"></a>工具的使用</h3><p>可以使用文档/思维导图/在线应用等多种方式实现<code>OKR</code>。在外网找到一个<code>OKR</code>在线网站 - <a href="https://weekdone.com/" target="_blank" rel="noopener">weekdone</a>，<code>3</code>人团队以下的<code>OKR</code>使用免费，不过其界面设置更倾向于公司<code>OKR</code>，当前追求的是个人<code>OKR</code>的学习和使用，所以使用思维导图是一件不错的选择</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>实际操作时，可以结合重要 - 紧急矩阵和<code>OKR</code>工作法，通过<code>OKR</code>工作法明确要干什么（目标）和该干什么（关键结果）</p>
<p><em><code>2020</code>年订个小目标：将<code>OKR</code>工作法熟练运用到工作和学习中</em></p>
]]></content>
      <categories>
        <category>软件工程</category>
        <category>开发流程</category>
      </categories>
      <tags>
        <tag>OKR</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins][GitLab]docker-compose实现</title>
    <url>/posts/1431c640.html</url>
    <content><![CDATA[<p>之前实现了<a href="https://zhujian.tech/posts/202ee452.html" target="_blank" rel="noopener">在Docker中运行Jenkins</a>以及<a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/platform/[Docker]GitLab%E4%BD%BF%E7%94%A8/" target="_blank" rel="noopener">[Docker]GitLab使用</a>，参考<a href="https://containerization-automation.readthedocs.io/zh_CN/latest/docker/compose/[%E8%AF%91]Docker%20Compose%E6%A6%82%E8%BF%B0/" target="_blank" rel="noopener">Docker Compose</a>，通过<code>docker-compose</code>方式同时启动两个容器</p><a id="more"></a>
<h2 id="docker-compose-yml"><a href="#docker-compose-yml" class="headerlink" title="docker-compose.yml"></a>docker-compose.yml</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">version: &quot;3.7&quot;</span><br><span class="line">services: </span><br><span class="line">    jenkins:</span><br><span class="line">        labels:</span><br><span class="line">            AUTHOR: &quot;zhujian &lt;zjzstu@github.com&gt;&quot;</span><br><span class="line">        container_name: jenkins</span><br><span class="line">        image: jenkins/jenkins</span><br><span class="line">        volumes: </span><br><span class="line">            - &quot;jenkins_home:/var/jenkins_home&quot;</span><br><span class="line">        ports: </span><br><span class="line">            - &quot;7070:8080&quot;</span><br><span class="line">            - &quot;50000:50000&quot;</span><br><span class="line">        restart: always</span><br><span class="line">        tty: true</span><br><span class="line">        stdin_open: true</span><br><span class="line">    gitlab:</span><br><span class="line">        labels:</span><br><span class="line">            AUTHOR: &quot;zhujian &lt;zjzstu@github.com&gt;&quot;</span><br><span class="line">        container_name: gitlab</span><br><span class="line">        image: gitlab/gitlab-ce:latest</span><br><span class="line">        volumes: </span><br><span class="line">            - &quot;/srv/gitlab/config:/etc/gitlab&quot;</span><br><span class="line">            - &quot;/srv/gitlab/logs:/var/log/gitlab&quot;</span><br><span class="line">            - &quot;/srv/gitlab/data:/var/opt/gitlab&quot;</span><br><span class="line">        ports: </span><br><span class="line">            - &quot;7010:7010&quot;</span><br><span class="line">            - &quot;7020:22&quot;</span><br><span class="line">        restart: always</span><br><span class="line">        tty: true</span><br><span class="line">        stdin_open: true</span><br><span class="line">volumes: </span><br><span class="line">    jenkins_home:</span><br><span class="line">        external: true</span><br></pre></td></tr></table></figure>
<h2 id="启动-停止"><a href="#启动-停止" class="headerlink" title="启动/停止"></a>启动/停止</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 启动，后台运行</span><br><span class="line">$ docker-compose up -d</span><br><span class="line"># 停止并移除容器</span><br><span class="line">$ docker-compose down</span><br></pre></td></tr></table></figure>
<p><strong>注意：上述命令需要在<code>docker-compose.yml</code>路径下执行</strong></p>
]]></content>
      <categories>
        <category>版本控制</category>
        <category>工具</category>
        <category>自动化</category>
        <category>托管平台</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>gitlab</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>[二分类]PR曲线</title>
    <url>/posts/bca792b4.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://en.wikipedia.org/wiki/Precision_and_recall" target="_blank" rel="noopener">Precision and recall</a></p><p><a href="https://zhujian.tech/posts/74ea027a.html" target="_blank" rel="noopener">混淆矩阵</a></p><p><code>PR</code>曲线是另一种衡量算法性能的评价标准，其使用精确度（<code>Precision</code>）和召回率（<code>Recall</code>）作为坐标系的基底</p><a id="more"></a>



<p><strong><em>本文着重于二分类的PR曲线</em></strong></p>
<h2 id="精确度"><a href="#精确度" class="headerlink" title="精确度"></a>精确度</h2><p>参考：<a href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values" target="_blank" rel="noopener">Positive and negative predictive values</a></p>
<p>精确度（<code>Precision</code>）也称为正预测值（<code>positive predictive value, PPV</code>），表示预测正确的正样本占整个实际正样本集的比率</p>
<script type="math/tex; mode=display">
PPV = \frac {TP}{TP + FP}</script><h2 id="召回率"><a href="#召回率" class="headerlink" title="召回率"></a>召回率</h2><p>参考：<a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" target="_blank" rel="noopener">Sensitivity and specificity</a></p>
<p>召回率（<code>Recall</code>）也称为敏感度（<code>sensitivity</code>）、真阳性率（<code>true positive rate, TPR</code>），表示预测正确的正样本占整个预测正样本集的比率</p>
<script type="math/tex; mode=display">
TPR = \frac {TP}{TP + FN}</script><h2 id="PR曲线"><a href="#PR曲线" class="headerlink" title="PR曲线"></a>PR曲线</h2><p><code>PPV</code>和<code>TPR</code>两者都是对于预测正样本集的理解和衡量</p>
<ul>
<li>高精度意味着算法预测结果能够更好的覆盖所有的正样本（也就是<strong>查准率</strong>），但也可能存在更多的假阴性样本</li>
<li>高召回率意味着算法预测结果中包含了更多的正样本（也就是<strong>查全率</strong>），但也可能导致正样本占实际正样本的比率不高（存在更多的假阳性样本）</li>
</ul>
<p><code>PR</code>曲线是一个图，其<code>y</code>轴表示精度，<code>x</code>轴表示召回率，通过在不同阈值条件下计算<code>(Recall, Precision)</code>数据对，绘制得到<code>PR</code>曲线</p>
<p>根据定义可知，最好的预测结果发生在右上角<code>(1,1)</code>，此时所有预测为真的样本均为实际正样本，没有正样本被预测为假</p>
<h2 id="如何通过PR判断分类器性能-AP"><a href="#如何通过PR判断分类器性能-AP" class="headerlink" title="如何通过PR判断分类器性能 - AP"></a>如何通过PR判断分类器性能 - AP</h2><p>和<code>ROC</code>曲线类似，需要计算曲线下面积来评判分类器性能，称之为平均精度（<code>AP, average precision</code>）</p>
<script type="math/tex; mode=display">
AP = \sum_{n}(R_{n} - R_{n-1})P_{n}</script><p>点$(R_{n}, P_{n})$表示第$n$个阈值下的精度和召回率</p>
<h2 id="Python实现"><a href="#Python实现" class="headerlink" title="Python实现"></a>Python实现</h2><p><code>Python</code>库<code>Sklearn</code>提供了<code>PR</code>曲线的计算函数：</p>
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" target="_blank" rel="noopener">sklearn.metrics.average_precision_score</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" target="_blank" rel="noopener">sklearn.metrics.precision_recall_curve</a></li>
</ul>
<h3 id="average-precision-score"><a href="#average-precision-score" class="headerlink" title="average_precision_score"></a>average_precision_score</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def average_precision_score(y_true, y_score, average=&quot;macro&quot;, pos_label=1,</span><br><span class="line">                            sample_weight=None):</span><br></pre></td></tr></table></figure>
<p>用于计算预测成绩的平均精度</p>
<ul>
<li><code>y_true</code>：数组形式，二值标签</li>
<li><code>y_score</code>：目标样本的成绩</li>
<li><code>pos_label</code>：正样本标签，默认为<code>1</code></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.metrics import average_precision_score</span><br><span class="line"></span><br><span class="line">y_true = np.array([0, 0, 1, 1])</span><br><span class="line">y_scores = np.array([0.1, 0.4, 0.35, 0.8])</span><br><span class="line">average_precision_score(y_true, y_scores)</span><br></pre></td></tr></table></figure>
<h3 id="precision-recall-curve"><a href="#precision-recall-curve" class="headerlink" title="precision_recall_curve"></a>precision_recall_curve</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def precision_recall_curve(y_true, probas_pred, pos_label=None,</span><br><span class="line">                           sample_weight=None):</span><br></pre></td></tr></table></figure>
<p>计算不同概率阈值下的精确率和召回率</p>
<ul>
<li><code>y_true</code>：数组形式，表示样本标签，如果不是<code>{-1,1}</code>或者<code>{0,1}</code>形式，那么属性<code>pos_label</code>应该指定</li>
<li><code>probas_pred</code>：预测置信度</li>
<li><code>pos_label</code>：正样本类，默认为<code>1</code></li>
</ul>
<p>返回<code>3</code>个数组，分别是精确率数组、召回率数组和阈值数组</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.metrics import precision_recall_curve</span><br><span class="line"></span><br><span class="line">y_true = np.array([0, 0, 1, 1])</span><br><span class="line">y_scores = np.array([0.1, 0.4, 0.35, 0.8])</span><br><span class="line">precision, recall, thresholds = precision_recall_curve(y_true, y_scores)</span><br></pre></td></tr></table></figure>
<h3 id="计算最佳阈值"><a href="#计算最佳阈值" class="headerlink" title="计算最佳阈值"></a>计算最佳阈值</h3><p>综合来看，就是最接近坐标<code>(1,1)</code>的点所对应的阈值就是最佳阈值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">best_th = threshold[np.argmax(precision + recall)]</span><br></pre></td></tr></table></figure>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>参考<a href="https://zhujian.tech/posts/71a847e.html" target="_blank" rel="noopener">[二分类]ROC曲线</a>使用<code>Fashion-MNIST</code>数据集，分两种情况</p>
<ol>
<li><code>6000</code>个运动鞋+<code>6000</code>个短靴作为训练集</li>
<li><code>1000</code>个运动鞋+<code>6000</code>个短靴作为训练集</li>
</ol>
<h3 id="测试１"><a href="#测试１" class="headerlink" title="测试１"></a>测试１</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   2-pr.py</span><br><span class="line">@time:   2020-01-10</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">from mnist_reader import load_mnist</span><br><span class="line">from lr_classifier import LogisticClassifier</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.metrics import precision_recall_curve</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_two_cate(ratio=1.0):</span><br><span class="line">    path = &quot;/home/zj/data/fashion-mnist/fashion-mnist/data/fashion/&quot;</span><br><span class="line">    train_images, train_labels = load_mnist(path, kind=&apos;train&apos;)</span><br><span class="line">    test_images, test_labels = load_mnist(path, kind=&apos;t10k&apos;)</span><br><span class="line"></span><br><span class="line">    num_train_seven = np.sum(train_labels == 7)</span><br><span class="line">    num_train_nine = np.sum(train_labels == 9)</span><br><span class="line">    # print(num_train_seven, num_train_nine)</span><br><span class="line"></span><br><span class="line">    num_test_seven = np.sum(test_labels == 7)</span><br><span class="line">    num_test_nine = np.sum(test_labels == 9)</span><br><span class="line">    # print(num_test_seven, num_test_nine)</span><br><span class="line"></span><br><span class="line">    x_train_0 = train_images[(train_labels == 7)]</span><br><span class="line">    x_train_1 = train_images[(train_labels == 9)]</span><br><span class="line">    y_train_0 = train_labels[(train_labels == 7)]</span><br><span class="line">    y_train_1 = train_labels[(train_labels == 9)]</span><br><span class="line"></span><br><span class="line">    x_train = np.vstack((x_train_0[:int(ratio * num_train_seven)], x_train_1))</span><br><span class="line">    y_train = np.concatenate((y_train_0[:int(ratio * num_train_seven)], y_train_1))</span><br><span class="line">    x_test = test_images[(test_labels == 7) + (test_labels == 9)]</span><br><span class="line">    y_test = test_labels[(test_labels == 7) + (test_labels == 9)]</span><br><span class="line"></span><br><span class="line">    return x_train, (y_train == 9) + 0, x_test, (y_test == 9) + 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(y, y_pred):</span><br><span class="line">    num = y.shape[0]</span><br><span class="line">    num_correct = np.sum(y_pred == y)</span><br><span class="line">    acc = float(num_correct) / num</span><br><span class="line">    return acc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    train_images, train_labels, test_images, test_labels = get_two_cate()</span><br><span class="line"></span><br><span class="line">    print(train_images.shape)</span><br><span class="line">    print(test_images.shape)</span><br><span class="line"></span><br><span class="line">    # cv2.imshow(&apos;img&apos;, train_images[100].reshape(28, -1))</span><br><span class="line">    # cv2.waitKey(0)</span><br><span class="line"></span><br><span class="line">    x_train = train_images.astype(np.float64)</span><br><span class="line">    x_test = test_images.astype(np.float64)</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-8</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(np.maximum(var, eps))</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(np.maximum(var, eps))</span><br><span class="line"></span><br><span class="line">    classifier = LogisticClassifier()</span><br><span class="line">    classifier.train(x_train, train_labels)</span><br><span class="line">    res_labels, scores = classifier.predict(x_test)</span><br><span class="line"></span><br><span class="line">    acc = compute_accuracy(test_labels, res_labels)</span><br><span class="line">    print(acc)</span><br><span class="line"></span><br><span class="line">    precision, recall, threshold = precision_recall_curve(test_labels, scores, pos_label=1)</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    plt.plot(precision, recall, label=&apos;PR&apos;)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    best_th = threshold[np.argmax(precision + recall)]</span><br><span class="line">    print(best_th)</span><br><span class="line">    y_pred = scores &gt; best_th + 0</span><br><span class="line">    acc = compute_accuracy(test_labels, y_pred)</span><br><span class="line">    print(acc)</span><br></pre></td></tr></table></figure>
<p>训练结果如下：</p>
<p><img src="/imgs/pr-lr/pr-logistic-regression.png" alt></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(12000, 784)</span><br><span class="line">(2000, 784)</span><br><span class="line">0.9205                                                 # 阈值为0.5</span><br><span class="line">0.45903893031121357</span><br><span class="line">0.9285                                                 # 阈值为0.4590</span><br></pre></td></tr></table></figure>
<p>通过寻找最佳阈值，使得最后的准确率增加了<code>0.8%</code></p>
<h3 id="测试2"><a href="#测试2" class="headerlink" title="测试2"></a>测试2</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">train_images, train_labels, test_images, test_labels = get_two_cate(ratio=1.0 / 6)</span><br></pre></td></tr></table></figure>
<p>训练结果如下：</p>
<p><img src="/imgs/pr-lr/pr-logistic-regression-2.png" alt></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(7000, 784)</span><br><span class="line">(2000, 784)</span><br><span class="line">0.871                                               # 阈值为0.5</span><br><span class="line">0.33526167648147953</span><br><span class="line">0.9215                                            # 阈值为0.3353</span><br></pre></td></tr></table></figure>
<p>从结果可知，<code>PR</code>曲线同样能够在类别数目不平衡的情况下有效的评估分类器性能</p>
<p><img src="/imgs/pr-lr/pr-compare.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>评价标准</category>
        <category>代码库</category>
        <category>PR曲线</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>sklearn</tag>
        <tag>AP</tag>
        <tag>精确率</tag>
        <tag>召回率</tag>
      </tags>
  </entry>
  <entry>
    <title>知识金字塔</title>
    <url>/posts/bd2847bc.html</url>
    <content><![CDATA[<p>从<code>2019</code>开始通过博客框架<code>Hexo</code>以及文档框架<code>Sphinx/MkDocs</code>进行文档整理，总结过去在书本以及实际编程中的知识和技能。随着文档的增多，如何有效、规范的整理越来越多的文档成了一个新的难题</p><a id="more"></a>
<p>偶然间看过一篇文章，里面采用金字塔的形式，按重要/难易程度分层排列不同的知识和技能。这种方式确实能够帮助理清学过的知识，同时能够更加明确未来学习的着重点。我将整个金字塔按重要/难易程度从上到下升序分为<code>5</code>层:</p>
<ul>
<li>工具篇</li>
<li>实现篇</li>
<li>语言篇</li>
<li>理论篇</li>
<li>基础篇</li>
</ul>
<p><img src="/imgs/knowledge-pyramid/knowledge-pyramid.png" alt></p>
<h2 id="工具篇"><a href="#工具篇" class="headerlink" title="工具篇"></a>工具篇</h2><ul>
<li><code>IDE</code><ul>
<li><a href="https://tools-platform-guide.readthedocs.io/zh_CN/latest/jetbrains/%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">JetBrains</a></li>
<li><a href="https://tools-platform-guide.readthedocs.io/zh_CN/latest/jupyter/[conda]JupyterLab%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">Jupyter Lab</a></li>
<li><a href="https://tools-platform-guide.readthedocs.io/zh_CN/latest/android/android-studio/[Ubuntu]Android%20Studio%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">Android Studio</a></li>
</ul>
</li>
<li>文档操作<ul>
<li><a href="https://tools-platform-guide.readthedocs.io/zh_CN/latest/vscode/" target="_blank" rel="noopener">VS code</a></li>
<li><a href="https://blog-website-building-guide.readthedocs.io/zh_CN/latest/?badge=latest" target="_blank" rel="noopener">Hexo</a></li>
<li><a href="https://zj-sphinx-github-readthedocs.readthedocs.io/en/latest/mkdocs/%E5%BC%95%E8%A8%80/" target="_blank" rel="noopener">MkDocs</a></li>
<li><a href="https://zj-sphinx-github-readthedocs.readthedocs.io/en/latest/readthedocs/ReadtheDocs%20-%20%E4%BB%8B%E7%BB%8D/" target="_blank" rel="noopener">Readthedocs</a></li>
</ul>
</li>
<li>开发平台<ul>
<li><a href="https://zj-linux-guide.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">Linux Tools</a></li>
<li><a href="https://tools-platform-guide.readthedocs.io/zh_CN/latest/node/nodeJS%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">NodeJS</a></li>
<li><a href="https://tools-platform-guide.readthedocs.io/zh_CN/latest/anaconda/%E7%8E%AF%E5%A2%83%E6%9F%A5%E8%AF%A2%EF%BC%8C%E5%AE%89%E8%A3%85%EF%BC%8C%E5%8D%B8%E8%BD%BD%EF%BC%8C%E5%85%8B%E9%9A%86/" target="_blank" rel="noopener">Anaconda</a></li>
<li><a href="https://tools-platform-guide.readthedocs.io/zh_CN/latest/android/ndk/NDK%E5%BC%80%E5%8F%91%E6%A6%82%E8%BF%B0/" target="_blank" rel="noopener">NDK</a></li>
</ul>
</li>
</ul>
<h2 id="实现篇"><a href="#实现篇" class="headerlink" title="实现篇"></a>实现篇</h2><ul>
<li><code>CI&amp;CD</code><ul>
<li><a href="https://containerization-automation.readthedocs.io/zh_CN/latest/jenkins/" target="_blank" rel="noopener">Jenkins</a></li>
</ul>
</li>
<li>网络连接<ul>
<li><a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/ssh/[SSH]%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/" target="_blank" rel="noopener">SSH</a></li>
<li><a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/intranet-penetration/%E5%89%8D%E8%A8%80/" target="_blank" rel="noopener">Ngrok</a></li>
<li><a href="https://wall-guide.readthedocs.io/zh/latest/?badge=latest" target="_blank" rel="noopener">Trojan</a></li>
</ul>
</li>
<li>服务器<ul>
<li><a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/nginx/%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">Nginx</a></li>
<li><a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/tomcat/%E5%85%B3%E4%BA%8ETomcat/" target="_blank" rel="noopener">Tomcat</a></li>
<li><a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/platform/[GitLab]%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">GitLab/GitHub</a></li>
</ul>
</li>
<li>版本控制<ul>
<li><a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">Git</a></li>
</ul>
</li>
<li>容器服務<ul>
<li><a href="https://containerization-automation.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">Docker</a></li>
</ul>
</li>
</ul>
<h2 id="语言篇"><a href="#语言篇" class="headerlink" title="语言篇"></a>语言篇</h2><ul>
<li>语言<ul>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/%E5%AD%A6%E4%B9%A0C++%E4%B9%8B%E8%B7%AF/" target="_blank" rel="noopener">C++11 Specification</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/python/%E7%B1%BB%E6%93%8D%E4%BD%9C/" target="_blank" rel="noopener">Python</a></li>
<li><a href="https://zj-linux-guide.readthedocs.io/zh_CN/latest/shell/dash%E5%92%8Cbash/" target="_blank" rel="noopener">Shell</a></li>
<li><a href="https://zj-sphinx-github-readthedocs.readthedocs.io/en/latest/markdown/Markdown%E4%BD%BF%E7%94%A8-1-%E5%BC%95%E8%A8%80/" target="_blank" rel="noopener">Markdown</a></li>
</ul>
</li>
<li>代码库<ul>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/opencv/OpenCV%E6%A6%82%E8%BF%B0/" target="_blank" rel="noopener">OpenCV</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/matplotlib/%E5%BC%95%E8%A8%80/" target="_blank" rel="noopener">Matplotlib</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/pytorch/%E5%BC%95%E8%A8%80/" target="_blank" rel="noopener">PyTorch</a></li>
</ul>
</li>
</ul>
<h2 id="理论篇"><a href="#理论篇" class="headerlink" title="理论篇"></a>理论篇</h2><ul>
<li>算法<ul>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/algorithm/machine-learning/" target="_blank" rel="noopener">机器学习</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/algorithm/deep-learning/" target="_blank" rel="noopener">深度学习</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/algorithm/optimization/" target="_blank" rel="noopener">最优化</a></li>
</ul>
</li>
<li>数据结构</li>
<li>版本规范<ul>
<li><a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/message/%E5%BC%95%E8%A8%80/" target="_blank" rel="noopener">消息提交规范</a></li>
<li><a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/version/[SEMVER]%E8%AF%AD%E4%B9%89%E7%89%88%E6%9C%AC%E8%A7%84%E8%8C%83/" target="_blank" rel="noopener">语义版本规范</a></li>
<li><a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/readme/%E5%BC%95%E8%A8%80/" target="_blank" rel="noopener">README编写规范</a></li>
<li><a href="https://www.zhujian.tech/posts/c7ee2f15.html">GIT工作流实践</a></li>
</ul>
</li>
</ul>
<h2 id="基础篇"><a href="#基础篇" class="headerlink" title="基础篇"></a>基础篇</h2><ul>
<li><a href="https://www.zhujian.tech/posts/fe7e69f4.html">数学</a></li>
<li><a href="https://www.zhujian.tech/posts/ee5b0da5.html">软件工程</a></li>
<li><a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/basic/ip%E5%9C%B0%E5%9D%80/" target="_blank" rel="noopener">计算机网络</a></li>
</ul>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>[二分类]ROC曲线</title>
    <url>/posts/71a847e.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" target="_blank" rel="noopener">Receiver operating characteristic</a></p><p><a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" target="_blank" rel="noopener">Sensitivity and specificity</a></p><a id="more"></a>


<p><a href="https://zhujian.tech/posts/74ea027a.html" target="_blank" rel="noopener">混淆矩阵</a></p>
<p><code>ROC</code>曲线（<code>receiver operating characteristic curve</code>, 操作者工作特征曲线）是一个二维图，用于说明分类器在不同阈值下的分类能力</p>
<p><strong><em>本文通过<code>ROC</code>曲线评价二元分类器</em></strong></p>
<h2 id="TPR"><a href="#TPR" class="headerlink" title="TPR"></a>TPR</h2><p><code>TPR(true positive rate)</code>指的是检测为正样本的数据集中包含实际正样本的概率，称为真阳性率，也称为召回率（<code>recall rate</code>）、敏感度（<code>sensitivity</code>），检测率（<code>probability of detection</code>）。计算公式如下：</p>
<script type="math/tex; mode=display">
TPR = \frac {TP}{P} = \frac {TP}{TP+FN}</script><h2 id="FPR"><a href="#FPR" class="headerlink" title="FPR"></a>FPR</h2><p><code>FPR(false positive rate)</code>指的是检测为负样本的数据集中包含实际正样本的概率，称为假阳性率，也称为误报率（<code>probability of false alarm</code>）。计算公式如下：</p>
<script type="math/tex; mode=display">
FPR = \frac {FP}{N} = \frac {FP}{FP+TN}</script><h2 id="ROC-curve"><a href="#ROC-curve" class="headerlink" title="ROC curve"></a>ROC curve</h2><p><code>ROC curve</code>全称是接受者操作特征曲线（<code>receiver operating characteristic curve</code>），它是一个二维曲线图，用于表明分类器的检测性能</p>
<p>其<code>y</code>轴表示<code>TPR</code>，<code>x</code>轴表示<code>FPR</code>。通过在不同阈值条件下计算<code>(FPR, TPR)</code>数据对，绘制得到<code>ROC</code>曲线</p>
<p><img src="/imgs/roc-curve/1024px-ROC_space-2.png" alt></p>
<p><code>ROC</code>描述了收益（<code>true positive</code>）和成本（<code>false positive</code>）之间的权衡。由上图可知</p>
<ul>
<li>最好的预测结果发生在左上角<code>(0,1)</code>，此时所有预测为真的样本均为实际正样本，没有正样本被预测为假</li>
<li>对角线表示的是随机猜测（<code>random guess</code>）的结果，对角线上方的坐标点表示分类器的检测结果比随机猜测好</li>
</ul>
<p>所以离左上角越近，表示预测效果越好，此时分类器的性能更佳</p>
<h2 id="如何通过ROC曲线判断分类器性能-AUC"><a href="#如何通过ROC曲线判断分类器性能-AUC" class="headerlink" title="如何通过ROC曲线判断分类器性能 - AUC"></a>如何通过ROC曲线判断分类器性能 - AUC</h2><p><code>AUC(Area under the curve)</code>指的是<code>ROC</code>曲线下的面积。其表示概率值：当随机给定一个正样本和一个负样本，分类器输出该正样本为正的概率值比分类器输出该负样本为正的概率值要大的可能性</p>
<p><em><code>AUC</code>越大，表明分类器性能越强</em></p>
<h2 id="python实现"><a href="#python实现" class="headerlink" title="python实现"></a>python实现</h2><p><code>sklean</code>库提供了多个函数用于<code>ROC/AUC</code>的计算，参考<a href="https://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc" target="_blank" rel="noopener">3.3.2.14. Receiver operating characteristic (ROC)</a></p>
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html" target="_blank" rel="noopener">sklearn.metrics.roc_curve</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" target="_blank" rel="noopener">sklearn.metrics.roc_auc_score</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html?highlight=auc#sklearn.metrics.auc" target="_blank" rel="noopener">sklearn.metrics.auc</a></li>
</ul>
<h3 id="roc-curve"><a href="#roc-curve" class="headerlink" title="roc_curve"></a>roc_curve</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def roc_curve(y_true, y_score, pos_label=None, sample_weight=None,</span><br><span class="line">              drop_intermediate=True):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>y_true</code>：一维数组形式，表示样本标签。如果不是<code>{-1,1}</code>或者<code>{0,1}</code>的格式，那么参数<code>pos_label</code>需要显式设定</li>
<li><code>y_score</code>：一维数组形式，表示目标成绩。可以是对正样本的概率估计/置信度</li>
<li><code>pos_label</code>：指明正样本所属标签。如果<code>y_true</code>是<code>{-1,1}</code>或<code>{0,1}</code>格式，那么<code>pos_label</code>默认为<code>1</code></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.metrics import roc_curve</span><br><span class="line"></span><br><span class="line">y = np.array([1, 1, 2, 2])</span><br><span class="line">scores = np.array([0.1, 0.4, 0.35, 0.8])</span><br><span class="line">fpr, tpr, thresholds = roc_curve(y, scores, pos_label=2)</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">plt.plot(fpr, tpr, label=&apos;ROC&apos;)</span><br><span class="line">plt.show()</span><br><span class="line">// 输出</span><br><span class="line">[0.  0.  0.5 0.5 1. ]               # FPR</span><br><span class="line">[0.  0.5 0.5 1.  1. ]               # TPR</span><br><span class="line">[1.8  0.8  0.4  0.35 0.1 ]    # thresholds</span><br></pre></td></tr></table></figure>
<p>返回的是<code>FPR、TPR</code>和阈值数组，<code>FPR</code>和<code>TPR</code>中每个坐标的值表示利用<code>thresholds</code>数组同样下标的阈值所得到的真阳性率和假阳性率</p>
<p><img src="/imgs/ROC-AUC/roc_curve.png" alt></p>
<h3 id="roc-auc-score-auc"><a href="#roc-auc-score-auc" class="headerlink" title="roc_auc_score/auc"></a>roc_auc_score/auc</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def roc_auc_score(y_true, y_score, average=&quot;macro&quot;, sample_weight=None,</span><br><span class="line">                  max_fpr=None):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>y_true</code>：格式为<code>[n_samples]</code>或者<code>[n_samples, n_classes]</code></li>
<li><code>y_score</code>：格式为<code>[n_samples]</code>或者<code>[n_samples, n_classes]</code></li>
</ul>
<p>返回的是<code>AUC</code>的值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def auc(x, y, reorder=&apos;deprecated&apos;):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>x：FPR</code></li>
<li><code>y：TPR</code></li>
</ul>
<p>利用<code>roc_curve</code>计算得到<code>FPR</code>和<code>TPR</code>后，就可以输入到<code>auc</code>计算<code>AUC</code>大小</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import roc_auc_score</span><br><span class="line">from sklearn.metrics import auc</span><br><span class="line"></span><br><span class="line">print(roc_auc_score(y, scores))</span><br><span class="line">print(auc(fpr, tpr))</span><br><span class="line"># 输出</span><br><span class="line">0.75</span><br><span class="line">0.75</span><br></pre></td></tr></table></figure>
<h3 id="如何计算最佳阈值"><a href="#如何计算最佳阈值" class="headerlink" title="如何计算最佳阈值"></a>如何计算最佳阈值</h3><p>参考：</p>
<p><a href="https://stats.stackexchange.com/questions/123124/how-to-determine-the-optimal-threshold-for-a-classifier-and-generate-roc-curve" target="_blank" rel="noopener">How to determine the optimal threshold for a classifier and generate ROC curve?</a></p>
<p><a href="https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python" target="_blank" rel="noopener">Roc curve and cut off point. Python</a></p>
<p>通过<code>ROC</code>图可知，<code>TPR</code>越大越好，<code>FPR</code>越小越好，所以只要能够得到不同阈值条件下的<code>TPR</code>和<code>FPR</code>，计算之间的差值，结果值最大的就是最佳阈值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">thresh = thresholds[np.argmax(tpr - fpr)]</span><br><span class="line">print(thresh)</span><br></pre></td></tr></table></figure>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>使用数据集<a href="https://zhujian.tech/posts/631c599a.html" target="_blank" rel="noopener">Fashion-MNIST</a>中的<code>Sneaker</code>(运动鞋，编号为<code>7</code>)和<code>Ankle boot</code>(短靴，编号为<code>9</code>)类别进行训练和测试</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from mnist_reader import load_mnist</span><br><span class="line"></span><br><span class="line">def get_two_cate():</span><br><span class="line">    path = &quot;/home/zj/data/fashion-mnist/fashion-mnist/data/fashion/&quot;</span><br><span class="line">    train_images, train_labels = load_mnist(path, kind=&apos;train&apos;)</span><br><span class="line">    test_images, test_labels = load_mnist(path, kind=&apos;t10k&apos;)</span><br><span class="line"></span><br><span class="line">    num_train_seven = np.sum(train_labels == 7)</span><br><span class="line">    num_train_nine = np.sum(train_labels == 9)</span><br><span class="line">    print(num_train_seven, num_train_nine)</span><br><span class="line"></span><br><span class="line">    num_test_seven = np.sum(test_labels == 7)</span><br><span class="line">    num_test_nine = np.sum(test_labels == 9)</span><br><span class="line">    print(num_test_seven, num_test_nine)</span><br><span class="line"></span><br><span class="line">    x_train = train_images[(train_labels == 7) + (train_labels == 9)]</span><br><span class="line">    y_train = train_labels[(train_labels == 7) + (train_labels == 9)]</span><br><span class="line">    x_test = test_images[(test_labels == 7) + (test_labels == 9)]</span><br><span class="line">    y_test = test_labels[(test_labels == 7) + (test_labels == 9)]</span><br><span class="line"></span><br><span class="line">    return x_train, (y_train == 9) + 0, x_test, (y_test == 9) + 0</span><br></pre></td></tr></table></figure>
<ul>
<li>训练集个数为<code>12000</code>，每类样本各<code>6000</code></li>
<li>测试集个数为<code>2000</code>，每类样本各<code>1000</code></li>
</ul>
<h3 id="正确率"><a href="#正确率" class="headerlink" title="正确率"></a>正确率</h3><p>通过计算正确率来判断通过<code>ROC</code>曲线得到的阈值的效果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def compute_accuracy(y, y_pred):</span><br><span class="line">    num = y.shape[0]</span><br><span class="line">    num_correct = np.sum(y_pred == y)</span><br><span class="line">    acc = float(num_correct) / num</span><br><span class="line">    return acc</span><br></pre></td></tr></table></figure>
<h3 id="分类器"><a href="#分类器" class="headerlink" title="分类器"></a>分类器</h3><p>使用<a href="https://zhujian.tech/posts/96ce93d9.html" target="_blank" rel="noopener">逻辑回归分类器</a>进行二分类<code>ROC</code>曲线的计算。对于二分类逻辑回归而言，对于每个检测样本，计算得到一个数值（取值为<code>(0,1)</code>），一般使用阈值<code>0.5</code>进行判断</p>
<p>在本次实验中，修改预测函数，返回阈值<code>0.5</code>的检测结果以及样本的置信度</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def predict(self, X):</span><br><span class="line">    scores = self.logistic_regression(X)</span><br><span class="line">    y_pred = (scores &gt; 0.5).astype(np.uint8)</span><br><span class="line"></span><br><span class="line">    return y_pred, scores</span><br></pre></td></tr></table></figure>
<h3 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h3><p>实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # 获取二类样本集</span><br><span class="line">    train_images, train_labels, test_images, test_labels = get_two_cate()</span><br><span class="line"></span><br><span class="line">    print(train_images.shape)</span><br><span class="line">    print(test_images.shape)</span><br><span class="line"></span><br><span class="line">    # cv2.imshow(&apos;img&apos;, train_images[100].reshape(28, -1))</span><br><span class="line">    # cv2.waitKey(0)</span><br><span class="line"></span><br><span class="line">    # 数据标准化</span><br><span class="line">    x_train = train_images.astype(np.float64)</span><br><span class="line">    x_test = test_images.astype(np.float64)</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-8</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(np.maximum(var, eps))</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(np.maximum(var, eps))</span><br><span class="line"></span><br><span class="line">    # 定义逻辑回归分类器，训练并进行预测</span><br><span class="line">    classifier = LogisticClassifier()</span><br><span class="line">    classifier.train(x_train, train_labels)</span><br><span class="line">    res_labels, scores = classifier.predict(x_test)</span><br><span class="line"></span><br><span class="line">    # 计算阈值0.5时的准确率</span><br><span class="line">    acc = compute_accuracy(test_labels, res_labels)</span><br><span class="line">    print(acc)</span><br><span class="line"></span><br><span class="line">    # 计算fpr/trp/阈值</span><br><span class="line">    fpr, tpr, thresholds = roc_curve(test_labels, scores, pos_label=1)</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    plt.plot(fpr, tpr, label=&apos;ROC&apos;)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    # 计算最佳阈值</span><br><span class="line">    thresh = thresholds[np.argmax(tpr - fpr)]</span><br><span class="line">    print(thresh)</span><br><span class="line">    # 计算最佳阈值下的准确率</span><br><span class="line">    y_pred = (scores &gt; thresh).astype(np.uint8)</span><br><span class="line">    acc = compute_accuracy(test_labels, y_pred)</span><br><span class="line">    print(acc)</span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<p><img src="/imgs/roc-lr/roc-logistic-regression.png" alt></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(12000, 784)</span><br><span class="line">(2000, 784)</span><br><span class="line">0.92</span><br><span class="line">0.4644471941592551</span><br><span class="line">0.9285</span><br></pre></td></tr></table></figure>
<p>由输出结果可知，最佳阈值为<code>0.4644</code>，最终得到的准确率提升了<code>0.75%</code></p>
<h3 id="类别不平衡"><a href="#类别不平衡" class="headerlink" title="类别不平衡"></a>类别不平衡</h3><p>设置类别<code>Sneaker</code>的训练个数为<code>1000</code>，同时保持<code>Ankle boot</code>的训练个数为<code>6000</code>，训练后绘制<code>ROC</code>曲线</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_two_cate():</span><br><span class="line">    path = &quot;/home/zj/data/fashion-mnist/fashion-mnist/data/fashion/&quot;</span><br><span class="line">    train_images, train_labels = load_mnist(path, kind=&apos;train&apos;)</span><br><span class="line">    test_images, test_labels = load_mnist(path, kind=&apos;t10k&apos;)</span><br><span class="line"></span><br><span class="line">    num_train_seven = np.sum(train_labels == 7)</span><br><span class="line">    num_train_nine = np.sum(train_labels == 9)</span><br><span class="line">    print(num_train_seven, num_train_nine)</span><br><span class="line"></span><br><span class="line">    num_test_seven = np.sum(test_labels == 7)</span><br><span class="line">    num_test_nine = np.sum(test_labels == 9)</span><br><span class="line">    print(num_test_seven, num_test_nine)</span><br><span class="line"></span><br><span class="line">    x_train_0 = train_images[(train_labels == 7)]</span><br><span class="line">    x_train_1 = train_images[(train_labels == 9)]</span><br><span class="line">    y_train_0 = train_labels[(train_labels == 7)]</span><br><span class="line">    y_train_1 = train_labels[(train_labels == 9)]</span><br><span class="line"></span><br><span class="line">    x_train = np.vstack((x_train_0[:1000], x_train_1))</span><br><span class="line">    y_train = np.concatenate((y_train_0[:1000], y_train_1))</span><br><span class="line">    x_test = test_images[(test_labels == 7) + (test_labels == 9)]</span><br><span class="line">    y_test = test_labels[(test_labels == 7) + (test_labels == 9)]</span><br><span class="line"></span><br><span class="line">    return x_train, (y_train == 9) + 0, x_test, (y_test == 9) + 0</span><br></pre></td></tr></table></figure>
<p>计算结果如下：</p>
<p><img src="/imgs/roc-lr/roc-logistic-regression-2.png" alt></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(7000, 784)</span><br><span class="line">(2000, 784)</span><br><span class="line">[0 0 0 ... 0 1 1]</span><br><span class="line">[1 0 0 ... 0 1 1]</span><br><span class="line">0.867                                              # 阈值0.5的正确率</span><br><span class="line">0.36547217942403787</span><br><span class="line">0.9235                                           # 阈值0.3655的正确率</span><br></pre></td></tr></table></figure>
<p>对比实验结果，<code>ROC</code>曲线能够有效验证类别样本数不平衡时的分类器性能</p>
<p><img src="/imgs/roc-lr/roc-compare.png" alt></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><code>ROC</code>曲线图能够不受类别数不平衡的影响，简单、直观的展示不同阈值下的分类器性能</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>评价标准</category>
        <category>代码库</category>
        <category>ROC曲线</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>sklearn</tag>
        <tag>AUC</tag>
        <tag>TPR</tag>
        <tag>FPR</tag>
      </tags>
  </entry>
  <entry>
    <title>[二分类]混淆矩阵</title>
    <url>/posts/74ea027a.html</url>
    <content><![CDATA[<p>参考：<a href="https://en.wikipedia.org/wiki/Confusion_matrix" target="_blank" rel="noopener">Confusion matrix</a></p><p>混淆矩阵（<code>confusion matrix</code>）是分类任务中最常见的特性，通过矩阵形式展示预测类别和真实类别的差异</p><a id="more"></a>

<p><strong><em>本文学习二分类下的混淆矩阵</em></strong></p>
<h2 id="正样本和负样本"><a href="#正样本和负样本" class="headerlink" title="正样本和负样本"></a>正样本和负样本</h2><p>将包含指定类别的图像称为正样本（<code>positive case</code>），不包含指定类别的图像称为负样本（<code>negative case</code>）</p>
<h2 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h2><p>混淆矩阵是一个两行两列的表格，其结构如下：</p>
<p><style type="text/css"><br>.tg  {border-collapse:collapse;border-spacing:0;}<br>.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}<br>.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}<br>.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
</style></p>
<table class="tg">
  <tr>
    <th class="tg-c3ow"></th>
    <th class="tg-c3ow"></th>
    <th class="tg-c3ow" colspan="2">预测</th>
    <th class="tg-c3ow"></th>
  </tr>
  <tr>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow">true</td>
    <td class="tg-c3ow">false</td>
    <td class="tg-c3ow"></td>
  </tr>
  <tr>
    <td class="tg-c3ow" rowspan="2">实际</td>
    <td class="tg-c3ow">positive</td>
    <td class="tg-c3ow">true positive(TP)</td>
    <td class="tg-c3ow">false positive(FP)</td>
    <td class="tg-c3ow">实际正样本个数=TP+FP</td>
  </tr>
  <tr>
    <td class="tg-c3ow">negative</td>
    <td class="tg-c3ow">false negative(FN)</td>
    <td class="tg-c3ow">true negative(TN)</td>
    <td class="tg-c3ow">实际负样本个数=FN+TN</td>
  </tr>
  <tr>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow">预测正样本个数=TP+FN</td>
    <td class="tg-c3ow">预测负样本个数=FP+TN</td>
    <td class="tg-c3ow"></td>
  </tr>
</table>

<p>对数据进行检测，能够得到以下<code>4</code>种检测结果</p>
<ul>
<li>预测结果是正样本<ul>
<li>实际是正样本，称为真阳性（<code>true positive</code>，简称<code>TP</code>）</li>
<li>实际是负样本，称为假阴性（<code>false negative</code>, 简称<code>FN</code>）</li>
</ul>
</li>
<li>预测结果是负样本<ul>
<li>实际是正样本，称为假阳性（<code>false positive</code>，简称<code>FP</code>）</li>
<li>实际是负样本，称为真阴性（<code>true negative</code>, 简称<code>TN</code>）</li>
</ul>
</li>
</ul>
<p>也就是说，<strong>根据实际情况</strong>决定预测结果是阳性还是阴性；<strong>根据预测结果和实际情况的比对</strong>决定预测结果是真还是假</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>评价标准</category>
        <category>混淆矩阵</category>
      </categories>
      <tags>
        <tag>真阳性</tag>
        <tag>假阳性</tag>
        <tag>真阴性</tag>
        <tag>假阴性</tag>
      </tags>
  </entry>
  <entry>
    <title>软件工程小结</title>
    <url>/posts/ee5b0da5.html</url>
    <content><![CDATA[<p>小结软件工程学习</p><ul>
<li><a href="https://www.zhujian.tech/posts/7baadea7.html">什么是软件工程</a></li>
<li><a href="https://www.zhujian.tech/posts/591ccb13.html">你在哪个端开发</a></li>
<li>开发模型<ul>
<li><a href="https://www.zhujian.tech/posts/a6cd9115.html">软件开发流程</a></li>
<li><a href="https://www.zhujian.tech/posts/9d00be46.html">瀑布模型</a></li>
<li><a href="https://www.zhujian.tech/posts/7080d667.html">迭代模型</a></li>
<li><a href="https://www.zhujian.tech/posts/8e9d3485.html">螺旋模型</a></li>
<li><a href="https://www.zhujian.tech/posts/ed2e9abb.html">敏捷开发</a></li>
</ul>
</li>
<li>开发流程<ul>
<li><a href="https://www.zhujian.tech/posts/913b0c70.html">测试驱动开发</a></li>
<li><a href="https://www.zhujian.tech/posts/b85d3c6c.html">OKR工作法</a></li>
</ul>
</li>
<li>测试模型<ul>
<li><a href="https://www.zhujian.tech/posts/cef93ee3.html">单元测试</a></li>
</ul>
</li>
</ul>]]></content>
      <categories>
        <category>随笔</category>
        <category>软件工程</category>
      </categories>
  </entry>
  <entry>
    <title>数学</title>
    <url>/posts/fe7e69f4.html</url>
    <content><![CDATA[<p>小结数学学习过程中总结的文档</p><ul>
<li><a href="https://www.zhujian.tech/posts/507c1b79.html">充分条件 必要条件</a></li>
<li><a href="https://www.zhujian.tech/posts/3d82a363.html">方差 标准差</a></li>
<li><a href="https://www.zhujian.tech/posts/6824c6e3.html">正态分布</a></li>
<li><a href="https://www.zhujian.tech/posts/a9bec5e9.html">导数、微分和梯度</a></li>
<li><a href="https://www.zhujian.tech/posts/d1deacd1.html">矩阵基础</a></li>
<li><a href="https://www.zhujian.tech/posts/b905521b.html">概率论基础</a></li>
<li><a href="https://www.zhujian.tech/posts/74e95c64.html">线性代数基础</a></li>
<li><a href="https://www.zhujian.tech/posts/29422005.html">Jacobian矩阵和梯度矩阵</a></li>
<li><a href="https://www.zhujian.tech/posts/b9ab243b.html">实值标量函数一阶微分和Jacobian矩阵辨识</a></li>
</ul>]]></content>
      <categories>
        <category>随笔</category>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title>MkDocs vs Sphinx</title>
    <url>/posts/50a5fdf2.html</url>
    <content><![CDATA[<p>参考：<a href="https://zhujian.tech/posts/359e7c3c.html" target="_blank" rel="noopener">从CSDN到Hexo</a></p><p>之前整理了一套文档生成、托管和发布流程，使用<code>Sphinx</code>完成工程文档的生成，使用<code>Github</code>完成文档的托管，使用<code>Readthedocs</code>完成文档的发布</p><a id="more"></a>

<p>在实践过程中发现整个流程都有或大或小的不足，尤其是<code>Sphinx</code>工具，最近学习了另外一个文档生成工具<code>MkDocs</code>，更加符合个人的需求</p>
<h2 id="Sphinx问题"><a href="#Sphinx问题" class="headerlink" title="Sphinx问题"></a>Sphinx问题</h2><p><code>Sphinx</code>是一个文档生成工具，提供了方便快捷的文档生成操作，默认支持<code>reStructuredText</code></p>
<p>虽然也能够使用<code>Markdown</code>，但是在实际操作过程中，发现若干问题：</p>
<ol>
<li>不能有效设置数学公式渲染</li>
<li>不支持<code>Markdown</code>表格</li>
</ol>
<h2 id="MkDocs解析"><a href="#MkDocs解析" class="headerlink" title="MkDocs解析"></a>MkDocs解析</h2><p><code>MkDocs</code>同样是一个简单、易用的文档生成工具，其默认支持<code>Markdown</code>，能够使用表格语法，同时通过扩展能够解决数学公式渲染的问题</p>
<p>同时相比于<code>Sphinx</code>，其配置更加简洁易懂，降低使用门槛</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>替换掉<code>Sphinx</code>，当前的文档操作流程是</p>
<blockquote>
<p>mkdocs文档制作，github远程托管，readthedocs在线发布 </p>
</blockquote>
<p>实现教程：<a href="https://zj-sphinx-github-readthedocs.readthedocs.io/en/latest/" target="_blank" rel="noopener">MkDocs-Github-Readthedocs</a></p>
]]></content>
      <categories>
        <category>随笔</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>sphinx</tag>
        <tag>mkdocs</tag>
      </tags>
  </entry>
  <entry>
    <title>数据集小结</title>
    <url>/posts/bdfae45b.html</url>
    <content><![CDATA[<p>把常用的数据集整理一下，方便后续查询和整理。本文章不定期更新中。。。</p><h2 id="数值数据集"><a href="#数值数据集" class="headerlink" title="数值数据集"></a>数值数据集</h2><ul>
<li><a href="https://www.zhujian.tech/posts/833d7df4.html">German Credit Data数据集解析</a></li>
<li><a href="https://zhujian.tech/posts/ffa9d775.html" target="_blank" rel="noopener">Iris数据集解析</a></li>
</ul><a id="more"></a>

<h2 id="图像数据集"><a href="#图像数据集" class="headerlink" title="图像数据集"></a>图像数据集</h2><ul>
<li><a href="https://blog.csdn.net/u012005313/article/details/84453316" target="_blank" rel="noopener">Python MNIST解压</a></li>
<li><a href="https://www.zhujian.tech/posts/43d7ec86.html">cifar-10数据集解析</a></li>
<li><a href="https://www.zhujian.tech/posts/adb6e880.html">cifar-100数据集解析</a></li>
<li><a href="https://www.zhujian.tech/posts/631c599a.html">Fashion-MNIST数据集解析</a></li>
<li><a href="https://www.zhujian.tech/posts/28b6703d.html">PASCAL-VOC数据集解析</a></li>
<li><a href="https://www.zhujian.tech/posts/5a56cd45.html">PASCAL VOC 2007数据集解析</a></li>
</ul>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><img src="/imgs/dataset/summary.png" alt></p>
]]></content>
      <categories>
        <category>随笔</category>
        <category>数据</category>
        <category>数据集</category>
      </categories>
  </entry>
  <entry>
    <title>[数据集]Iris</title>
    <url>/posts/ffa9d775.html</url>
    <content><![CDATA[<p>参考：<a href="http://archive.ics.uci.edu/ml/datasets/Iris" target="_blank" rel="noopener">Iris Data Set</a></p><p><code>Iris</code>数据集包含<code>3</code>个类别<code>4</code>个属性，共<code>150</code>个实例</p><h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><p><code>4</code>个属性分别表示（单位<code>cm</code>）：</p><a id="more"></a>


<ol>
<li>萼片(<code>sepal</code>)长度</li>
<li>萼片宽度</li>
<li>花瓣(<code>petal</code>)长度</li>
<li>花瓣宽度</li>
</ol>
<p>每个类别有<code>50</code>个实例，整个数据集共<code>150</code>个</p>
<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>下载地址：<a href="http://archive.ics.uci.edu/ml/machine-learning-databases/iris/" target="_blank" rel="noopener">machine-learning-databases/iris</a></p>
<p>文件<code>iris.data</code>中共<code>150</code>行，每行<code>5</code>个值，前<code>4</code>个表示属性，最后一个表示类别，每列用逗号隔开</p>
<p><em><code>Kaggle</code>也提供了<code>Iris</code>数据集，其数据集格式略有差别，具体参考<a href="https://zhujian.tech/posts/2626bec3.html" target="_blank" rel="noopener">鸢尾数据集</a></em></p>
<h2 id="解析-1"><a href="#解析-1" class="headerlink" title="解析"></a>解析</h2><p>通过<code>pandas</code>库解析<code>csv</code>文件，通过<code>sklearn</code>库分离训练集和测试集，通过<code>matplotlib</code>绘制图像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   iris.py</span><br><span class="line">@time:   2019-12-14</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">import sklearn.utils as utils</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def iris_str_to_int(x):</span><br><span class="line">    if &apos;Iris-setosa&apos;.__eq__(x):</span><br><span class="line">        return 0</span><br><span class="line">    elif &apos;Iris-versicolor&apos;.__eq__(x):</span><br><span class="line">        return 1</span><br><span class="line">    else:</span><br><span class="line">        return 2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_iris_data(data_path, shuffle=True, tsize=0.8):</span><br><span class="line">    data_list = pd.read_csv(data_path, header=None, sep=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    data_array = data_list.values</span><br><span class="line">    height, width = data_array.shape[:2]</span><br><span class="line">    data_x = data_array[:, :(width - 1)].astype(np.float)</span><br><span class="line">    data_y = data_array[:, (width - 1)]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=shuffle)</span><br><span class="line">    y_train = np.array(list(map(lambda x: iris_str_to_int(x), y_train)))</span><br><span class="line">    y_test = np.array(list(map(lambda x: iris_str_to_int(x), y_test)))</span><br><span class="line"></span><br><span class="line">    return x_train, x_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw_iris(x_data, y_data, title, xlabel, ylabel):</span><br><span class="line">    fig = plt.figure()</span><br><span class="line"></span><br><span class="line">    x = x_data[y_data == 0]</span><br><span class="line">    plt.scatter(x[:, 0], x[:, 1], c=&apos;r&apos;, marker=&apos;&lt;&apos;, label=&apos;Iris-setosa&apos;)</span><br><span class="line"></span><br><span class="line">    x = x_data[y_data == 1]</span><br><span class="line">    plt.scatter(x[:, 0], x[:, 1], c=&apos;g&apos;, marker=&apos;8&apos;, label=&apos;Iris-versicolor&apos;)</span><br><span class="line"></span><br><span class="line">    x = x_data[y_data == 2]</span><br><span class="line">    plt.scatter(x[:, 0], x[:, 1], c=&apos;y&apos;, marker=&apos;*&apos;, label=&apos;Iris-virginica&apos;)</span><br><span class="line"></span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.xlabel(xlabel)</span><br><span class="line">    plt.ylabel(ylabel)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    iris_path = &apos;/home/zj/data/iris-species/iris.data&apos;</span><br><span class="line">    x_train, x_test, y_train, y_test = load_iris_data(iris_path, shuffle=True, tsize=0.8)</span><br><span class="line"></span><br><span class="line">    x_train = x_train.astype(np.double)</span><br><span class="line">    x_test = x_test.astype(np.double)</span><br><span class="line">    # 计算训练集每个属性的均值和方差</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-8</span><br><span class="line">    # 将数据变换为均值为0，方差为1的标准正态分布</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(var + eps)</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(var + eps)</span><br><span class="line"></span><br><span class="line">    draw_iris(x_train[:, :2], y_train, &apos;sepal height/width&apos;, &apos;height&apos;, &apos;width&apos;)</span><br><span class="line">    draw_iris(x_train[:, 2:], y_train, &apos;petal height/width&apos;, &apos;height&apos;, &apos;width&apos;)</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/iris/iris-sepal.png" alt></p>
<p><img src="/imgs/iris/iris-petal.png" alt></p>
<h2 id="sklearn"><a href="#sklearn" class="headerlink" title="sklearn"></a>sklearn</h2><p><code>sklearn</code>库提供了<code>iris</code>数据集的封装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">def load_data():</span><br><span class="line">    # Import some data to play with</span><br><span class="line">    iris = datasets.load_iris()</span><br><span class="line">    X = iris.data</span><br><span class="line">    y = iris.target</span><br><span class="line"></span><br><span class="line">    # shuffle and split training and test sets</span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)</span><br><span class="line"></span><br><span class="line">    return X_train, X_test, y_train, y_test</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    X_train, X_test, y_train, y_test = load_data()</span><br><span class="line"></span><br><span class="line">    print(X_train.shape)</span><br><span class="line">    print(X_test.shape)</span><br><span class="line">    print(y_train.shape)</span><br><span class="line">    print(y_test.shape)</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(75, 4)</span><br><span class="line">(75, 4)</span><br><span class="line">(75,)</span><br><span class="line">(75,)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据</category>
        <category>代码库</category>
        <category>数据集</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>sklearn</tag>
        <tag>pandas</tag>
        <tag>iris</tag>
      </tags>
  </entry>
  <entry>
    <title>[数据集]German Credit Data</title>
    <url>/posts/833d7df4.html</url>
    <content><![CDATA[<p>参考：<a href="http://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data" target="_blank" rel="noopener">Statlog (German Credit Data) Data Set</a>)</p><p>德国信用卡数据（<code>German Credit Data</code>）提供了一个二分类数据集，下载地址 - <a href="http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/" target="_blank" rel="noopener">statlog/german</a></p><a id="more"></a>

<h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><ul>
<li>文件<code>german.data</code>提供了<code>20</code>个属性（<code>13</code>个类别属性+<code>7</code>个数字属性）共<code>1000</code>个实例，最后一列表示类别（分别为<code>1</code>和<code>2</code>）</li>
<li>文件<code>german.data-numeric</code>提供了<code>24</code>个数字属性，共<code>1000</code>个实例，最后一列表示类别（分别为<code>1</code>和<code>2</code>）</li>
</ul>
<p>最开始数据集仅提供了文件<code>german.data</code>，后续提供了文件<code>german.data-numeric</code>，添加了属性并全部转换成数值</p>
<h2 id="python读取"><a href="#python读取" class="headerlink" title="python读取"></a>python读取</h2><p>利用<code>pandas</code>库读取<code>csv</code>文件，利用<code>sklearn</code>库分离训练集和数据集，对数据进行标准化操作</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   german.py</span><br><span class="line">@time:   2019-12-13</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_german_data(data_path, shuffle=True, tsize=0.8):</span><br><span class="line">    data_list = pd.read_csv(data_path, header=None, sep=&apos;\s+&apos;)</span><br><span class="line"></span><br><span class="line">    data_array = data_list.values</span><br><span class="line">    height, width = data_array.shape[:2]</span><br><span class="line">    data_x = data_array[:, :(width - 1)]</span><br><span class="line">    data_y = data_array[:, (width - 1)]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    y_train = np.array(list(map(lambda x: 1 if x == 2 else 0, y_train)))</span><br><span class="line">    y_test = np.array(list(map(lambda x: 1 if x == 2 else 0, y_test)))</span><br><span class="line"></span><br><span class="line">    return x_train, x_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    data_path = &apos;/home/zj/data/german/german.data-numeric&apos;</span><br><span class="line">    x_train, x_test, y_train, y_test = load_german_data(data_path)</span><br><span class="line"></span><br><span class="line">    x_train = x_train.astype(np.double)</span><br><span class="line">    x_test = x_test.astype(np.double)</span><br><span class="line">    # 计算训练集每个属性的均值和方差</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-8</span><br><span class="line">    # 将数据变换为均值为0，方差为1的标准正态分布</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(var + eps)</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(var + eps)</span><br><span class="line"></span><br><span class="line">    print(x_test)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据</category>
        <category>代码库</category>
        <category>数据集</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>sklearn</tag>
        <tag>pandas</tag>
        <tag>german credit data</tag>
      </tags>
  </entry>
  <entry>
    <title>[ROC][AUC]二分类任务评判标准</title>
    <url>/posts/887dcf29.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" target="_blank" rel="noopener">Sensitivity and specificity</a></p><p><a href="https://en.wikipedia.org/wiki/Confusion_matrix" target="_blank" rel="noopener">Confusion matrix</a></p><p><a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" target="_blank" rel="noopener">Receiver operating characteristic</a></p><a id="more"></a>



<p>对于分类问题，最开始想到的评判标准就是检测准确率（<code>accuracy</code>），即样本检测类别和实际一致的数量占整个样本集的比率。进一步研究发现，还可以用更精细的标准来比较检测性能，学习步骤如下：</p>
<ol>
<li>正样本和负样本</li>
<li><code>TP/FP/TN/FN</code></li>
<li><code>TPR/FPR/FDR/PPV/ACC</code></li>
<li><code>ROC/AUC</code></li>
</ol>
<h2 id="正样本和负样本"><a href="#正样本和负样本" class="headerlink" title="正样本和负样本"></a>正样本和负样本</h2><p>在二分类问题中，将待识别的物体称为正样本（<code>positive case</code>），另外一个称为负样本（<code>negative case</code>）</p>
<h2 id="TP-FP-TN-FN"><a href="#TP-FP-TN-FN" class="headerlink" title="TP/FP/TN/FN"></a>TP/FP/TN/FN</h2><p>对数据进行检测，能够得到以下<code>4</code>种检测结果</p>
<ul>
<li>预测结果是正样本<ul>
<li>实际是正样本，称为真阳性（<code>true positive</code>，简称<code>TP</code>）</li>
<li>实际是负样本，称为假阴性（<code>false negative</code>, 简称<code>FN</code>）</li>
</ul>
</li>
<li>预测结果是负样本<ul>
<li>实际是正样本，称为假阳性（<code>false positive</code>，简称<code>FP</code>）</li>
<li>实际是负样本，成为真阴性（<code>true negative</code>, 简称<code>TN</code>）</li>
</ul>
</li>
</ul>
<p>也就是说，<strong>根据实际情况</strong>决定预测结果是阳性还是阴性；<strong>根据预测结果和实际情况的比对</strong>决定预测结果是真还是假</p>
<p><style type="text/css"><br>.tg  {border-collapse:collapse;border-spacing:0;}<br>.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}<br>.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}<br>.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
</style></p>
<table class="tg">
  <tr>
    <th class="tg-c3ow"></th>
    <th class="tg-c3ow"></th>
    <th class="tg-c3ow" colspan="2">预测</th>
    <th class="tg-c3ow"></th>
  </tr>
  <tr>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow">true</td>
    <td class="tg-c3ow">false</td>
    <td class="tg-c3ow"></td>
  </tr>
  <tr>
    <td class="tg-c3ow" rowspan="2">实际</td>
    <td class="tg-c3ow">positive</td>
    <td class="tg-c3ow">true positive(TP)</td>
    <td class="tg-c3ow">false positive(FP)</td>
    <td class="tg-c3ow">正样本个数=TP+FP</td>
  </tr>
  <tr>
    <td class="tg-c3ow">negative</td>
    <td class="tg-c3ow">false negative(FN)</td>
    <td class="tg-c3ow">true negative(TN)</td>
    <td class="tg-c3ow">负样本个数=FN+TN</td>
  </tr>
  <tr>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow">预测正样本个数=TP+FN</td>
    <td class="tg-c3ow">预测负样本个数=FP+TN</td>
    <td class="tg-c3ow"></td>
  </tr>
</table>

<p>所以预测为真的样本数$P=TP+FN$，预测为负的样本数$N=FP+TN$</p>
<h2 id="TPR-FPR-FDR-PPV-ACC"><a href="#TPR-FPR-FDR-PPV-ACC" class="headerlink" title="TPR/FPR/FDR/PPV/ACC"></a>TPR/FPR/FDR/PPV/ACC</h2><h3 id="TPR-FPR"><a href="#TPR-FPR" class="headerlink" title="TPR/FPR"></a>TPR/FPR</h3><ul>
<li>真阳性率（<code>TPR, true positive rate</code>），也称为敏感度（<code>sensitivity</code>）、召回率（<code>recall rate</code>）、检测率（<code>probability of detection</code>），其计算的是检测为真的正样本在整个检测为真的样本集中的比率</li>
</ul>
<script type="math/tex; mode=display">
TPR = \frac {TP}{P} = \frac {TP}{TP+FN}</script><ul>
<li>假阳性率（<code>FPR, false positive rate</code>），也称为误报率（<code>probability of false alarm</code>），其计算的是检测为假的正样本在整个检测为假的样本集中的比率</li>
</ul>
<script type="math/tex; mode=display">
FPR = \frac {FP}{N} = \frac {FP}{FP+TN}</script><h3 id="FDR和PPV"><a href="#FDR和PPV" class="headerlink" title="FDR和PPV"></a>FDR和PPV</h3><ul>
<li>漏检率（<code>FDR, false discovery rate</code>）计算的是假阳性样本占实际正样本集的比率</li>
</ul>
<script type="math/tex; mode=display">
FDR=\frac {FP}{TP+FP}</script><ul>
<li><code>PPV(positive predictive value)</code>，也称为精度（<code>precision</code>），其计算的是检测为真的正样本占整个实际正样本集的比率</li>
</ul>
<script type="math/tex; mode=display">
PPV=\frac {TP}{TP+FP}</script><h3 id="ACC"><a href="#ACC" class="headerlink" title="ACC"></a>ACC</h3><p><code>ACC(accuracy)</code>就是指正确率，指的是真阳性和真阴性占整个样本集的比率</p>
<script type="math/tex; mode=display">
ACC = \frac {TP+TN}{P+N} = \frac {TP+TN}{TP+TN+FP+FN}</script><h2 id="ROC-AUC"><a href="#ROC-AUC" class="headerlink" title="ROC/AUC"></a>ROC/AUC</h2><h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h3><p><code>ROC</code>曲线，全称是接受者操作特征曲线（<code>receiver operating characteristic curve</code>），它是一个二维图，用于表明分类器的检测性能</p>
<p>其<code>y</code>轴表示<code>TPR</code>，<code>x</code>轴表示<code>FPR</code>。通过在不同阈值条件下计算<code>(FPR, TPR)</code>数据对，绘制得到<code>ROC</code>曲线</p>
<p><img src="/imgs/ROC-AUC/1024px-ROC_space-2.png" alt></p>
<p><code>ROC</code>曲线描述了收益（<code>true positive</code>）和成本（<code>false positive</code>）之间的权衡。由上图可知</p>
<ul>
<li>最好的预测结果发生在左上角<code>(0,1)</code>，此时所有预测为真的样本均为实际正样本，没有正样本被预测为假</li>
<li>对角线表示的是随机猜测（<code>random guess</code>）的结果，对角线上方的坐标点表示分类器的检测结果比随机猜测好</li>
</ul>
<p>所以离左上角越近，表示预测效果越好，此时分类器的性能更佳</p>
<h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><p>参考：<a href="https://www.zhihu.com/question/39840928?from=profile_question_card" target="_blank" rel="noopener">如何理解机器学习和统计中的AUC？</a></p>
<p><code>AUC(area under the curve)</code>指的是<code>ROC</code>曲线图中曲线下方的面积。其表示概率值，表示当随机给定一个正样本和一个负样本，分类器输出该正样本为正的那个概率值比分类器输出该负样本为正的那个概率值要大的可能性</p>
<p><em>通过计算AUC值，也可以判断出最佳阈值</em></p>
<h3 id="如何计算最佳阈值"><a href="#如何计算最佳阈值" class="headerlink" title="如何计算最佳阈值"></a>如何计算最佳阈值</h3><p>参考：</p>
<p><a href="https://stats.stackexchange.com/questions/123124/how-to-determine-the-optimal-threshold-for-a-classifier-and-generate-roc-curve" target="_blank" rel="noopener">How to determine the optimal threshold for a classifier and generate ROC curve?</a></p>
<p><a href="https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python" target="_blank" rel="noopener">Roc curve and cut off point. Python</a></p>
<p>通过<code>ROC</code>图可知，<code>TPR</code>越大越好，<code>FPR</code>越小越好，所以只要能够得到不同阈值条件下的<code>TPR</code>和<code>FPR</code>，计算之间的差值，结果值最大的就是最佳阈值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">thresh = thresholds[np.argmax(tpr - fpr)]</span><br><span class="line">print(thresh)</span><br></pre></td></tr></table></figure>
<h2 id="python实现"><a href="#python实现" class="headerlink" title="python实现"></a>python实现</h2><p><code>sklean</code>库提供了多个函数用于<code>ROC/AUC</code>的计算，参考<a href="https://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc" target="_blank" rel="noopener">3.3.2.14. Receiver operating characteristic (ROC)</a></p>
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html" target="_blank" rel="noopener">sklearn.metrics.roc_curve</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" target="_blank" rel="noopener">sklearn.metrics.roc_auc_score</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html?highlight=auc#sklearn.metrics.auc" target="_blank" rel="noopener">sklearn.metrics.auc</a></li>
</ul>
<h3 id="roc-curve"><a href="#roc-curve" class="headerlink" title="roc_curve"></a>roc_curve</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def roc_curve(y_true, y_score, pos_label=None, sample_weight=None,</span><br><span class="line">              drop_intermediate=True):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>y_true</code>：一维数组形式，表示样本标签。如果不是<code>{-1,1}</code>或者<code>{0,1}</code>的格式，那么参数<code>pos_label</code>需要显式设定</li>
<li><code>y_score</code>：一维数组形式，表示目标成绩。可以是对正样本的概率估计/置信度</li>
<li><code>pos_label</code>：指明正样本所属标签。如果<code>y_true</code>是<code>{-1,1}</code>或<code>{0,1}</code>格式，那么<code>pos_label</code>默认为<code>1</code></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.metrics import roc_curve</span><br><span class="line"></span><br><span class="line">y = np.array([1, 1, 2, 2])</span><br><span class="line">scores = np.array([0.1, 0.4, 0.35, 0.8])</span><br><span class="line">fpr, tpr, thresholds = roc_curve(y, scores, pos_label=2)</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">plt.plot(fpr, tpr, label=&apos;ROC&apos;)</span><br><span class="line">plt.show()</span><br><span class="line">// 输出</span><br><span class="line">[0.  0.  0.5 0.5 1. ]               # FPR</span><br><span class="line">[0.  0.5 0.5 1.  1. ]               # TPR</span><br><span class="line">[1.8  0.8  0.4  0.35 0.1 ]    # thresholds</span><br></pre></td></tr></table></figure>
<p>返回的是<code>FPR、TPR</code>和阈值数组，<code>FPR</code>和<code>TPR</code>中每个坐标的值表示利用<code>thresholds</code>数组同样下标的阈值所得到的真阳性率和假阳性率</p>
<p><img src="/imgs/ROC-AUC/roc_curve.png" alt></p>
<h3 id="roc-auc-score-auc"><a href="#roc-auc-score-auc" class="headerlink" title="roc_auc_score/auc"></a>roc_auc_score/auc</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def roc_auc_score(y_true, y_score, average=&quot;macro&quot;, sample_weight=None,</span><br><span class="line">                  max_fpr=None):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>y_true</code>：格式为<code>[n_samples]</code>或者<code>[n_samples, n_classes]</code></li>
<li><code>y_score</code>：格式为<code>[n_samples]</code>或者<code>[n_samples, n_classes]</code></li>
</ul>
<p>返回的是<code>AUC</code>的值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def auc(x, y, reorder=&apos;deprecated&apos;):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>x：FPR</code></li>
<li><code>y：TPR</code></li>
</ul>
<p>利用<code>roc_curve</code>计算得到<code>FPR</code>和<code>TPR</code>后，就可以输入到<code>auc</code>计算<code>AUC</code>大小</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from sklearn.metrics import roc_auc_score</span><br><span class="line">from sklearn.metrics import auc</span><br><span class="line"></span><br><span class="line">print(roc_auc_score(y, scores))</span><br><span class="line">print(auc(fpr, tpr))</span><br><span class="line"># 输出</span><br><span class="line">0.75</span><br><span class="line">0.75</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程</category>
        <category>评判标准</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>sklearn</tag>
        <tag>ROC</tag>
        <tag>AUC</tag>
      </tags>
  </entry>
  <entry>
    <title>[PyTorch]Tensorboard使用实践</title>
    <url>/posts/f793688d.html</url>
    <content><![CDATA[<p>学习了<code>PyTorch</code>环境下的<code>Tensorboard</code>使用 - <a href="https://zhujian.tech/posts/eb6f2b71.html#more" target="_blank" rel="noopener">[PyTorch]Tensorboard可视化实现</a>。<code>PyTorch</code>也提供了<code>Tensorboard</code>学习教程 - <a href="https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html#visualizing-models-data-and-training-with-tensorboard" target="_blank" rel="noopener">Visualizing Models, Data, and Training with TensorBoard</a></p><a id="more"></a>
<p>下面结合一个完整的训练过程，通过<code>Tensorboard</code>实现可视化</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>利用<code>LeNet-5</code>模型训练并测试<code>Fashion-MNIST</code>，训练参数如下：</p>
<ul>
<li>批量大小：<code>256</code></li>
<li>学习率：<code>1e-3</code></li>
<li>动量：<code>0.9</code></li>
<li>迭代次数：<code>50</code></li>
</ul>
<p>操作流程如下：</p>
<ol>
<li>加载训练集，新建模型，损失器和优化器，转换数据和模型到<code>GPU</code></li>
<li>迭代数据集训练网络，每轮完成训练后计算损失值，训练集精度和测试集精度</li>
<li>绘制损失图和精度图</li>
</ol>
<p>完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   tensorboard-fashion-mnist.py</span><br><span class="line">@time:   2019-12-11</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import torch.optim as optim</span><br><span class="line"></span><br><span class="line">import torchvision</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">import torchvision.utils</span><br><span class="line"></span><br><span class="line">learning_rate = 1e-3</span><br><span class="line">moment = 0.9</span><br><span class="line">epoches = 50</span><br><span class="line">bsize = 256</span><br><span class="line"></span><br><span class="line"># constant for classes</span><br><span class="line">classes = (&apos;T-shirt/top&apos;, &apos;Trouser&apos;, &apos;Pullover&apos;, &apos;Dress&apos;, &apos;Coat&apos;,</span><br><span class="line">           &apos;Sandal&apos;, &apos;Shirt&apos;, &apos;Sneaker&apos;, &apos;Bag&apos;, &apos;Ankle Boot&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(bsize):</span><br><span class="line">    # transforms</span><br><span class="line">    transform = transforms.Compose(</span><br><span class="line">        [transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize((0.5,), (0.5,))])</span><br><span class="line"></span><br><span class="line">    # datasets</span><br><span class="line">    trainset = torchvision.datasets.FashionMNIST(&apos;./data&apos;,</span><br><span class="line">                                                 download=True,</span><br><span class="line">                                                 train=True,</span><br><span class="line">                                                 transform=transform)</span><br><span class="line">    testset = torchvision.datasets.FashionMNIST(&apos;./data&apos;,</span><br><span class="line">                                                download=True,</span><br><span class="line">                                                train=False,</span><br><span class="line">                                                transform=transform)</span><br><span class="line"></span><br><span class="line">    # dataloaders</span><br><span class="line">    trainloader = torch.utils.data.DataLoader(trainset, batch_size=bsize,</span><br><span class="line">                                              shuffle=True, num_workers=2)</span><br><span class="line"></span><br><span class="line">    testloader = torch.utils.data.DataLoader(testset, batch_size=bsize,</span><br><span class="line">                                             shuffle=False, num_workers=2)</span><br><span class="line">    return trainloader, testloader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Net(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(1, 6, 5)</span><br><span class="line">        self.pool = nn.MaxPool2d(2, 2)</span><br><span class="line">        self.conv2 = nn.Conv2d(6, 16, 5)</span><br><span class="line">        self.fc1 = nn.Linear(16 * 4 * 4, 120)</span><br><span class="line">        self.fc2 = nn.Linear(120, 84)</span><br><span class="line">        self.fc3 = nn.Linear(84, 10)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(-1, 16 * 4 * 4)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(loader, net, device):</span><br><span class="line">    total_accu = 0.0</span><br><span class="line">    num = 0</span><br><span class="line"></span><br><span class="line">    for i, data in enumerate(loader, 0):</span><br><span class="line">        inputs, labels = data[0].to(device), data[1].to(device)</span><br><span class="line"></span><br><span class="line">        outputs = net.forward(inputs)</span><br><span class="line">        predicted = torch.argmax(outputs, dim=1)</span><br><span class="line">        total_accu += torch.mean((predicted == labels).float()).item()</span><br><span class="line">        num += 1</span><br><span class="line">    return total_accu / num</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(values, xlabel, ylabel, title, label):</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    plt.plot(list(range(len(values))), values, label=label)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(xlabel)</span><br><span class="line">    plt.ylabel(ylabel)</span><br><span class="line">    plt.title(title)</span><br><span class="line"></span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def train(trainloader, testloader, net, criterion, optimizer, device):</span><br><span class="line">    train_accu_list = list()</span><br><span class="line">    test_accu_list = list()</span><br><span class="line">    loss_list = list()</span><br><span class="line"></span><br><span class="line">    for epoch in range(epoches):  # loop over the dataset multiple times</span><br><span class="line">        num = 0</span><br><span class="line">        running_loss = 0.0</span><br><span class="line">        for i, data in enumerate(trainloader, 0):</span><br><span class="line">            # get the inputs; data is a list of [inputs, labels]</span><br><span class="line">            inputs, labels = data[0].to(device), data[1].to(device)</span><br><span class="line"></span><br><span class="line">            # zero the parameter gradients</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">            # forward + backward + optimize</span><br><span class="line">            outputs = net(inputs)</span><br><span class="line">            loss = criterion(outputs, labels)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            running_loss += loss.item()</span><br><span class="line">            num += 1</span><br><span class="line">        # 每轮迭代完成后，记录损失值，计算训练集和测试集的检测精度</span><br><span class="line">        avg_loss = running_loss / num</span><br><span class="line">        print(&apos;[%d] loss: %.4f&apos; % (epoch + 1, avg_loss))</span><br><span class="line">        loss_list.append(avg_loss)</span><br><span class="line"></span><br><span class="line">        train_accu = compute_accuracy(trainloader, net, device)</span><br><span class="line">        test_accu = compute_accuracy(testloader, net, device)</span><br><span class="line">        print(&apos;train: %.4f, test: %.4f&apos; % (train_accu, test_accu))</span><br><span class="line">        train_accu_list.append(train_accu)</span><br><span class="line">        test_accu_list.append(test_accu)</span><br><span class="line"></span><br><span class="line">    print(&apos;Finished Training&apos;)</span><br><span class="line">    return train_accu_list, test_accu_list, loss_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">    print(device)</span><br><span class="line"></span><br><span class="line">    net = Net().to(device)</span><br><span class="line">    criterion = nn.CrossEntropyLoss().to(device)</span><br><span class="line">    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=moment)</span><br><span class="line"></span><br><span class="line">    trainloader, testloader = load_data(bsize)</span><br><span class="line"></span><br><span class="line">    train_accu_list, test_accu_list, loss_list = train(trainloader, testloader, net, criterion, optimizer, device)</span><br><span class="line"></span><br><span class="line">    draw(train_accu_list, &apos;epoch&apos;, &apos;accuracy&apos;, &apos;train accuracy&apos;, &apos;fashion-mnist&apos;)</span><br><span class="line">    draw(test_accu_list, &apos;epoch&apos;, &apos;accuracy&apos;, &apos;test accuracy&apos;, &apos;fashion-mnist&apos;)</span><br><span class="line">    draw(loss_list, &apos;epoch&apos;, &apos;loss_value&apos;, &apos;loss&apos;, &apos;fashion-mnist&apos;)</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/tensorboard-work/normal-training-process-result.png" alt></p>
<h2 id="Tensorboard实践"><a href="#Tensorboard实践" class="headerlink" title="Tensorboard实践"></a>Tensorboard实践</h2><p>实现流程如下：</p>
<ol>
<li>启动<code>Tensorboard</code></li>
<li>写入样本图像</li>
<li>写入模型</li>
<li>高维特征投影</li>
<li>追踪训练过程</li>
</ol>
<h3 id="启动Tensorboard"><a href="#启动Tensorboard" class="headerlink" title="启动Tensorboard"></a>启动Tensorboard</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line"></span><br><span class="line"># default `log_dir` is &quot;runs&quot; - we&apos;ll be more specific here</span><br><span class="line">writer = SummaryWriter(&apos;runs/fashion_mnist_experiment_1&apos;)</span><br></pre></td></tr></table></figure>
<p>打开新的命令行窗口，在同一路径下输入命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ tensorboard --logdir=runs --host=192.168.0.112 --port=7878</span><br></pre></td></tr></table></figure>
<p>打开浏览器，输入<code>192.168.0.112:7878</code>，即可打开<code>Tensorboard</code></p>
<h3 id="写入样本图像"><a href="#写入样本图像" class="headerlink" title="写入样本图像"></a>写入样本图像</h3><p>修改数据加载函数，分离转换器，以便能偶加载未标准化的数据集</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def load_data(bsize, tf=None):</span><br><span class="line">    # datasets</span><br><span class="line">    trainset = torchvision.datasets.FashionMNIST(&apos;./data&apos;,</span><br><span class="line">                                                 download=True,</span><br><span class="line">                                                 train=True,</span><br><span class="line">                                                 transform=tf)</span><br><span class="line">    testset = torchvision.datasets.FashionMNIST(&apos;./data&apos;,</span><br><span class="line">                                                download=True,</span><br><span class="line">                                                train=False,</span><br><span class="line">                                                transform=tf)</span><br><span class="line"></span><br><span class="line">    # dataloaders</span><br><span class="line">    trainloader = torch.utils.data.DataLoader(trainset, batch_size=bsize,</span><br><span class="line">                                              shuffle=True, num_workers=4)</span><br><span class="line"></span><br><span class="line">    testloader = torch.utils.data.DataLoader(testset, batch_size=bsize,</span><br><span class="line">                                             shuffle=False, num_workers=4)</span><br><span class="line">    return trainloader, testloader</span><br></pre></td></tr></table></figure>
<p>加载数据集，写入图像。<code>torchvision</code>提供了函数<a href="https://pytorch.org/docs/stable/torchvision/utils.html#torchvision.utils.make_grid" target="_blank" rel="noopener">make_grid</a>将<code>Tensor</code>数组转换成单个图像（<code>[64, 1, 28, 28] -&gt; [3, 242, 242]</code>）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">transform = transforms.Compose(</span><br><span class="line">        [transforms.ToTensor()])</span><br><span class="line"></span><br><span class="line">trainloader, testloader = load_data(64, tf=transform)</span><br><span class="line">print(trainloader)</span><br><span class="line"></span><br><span class="line"># get some random training images</span><br><span class="line">dataiter = iter(trainloader)</span><br><span class="line">images, labels = dataiter.__next__()</span><br><span class="line">print(images.size())</span><br><span class="line"></span><br><span class="line"># create grid of images</span><br><span class="line">img_grid = torchvision.utils.make_grid(images)</span><br><span class="line">print(img_grid.size())</span><br><span class="line"></span><br><span class="line"># write to tensorboard</span><br><span class="line">writer.add_image(&apos;fashion_mnist_images&apos;, img_grid)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>打开<code>Tensorboard IMAGES</code>页面，选择<code>fashion_mnist_images</code>标签的图像</p>
<p><img src="/imgs/tensorboard-work/fashion-mnist-images.png" alt></p>
<h3 id="写入模型"><a href="#写入模型" class="headerlink" title="写入模型"></a>写入模型</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">net = Net()</span><br><span class="line"></span><br><span class="line">writer.add_graph(net, images)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>打开<code>Tensorboard GRAPHS</code>页面，在右侧类别<code>Runs</code>中选择当前写入的文件<code>fashion-mnist-lenet5</code></p>
<p><img src="/imgs/tensorboard-work/graph-lenet-5.png" alt></p>
<h3 id="高维特征投影"><a href="#高维特征投影" class="headerlink" title="高维特征投影"></a>高维特征投影</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># constant for classes</span><br><span class="line">classes = (&apos;T-shirt/top&apos;, &apos;Trouser&apos;, &apos;Pullover&apos;, &apos;Dress&apos;, &apos;Coat&apos;,</span><br><span class="line">           &apos;Sandal&apos;, &apos;Shirt&apos;, &apos;Sneaker&apos;, &apos;Bag&apos;, &apos;Ankle Boot&apos;)</span><br><span class="line"></span><br><span class="line"># get some random training images</span><br><span class="line">dataiter = iter(trainloader)</span><br><span class="line">images, labels = dataiter.__next__()</span><br><span class="line">print(images.size())</span><br><span class="line"></span><br><span class="line"># select random images and their target indices</span><br><span class="line"># images, labels = select_n_random(trainset.data, trainset.targets)</span><br><span class="line"></span><br><span class="line"># get the class labels for each image</span><br><span class="line">class_labels = [classes[lab] for lab in labels]</span><br><span class="line"></span><br><span class="line"># log embeddings</span><br><span class="line">features = images.view(-1, 28 * 28)</span><br><span class="line">print(features.size())</span><br><span class="line">writer.add_embedding(features,</span><br><span class="line">                    metadata=class_labels,</span><br><span class="line">                    label_img=images)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>随机提取批量大小数据集，转换成向量数组，输入<code>add_embedding</code>函数中</p>
<p>打开<code>Tensorboard GRAPHS</code>页面，在右侧类别<code>Runs</code>中选择当前写入的文件<code>fashion-mnist-lenet5</code>，可在右下角选择不同的投影规则（默认<code>PCA</code>）</p>
<p><img src="/imgs/tensorboard-work/projector-pca.png" alt></p>
<h3 id="追踪训练过程"><a href="#追踪训练过程" class="headerlink" title="追踪训练过程"></a>追踪训练过程</h3><p>每轮迭代完成后，计算其损失值，训练集和测试集精度值，输入到<code>add_scalar(s)</code>函数中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for epoch in range(epoches):  # loop over the dataset multiple times</span><br><span class="line">    num = 0</span><br><span class="line">    running_loss = 0.0</span><br><span class="line">    for i, data in enumerate(trainloader, 0):</span><br><span class="line"></span><br><span class="line">        # get the inputs; data is a list of [inputs, labels]</span><br><span class="line">        inputs, labels = data[0].to(device), data[1].to(device)</span><br><span class="line"></span><br><span class="line">        # zero the parameter gradients</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        # forward + backward + optimize</span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        num += 1</span><br><span class="line">    # 每轮迭代完成后，记录损失值，计算训练集和测试集的检测精度</span><br><span class="line">    avg_loss = running_loss/num</span><br><span class="line">    print(&apos;[%d] loss: %.4f&apos; % (epoch+1, avg_loss))</span><br><span class="line"></span><br><span class="line">    train_accu = compute_accuracy(trainloader, net, device)</span><br><span class="line">    test_accu = compute_accuracy(testloader, net, device)</span><br><span class="line">    print(&apos;train: %.4f, test: %.4f&apos; % (train_accu, test_accu))</span><br><span class="line">    </span><br><span class="line">    # 添加损失值</span><br><span class="line">    writer.add_scalar(&quot;training loss&quot;, avg_loss, epoch)</span><br><span class="line"></span><br><span class="line">    # 添加训练集和测试集精度</span><br><span class="line">    writer.add_scalars(&quot;training accurancy&quot;, &#123;&apos;loss&apos;: avg_loss,</span><br><span class="line">                          &apos;train_accu&apos;: train_accu,</span><br><span class="line">                          &apos;test_accu&apos;: test_accu&#125;, epoch)</span><br><span class="line"></span><br><span class="line">print(&apos;Finished Training&apos;)</span><br></pre></td></tr></table></figure>
<p>打开<code>Tensorboard SCALARS</code>页面，在右下角选择类别</p>
<p><img src="/imgs/tensorboard-work/train-test-loss.png" alt></p>
]]></content>
      <categories>
        <category>编程</category>
        <category>工具</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>torchvision</tag>
        <tag>tensorboard</tag>
      </tags>
  </entry>
  <entry>
    <title>[PyTorch]Tensorboard可视化实现</title>
    <url>/posts/eb6f2b71.html</url>
    <content><![CDATA[<p>参考：<a href="https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html#visualizing-models-data-and-training-with-tensorboard" target="_blank" rel="noopener">Visualizing Models, Data, and Training with TensorBoard</a></p><a id="more"></a>
<p>最新版本的<code>PyTorch 1.3</code>内置支持了<a href="https://github.com/tensorflow/tensorboard" target="_blank" rel="noopener">Tensorboard</a>，实现模型、数据以及训练可视化</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>除了安装<code>PyTorch</code>以外，还需要额外安装<code>Tensorboard</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda install tensorboard</span><br></pre></td></tr></table></figure>
<h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>启动<code>tensorboard</code>，指定文件路径，<code>IP</code>地址以及端口号</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ tensorboard --logdir PATH --host ADDR --port PORT</span><br></pre></td></tr></table></figure>
<ul>
<li><code>logdir</code>：指定<code>Tensorflow event files</code>文件路径，通常设置为<code>runs</code>，会递归搜索<code>runs</code>文件夹内命名为<code>*tfevents.*</code>文件</li>
<li><code>host</code>：制定监听的主机名，默认为<code>localhost</code></li>
<li><code>port</code>：监听端口，默认为<code>6006</code></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ tensorboard --logdir=runs --host=192.168.0.112 --port=7878</span><br><span class="line">TensorFlow installation not found - running with reduced feature set.</span><br><span class="line">W1211 15:14:25.693824 140379677206272 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.</span><br><span class="line">W1211 15:14:25.694132 140379677206272 plugin_event_accumulator.py:322] Found more than one &quot;run metadata&quot; event with tag step1. Overwriting it with the newest event.</span><br><span class="line">TensorBoard 2.0.0 at http://192.168.0.112:7878/ (Press CTRL+C to quit)</span><br></pre></td></tr></table></figure>
<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="pytorch-ImportError-TensorBoard-logging-requires-TensorBoard-with-Python-summary-writer-installed"><a href="#pytorch-ImportError-TensorBoard-logging-requires-TensorBoard-with-Python-summary-writer-installed" class="headerlink" title="pytorch ImportError: TensorBoard logging requires TensorBoard with Python summary writer installed"></a>pytorch ImportError: TensorBoard logging requires TensorBoard with Python summary writer installed</h3><p>参考：<a href="https://blog.csdn.net/wangweiwells/article/details/101565407" target="_blank" rel="noopener">pytorch ImportError: TensorBoard logging requires TensorBoard with Python summary writer installed</a></p>
<p>安装<code>tensorboard</code>即可</p>
<h3 id="tensorboard-shows-a-SyntaxError-can’t-assign-to-operator"><a href="#tensorboard-shows-a-SyntaxError-can’t-assign-to-operator" class="headerlink" title="tensorboard shows a SyntaxError: can’t assign to operator"></a>tensorboard shows a SyntaxError: can’t assign to operator</h3><p>在<code>JupyterLab</code>上启动<code>Tensorboard</code>，发现如上问题，参考<a href="https://stackoverflow.com/questions/45392902/tensorboard-shows-a-syntaxerror-cant-assign-to-operator" target="_blank" rel="noopener">tensorboard shows a SyntaxError: can’t assign to operator</a>。解决方案：在命令前添加<code>!</code>即可</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">!tensorboard --logdir=runs</span><br></pre></td></tr></table></figure>
<h3 id="can’t-assign-to-operator"><a href="#can’t-assign-to-operator" class="headerlink" title="can’t assign to operator"></a>can’t assign to operator</h3><p>在<code>PyCharm</code>启动<code>tensorboard</code>时出现上述错误，参考<a href="https://blog.csdn.net/weixin_40292207/article/details/80672041" target="_blank" rel="noopener">运行tensorboard —logdir=log遇到的错误之can’t assign to operator</a>，新开一个命令行窗口启动即可</p>
<h2 id="入口函数"><a href="#入口函数" class="headerlink" title="入口函数"></a>入口函数</h2><p><a href="https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter" target="_blank" rel="noopener">SummaryWriter</a>类提供了一个高级<code>API</code>，用于在给定目录中创建事件文件并向其中添加摘要和事件。该对象异步更新文件内容，这样允许训练程序直接在训练过程中调用方法循环向文件中添加数据，而不会减慢训练速度</p>
<p>所有的<code>PyTorch</code>数据写入操作均通过<code>SummaryWriter</code>实现，声明如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line"></span><br><span class="line"># default `log_dir` is &quot;runs&quot; - we&apos;ll be more specific here</span><br><span class="line">writer = SummaryWriter(&apos;runs/fashion_mnist_experiment_1&apos;)</span><br></pre></td></tr></table></figure>
<p>需要指定文件保存路径，通常设置为<code>runs</code></p>
<p><strong>注意：后续的写入操作完成后调用<code>close</code>函数结束</strong></p>
<h2 id="add-image"><a href="#add-image" class="headerlink" title="add_image"></a>add_image</h2><p>增加图像数据到<code>Tensorboard</code>，使用函数<a href="https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_image" target="_blank" rel="noopener">add_image</a></p>
<p><strong>注意：需要额外安装<code>pillow</code></strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def add_image(self, tag, img_tensor, global_step=None, walltime=None, dataformats=&apos;CHW&apos;):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>tag</code>：数据标识符</li>
<li><code>img_tensor：torch.Tensor</code>格式图像</li>
</ul>
<p>使用如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import torch</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line"></span><br><span class="line"># default `log_dir` is &quot;runs&quot; - we&apos;ll be more specific here</span><br><span class="line">writer = SummaryWriter(&apos;runs/test&apos;)</span><br><span class="line"></span><br><span class="line">lena = cv2.imread(&apos;lena.jpg&apos;)</span><br><span class="line">lena = cv2.cvtColor(lena, cv2.COLOR_BGR2RGB)</span><br><span class="line">lena_tensor = torch.from_numpy(lena.transpose((2, 0, 1)))</span><br><span class="line">print(lena_tensor.size())</span><br><span class="line"></span><br><span class="line"># 写入</span><br><span class="line">writer.add_image(&apos;lena&apos;, lena_tensor)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>完成上述操作后，在<code>tensorboard</code>页面菜单栏选择<code>IMAGES</code>标签，会出现写入的<code>lena</code>图像</p>
<p><img src="/imgs/tensorboard/add_image.png" alt></p>
<p><em>可以在同一个标签上添加多个图像，在页面上拖动滑动条显示不同的图像</em></p>
<h2 id="add-graph"><a href="#add-graph" class="headerlink" title="add_graph"></a>add_graph</h2><p>调用函数<a href="https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_graph" target="_blank" rel="noopener">add_graph</a>实现模型可视化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def add_graph(self, model, input_to_model=None, verbose=False):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>model：torch.nn.Module</code>（待绘制的模型）</li>
<li><code>input_to_model</code>：模型输入数据，可输入单张图像（<code>torch.Tensor</code>）或者图像列表（<code>list of torch.Tensor</code>）</li>
<li><code>verbose</code>：是否在控制台详细打印图结构</li>
</ul>
<p>使用如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">import torchvision</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line"></span><br><span class="line"># 定义模型</span><br><span class="line">class Net(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(1, 6, 5)</span><br><span class="line">        self.pool = nn.MaxPool2d(2, 2)</span><br><span class="line">        self.conv2 = nn.Conv2d(6, 16, 5)</span><br><span class="line">        self.fc1 = nn.Linear(16 * 4 * 4, 120)</span><br><span class="line">        self.fc2 = nn.Linear(120, 84)</span><br><span class="line">        self.fc3 = nn.Linear(84, 10)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(-1, 16 * 4 * 4)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br><span class="line"></span><br><span class="line"># 获取数据</span><br><span class="line"># transforms</span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((0.5,), (0.5,))])</span><br><span class="line"></span><br><span class="line"># datasets</span><br><span class="line">trainset = torchvision.datasets.FashionMNIST(&apos;./data&apos;,</span><br><span class="line">                                             download=True,</span><br><span class="line">                                             train=True,</span><br><span class="line">                                             transform=transform)</span><br><span class="line">testset = torchvision.datasets.FashionMNIST(&apos;./data&apos;,</span><br><span class="line">                                            download=True,</span><br><span class="line">                                            train=False,</span><br><span class="line">                                            transform=transform)</span><br><span class="line"></span><br><span class="line"># dataloaders</span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,</span><br><span class="line">                                          shuffle=True, num_workers=2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=4,</span><br><span class="line">                                         shuffle=False, num_workers=2)</span><br><span class="line"></span><br><span class="line"># constant for classes</span><br><span class="line">classes = (&apos;T-shirt/top&apos;, &apos;Trouser&apos;, &apos;Pullover&apos;, &apos;Dress&apos;, &apos;Coat&apos;,</span><br><span class="line">           &apos;Sandal&apos;, &apos;Shirt&apos;, &apos;Sneaker&apos;, &apos;Bag&apos;, &apos;Ankle Boot&apos;)</span><br><span class="line"></span><br><span class="line"># get some random training images</span><br><span class="line">dataiter = iter(trainloader)</span><br><span class="line">images, labels = dataiter.next()</span><br><span class="line">print(images.size())</span><br><span class="line"></span><br><span class="line">## 写入模型</span><br><span class="line">writer.add_graph(net, input_to_model=images,verbose=True)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>完成上述操作后，在<code>tensorboard</code>页面菜单栏选择<code>GRAPHS</code>标签，会可视化模型，双击即可扩展模型细节</p>
<p><img src="/imgs/tensorboard/add_graph.png" alt></p>
<p><img src="/imgs/tensorboard/expand_model.png" alt></p>
<h2 id="add-embedding"><a href="#add-embedding" class="headerlink" title="add_embedding"></a>add_embedding</h2><p>调用函数<a href="https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_graph" target="_blank" rel="noopener">add_embedding</a>实现高维数据可视化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def add_embedding(self, mat, metadata=None, label_img=None, global_step=None, tag=&apos;default&apos;, metadata_header=None):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>mat</code>：矩阵，每行表示一个数据点的特征向量，其大小为$(N,D)$</li>
<li><code>metadata</code>：字符串列表，表示标签</li>
<li><code>label_imgs</code>：相对于每个数据点的图像列表，其大小为$(N,C,H,W)$</li>
</ul>
<p>测试如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import keyword</span><br><span class="line">import torch</span><br><span class="line"></span><br><span class="line">// 提取关键字</span><br><span class="line">meta = []</span><br><span class="line">while len(meta)&lt;100:</span><br><span class="line">    meta = meta+keyword.kwlist # get some strings</span><br><span class="line">// 取前100个</span><br><span class="line">meta = meta[:100]</span><br><span class="line"></span><br><span class="line">// 转换成标签</span><br><span class="line">for i, v in enumerate(meta):</span><br><span class="line">    meta[i] = v+str(i)</span><br><span class="line"></span><br><span class="line">// 随机生成100张图像</span><br><span class="line">label_img = torch.rand(100, 3, 10, 32)</span><br><span class="line">// 缩放到(0,1)</span><br><span class="line">for i in range(100):</span><br><span class="line">    label_img[i]*=i/100.0</span><br><span class="line"></span><br><span class="line">writer.add_embedding(torch.randn(100, 5), metadata=meta, label_img=label_img)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>完成上述操作后，在<code>tensorboard</code>页面菜单栏选择<code>PROJECTOR</code>标签，将高维数据投影到<code>3</code>维空间中</p>
<p><img src="/imgs/tensorboard/add_embedding.png" alt></p>
<h2 id="add-scalar"><a href="#add-scalar" class="headerlink" title="add_scalar"></a>add_scalar</h2><p>调用函数<a href="https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalar" target="_blank" rel="noopener">add_scalar</a>或者<a href="https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalars" target="_blank" rel="noopener">add_scalars</a>实现训练数据实时写入</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def add_scalar(self, tag, scalar_value, global_step=None, walltime=None):</span><br><span class="line">def add_scalars(self, main_tag, tag_scalar_dict, global_step=None, walltime=None):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>main_tag</code>：标识符</li>
<li><code>scalar_value</code>：浮点值（<code>float</code>）或者字符串（<code>str</code>）</li>
<li><code>tag_scalar_dict：dict</code>，以键值对的方式保存子标签和相应的值</li>
<li><code>global_step</code>：步长</li>
</ul>
<p>实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">r = 5</span><br><span class="line">for i in range(100):</span><br><span class="line">    writer.add_scalars(&apos;run_14h&apos;, &#123;&apos;xsinx&apos;:i*np.sin(i/r),</span><br><span class="line">                                    &apos;xcosx&apos;:i*np.cos(i/r),</span><br><span class="line">                                    &apos;tanx&apos;: np.tan(i/r)&#125;, i)</span><br><span class="line">writer.close()</span><br><span class="line"># This call adds three values to the same scalar plot with the tag</span><br><span class="line"># &apos;run_14h&apos; in TensorBoard&apos;s scalar section.</span><br></pre></td></tr></table></figure>
<p>点击菜单栏的<code>SCALARS</code>标签，能够显示实时的训练数据</p>
<p><img src="/imgs/tensorboard/add_scalar.png" alt></p>
<p>将鼠标移动到图中，会显示不同阶段相应的训练结果</p>
<p><img src="/imgs/tensorboard/expand_scalar.png" alt></p>
<h2 id="add-figure"><a href="#add-figure" class="headerlink" title="add_figure"></a>add_figure</h2><p><a href="https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_figure" target="_blank" rel="noopener">add_figure</a>作用与<code>add_image</code>类似，均是显示图像到<code>tensorboard</code>页面，不同的是<code>add_figure</code>指定渲染<code>Matplotlib</code>图像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def add_figure(self, tag, figure, global_step=None, close=True, walltime=None):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>tag</code>：标识符</li>
<li><code>figure：matplotlib.pyplot.figure</code>格式图像</li>
<li><code>global_step</code>：步长</li>
</ul>
<p>实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">plt.imshow(lena)</span><br><span class="line">writer.add_figure(&apos;plt&apos;, fig, 0)</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">plt.imshow(gray, cmap=&quot;Greys&quot;)</span><br><span class="line">writer.add_figure(&apos;plt&apos;, fig, 1)</span><br></pre></td></tr></table></figure>
<p>写入后即可在<code>IMAGES</code>页面查询</p>
<h2 id="add-pr-curve"><a href="#add-pr-curve" class="headerlink" title="add_pr_curve"></a>add_pr_curve</h2><p>调用函数<a href="https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_figure" target="_blank" rel="noopener">add_pr_curve</a>绘制精度召回曲线（<code>precision-recall curve</code>）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def add_pr_curve(self, tag, labels, predictions, global_step=None,</span><br><span class="line">                     num_thresholds=127, weights=None, walltime=None):</span><br></pre></td></tr></table></figure>
<ul>
<li><code>tag</code>：数据标识符</li>
<li><code>labels</code>：真实标签。取值为二值标签</li>
<li><code>predictions</code>：元素被归为正确的概率，取值为0或1</li>
<li><code>global_step</code>：步长</li>
<li><code>num_thresholds</code>：绘制曲线的阈值数量</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">labels = np.random.randint(2, size=100)  # binary label</span><br><span class="line">print(labels)</span><br><span class="line">predictions = np.random.rand(100)</span><br><span class="line">print(predictions)</span><br><span class="line"></span><br><span class="line">writer.add_pr_curve(&apos;pr_curve&apos;, labels, predictions, 0)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程</category>
        <category>工具</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>torchvision</tag>
        <tag>tensorboard</tag>
      </tags>
  </entry>
  <entry>
    <title>[数据集]Fashion-MNIST</title>
    <url>/posts/631c599a.html</url>
    <content><![CDATA[<p>之前识别测试最常用的是手写数字数据集<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">MNIST</a>，今天遇到一个新的基准数据集 - <a href="https://github.com/zalandoresearch/fashion-mnist" target="_blank" rel="noopener">Fashion-MNIST</a></p><a id="more"></a>
<p><img src="/imgs/..//imgs/fashion-mnist/fashion-mnist-sprite.png" alt></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><code>Fashion-MNIST</code>是关于衣物饰品的数据集，其格式类似于<code>MNIST</code>，包含了<code>10</code>类标签，每张图片为<code>28x28</code>大小灰度图像，共<code>60000</code>张训练集和<code>10000</code>张测试集</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Label</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>T-shirt/top(T恤)</td>
</tr>
<tr>
<td>1</td>
<td>Trouser(裤子)</td>
</tr>
<tr>
<td>2</td>
<td>Pullover(套衫)</td>
</tr>
<tr>
<td>3</td>
<td>Dress(连衣裙)</td>
</tr>
<tr>
<td>4</td>
<td>Coat(外套)</td>
</tr>
<tr>
<td>5</td>
<td>Sandal(凉鞋)</td>
</tr>
<tr>
<td>6</td>
<td>Shirt(衬衫)</td>
</tr>
<tr>
<td>7</td>
<td>Sneaker(运动鞋)</td>
</tr>
<tr>
<td>8</td>
<td>Bag(包)</td>
</tr>
<tr>
<td>9</td>
<td>Ankle boot(短靴)</td>
</tr>
</tbody>
</table>
</div>
<h2 id="fashion-mnist-vs-mnist"><a href="#fashion-mnist-vs-mnist" class="headerlink" title="fashion-mnist vs. mnist"></a>fashion-mnist vs. mnist</h2><p><code>Fashion-MNIST</code>希望替代<code>MNIST</code>成为新的基准数据集，给出了以下<code>3</code>个理由：</p>
<ol>
<li><code>MNIST</code>没有挑战性。使用最新的卷积神经网络算法能够达到<code>99.7%</code>，使用传统的机器学习算法也能够达到<code>97%</code></li>
<li><code>MNIST</code>没有新奇感。不解释</li>
<li><code>MNIST</code>无法代表现代<code>CV</code>任务。某位大牛说的</li>
</ol>
<p>总的来说，在使用相同样本格式的情况下，<code>Fashion-MNIST</code>的难度大于<code>MNIST</code>，参考<a href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#" target="_blank" rel="noopener">benchmarks</a></p>
<p>与此同时，<code>Fashion-MNIST</code>还提供了更丰富的语言接口</p>
<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p><code>Fashion-MNIST</code>的存储格式和<code>MNIST</code>一样，具体格式参考<a href="https://blog.csdn.net/u012005313/article/details/84453316" target="_blank" rel="noopener">Python MNIST解压</a></p>
<p>下载地址如下：</p>
<ol>
<li><a href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz" target="_blank" rel="noopener">train-images-idx3-ubyte.gz</a></li>
<li><a href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz" target="_blank" rel="noopener">train-labels-idx1-ubyte.gz</a></li>
<li><a href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz" target="_blank" rel="noopener">t10k-images-idx3-ubyte.gz</a></li>
<li><a href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz" target="_blank" rel="noopener">t10k-labels-idx1-ubyte.gz</a></li>
</ol>
<p>或者下载仓库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git clone git@github.com:zalandoresearch/fashion-mnist.git</span><br></pre></td></tr></table></figure>
<p>数据集保存在<code>/data/fashion</code>路径下</p>
<h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><p><code>Fashion-MNIST</code>提供了多种语言的数据加载接口，包括<code>Python/C/C++/Java</code>等，同时基于多种机器学习库，比如<code>PyTorch/Torch</code></p>
<h3 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h3><p>下载整个仓库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git clone git@github.com:zalandoresearch/fashion-mnist.git</span><br></pre></td></tr></table></figure>
<p>使用<code>utils/mnist_reader</code>脚本加载图片</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">utils$ python</span><br><span class="line">Python 3.7.4 (default, Aug 13 2019, 20:35:49) </span><br><span class="line">[GCC 7.3.0] :: Anaconda, Inc. on linux</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">&gt;&gt;&gt; import mnist_reader</span><br><span class="line">&gt;&gt;&gt; X_train, y_train = mnist_reader.load_mnist(&apos;../data/fashion&apos;, kind=&apos;train&apos;)</span><br><span class="line">&gt;&gt;&gt; X_test, y_test = mnist_reader.load_mnist(&apos;../data/fashion&apos;, kind=&apos;t10k&apos;)</span><br><span class="line">&gt;&gt;&gt; </span><br><span class="line">&gt;&gt;&gt; </span><br><span class="line">&gt;&gt;&gt; X_train.shape</span><br><span class="line">(60000, 784)</span><br><span class="line">&gt;&gt;&gt; y_train.shape</span><br><span class="line">(60000,)</span><br><span class="line">&gt;&gt;&gt; X_test.shape</span><br><span class="line">(10000, 784)</span><br><span class="line">&gt;&gt;&gt; y_test.shape</span><br><span class="line">(10000,)</span><br></pre></td></tr></table></figure>
<h3 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line"></span><br><span class="line"># transforms</span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((0.5,), (0.5,))])</span><br><span class="line"></span><br><span class="line"># datasets</span><br><span class="line">trainset = torchvision.datasets.FashionMNIST(&apos;./data&apos;,</span><br><span class="line">    download=True,</span><br><span class="line">    train=True,</span><br><span class="line">    transform=transform)</span><br><span class="line">testset = torchvision.datasets.FashionMNIST(&apos;./data&apos;,</span><br><span class="line">    download=True,</span><br><span class="line">    train=False,</span><br><span class="line">    transform=transform)</span><br><span class="line"></span><br><span class="line"># dataloaders</span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,</span><br><span class="line">                                        shuffle=True, num_workers=2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=4,</span><br><span class="line">                                        shuffle=False, num_workers=2)</span><br></pre></td></tr></table></figure>
<h3 id="C"><a href="#C" class="headerlink" title="C++"></a>C++</h3><p>参考：<a href="https://github.com/wichtounet/mnist" target="_blank" rel="noopener">wichtounet/mnist</a></p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>分别使用<code>MNIST</code>和<code>Fashion-MNIST</code>，使用<code>AlexNet</code>卷积神经网络模型，利用<code>PyTorch</code>实现，训练参数如下：</p>
<ul>
<li>批量大小：<code>256</code></li>
<li>学习率：<code>1e-3</code></li>
<li>动量大小：<code>0.9</code></li>
<li>迭代次数：<code>30</code></li>
</ul>
<p>实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   mnist.py</span><br><span class="line">@time:   2019-12-10</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line"></span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import torchvision.datasets as datasets</span><br><span class="line"></span><br><span class="line">root = &apos;./data&apos;</span><br><span class="line">bsize = 256</span><br><span class="line">shuffle = True</span><br><span class="line">num_work = 8</span><br><span class="line"></span><br><span class="line">learning_rate = 1e-3</span><br><span class="line">moment = 0.9</span><br><span class="line">epoches = 30</span><br><span class="line"></span><br><span class="line">classes = range(10)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_mnist(transform, root, bsize, shuffle, num_work):</span><br><span class="line">    train_dataset = datasets.MNIST(root, train=True, download=True, transform=transform)</span><br><span class="line">    train_loader = DataLoader(train_dataset, batch_size=bsize, shuffle=shuffle, num_workers=num_work)</span><br><span class="line"></span><br><span class="line">    test_dataset = datasets.MNIST(root, train=False, download=True, transform=transform)</span><br><span class="line">    test_loader = DataLoader(test_dataset, batch_size=bsize, shuffle=shuffle, num_workers=num_work)</span><br><span class="line"></span><br><span class="line">    return train_loader, test_loader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_fashion_mnist(transform, root, bsize, shuffle, num_work):</span><br><span class="line">    train_dataset = datasets.FashionMNIST(root, train=True, download=True, transform=transform)</span><br><span class="line">    train_loader = DataLoader(train_dataset, batch_size=bsize, shuffle=shuffle, num_workers=num_work)</span><br><span class="line"></span><br><span class="line">    test_dataset = datasets.FashionMNIST(root, train=False, download=True, transform=transform)</span><br><span class="line">    test_loader = DataLoader(test_dataset, batch_size=bsize, shuffle=shuffle, num_workers=num_work)</span><br><span class="line"></span><br><span class="line">    return train_loader, test_loader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(loader, net, device):</span><br><span class="line">    total_accu = 0.0</span><br><span class="line">    num = 0</span><br><span class="line"></span><br><span class="line">    for i, data in enumerate(loader, 0):</span><br><span class="line">        inputs, labels = data[0].to(device), data[1].to(device)</span><br><span class="line"></span><br><span class="line">        outputs = net.forward(inputs)</span><br><span class="line">        predicted = torch.argmax(outputs, dim=1)</span><br><span class="line">        total_accu += torch.mean((predicted == labels).float()).item()</span><br><span class="line">        num += 1</span><br><span class="line">    return total_accu / num</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class AlexNet(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, num_channels=3, num_classes=1000):</span><br><span class="line">        super(AlexNet, self).__init__()</span><br><span class="line">        self.features = nn.Sequential(</span><br><span class="line">            nn.Conv2d(num_channels, 64, kernel_size=11, stride=4, padding=2),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">            nn.Conv2d(64, 192, kernel_size=5, padding=2),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">            nn.Conv2d(192, 384, kernel_size=3, padding=1),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Conv2d(384, 256, kernel_size=3, padding=1),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Conv2d(256, 256, kernel_size=3, padding=1),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">        )</span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(256 * 6 * 6, 4096),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(4096, 4096),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Linear(4096, num_classes),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        x = torch.flatten(x, 1)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Resize((227, 227)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=(0.5,), std=(0.5,))</span><br><span class="line">    ])</span><br><span class="line">    train_loader, test_loader = load_mnist(transform, root, bsize, shuffle, num_work)</span><br><span class="line">    # train_loader, test_loader = load_fashion_mnist(transform, root, bsize, shuffle, num_work)</span><br><span class="line"></span><br><span class="line">    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">    net = AlexNet(num_channels=1, num_classes=10).to(device)</span><br><span class="line">    criterion = nn.CrossEntropyLoss().to(device)</span><br><span class="line">    optimer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)</span><br><span class="line"></span><br><span class="line">    train_accu_list = list()</span><br><span class="line">    test_accu_list = list()</span><br><span class="line">    loss_list = list()</span><br><span class="line"></span><br><span class="line">    for epoch in range(epoches):</span><br><span class="line">        num = 0</span><br><span class="line">        total_loss = 0.0</span><br><span class="line">        start = time.time()</span><br><span class="line">        for i, data in enumerate(train_loader, 0):</span><br><span class="line">            inputs, labels = data[0].to(device), data[1].to(device)</span><br><span class="line"></span><br><span class="line">            optimer.zero_grad()</span><br><span class="line"></span><br><span class="line">            outputs = net(inputs)</span><br><span class="line">            loss = criterion(outputs, labels)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimer.step()</span><br><span class="line"></span><br><span class="line">            total_loss += loss.item()</span><br><span class="line">            num += 1</span><br><span class="line">        end = time.time()</span><br><span class="line"></span><br><span class="line">        avg_loss = total_loss / num</span><br><span class="line">        print(&apos;[%d] loss: %.5f, time: %.3f&apos; % (epoch + 1, avg_loss, end - start))</span><br><span class="line">        loss_list.append(avg_loss)</span><br><span class="line"></span><br><span class="line">        train_accu = compute_accuracy(train_loader, net, device)</span><br><span class="line">        test_accu = compute_accuracy(test_loader, net, device)</span><br><span class="line">        print(&apos;train: %.3f, test: %.3f&apos; % (train_accu, test_accu))</span><br><span class="line">        train_accu_list.append(train_accu)</span><br><span class="line">        test_accu_list.append(test_accu)</span><br><span class="line"></span><br><span class="line">    print(loss_list)</span><br><span class="line">    print(train_accu_list)</span><br><span class="line">    print(test_accu_list)</span><br></pre></td></tr></table></figure>
<p>训练完成后通过<code>matplotlib</code>绘制</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">def draw(mnist_list,fashion_list, xlabel,ylabel,title):</span><br><span class="line">    fig=plt.figure()</span><br><span class="line">    x = list(range(30))</span><br><span class="line">    plt.plot(x, mnist_list, label=&apos;mnist&apos;)</span><br><span class="line">    plt.plot(x, fashion_list, label=&apos;fashion-mnist&apos;)</span><br><span class="line">    </span><br><span class="line">    plt.xlabel(xlabel)</span><br><span class="line">    plt.ylabel(ylabel)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">draw(mnist_loss_list, fashion_loss_list, &apos;epoch&apos;,&apos;loss_value&apos;,&apos;loss&apos;)</span><br><span class="line">draw(mnist_train_accu_list, fashion_train_accu_list, &apos;epoch&apos;,&apos;accurancy&apos;,&apos;train accurancy&apos;)</span><br><span class="line">draw(mnist_test_accu_list, fashion_test_accu_list, &apos;epoch&apos;,&apos;accurancy&apos;,&apos;test accurancy&apos;)</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/..//imgs/fashion-mnist/mnist_fashion_loss.png" alt></p>
<p><img src="/imgs/..//imgs/fashion-mnist/mnist_fashion_train.png" alt></p>
<p><img src="/imgs/..//imgs/fashion-mnist/mnist_fashion_test.png" alt></p>
<p>从训练结果可以发现，相比较于<code>MNIST</code>，数据集<code>Fashion-MNIST</code>更具挑战性</p>
]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据</category>
        <category>代码库</category>
        <category>数据集</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>torchvision</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>fashion-mnist</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]Writing Custom Datasets, DataLoaders and Transforms</title>
    <url>/posts/aa0415d3.html</url>
    <content><![CDATA[<p>PyTorch通过TorchVision工具包提供统一的数据加载、数据处理的接口，允许自定义类的方式加载数据集，通过DataLoader接口来批量处理</p><a id="more"></a>
<p>原文地址：<a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html" target="_blank" rel="noopener">Writing Custom Datasets, DataLoaders and Transforms</a></p>
<blockquote>
<p>A lot of effort in solving any machine learning problem goes in to preparing the data. PyTorch provides many tools to make data loading easy and hopefully, to make your code more readable. In this tutorial, we will see how to load and preprocess/augment data from a non trivial dataset.</p>
</blockquote>
<p>在解决任何机器学习问题时，都要花很多精力准备数据。PyTorch提供了许多工具来使数据加载变得容易，并且有可能使您的代码更具可读性。在本教程中，我们将看到如何从一个自定义数据集中加载和预处理/扩充数据</p>
<blockquote>
<p>To run this tutorial, please make sure the following packages are installed:</p>
<ul>
<li>scikit-image: For image io and transforms</li>
<li>pandas: For easier csv parsing</li>
</ul>
</blockquote>
<p>运行本教程之前，确保以下包已安装：</p>
<ul>
<li>scikit-image: 用于图像输出和转换</li>
<li>pandas: 用于CSV文件解析</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from __future__ import print_function, division</span><br><span class="line">import os</span><br><span class="line">import torch</span><br><span class="line">import pandas as pd</span><br><span class="line">from skimage import io, transform</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from torch.utils.data import Dataset, DataLoader</span><br><span class="line">from torchvision import transforms, utils</span><br><span class="line"></span><br><span class="line"># Ignore warnings</span><br><span class="line">import warnings</span><br><span class="line">warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class="line"></span><br><span class="line">plt.ion()   # interactive mode</span><br></pre></td></tr></table></figure>
<blockquote>
<p>The dataset we are going to deal with is that of facial pose. This means that a face is annotated like this:</p>
</blockquote>
<p>我们将要处理的数据集是面部姿态数据集。这意味着一张脸被这样标注:</p>
<p><img src="/imgs/pytorch-自定义数据集/landmarked_face2.png" alt></p>
<blockquote>
<p>Over all, 68 different landmark points are annotated for each face.</p>
</blockquote>
<p>总的来说，为每张脸标注了68个不同的地点</p>
<blockquote>
<p>Download the dataset from <a href="https://download.pytorch.org/tutorial/faces.zip" target="_blank" rel="noopener">here</a> so that the images are in a directory named ‘data/faces/‘. This dataset was actually generated by applying excellent <a href="https://blog.dlib.net/2014/08/real-time-face-pose-estimation.html" target="_blank" rel="noopener">dlib’s pose estimation</a> on a few images from imagenet tagged as ‘face’</p>
</blockquote>
<p>从这里下载数据集，以便图像位于名为“data/faces/”的目录中（就是解压后放置在data/faces目录下）。这个数据集实际上是通过对标记为“人脸”的imagenet中的图像应用出色的dlib姿态估计方法生成的</p>
<blockquote>
<p>Dataset comes with a csv file with annotations which looks like this:</p>
</blockquote>
<p>数据集附带一个csv文件，其格式如下（第一行为注释信息，第二行开始是图像名及标注坐标）:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">image_name,part_0_x,part_0_y,part_1_x,part_1_y,part_2_x,part_2_y,part_3_x,part_3_y,...</span><br><span class="line">0805personali01.jpg,27,83,27,98,29,113,33,127,39,139,49,150,60,159,73,166,87,168,100,166,...</span><br><span class="line">10comm-decarlo.jpg,66,114,65,128,67,142,68,156,72,169,80,180,91,...</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Let’s quickly read the CSV and get the annotations in an (N, 2) array where N is the number of landmarks.</p>
</blockquote>
<p>让我们快速阅读CSV并将标注地点保存在(N，2)大小数组，其中N是标注的数量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">landmarks_frame = pd.read_csv(&apos;data/faces/face_landmarks.csv&apos;)</span><br><span class="line"></span><br><span class="line">n = 65</span><br><span class="line">img_name = landmarks_frame.iloc[n, 0]</span><br><span class="line">landmarks = landmarks_frame.iloc[n, 1:].as_matrix()</span><br><span class="line">landmarks = landmarks.astype(&apos;float&apos;).reshape(-1, 2)</span><br><span class="line"></span><br><span class="line">print(&apos;Image name: &#123;&#125;&apos;.format(img_name))</span><br><span class="line">print(&apos;Landmarks shape: &#123;&#125;&apos;.format(landmarks.shape))</span><br><span class="line">print(&apos;First 4 Landmarks: &#123;&#125;&apos;.format(landmarks[:4]))</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Image name: person-7.jpg</span><br><span class="line">Landmarks shape: (68, 2)</span><br><span class="line">First 4 Landmarks: [[32. 65.]</span><br><span class="line"> [33. 76.]</span><br><span class="line"> [34. 86.]</span><br><span class="line"> [34. 97.]]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Let’s write a simple helper function to show an image and its landmarks and use it to show a sample.</p>
</blockquote>
<p>让我们编写一个简单的辅助函数来显示图像及其标注，并显示该结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def show_landmarks(image, landmarks):</span><br><span class="line">    &quot;&quot;&quot;Show image with landmarks&quot;&quot;&quot;</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker=&apos;.&apos;, c=&apos;r&apos;)</span><br><span class="line">    # 这一行代码需要去除 plt.pause(0.001)  # pause a bit so that plots are updated</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">show_landmarks(io.imread(os.path.join(&apos;data/faces/&apos;, img_name)),</span><br><span class="line">               landmarks)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/pytorch-自定义数据集/sphx_glr_data_loading_tutorial_001.png" alt></p>
<h2 id="Dataset-Class"><a href="#Dataset-Class" class="headerlink" title="Dataset Class"></a>Dataset Class</h2><blockquote>
<p>torch.utils.data.Dataset is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:</p>
<ul>
<li><code>__len__</code> so that len(dataset) returns the size of the dataset.</li>
<li><code>__getitem__</code> to support the indexing such that dataset[i] can be used to get ith sample</li>
</ul>
</blockquote>
<p>torch.util.data.Dataset是表示数据集的抽象类。自定义数据集类必须继承该类并重写以下方法：</p>
<ul>
<li><code>__len__</code>：返回数据集个数</li>
<li><code>__getitem__</code>：支持数据集检索，返回指定的图像</li>
</ul>
<blockquote>
<p>Let’s create a dataset class for our face landmarks dataset. We will read the csv in <code>__init__</code> but leave the reading of images to <code>__getitem__</code>. This is memory efficient because all the images are not stored in the memory at once but read as required.</p>
</blockquote>
<p>创建人脸标注数据集类。在<code>__init__</code>方法中读取CSV文件，在<code>__getItem__</code>方法中读取图像。这种方式更有效率，因为不需要一次性读取所有的图像</p>
<blockquote>
<p>Sample of our dataset will be a dict {‘image’: image, ‘landmarks’: landmarks}. Our dataset will take an optional argument transform so that any required processing can be applied on the sample. We will see the usefulness of transform in the next section.</p>
</blockquote>
<p>数据集中每个样本的格式为dict - {‘image’: image, ‘landmarks’: landmarks}。数据集类设置一个可选参数transform，作为参数转换，以便对样本应用任何所需的处理。我们将在下一节看到这个参数的操作</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class FaceLandmarksDataset(Dataset):</span><br><span class="line">    &quot;&quot;&quot;Face Landmarks dataset.&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, csv_file, root_dir, transform=None):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Args:</span><br><span class="line">            csv_file (string): Path to the csv file with annotations.</span><br><span class="line">            root_dir (string): Directory with all the images.</span><br><span class="line">            transform (callable, optional): Optional transform to be applied</span><br><span class="line">                on a sample.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.landmarks_frame = pd.read_csv(csv_file)</span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return len(self.landmarks_frame)</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, idx):</span><br><span class="line">        if torch.is_tensor(idx):</span><br><span class="line">            idx = idx.tolist()</span><br><span class="line"></span><br><span class="line">        img_name = os.path.join(self.root_dir,</span><br><span class="line">                                self.landmarks_frame.iloc[idx, 0])</span><br><span class="line">        image = io.imread(img_name)</span><br><span class="line">        landmarks = self.landmarks_frame.iloc[idx, 1:]</span><br><span class="line">        landmarks = np.array([landmarks])</span><br><span class="line">        landmarks = landmarks.astype(&apos;float&apos;).reshape(-1, 2)</span><br><span class="line">        sample = &#123;&apos;image&apos;: image, &apos;landmarks&apos;: landmarks&#125;</span><br><span class="line"></span><br><span class="line">        if self.transform:</span><br><span class="line">            sample = self.transform(sample)</span><br><span class="line"></span><br><span class="line">        return sample</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Let’s instantiate this class and iterate through the data samples. We will print the sizes of first 4 samples and show their landmarks.</p>
</blockquote>
<p>让我们实例化这个类并遍历数据样本。我们将打印前4个样本的尺寸，并显示它们的标注信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">face_dataset = FaceLandmarksDataset(csv_file=&apos;data/faces/face_landmarks.csv&apos;,</span><br><span class="line">                                    root_dir=&apos;data/faces/&apos;)</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">for i in range(len(face_dataset)):</span><br><span class="line">    sample = face_dataset[i]</span><br><span class="line"></span><br><span class="line">    print(i, sample[&apos;image&apos;].shape, sample[&apos;landmarks&apos;].shape)</span><br><span class="line"></span><br><span class="line">    ax = plt.subplot(1, 4, i + 1)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    ax.set_title(&apos;Sample #&#123;&#125;&apos;.format(i))</span><br><span class="line">    ax.axis(&apos;off&apos;)</span><br><span class="line">    show_landmarks(**sample)</span><br><span class="line"></span><br><span class="line">    if i == 3:</span><br><span class="line">        plt.show()</span><br><span class="line">        break</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/pytorch-自定义数据集/sphx_glr_data_loading_tutorial_002.png" alt></p>
<p>输出</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0 (324, 215, 3) (68, 2)</span><br><span class="line">1 (500, 333, 3) (68, 2)</span><br><span class="line">2 (250, 258, 3) (68, 2)</span><br><span class="line">3 (434, 290, 3) (68, 2)</span><br></pre></td></tr></table></figure>
<h2 id="Transforms"><a href="#Transforms" class="headerlink" title="Transforms"></a>Transforms</h2><p>转换</p>
<blockquote>
<p>One issue we can see from the above is that the samples are not of the same size. Most neural networks expect the images of a fixed size. Therefore, we will need to write some prepocessing code. Let’s create three transforms:</p>
<ul>
<li>Rescale: to scale the image</li>
<li>RandomCrop: to crop from image randomly. This is data augmentation.</li>
<li>ToTensor: to convert the numpy images to torch images (we need to swap axes).</li>
</ul>
</blockquote>
<p>从上面我们可以看到的一个问题是样本的大小不同。大多数神经网络期望图像的大小是固定的。因此，我们需要编写一些预处理代码。让我们创建三个转换:</p>
<ul>
<li>Rescale：缩放图像</li>
<li>RandomCrop：随机裁剪。作用于数据扩充</li>
<li>ToTensor：转换numpy格式图像到torch格式</li>
</ul>
<blockquote>
<p>We will write them as callable classes instead of simple functions so that parameters of the transform need not be passed everytime it’s called. For this, we just need to implement <code>__call__</code> method and if required,<code>__init__</code> method. We can then use a transform like this:</p>
</blockquote>
<p>我们将把它们写成可调用的类，而不是简单的函数，这样就不需要每次调用时都传递转换的参数。为此，我们只需要实现<code>__call__</code>方法，如果需要的话，还可以实现<code>__init__</code>方法。然后我们可以使用如下转换:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tsfm = Transform(params)</span><br><span class="line">transformed_sample = tsfm(sample)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Observe below how these transforms had to be applied both on the image and landmarks.</p>
</blockquote>
<p>下面观察这些变换是如何应用于图像和标注信息的</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Rescale(object):</span><br><span class="line">    &quot;&quot;&quot;Rescale the image in a sample to a given size.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        output_size (tuple or int): Desired output size. If tuple, output is</span><br><span class="line">            matched to output_size. If int, smaller of image edges is matched</span><br><span class="line">            to output_size keeping aspect ratio the same.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, output_size):</span><br><span class="line">        assert isinstance(output_size, (int, tuple))</span><br><span class="line">        self.output_size = output_size</span><br><span class="line"></span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        image, landmarks = sample[&apos;image&apos;], sample[&apos;landmarks&apos;]</span><br><span class="line"></span><br><span class="line">        h, w = image.shape[:2]</span><br><span class="line">        if isinstance(self.output_size, int):</span><br><span class="line">            if h &gt; w:</span><br><span class="line">                new_h, new_w = self.output_size * h / w, self.output_size</span><br><span class="line">            else:</span><br><span class="line">                new_h, new_w = self.output_size, self.output_size * w / h</span><br><span class="line">        else:</span><br><span class="line">            new_h, new_w = self.output_size</span><br><span class="line"></span><br><span class="line">        new_h, new_w = int(new_h), int(new_w)</span><br><span class="line"></span><br><span class="line">        img = transform.resize(image, (new_h, new_w))</span><br><span class="line"></span><br><span class="line">        # h and w are swapped for landmarks because for images,</span><br><span class="line">        # x and y axes are axis 1 and 0 respectively</span><br><span class="line">        landmarks = landmarks * [new_w / w, new_h / h]</span><br><span class="line"></span><br><span class="line">        return &#123;&apos;image&apos;: img, &apos;landmarks&apos;: landmarks&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class RandomCrop(object):</span><br><span class="line">    &quot;&quot;&quot;Crop randomly the image in a sample.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        output_size (tuple or int): Desired output size. If int, square crop</span><br><span class="line">            is made.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, output_size):</span><br><span class="line">        assert isinstance(output_size, (int, tuple))</span><br><span class="line">        if isinstance(output_size, int):</span><br><span class="line">            self.output_size = (output_size, output_size)</span><br><span class="line">        else:</span><br><span class="line">            assert len(output_size) == 2</span><br><span class="line">            self.output_size = output_size</span><br><span class="line"></span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        image, landmarks = sample[&apos;image&apos;], sample[&apos;landmarks&apos;]</span><br><span class="line"></span><br><span class="line">        h, w = image.shape[:2]</span><br><span class="line">        new_h, new_w = self.output_size</span><br><span class="line"></span><br><span class="line">        top = np.random.randint(0, h - new_h)</span><br><span class="line">        left = np.random.randint(0, w - new_w)</span><br><span class="line"></span><br><span class="line">        image = image[top: top + new_h,</span><br><span class="line">                      left: left + new_w]</span><br><span class="line"></span><br><span class="line">        landmarks = landmarks - [left, top]</span><br><span class="line"></span><br><span class="line">        return &#123;&apos;image&apos;: image, &apos;landmarks&apos;: landmarks&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ToTensor(object):</span><br><span class="line">    &quot;&quot;&quot;Convert ndarrays in sample to Tensors.&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __call__(self, sample):</span><br><span class="line">        image, landmarks = sample[&apos;image&apos;], sample[&apos;landmarks&apos;]</span><br><span class="line"></span><br><span class="line">        # swap color axis because</span><br><span class="line">        # numpy image: H x W x C</span><br><span class="line">        # torch image: C X H X W</span><br><span class="line">        image = image.transpose((2, 0, 1))</span><br><span class="line">        return &#123;&apos;image&apos;: torch.from_numpy(image),</span><br><span class="line">                &apos;landmarks&apos;: torch.from_numpy(landmarks)&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Compose-transforms"><a href="#Compose-transforms" class="headerlink" title="Compose transforms"></a>Compose transforms</h2><p>组合转换</p>
<blockquote>
<p>Now, we apply the transforms on a sample.</p>
</blockquote>
<p>现在将转换操作应用到样本中</p>
<blockquote>
<p>Let’s say we want to rescale the shorter side of the image to 256 and then randomly crop a square of size 224 from it. i.e, we want to compose Rescale and RandomCrop transforms. torchvision.transforms.Compose is a simple callable class which allows us to do this.</p>
</blockquote>
<p>假设我们想将图像的短边重新缩放到256，然后从中随机裁剪一个224大小的正方形。比如，我们想要组合Rescale和RandomCrop转换操作。可以通过torchvision.transforms.Compose实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scale = Rescale(256)</span><br><span class="line">crop = RandomCrop(128)</span><br><span class="line">composed = transforms.Compose([Rescale(256),</span><br><span class="line">                               RandomCrop(224)])</span><br><span class="line"></span><br><span class="line"># Apply each of the above transforms on sample.</span><br><span class="line">fig = plt.figure()</span><br><span class="line">sample = face_dataset[65]</span><br><span class="line">for i, tsfrm in enumerate([scale, crop, composed]):</span><br><span class="line">    transformed_sample = tsfrm(sample)</span><br><span class="line"></span><br><span class="line">    ax = plt.subplot(1, 3, i + 1)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    ax.set_title(type(tsfrm).__name__)</span><br><span class="line">    show_landmarks(**transformed_sample)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/pytorch-自定义数据集/sphx_glr_data_loading_tutorial_003.png" alt></p>
<h2 id="Iterating-through-the-dataset"><a href="#Iterating-through-the-dataset" class="headerlink" title="Iterating through the dataset"></a>Iterating through the dataset</h2><p>数据集迭代</p>
<blockquote>
<p>Let’s put this all together to create a dataset with composed transforms. To summarize, every time this dataset is sampled:</p>
<ul>
<li>An image is read from the file on the fly</li>
<li>Transforms are applied on the read image</li>
<li>Since one of the transforms is random, data is augmentated on sampling</li>
</ul>
</blockquote>
<p>让我们把这些放在一起，创建一个具有组合转换的数据集。总而言之，每次对该数据集进行采样时:</p>
<ul>
<li>从文件中动态读取图像</li>
<li>对读取的图像应用变换</li>
<li>因为其中一个变换是随机的，所以数据在采样时被扩充了</li>
</ul>
<blockquote>
<p>We can iterate over the created dataset with a for i in range loop as before.</p>
</blockquote>
<p>之前我们可以通过for i in range方式来完成</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">transformed_dataset = FaceLandmarksDataset(csv_file=&apos;data/faces/face_landmarks.csv&apos;,</span><br><span class="line">                                           root_dir=&apos;data/faces/&apos;,</span><br><span class="line">                                           transform=transforms.Compose([</span><br><span class="line">                                               Rescale(256),</span><br><span class="line">                                               RandomCrop(224),</span><br><span class="line">                                               ToTensor()</span><br><span class="line">                                           ]))</span><br><span class="line"></span><br><span class="line">for i in range(len(transformed_dataset)):</span><br><span class="line">    sample = transformed_dataset[i]</span><br><span class="line"></span><br><span class="line">    print(i, sample[&apos;image&apos;].size(), sample[&apos;landmarks&apos;].size())</span><br><span class="line"></span><br><span class="line">    if i == 3:</span><br><span class="line">        break</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0 torch.Size([3, 224, 224]) torch.Size([68, 2])</span><br><span class="line">1 torch.Size([3, 224, 224]) torch.Size([68, 2])</span><br><span class="line">2 torch.Size([3, 224, 224]) torch.Size([68, 2])</span><br><span class="line">3 torch.Size([3, 224, 224]) torch.Size([68, 2])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>However, we are losing a lot of features by using a simple for loop to iterate over the data. In particular, we are missing out on:</p>
<ul>
<li>Batching the data</li>
<li>Shuffling the data</li>
<li>Load the data in parallel using multiprocessing workers.</li>
</ul>
</blockquote>
<p>然而，通过使用一个简单的for循环来迭代数据会丢失很多特性。特别是我们错过了:</p>
<ul>
<li>批量处理数据</li>
<li>打乱数据</li>
<li>使用多处理器并行加载数据</li>
</ul>
<blockquote>
<p>torch.utils.data.DataLoader is an iterator which provides all these features. Parameters used below should be clear. One parameter of interest is collate_fn. You can specify how exactly the samples need to be batched using collate_fn. However, default collate should work fine for most use cases.</p>
</blockquote>
<p>torch.utils.data.DataLoader是一个迭代器，能够提供上述所有的特性。感兴趣的一个参数是collate_fn。您可以使用collate_fn指定如何批量化样本集，默认设置已经能够很好的作用于大多数情况了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dataloader = DataLoader(transformed_dataset, batch_size=4,</span><br><span class="line">                        shuffle=True, num_workers=4)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Helper function to show a batch</span><br><span class="line">def show_landmarks_batch(sample_batched):</span><br><span class="line">    &quot;&quot;&quot;Show image with landmarks for a batch of samples.&quot;&quot;&quot;</span><br><span class="line">    images_batch, landmarks_batch = \</span><br><span class="line">            sample_batched[&apos;image&apos;], sample_batched[&apos;landmarks&apos;]</span><br><span class="line">    batch_size = len(images_batch)</span><br><span class="line">    im_size = images_batch.size(2)</span><br><span class="line">    grid_border_size = 2</span><br><span class="line"></span><br><span class="line">    grid = utils.make_grid(images_batch)</span><br><span class="line">    plt.imshow(grid.numpy().transpose((1, 2, 0)))</span><br><span class="line"></span><br><span class="line">    for i in range(batch_size):</span><br><span class="line">        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size + (i + 1) * grid_border_size,</span><br><span class="line">                    landmarks_batch[i, :, 1].numpy() + grid_border_size,</span><br><span class="line">                    s=10, marker=&apos;.&apos;, c=&apos;r&apos;)</span><br><span class="line"></span><br><span class="line">        plt.title(&apos;Batch from dataloader&apos;)</span><br><span class="line"></span><br><span class="line">for i_batch, sample_batched in enumerate(dataloader):</span><br><span class="line">    print(i_batch, sample_batched[&apos;image&apos;].size(),</span><br><span class="line">          sample_batched[&apos;landmarks&apos;].size())</span><br><span class="line"></span><br><span class="line">    # observe 4th batch and stop.</span><br><span class="line">    if i_batch == 3:</span><br><span class="line">        plt.figure()</span><br><span class="line">        show_landmarks_batch(sample_batched)</span><br><span class="line">        plt.axis(&apos;off&apos;)</span><br><span class="line">        plt.ioff()</span><br><span class="line">        plt.show()</span><br><span class="line">        break</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/pytorch-自定义数据集/sphx_glr_data_loading_tutorial_004.png" alt></p>
<p>输出</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])</span><br><span class="line">1 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])</span><br><span class="line">2 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])</span><br><span class="line">3 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])</span><br></pre></td></tr></table></figure>
<h2 id="Afterword-torchvision"><a href="#Afterword-torchvision" class="headerlink" title="Afterword: torchvision"></a>Afterword: torchvision</h2><p>后记：torchvision</p>
<blockquote>
<p>In this tutorial, we have seen how to write and use datasets, transforms and dataloader. torchvision package provides some common datasets and transforms. You might not even have to write custom classes. One of the more generic datasets available in torchvision is ImageFolder. It assumes that images are organized in the following way:</p>
</blockquote>
<p>在本教程中，我们已经看到了如何编写和使用数据集、转换和数据加载器。torchvision包提供了一些常见的数据集和转换。你甚至不必编写自定义类。在torchvision中最通用的数据集之一是ImageFolder。它假设图像以下列方式组织:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root/ants/xxx.png</span><br><span class="line">root/ants/xxy.jpeg</span><br><span class="line">root/ants/xxz.png</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">root/bees/123.jpg</span><br><span class="line">root/bees/nsdf3.png</span><br><span class="line">root/bees/asd932_.png</span><br></pre></td></tr></table></figure>
<blockquote>
<p>where ‘ants’, ‘bees’ etc. are class labels. Similarly generic transforms which operate on PIL.Image like RandomHorizontalFlip, Scale, are also available. You can use these to write a dataloader like this:</p>
</blockquote>
<p>其中<code>ants</code>、<code>bees</code>是类标签。里面集成了通用的转换操作，比如RandomHorizontalFlip/Scale等等。您可以使用这些来编写如下数据加载器:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torchvision import transforms, datasets</span><br><span class="line"></span><br><span class="line">data_transform = transforms.Compose([</span><br><span class="line">        transforms.RandomSizedCrop(224),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=[0.485, 0.456, 0.406],</span><br><span class="line">                             std=[0.229, 0.224, 0.225])</span><br><span class="line">    ])</span><br><span class="line">hymenoptera_dataset = datasets.ImageFolder(root=&apos;hymenoptera_data/train&apos;,</span><br><span class="line">                                           transform=data_transform)</span><br><span class="line">dataset_loader = torch.utils.data.DataLoader(hymenoptera_dataset,</span><br><span class="line">                                             batch_size=4, shuffle=True,</span><br><span class="line">                                             num_workers=4)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>代码库</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>torchvision</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>pandas</tag>
        <tag>skimage</tag>
      </tags>
  </entry>
  <entry>
    <title>[数据集]PASCAL VOC 2007</title>
    <url>/posts/5a56cd45.html</url>
    <content><![CDATA[<p>参考：<a href="https://www.zhujian.tech/posts/28b6703d.html">PASCAL-VOC数据集解析</a></p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>参考：<a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/index.html" target="_blank" rel="noopener">The PASCAL Visual Object Classes Challenge 2007</a></p><a id="more"></a>

<p><code>PASCAL VOC 2007</code>数据集基于<code>4</code>个大类别，共包含了<code>20</code>个目标类：</p>
<ul>
<li><code>Person: person</code></li>
<li><code>Animal: bird, cat, cow（奶牛）, dog, horse, sheep（绵羊）</code></li>
<li><code>Vehicle（交通工具）: aeroplane（飞机）, bicycle, boat（小船）, bus（公共汽车）, car（轿车）, motorbike（摩托车）, train（火车）</code></li>
<li><code>Indoor（室内）: bottle（瓶子）, chair（椅子）, dining table（餐桌）, potted plant（盆栽植物）, sofa, tv/monitor（电视/显示器）</code></li>
</ul>
<p><code>PASCAL VOC 2007</code>数据集主要用于分类/测试任务，同时也提供了分割和人体部件检测的数据。示例如下：</p>
<ul>
<li><a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/examples/index.html" target="_blank" rel="noopener">分类/测试示例</a></li>
<li><a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/segexamples/index.html" target="_blank" rel="noopener">分割示例</a></li>
<li><a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/layoutexamples/index.html" target="_blank" rel="noopener">人体部件检测示例</a></li>
</ul>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p>通过标注文件的方式提供了训练/验证/测试集的数据。整个数据集分为<code>50%</code>的训练/验证集以及<code>50%</code>的测试集。总共有<code>9963</code>幅图像，包含<code>24640</code>个标注对象，具体信息如下</p>
<ol>
<li>标注准则参考<a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/guidelines.html" target="_blank" rel="noopener">Annotation Guidelines</a></li>
<li>详细的训练/验证数据集的个数参考<a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/dbstats.html" target="_blank" rel="noopener">Database Statistics</a></li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   pascal-voc.py</span><br><span class="line">@time:   2020-01-19</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">from torchvision.datasets import VOCDetection</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def show_data():</span><br><span class="line">    dataset = VOCDetection(&apos;./data&apos;, year=&apos;2007&apos;, image_set=&apos;trainval&apos;)</span><br><span class="line"></span><br><span class="line">    for i in range(10):</span><br><span class="line">        img, target = dataset.__getitem__(i)</span><br><span class="line">        img = np.array(img)</span><br><span class="line"></span><br><span class="line">        print(img.shape)</span><br><span class="line">        print(target)</span><br><span class="line"></span><br><span class="line">        objects = target[&apos;annotation&apos;][&apos;object&apos;]</span><br><span class="line">        if isinstance(objects, list):</span><br><span class="line">            for obj in objects:</span><br><span class="line">                print(obj)</span><br><span class="line">                bndbox = obj[&apos;bndbox&apos;]</span><br><span class="line">                cv2.rectangle(img, (int(bndbox[&apos;xmin&apos;]), int(bndbox[&apos;ymin&apos;])),</span><br><span class="line">                              (int(bndbox[&apos;xmax&apos;]), int(bndbox[&apos;ymax&apos;])), (0, 255, 0), thickness=1)</span><br><span class="line">                cv2.putText(img, obj[&apos;name&apos;], (int(bndbox[&apos;xmin&apos;]), int(bndbox[&apos;ymin&apos;])),</span><br><span class="line">                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))</span><br><span class="line">        elif isinstance(objects, dict):</span><br><span class="line">            bndbox = objects[&apos;bndbox&apos;]</span><br><span class="line">            cv2.rectangle(img, (int(bndbox[&apos;xmin&apos;]), int(bndbox[&apos;ymin&apos;])),</span><br><span class="line">                          (int(bndbox[&apos;xmax&apos;]), int(bndbox[&apos;ymax&apos;])), (0, 255, 0), thickness=1)</span><br><span class="line">            cv2.putText(img, objects[&apos;name&apos;], (int(bndbox[&apos;xmin&apos;]), int(bndbox[&apos;ymin&apos;])),</span><br><span class="line">                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))</span><br><span class="line">        else:</span><br><span class="line">            pass</span><br><span class="line"></span><br><span class="line">        cv2.imshow(target[&apos;annotation&apos;][&apos;filename&apos;], img)</span><br><span class="line">        cv2.waitKey(0)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    show_data()</span><br></pre></td></tr></table></figure>
<p><img src="/img-dataset/voc-2007/voc-samples.png" alt></p>
<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>训练相关</p>
<ul>
<li>训练/验证数据集下载：<a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar" target="_blank" rel="noopener">training/validation data</a></li>
<li>工具包代码（<code>Matlab</code>版本）及开发文档：<a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCdevkit_08-Jun-2007.tar" target="_blank" rel="noopener">development kit code and documentation</a></li>
<li>单独下载的开发文档：<a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/devkit_doc_07-Jun-2007.pdf" target="_blank" rel="noopener">PDF documentation</a></li>
</ul>
<p>测试相关</p>
<ul>
<li>测试数据集（含标注）下载：<a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/index.html" target="_blank" rel="noopener">annotated test data</a></li>
<li>单独的标注信息下载：<a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtestnoimgs_06-Nov-2007.tar" target="_blank" rel="noopener">annotation only</a></li>
</ul>
<h2 id="解析标注数据"><a href="#解析标注数据" class="headerlink" title="解析标注数据"></a>解析标注数据</h2><p>参考：<a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/python/[python]%E8%AF%BB%E5%8F%96XML%E6%96%87%E4%BB%B6.html" target="_blank" rel="noopener">[python]读取XML文件</a></p>
<p><code>VOC</code>数据集的图像保存在文件夹<code>JPEGImages</code>中，标注数据保存在<code>Annotations</code>中</p>
<p>编写如下代码解析标注数据，将训练/验证/测试数据从原图像中提取出来</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: zj</span><br><span class="line">@file:   batch_xml.py</span><br><span class="line">@time:   2019-12-07</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import cv2</span><br><span class="line">import os</span><br><span class="line">import xml.etree.cElementTree as ET</span><br><span class="line"></span><br><span class="line">train_xml_dir = &apos;/home/zj/data/PASCAL-VOC/2007/train/Annotations&apos;</span><br><span class="line">train_jpeg_dir = &apos;/home/zj/data/PASCAL-VOC/2007/train/JPEGImages&apos;</span><br><span class="line"></span><br><span class="line">test_xml_dir = &apos;/home/zj/data/PASCAL-VOC/2007/test/Annotations&apos;</span><br><span class="line">test_jpeg_dir = &apos;/home/zj/data/PASCAL-VOC/2007/test/JPEGImages&apos;</span><br><span class="line"></span><br><span class="line"># 标注图像保存路径</span><br><span class="line">train_imgs_dir = &apos;/home/zj/data/PASCAL-VOC/2007/train_imgs&apos;</span><br><span class="line">test_imgs_dir = &apos;/home/zj/data/PASCAL-VOC/2007/test_imgs&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parse_xml(xml_path):</span><br><span class="line">    tree = ET.ElementTree(file=xml_path)</span><br><span class="line">    root = tree.getroot()</span><br><span class="line"></span><br><span class="line">    img_name = &apos;&apos;</span><br><span class="line">    obj_list = list()</span><br><span class="line">    bndbox_list = list()</span><br><span class="line"></span><br><span class="line">    # 遍历根节点下所有节点，查询文件名和目标坐标</span><br><span class="line">    for child_node in root:</span><br><span class="line">        if &apos;filename&apos;.__eq__(child_node.tag):</span><br><span class="line">            img_name = child_node.text</span><br><span class="line">        if &apos;object&apos;.__eq__(child_node.tag):</span><br><span class="line">            obj_name = &apos;&apos;</span><br><span class="line">            for obj_node in child_node:</span><br><span class="line">                if &apos;name&apos;.__eq__(obj_node.tag):</span><br><span class="line">                    obj_name = obj_node.text</span><br><span class="line">                if &apos;bndbox&apos;.__eq__(obj_node.tag):</span><br><span class="line">                    node_bndbox = obj_node</span><br><span class="line"></span><br><span class="line">                    node_xmin = node_bndbox[0]</span><br><span class="line">                    node_ymin = node_bndbox[1]</span><br><span class="line">                    node_xmax = node_bndbox[2]</span><br><span class="line">                    node_ymax = node_bndbox[3]</span><br><span class="line"></span><br><span class="line">                    obj_list.append(obj_name)</span><br><span class="line">                    bndbox_list.append((</span><br><span class="line">                        int(node_xmin.text), int(node_ymin.text), int(node_xmax.text), int(node_ymax.text)))</span><br><span class="line"></span><br><span class="line">    return img_name, obj_list, bndbox_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def batch_parse(xml_dir, jpeg_dir, imgs_dir):</span><br><span class="line">    xml_list = os.listdir(xml_dir)</span><br><span class="line">    jepg_list = os.listdir(jpeg_dir)</span><br><span class="line"></span><br><span class="line">    for xml_name in xml_list:</span><br><span class="line">        xml_path = os.path.join(xml_dir, xml_name)</span><br><span class="line">        img_name, obj_list, bndbox_list = parse_xml(xml_path)</span><br><span class="line">        print(img_name, obj_list, bndbox_list)</span><br><span class="line"></span><br><span class="line">        if img_name in jepg_list:</span><br><span class="line">            img_path = os.path.join(jpeg_dir, img_name)</span><br><span class="line">            src = cv2.imread(img_path)</span><br><span class="line">            for i in range(len(obj_list)):</span><br><span class="line">                obj_name = obj_list[i]</span><br><span class="line">                bndbox = bndbox_list[i]</span><br><span class="line"></span><br><span class="line">                obj_dir = os.path.join(imgs_dir, obj_name)</span><br><span class="line">                if not os.path.exists(obj_dir):</span><br><span class="line">                    os.mkdir(obj_dir)</span><br><span class="line">                obj_path = os.path.join(obj_dir, &apos;%s-%s-%d-%d-%d-%d.png&apos; % (</span><br><span class="line">                    img_name, obj_name, bndbox[0], bndbox[1], bndbox[2], bndbox[3]))</span><br><span class="line"></span><br><span class="line">                res = src[bndbox[1]:bndbox[3], bndbox[0]:bndbox[2]]</span><br><span class="line">                cv2.imwrite(obj_path, res)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    batch_parse(train_xml_dir, train_jpeg_dir, train_imgs_dir)</span><br><span class="line">    batch_parse(test_xml_dir, test_jpeg_dir, test_imgs_dir)</span><br></pre></td></tr></table></figure>
<p>通过解析<code>XML</code>文件，获取图像名以及标注的目标名和边界框数据；通过<code>OpenCV</code>读取图像，截取图像后保存在指定类别文件夹</p>
<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p>如果利用了<code>VOC 2007</code>数据，可以引用（<code>citation</code>）以下参考信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@misc&#123;pascal-voc-2007,</span><br><span class="line">	author = &quot;Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.&quot;,</span><br><span class="line">	title = &quot;The &#123;PASCAL&#125; &#123;V&#125;isual &#123;O&#125;bject &#123;C&#125;lasses &#123;C&#125;hallenge 2007 &#123;(VOC2007)&#125; &#123;R&#125;esults&quot;,</span><br><span class="line">	howpublished = &quot;http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html&quot;&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据</category>
        <category>代码库</category>
        <category>数据集</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
        <tag>pascal voc</tag>
        <tag>xml</tag>
      </tags>
  </entry>
  <entry>
    <title>[ubuntu 18.04]重装系统小结</title>
    <url>/posts/e70eeac0.html</url>
    <content><![CDATA[<p>原先笔记本自带的是<code>Win10</code>系统，想着日常开发中更常用的是<code>Linux</code>环境，所以重装了<code>Ubuntu</code>。之前用的是<code>16.04</code>版本，用了也快一年了，电脑里面的东西攒的挺多的，而且现在也都快<code>2020</code>了，所以打算重装<code>Ubuntu 18.04</code>版本，小结重装<code>Ubuntu</code>系统后相关环境配置</p><a id="more"></a>
<p><img src="/imgs/重装系统小结/screen.png" alt></p>
<h2 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a>系统配置</h2><h3 id="镜像源"><a href="#镜像源" class="headerlink" title="镜像源"></a>镜像源</h3><p>首先是替换阿里云镜像源，参考：<a href="https://zj-linux-guide.readthedocs.io/zh_CN/latest/tool-install-configure/[Ali%20mirror]]%E6%9B%B4%E6%8D%A2%E5%9B%BD%E5%86%85%E6%BA%90/" target="_blank" rel="noopener">[Ali mirror]更换国内源</a></p>
<p>调用<code>apt</code>命令更新并安装常用的软件包和库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get upgrade</span><br><span class="line">$ sudo apt-get install gcc g++ build_essential cmake git vim</span><br></pre></td></tr></table></figure>
<h3 id="输入法"><a href="#输入法" class="headerlink" title="输入法"></a>输入法</h3><p>系统安装设置中文时自动安装了输入法，不过效果不咋的，重装了<code>Google-Pinyin</code></p>
<h3 id="Nvidia驱动"><a href="#Nvidia驱动" class="headerlink" title="Nvidia驱动"></a>Nvidia驱动</h3><p>之前比较推崇手动安装<code>Nvidia</code>驱动，不过这一次发现可以通过工具安装，更加方便快捷，参考<a href="https://zj-linux-guide.readthedocs.io/zh_CN/latest/tool-install-configure/[Ubuntu%2018.04]PPA%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85Nvidia%E9%A9%B1%E5%8A%A8/" target="_blank" rel="noopener">[Ubuntu 18.04]PPA方式安装Nvidia驱动</a></p>
<h3 id="系统美化"><a href="#系统美化" class="headerlink" title="系统美化"></a>系统美化</h3><p><code>Ubuntu 18.04</code>默认使用<code>GNome</code>桌面，主要美化<code>4</code>个部分：</p>
<ol>
<li>主题</li>
<li>图标</li>
<li>任务栏</li>
<li>壁纸</li>
</ol>
<p>参考：<a href="https://zj-linux-guide.readthedocs.io/zh_CN/latest/tool-install-configure/[Ubuntu%2018.04]%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96/" target="_blank" rel="noopener">[Ubuntu 18.04]桌面美化</a></p>
<h2 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h2><p>主要完成日常编辑、<code>Python、C++、NodeJS、JAVA</code>环境配置</p>
<h3 id="Python环境"><a href="#Python环境" class="headerlink" title="Python环境"></a>Python环境</h3><ul>
<li><p>安装<code>Anaconda</code>工具包，替换国内镜像源能够加速安装，参考：<a href="https://vscode-guide.readthedocs.io/zh_CN/latest/anaconda/%E9%85%8D%E7%BD%AE%E5%9B%BD%E5%86%85%E9%95%9C%E5%83%8F%E6%BA%90/" target="_blank" rel="noopener">配置国内镜像源</a></p>
</li>
<li><p>安装<code>PyCharm</code></p>
</li>
</ul>
<h3 id="C-环境"><a href="#C-环境" class="headerlink" title="C++环境"></a>C++环境</h3><ul>
<li>安装<code>CMake</code>（<code>apt</code>安装的<code>cmake</code>版本过低，需要下源码重新安装，参考<a href="https://zj-linux-guide.readthedocs.io/zh_CN/latest/tool-install-configure/CMake%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">CMake安装</a></li>
<li>安装<code>CLion</code></li>
</ul>
<h3 id="JAVA环境"><a href="#JAVA环境" class="headerlink" title="JAVA环境"></a>JAVA环境</h3><ul>
<li>配置<code>JDK</code>，参考<a href="https://zj-linux-guide.readthedocs.io/zh_CN/latest/tool-install-configure/Java%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">Java安装</a></li>
<li>安装<code>IntelliJ IDEA</code></li>
</ul>
<h3 id="JS环境"><a href="#JS环境" class="headerlink" title="JS环境"></a>JS环境</h3><ul>
<li>安装<code>NodeJS</code></li>
</ul>
<h3 id="其他工具"><a href="#其他工具" class="headerlink" title="其他工具"></a>其他工具</h3><ul>
<li><code>Chrome</code>：虽然系统自带了<code>FireFox</code>，不过更常用的还是<code>Chrome</code></li>
<li><code>VSCode</code>：最方便的编辑工具</li>
<li><code>MindMaster</code>：思维导图。官网：<a href="https://www.edrawsoft.cn/mindmaster/" target="_blank" rel="noopener">MindMaster</a></li>
<li><code>EDraw</code>：国产绘图神器，没想到还有<code>Linux</code>版本。官网：<a href="https://www.edrawsoft.cn/lp/edraw.html" target="_blank" rel="noopener">亿图图示</a></li>
</ul>
<h2 id="虚拟机和容器"><a href="#虚拟机和容器" class="headerlink" title="虚拟机和容器"></a>虚拟机和容器</h2><h3 id="VMWare"><a href="#VMWare" class="headerlink" title="VMWare"></a>VMWare</h3><p>虽然在<code>Linux</code>环境下开发，但是有时候还是需要在<code>Windows</code>下操作</p>
<p><code>VMWare</code>的安装还挺多坑的，参考<a href="https://zj-linux-guide.readthedocs.io/zh_CN/latest/tool-install-configure/[Ubuntu%2018.04]VMware%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">[Ubuntu 18.04]VMware安装</a></p>
<h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><p><code>Docker</code>是目前最热门的容器工具，几乎所有软件都可以通过<code>Docker</code>安装和配置</p>
<ul>
<li><code>Docker</code>安装：<a href="https://containerization-automation.readthedocs.io/zh_CN/latest/docker/basic/%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">安装</a></li>
<li>阿里云加速：<a href="https://containerization-automation.readthedocs.io/zh_CN/latest/docker/basic/[Aliyun]%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F/" target="_blank" rel="noopener">[Aliyun]镜像加速</a></li>
<li>非<code>root</code>登录/开机自启动：<a href="https://containerization-automation.readthedocs.io/zh_CN/latest/docker/basic/%E5%8F%AF%E9%80%89%E8%AE%BE%E7%BD%AE/" target="_blank" rel="noopener">可选设置</a></li>
</ul>
<p>之前也学习了通过<code>Docker</code>配置软件，当前使用的有：</p>
<ol>
<li><code>WeChat</code>：<a href="https://containerization-automation.readthedocs.io/zh_CN/latest/docker/gui/[Docker][deepin-wine]%E5%BE%AE%E4%BF%A1%E8%BF%90%E8%A1%8C/" target="_blank" rel="noopener">[Docker][deepin-wine]微信运行</a></li>
<li><code>Tim</code>：<a href="https://containerization-automation.readthedocs.io/zh_CN/latest/docker/gui/[Docker][deepin-wine]TIM%E8%BF%90%E8%A1%8C/" target="_blank" rel="noopener">[Docker][deepin-wine]TIM运行</a></li>
<li><code>Thunder</code>：<a href="https://containerization-automation.readthedocs.io/zh_CN/latest/docker/gui/[Docker][deepin-wine]%E8%BF%85%E9%9B%B7%E8%BF%90%E8%A1%8C/" target="_blank" rel="noopener">[Docker][deepin-wine]迅雷运行</a></li>
<li><code>WPS</code>：包含了<code>word/excel/ppt/pdf</code>，完美替换<code>libreoffice</code>，参考<a href="https://containerization-automation.readthedocs.io/zh_CN/latest/docker/gui/[Docker][Ubuntu]WPS%E8%BF%90%E8%A1%8C/" target="_blank" rel="noopener">[Docker][Ubuntu]WPS运行</a></li>
<li><code>Jenkins</code>：<a href="https://www.zhujian.tech/posts/202ee452.html">在Docker中运行Jenkins</a></li>
<li><code>GitLab</code>：<a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/platform/[Docker]GitLab%E4%BD%BF%E7%94%A8/" target="_blank" rel="noopener">[Docker]GitLab使用</a></li>
<li><code>Nginx</code>：<a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/nginx/docker%E5%AE%89%E8%A3%85nginx/" target="_blank" rel="noopener">docker安装nginx</a></li>
</ol>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><img src="/imgs/重装系统小结/Ubuntu&#32;18.04.png" alt></p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>[Jenkins]手动设置私钥</title>
    <url>/posts/c343c930.html</url>
    <content><![CDATA[<p>需要在<code>Jenkins</code>操作完成后上传代码到另一个网站的仓库，所以需要手动设置<code>credential</code></p><h2 id="自动验证"><a href="#自动验证" class="headerlink" title="自动验证"></a>自动验证</h2><a id="more"></a>
<p>在<code>Jenkins</code>中添加<code>SSH Username with private key</code>类型的凭据后，就可以在配置git仓库的时候设置</p>
<p><img src="/imgs/jenkins-credentials/credentials.png" alt></p>
<p>之后运行过程中<code>Jenkins</code>会自动通过该凭据进行<code>ssh</code>验证，下载<code>git</code>代码</p>
<h2 id="手动验证"><a href="#手动验证" class="headerlink" title="手动验证"></a>手动验证</h2><p>在<code>Freestyle</code>工程和<code>Pipeline</code>工程中进行配置如下</p>
<h3 id="Freestyle"><a href="#Freestyle" class="headerlink" title="Freestyle"></a>Freestyle</h3><p>新建<code>Freestyle</code>工程，在<code>配置 -&gt; 构建环境</code>类别中选择<code>Use secret text(s) or files(s)</code>，新增一个<code>SSH User Private Key</code></p>
<p><img src="/imgs/jenkins-credentials/freestyle-env.png" alt></p>
<p>在<code>Key文件变量</code>中设置一个变量名，在<code>凭据</code>中选定之前设置的私钥</p>
<p>在构建环节，选择脚本执行，在操作时将私钥写入<code>.ssh</code>文件夹并设置文件权限</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm ~/.ssh/id_rsa</span><br><span class="line">cat $TTE &gt; ~/.ssh/id_rsa</span><br><span class="line">chmod 600 ~/.ssh/id_rsa</span><br><span class="line"></span><br><span class="line">git clone git@148.xx.xxx.x:/data/repositories/blogs.git</span><br><span class="line"></span><br><span class="line">rm ~/.ssh/id_rsa</span><br></pre></td></tr></table></figure>
<h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>参考：<a href="https://jenkins.io/zh/doc/book/pipeline/jenkinsfile/#for-secret-text-usernames-and-passwords-and-secret-files" target="_blank" rel="noopener">Secret 文本，带密码的用户名，Secret 文件</a></p>
<p>新建<code>Pipeline</code>工程，在<code>配置 -&gt; 流水线</code>中选择脚本操作，实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">   agent any</span><br><span class="line"></span><br><span class="line">  environment &#123;</span><br><span class="line">    id_rsa=credentials(&apos;fa1b8cd3-cxxx-4xxx-axx-2xxxa8dc5b4a&apos;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">   stages &#123;</span><br><span class="line">      stage(&apos;Hello&apos;) &#123;</span><br><span class="line">         steps &#123;</span><br><span class="line">            echo &apos;Hello World&apos;</span><br><span class="line">            sh &apos;&apos;&apos;</span><br><span class="line">            git --version</span><br><span class="line">            cat $&#123;id_rsa&#125; &gt; ~/.ssh/zj_id_rsa</span><br><span class="line">            chmod 600 ~/.ssh/zj_id_rsa</span><br><span class="line"></span><br><span class="line">            git clone ...        </span><br><span class="line">            &apos;&apos;&apos;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>设置环境变量<code>id_rsa</code>，调用函数<code>credentials</code>提取已定义的私钥（标识号可在凭证中查询）</p>
<p><img src="/imgs/jenkins-credentials/unique-label.png" alt></p>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>Git工作流实践</title>
    <url>/posts/c7ee2f15.html</url>
    <content><![CDATA[<p>在好多个工程上都使用了<code>git</code>，随着时间的拉长会发现工程的提交历史和分支管理很混乱，所以希望能够有一套规范的<code>git</code>使用流程来更好的实现版本管理</p><a id="more"></a>
<p>参考<a href="https://blog.csdn.net/qq_32452623/article/details/78905181" target="_blank" rel="noopener">Git三大特色之WorkFlow(工作流)</a>，学习了目前最流行的三种<code>git</code>工作流</p>
<ul>
<li><a href="https://nvie.com/posts/a-successful-git-branching-model/" target="_blank" rel="noopener">git flow</a></li>
<li><a href="http://scottchacon.com/2011/08/31/github-flow.html" target="_blank" rel="noopener">github flow</a></li>
<li><a href="https://docs.gitlab.com/ee/topics/gitlab_flow.html" target="_blank" rel="noopener">gitlab flow</a></li>
</ul>
<h2 id="git-flow"><a href="#git-flow" class="headerlink" title="git flow"></a>git flow</h2><p>翻译地址：<a href="https://www.zhujian.tech/posts/aae96086.html#more">[译]A successful Git branching model</a></p>
<p><code>git-flow</code>是最早发布的<code>git</code>工作流，其思路简洁清晰，通过<code>5</code>种分支类型即可管理整个工程</p>
<ul>
<li><code>master</code>：主分支。保存后续生产环节的代码</li>
<li><code>develop</code>：开发分支。当实现功能足以反映下一版本的状态时，发布给<code>release</code>分支</li>
<li><code>feature</code>：特征分支。从<code>develop</code>分支<code>fork</code>，开发某个新特性，完成后合并回<code>develop</code></li>
<li><code>release</code>：发布分支（或称为版本分支）。从<code>develop</code>分支<code>fork</code>，执行发布前的准备，包括小错误修复、版本元数据更新，最后合并到<code>master</code>和<code>develop</code>分支</li>
<li><code>hotfix</code>：热修复分支。从<code>master</code>分支<code>fork</code>，修复实时生产环节中出现的错误，完成后合并回<code>master</code>和<code>develop</code>分支</li>
</ul>
<p>其中前两种分支属于主分支，长期存在于中间仓库中，后<code>3</code>种分支属于支持分支，完成所需要的目的后即可销毁</p>
<p><img src="../imgs/git-workflow/git-model@2x.png" alt></p>
<h2 id="github-flow"><a href="#github-flow" class="headerlink" title="github flow"></a>github flow</h2><p>翻译地址：<a href="https://www.zhujian.tech/posts/a20843e9.html#more">[译]GitHub Flow</a></p>
<p><code>github-flow</code>是<code>git-flow</code>的一个补充，提供了更加简单的工作流程。<code>github-flow</code>适用于持续部署的工程，直接将最新特征部署到<code>master</code>分支上，不再操作<code>develop</code>分支；同时通过<code>CI&amp;CD</code>的使用，不再需要额外操作<code>release</code>分支和<code>hotfix</code>分支。<code>github</code>还结合了推送请求（<code>pull request</code>）功能，在合并<code>feature</code>分支之前通过<code>PR</code>请求其他成员对代码进行检查</p>
<ul>
<li><code>master</code>分支中的任何东西都是可部署的</li>
<li>要开发新的东西，从<code>master</code>分支中创建一个描述性命名的分支(比如：<code>new-oauth2-scopes</code>)</li>
<li>在本地提交到该分支，并定期将您的工作推送到服务器上的同一个命名分支</li>
<li>当您需要反馈或帮助，或者您认为分支已经准备好合并时，可以提交一个推送请求（<code>PR</code>）</li>
<li>在其他人审阅并签署了该功能后，可以将其合并到<code>master</code>中</li>
<li>一旦它被合并并推送到<code>主服务器</code>，就可以并且应该立即部署</li>
</ul>
<h2 id="gitlab-flow"><a href="#gitlab-flow" class="headerlink" title="gitlab flow"></a>gitlab flow</h2><p>翻译地址：<a href="https://www.zhujian.tech/posts/b35b83bc.html#more">[译]Introduction to GitLab Flow</a></p>
<p><code>gitlab-flow</code>出现的时间最晚，其内容更像是对前两者的补充，通过集成<code>git</code>工作流和问题跟踪系统，提供更加有序的关于环境、部署、发布和问题集成的管理</p>
<h2 id="当前实践"><a href="#当前实践" class="headerlink" title="当前实践"></a>当前实践</h2><p>以上<code>3</code>种工作流各有所长，提供了不同工作环境下的分支策略和发布管理实践。结合自身实际需求，基于上述方法针对不同的项目进行调整</p>
<p>当前操作的工程大体分为三类：</p>
<ol>
<li>文档工程</li>
<li>网站工程</li>
<li>代码库工程</li>
</ol>
<h3 id="文档工程"><a href="#文档工程" class="headerlink" title="文档工程"></a>文档工程</h3><p>文档工程指的是仓库存储的仅是文档以及文档生成框架，比如<a href="https://github.com/zjZSTU/wall-guide" target="_blank" rel="noopener">zjZSTU/wall-guide</a>和<a href="https://github.com/zjZSTU/linux-guide" target="_blank" rel="noopener">zjZSTU/linux-guide</a>，通常这些文档工程会结合<code>readthedocs</code>进行<code>CI&amp;CD</code>的实现；有些文档工程会额外包含一些代码文件，比如<a href="https://github.com/zjZSTU/Containerization-Automation" target="_blank" rel="noopener">zjZSTU/Containerization-Automation</a>，里面包含了多个生成<code>docker</code>镜像的<code>dockerfiles</code>文件以及相关的配置文件</p>
<p>主要参考<code>GitHub Flow</code>，实现如下的分支策略：</p>
<ol>
<li>文档可直接发布到<code>master</code>分支</li>
<li>要更新文档生成框架，需要创建特征分支，完成更新后再合并到<code>master</code>分支（<strong>注意：合并前需要标记<code>master</code>分支，注明之前使用的版本</strong>）</li>
<li>每次添加新的代码功能，需要创建特征分支，完成更新后再合并到<code>master</code>分支</li>
<li>如果需要修复已有的代码错误，直接在<code>master</code>分支上操作</li>
</ol>
<h3 id="网站工程"><a href="#网站工程" class="headerlink" title="网站工程"></a>网站工程</h3><p>当前网站工程指的是基于<code>Hexo</code>的博客网站使用，博客网站主要包含<code>3</code>方面内容：</p>
<ol>
<li>网站框架</li>
<li>主题</li>
<li>文档</li>
</ol>
<p>通常主题会在另一个仓库中管理，当前仓库中仅包含网站框架以及文档，同时还会包含<code>CI</code>配置文件</p>
<p>网上推荐的一种工作流比较简单：</p>
<ol>
<li>仅包含<code>master</code>和<code>dev</code>分支，其中<code>dev</code>分支存放工程源码，<code>master</code>分支存放编译后的<code>HTML</code>文件</li>
<li>每次上传到<code>dev</code>分支后触发<code>CI</code>工具进行编译，并发送给<code>master</code>分支</li>
<li><code>Web</code>服务器利用<code>master</code>分支进行网站发布</li>
</ol>
<p>在实际操作中发现并不是每次上传到<code>dev</code>分支的修改都有必要通过<code>CI</code>工具进行编译，比如<code>README.md</code>；同时，在测试、更新<code>CI</code>工具和网站生成工具时，过多的调试不利于之后<code>log</code>的查询</p>
<p>参考<code>Git Flow</code>和<code>Github Flow</code>，实现如下的分支策略：</p>
<ol>
<li><code>master</code>分支存放编译好的网站文件</li>
<li><code>dev</code>分支存放仓库源码</li>
<li>文档文件直接上传到<code>dev</code>分支（<em>区分是否需要编译，通过<code>CI</code>文件进行判断</em>）</li>
<li>要添加新的<code>CI</code>功能，需要创建特征分支，完成调试后再合并到<code>dev</code>分支</li>
<li>要更新网站生成框架，需要创建特征分支，完成调试后再合并到<code>dev</code>分支（<strong>注意：合并前需要标记<code>dev</code>分支，注明之前使用的版本</strong>）</li>
<li>修复<code>CI</code>配置文件或者网站配置文件错误，直接上传到<code>dev</code>分支</li>
</ol>
<h3 id="代码库工程"><a href="#代码库工程" class="headerlink" title="代码库工程"></a>代码库工程</h3><p>代码库工程是最常见的仓库类型，比如博客网站配套的主题仓库，<a href="https://github.com/zjZSTU/PyNet/tree/dev" target="_blank" rel="noopener">zjZSTU/PyNet</a>，<a href="https://github.com/zjZSTU/GraphLib/tree/dev" target="_blank" rel="noopener">zjZSTU/GraphLib</a>，里面不仅包含源代码，还有可能包含文档、图片、<code>CI</code>文件等等，对于个人操作而言，比较适用于<code>GitHub Flow</code>，通过快速的更新和迭代来完成开发</p>
]]></content>
      <categories>
        <category>版本控制</category>
        <category>规范</category>
        <category>workflow</category>
      </categories>
      <tags>
        <tag>git-flow</tag>
        <tag>gitlab-flow</tag>
        <tag>github-flow</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]Introduction to GitLab Flow</title>
    <url>/posts/b35b83bc.html</url>
    <content><![CDATA[<p>原文地址：<a href="https://docs.gitlab.com/ee/topics/gitlab_flow.html" target="_blank" rel="noopener">Introduction to GitLab Flow</a></p><blockquote>
<p>Git allows a wide variety of branching strategies and workflows. Because of this, many organizations end up with workflows that are too complicated, not clearly defined, or not integrated with issue tracking systems. Therefore, we propose GitLab flow as a clearly defined set of best practices. It combines feature-driven development and feature branches with issue tracking.</p>
</blockquote><a id="more"></a>

<p>Git允许多种分支策略和工作流。正因为如此，许多组织的工作流过于复杂，没有明确定义，或者没有与问题跟踪系统集成。因此，我们建议将gitlab-flow作为一组明确定义的最佳实践。它将<a href="https://en.wikipedia.org/wiki/Feature-driven_development" target="_blank" rel="noopener">特征驱动开发</a>和<a href="https://martinfowler.com/bliki/FeatureBranch.html" target="_blank" rel="noopener">特征分支</a>与问题跟踪结合起来</p>
<p><img src="/imgs/gitlab-flow/gitlab_flow.png" alt></p>
<blockquote>
<p>Organizations coming to Git from other version control systems frequently find it hard to develop a productive workflow. This article describes GitLab flow, which integrates the Git workflow with an issue tracking system. It offers a simple, transparent, and effective way to work with Git.</p>
</blockquote>
<p>从其他版本控制系统来到Git的组织经常发现很难开发出高效的工作流。本文描述了GitLab流程，它将Git工作流与问题跟踪系统集成在一起。它提供了使用Git的简单、透明和有效的方法</p>
<p><img src="/imgs/gitlab-flow/gitlab_flow_four_stages.png" alt></p>
<blockquote>
<p>When converting to Git, you have to get used to the fact that it takes three steps to share a commit with colleagues. Most version control systems have only one step: committing from the working copy to a shared server. In Git, you add files from the working copy to the staging area. After that, you commit them to your local repo. The third step is pushing to a shared remote repository. After getting used to these three steps, the next challenge is the branching model.</p>
</blockquote>
<p>在转换为Git后，您必须习惯于这样一个事实：与同事共享commit需要三个步骤。大多数版本控制系统只有一个步骤：从工作副本提交到共享服务器。在Git中，您可以将工作副本中的文件添加到临时区域。在那之后，你把它们交给你的本地仓库。第三步是推送到共享的远程存储库。在习惯了这三个步骤之后，下一个挑战是分支模型</p>
<p><img src="/imgs/gitlab-flow/gitlab_flow_messy_flow.png" alt></p>
<blockquote>
<p>Since many organizations new to Git have no conventions for how to work with it, their repositories can quickly become messy. The biggest problem is that many long-running branches emerge that all contain part of the changes. People have a hard time figuring out which branch has the latest code, or which branch to deploy to production. Frequently, the reaction to this problem is to adopt a standardized pattern such as Git flow and GitHub flow. We think there is still room for improvement. In this document, we describe a set of practices we call GitLab flow.</p>
</blockquote>
<p>由于许多刚接触Git的组织对于如何使用它没有约定，它们的存储库很快就会变得混乱。最大的问题是出现了许多长期运行的分支，这些分支都包含了部分更改。人们很难弄清楚哪个分支有最新的代码，或者哪个分支要部署到生产环境中。通常，对这个问题的反应是采用一个标准化的模式，比如<a href="https://nvie.com/posts/a-successful-git-branching-model/" target="_blank" rel="noopener">git-flow</a>和<a href="http://scottchacon.com/2011/08/31/github-flow.html" target="_blank" rel="noopener">github-flow</a>。我们认为还有改进的余地。在本文中，我们描述了一组称为gitlab-flow的实践</p>
<h2 id="Git-flow-and-its-problems"><a href="#Git-flow-and-its-problems" class="headerlink" title="Git flow and its problems"></a>Git flow and its problems</h2><p><img src="/imgs/gitlab-flow/gitlab_flow_gitdashflow.png" alt></p>
<blockquote>
<p>Git flow was one of the first proposals to use Git branches, and it has received a lot of attention. It suggests a master branch and a separate develop branch, as well as supporting branches for features, releases, and hotfixes. The development happens on the develop branch, moves to a release branch, and is finally merged into the master branch.</p>
</blockquote>
<p>Git流是最早使用Git分支的提议之一，因此它受到了广泛的关注。它建议一个主（master）分支和一个单独的开发（develop）分支，以及功能（feature）、版本（release）和热修复（hotfix）的支持分支。开发发生在develop分支上，移动到release分支，最后合并到master分支</p>
<blockquote>
<p>Git flow is a well-defined standard, but its complexity introduces two problems. The first problem is that developers must use the develop branch and not master. master is reserved for code that is released to production. It is a convention to call your default branch master and to mostly branch from and merge to this. Since most tools automatically use the master branch as the default, it is annoying to have to switch to another branch.</p>
</blockquote>
<p>git-flow是一个定义明确的标准，但是它的复杂性带来了两个问题。第一个问题是开发人员必须使用develop分支，而不是master。master用于保留生产环境代码。通常情况下会调用master作为默认分支，并且大多数分支将合并到这里。由于大多数工具自动使用master分支作为默认分支，因此不得不切换到另一个分支是很烦人的</p>
<blockquote>
<p>The second problem of Git flow is the complexity introduced by the hotfix and release branches. These branches can be a good idea for some organizations but are overkill for the vast majority of them. Nowadays, most organizations practice continuous delivery, which means that your default branch can be deployed. Continuous delivery removes the need for hotfix and release branches, including all the ceremony they introduce. An example of this ceremony is the merging back of release branches. Though specialized tools do exist to solve this, they require documentation and add complexity. Frequently, developers make mistakes such as merging changes only into master and not into the develop branch. The reason for these errors is that Git flow is too complicated for most use cases. For example, many projects do releases but don’t need to do hotfixes.</p>
</blockquote>
<p>git-flow的第二个问题是hotfix和release分支引入的复杂性。这些分支对一些组织来说可能是个好主意，但对绝大多数组织来说却是多余的。如今，大多数组织都实行持续交付（CD），这意味着可以部署您的默认分支。持续交付消除了对hotfix和release分支的需求，包括它们引入的所有仪式。这个仪式的一个例子是release分支的合并。尽管有专门的工具来解决这个问题，但是它们需要文档并增加复杂性。开发人员经常会犯一些错误，比如只将变更合并到master中，而不合并到develop分支中。这些错误的原因是git-flow对于大多数用例来说太复杂了。例如，许多项目都发布版本，但不需要做热修复</p>
<h2 id="GitHub-flow-as-a-simpler-alternative"><a href="#GitHub-flow-as-a-simpler-alternative" class="headerlink" title="GitHub flow as a simpler alternative"></a>GitHub flow as a simpler alternative</h2><p><img src="/imgs/gitlab-flow/gitlab_flow_github_flow.png" alt></p>
<blockquote>
<p>In reaction to Git flow, GitHub created a simpler alternative. GitHub flow has only feature branches and a master branch. This flow is clean and straightforward, and many organizations have adopted it with great success. Atlassian recommends a similar strategy, although they rebase feature branches. Merging everything into the master branch and frequently deploying means you minimize the amount of unreleased code, which is in line with lean and continuous delivery best practices. However, this flow still leaves a lot of questions unanswered regarding deployments, environments, releases, and integrations with issues. With GitLab flow, we offer additional guidance for these questions.</p>
</blockquote>
<p>作为对git-flow的反馈，GitHub创建了一个更简单的替代方案。<a href="https://guides.github.com/introduction/flow/index.html" target="_blank" rel="noopener">github-flow</a>只有特征（feature）分支和主（master）分支。这一流程简洁明了，许多组织已经非常成功地采用了它。Atlassian推荐一个<a href="https://www.atlassian.com/blog/git/simple-git-workflow-is-simple" target="_blank" rel="noopener">类似的策略</a>，尽管他们会重新设置feature分支。将所有内容合并到master分支并频繁部署意味着您将未发布代码的数量降至最低，这符合精益和持续交付的最佳实践。然而，这个流程仍然有许多关于部署、环境、发布和问题集成的问题没有得到回答。通过gitlab-flow，我们为这些问题提供了额外的指导</p>
<h2 id="Production-branch-with-GitLab-flow"><a href="#Production-branch-with-GitLab-flow" class="headerlink" title="Production branch with GitLab flow"></a>Production branch with GitLab flow</h2><p><img src="/imgs/gitlab-flow/gitlab_flow_production_branch.png" alt></p>
<p>gitlab-flow的生产分支</p>
<blockquote>
<p>GitHub flow assumes you can deploy to production every time you merge a feature branch. While this is possible in some cases, such as SaaS applications, there are many cases where this is not possible. One case is where you don’t control the timing of a release, for example, an iOS application that is released when it passes App Store validation. Another case is when you have deployment windows — for example, workdays from 10 AM to 4 PM when the operations team is at full capacity — but you also merge code at other times. In these cases, you can make a production branch that reflects the deployed code. You can deploy a new version by merging master into the production branch. If you need to know what code is in production, you can just checkout the production branch to see. The approximate time of deployment is easily visible as the merge commit in the version control system. This time is pretty accurate if you automatically deploy your production branch. If you need a more exact time, you can have your deployment script create a tag on each deployment. This flow prevents the overhead of releasing, tagging, and merging that happens with Git flow.</p>
</blockquote>
<p>gitHub-flow假设您可以在每次合并feature分支时部署到生产环境中。虽然这在某些情况下是可能的，例如SaaS应用程序，但在许多情况下这是不可能的。一种情况是，您不能控制发布的时间，例如，当一个iOS应用程序通过应用商店验证时，它就会被发布。另一种情况是，当您有部署窗口时，例如，当操作团队满负荷时，工作日从上午10点到下午4点，但您也可以在其他时间合并代码。在这些情况下，您可以创建一个反映部署代码的生产（production）分支。您可以通过将master合并到production分支中来部署新版本。如果您需要知道生产中有什么代码，您可以只签出production分支来查看。随着版本控制系统中的合并提交，部署的大致时间是很容易看到的。如果您自动部署production分支，这一次非常准确。如果您需要更准确的时间，可以让您的部署脚本在每个部署上创建一个标签。这个流程防止了git-flow发生的发布、标记和合并的开销</p>
<h2 id="Environment-branches-with-GitLab-flow"><a href="#Environment-branches-with-GitLab-flow" class="headerlink" title="Environment branches with GitLab flow"></a>Environment branches with GitLab flow</h2><p><img src="/imgs/gitlab-flow/gitlab_flow_environment_branches.png" alt></p>
<p>gitlab-flow的环境分支</p>
<blockquote>
<p>It might be a good idea to have an environment that is automatically updated to the master branch. Only, in this case, the name of this environment might differ from the branch name. Suppose you have a staging environment, a pre-production environment, and a production environment. In this case, deploy the master branch to staging. To deploy to pre-production, create a merge request from the master branch to the pre-production branch. Go live by merging the pre-production branch into the production branch. This workflow, where commits only flow downstream, ensures that everything is tested in all environments. If you need to cherry-pick a commit with a hotfix, it is common to develop it on a feature branch and merge it into master with a merge request. In this case, do not delete the feature branch yet. If master passes automatic testing, you then merge the feature branch into the other branches. If this is not possible because more manual testing is required, you can send merge requests from the feature branch to the downstream branches.</p>
</blockquote>
<p>拥有一个能够自动更新到master分支的环境可能是个好主意。仅在这种情况下，此环境的名称可能不同于分支名称。假设您有一个阶段（staging）环境、一个预生产（pre-production）环境和一个生产（production）环境。在这种情况下，将master分支部署到staging。要部署到pre-production，请创建从master分支到pre-production分支的合并请求。通过将pre-production分支合并到production分支来上线。这个工作流(提交只流向下游)确保在所有环境中测试一切。如果您需要实现一个hotfix提交，通常是在一个feature分支上开发它，并通过合并请求将其合并到master中。在这种情况下，暂时不要删除feature分支。如果master通过了自动测试，则可以将feature分支合并到其他分支中。如果因为需要更多的手动测试而无法做到这一点，您可以将合并请求从feature分支发送到下游分支</p>
<h2 id="Release-branches-with-GitLab-flow"><a href="#Release-branches-with-GitLab-flow" class="headerlink" title="Release branches with GitLab flow"></a>Release branches with GitLab flow</h2><p><img src="/imgs/gitlab-flow/gitlab_flow_release_branches.png" alt></p>
<p>gitlab-flow的发布分支</p>
<blockquote>
<p>You only need to work with release branches if you need to release software to the outside world. In this case, each branch contains a minor version, for example, 2-3-stable, 2-4-stable, etc. Create stable branches using master as a starting point, and branch as late as possible. By doing this, you minimize the length of time during which you have to apply bug fixes to multiple branches. After announcing a release branch, only add serious bug fixes to the branch. If possible, first merge these bug fixes into master, and then cherry-pick them into the release branch. If you start by merging into the release branch, you might forget to cherry-pick them into master, and then you’d encounter the same bug in subsequent releases. Merging into master and then cherry-picking into release is called an “upstream first” policy, which is also practiced by Google and Red Hat. Every time you include a bug fix in a release branch, increase the patch version (to comply with Semantic Versioning) by setting a new tag. Some projects also have a stable branch that points to the same commit as the latest released branch. In this flow, it is not common to have a production branch (or Git flow master branch).</p>
</blockquote>
<p>如果你需要向外界发布软件，你只需要使用发布（release）分支。在这种情况下，每个分支包含一个次要版本，例如，2-3-稳定、2-4-稳定等。以master为起点创建稳定的分支，并尽可能晚地执行分支操作。通过这样做，您可以最大限度地减少将修复的bug应用到多个分支的时间长度。在宣布release分支后，只能给分支添加严重的bug修复。如果可能的话，首先将这些bug修复合并到master中，然后将它们合并到release分支中。如果您从合并release分支开始，您可能会忘记将它们加入master，然后您会在后续的发布中遇到相同的错误。合并到master中，然后精选到release中被称为“上游优先”政策，这也是<a href="https://www.chromium.org/chromium-os/chromiumos-design-docs/upstream-first" target="_blank" rel="noopener">谷歌</a>和<a href="https://www.redhat.com/en/blog/a-community-for-using-openstack-with-red-hat-rdo" target="_blank" rel="noopener">红帽</a>的做法。每次在发布分支中包含bug修复时，通过设置新标签来增加补丁版本(以符合<a href="https://semver.org/" target="_blank" rel="noopener">语义版本控制</a>)。一些项目也有一个稳定的分支，指向与最新发布的分支相同的提交。在这个流程中，production分支(或git-flow master分支)并不常见</p>
<h2 id="Merge-pull-requests-with-GitLab-flow"><a href="#Merge-pull-requests-with-GitLab-flow" class="headerlink" title="Merge/pull requests with GitLab flow"></a>Merge/pull requests with GitLab flow</h2><p><img src="/imgs/gitlab-flow/gitlab_flow_mr_inline_comments.png" alt></p>
<p>gitlab-flow的合并/拉取请求</p>
<blockquote>
<p>Merge or pull requests are created in a Git management application. They ask an assigned person to merge two branches. Tools such as GitHub and Bitbucket choose the name “pull request” since the first manual action is to pull the feature branch. Tools such as GitLab and others choose the name “merge request” since the final action is to merge the feature branch. In this article, we’ll refer to them as merge requests.</p>
</blockquote>
<p>合并或拉取请求是在Git管理应用程序中创建的。他们要求指定的人合并两个分支。GitHub和Bitbucket等工具选择名称“拉取请求”（pull request），因为第一个手动操作是拉取特征分支。GitLab等工具称之为“合并请求”（merge request），因为最终的操作是合并特征分支。在本文中，我们将它们称为合并请求</p>
<blockquote>
<p>If you work on a feature branch for more than a few hours, it is good to share the intermediate result with the rest of the team. To do this, create a merge request without assigning it to anyone. Instead, mention people in the description or a comment, for example, “/cc @mark @susan.” This indicates that the merge request is not ready to be merged yet, but feedback is welcome. Your team members can comment on the merge request in general or on specific lines with line comments. The merge request serves as a code review tool, and no separate code review tools should be needed. If the review reveals shortcomings, anyone can commit and push a fix. Usually, the person to do this is the creator of the merge request. The diff in the merge request automatically updates when new commits are pushed to the branch.</p>
</blockquote>
<p>如果您在一个feature分支上工作了几个小时以上，最好与团队的其他成员共享中间结果。为此，请创建一个合并请求，而不是直接将其分配给其他人。相反，在描述或评论中提及人，例如，“/cc @mark @susan”。这表示合并请求尚未准备好合并，但欢迎反馈。您的团队成员可以对合并请求进行一般性评论，也可以对带有行评论的特定行进行评论。合并请求用作代码审查时不需要单独的代码审查工具。如果审查发现了缺点，任何人都可以提交并推动解决方案。通常要这样做的人是合并请求的创建者。当新提交被推送到分支时，合并请求中的差异会自动更新</p>
<blockquote>
<p>When you are ready for your feature branch to be merged, assign the merge request to the person who knows most about the codebase you are changing. Also, mention any other people from whom you would like feedback. After the assigned person feels comfortable with the result, they can merge the branch. If the assigned person does not feel comfortable, they can request more changes or close the merge request without merging.</p>
</blockquote>
<p>当您准备好要合并的特征分支时，请将合并请求分配给最了解您正在更改的代码库的人。此外，提及你希望得到反馈的任何其他人。当被指派的人对结果感到满意后，他们可以合并分支。如果被分配的人感觉不舒服，他们可以请求更多更改或关闭合并请求而不合并</p>
<blockquote>
<p>In GitLab, it is common to protect the long-lived branches, e.g., the master branch, so that most developers can’t modify them. So, if you want to merge into a protected branch, assign your merge request to someone with maintainer permissions.</p>
</blockquote>
<p>在GitLab中，保护长期存在的分支是很常见的，例如master分支，这样<a href="https://docs.gitlab.com/ee/user/permissions.html" target="_blank" rel="noopener">大多数开发人员就不能修改它们</a>。因此，如果您想合并到受保护的分支，请将合并请求分配给具有维护者权限的人</p>
<blockquote>
<p>After you merge a feature branch, you should remove it from the source control software. In GitLab, you can do this when merging. Removing finished branches ensures that the list of branches shows only work in progress. It also ensures that if someone reopens the issue, they can use the same branch name without causing problems.</p>
</blockquote>
<p>合并feature分支后，应将其从源代码管理软件中删除。在GitLab中，合并时可以这样做。移除已完成的分支可确保分支列表仅显示正在进行的工作。它还确保了如果有人重新打开问题，他们可以使用相同的分支名称而不会造成问题</p>
<blockquote>
<p>Note: When you reopen an issue you need to create a new merge request.</p>
</blockquote>
<p><strong>注意：当你重新打开一个问题的时候，你需要重建一个新的合并请求</strong></p>
<p><img src="/imgs/gitlab-flow/gitlab_flow_remove_checkbox.png" alt></p>
<h2 id="Issue-tracking-with-GitLab-flow"><a href="#Issue-tracking-with-GitLab-flow" class="headerlink" title="Issue tracking with GitLab flow"></a>Issue tracking with GitLab flow</h2><p><img src="/imgs/gitlab-flow/gitlab_flow_merge_request.png" alt></p>
<blockquote>
<p>GitLab flow is a way to make the relation between the code and the issue tracker more transparent.</p>
</blockquote>
<p>gitlab-flow是一种使代码和问题跟踪器之间的关系更加透明的方法</p>
<blockquote>
<p>Any significant change to the code should start with an issue that describes the goal. Having a reason for every code change helps to inform the rest of the team and to keep the scope of a feature branch small. In GitLab, each change to the codebase starts with an issue in the issue tracking system. If there is no issue yet, create the issue, as long as the change will take a significant amount of work, i.e., more than 1 hour. In many organizations, raising an issue is part of the development process because they are used in sprint planning. The issue title should describe the desired state of the system. For example, the issue title “As an administrator, I want to remove users without receiving an error” is better than “Admin can’t remove users.”</p>
</blockquote>
<p>对代码的任何重大更改都应该从描述目标的问题开始。每一次代码变更都有一个原因，这有助于通知团队的其他成员，并保持一个小范围的feature分支。在GitLab中，对代码库的每次更改都从问题跟踪系统中的一个问题开始。如果还没有问题，创建问题，只要更改需要大量工作，即超过1小时即可。在许多组织中，提出问题是开发过程的一部分，因为它们用于冲刺规划。问题标题应该描述系统的期望状态。例如，问题标题“作为管理员，我希望在没有收到错误的情况下删除用户”优于“管理员不能删除用户”</p>
<blockquote>
<p>When you are ready to code, create a branch for the issue from the master branch. This branch is the place for any work related to this change.</p>
</blockquote>
<p>当准备好编程后，从master分支为问题创建一个分支。该分支是与此变更相关的任何工作的场所</p>
<blockquote>
<p>Note: The name of a branch might be dictated by organizational standards.</p>
</blockquote>
<p><strong>注意：此分支名由组织标准决定</strong></p>
<blockquote>
<p>When you are done or want to discuss the code, open a merge request. A merge request is an online place to discuss the change and review the code.</p>
</blockquote>
<p>当您完成或想要讨论代码时，请打开合并请求。合并请求是一个讨论变更和审查代码的在线场所</p>
<blockquote>
<p>If you open the merge request but do not assign it to anyone, it is a “Work In Progress” merge request. These are used to discuss the proposed implementation but are not ready for inclusion in the master branch yet. Start the title of the merge request with [WIP] or WIP: to prevent it from being merged before it’s ready.</p>
</blockquote>
<p>如果您打开合并请求，但没有将其分配给任何人，则它是一个“正在进行中”的合并请求。这些用于讨论提议的实施，但是还没有准备好包含在master分支中。用<code>[WIP]</code>或<code>WIP:</code>开始合并请求的标题，以防止在准备好之前将其合并</p>
<blockquote>
<p>When you think the code is ready, assign the merge request to a reviewer. The reviewer can merge the changes when they think the code is ready for inclusion in the master branch. When they press the merge button, GitLab merges the code and creates a merge commit that makes this event easily visible later on. Merge requests always create a merge commit, even when the branch could be merged without one. This merge strategy is called “no fast-forward” in Git. After the merge, delete the feature branch since it is no longer needed. In GitLab, this deletion is an option when merging.</p>
</blockquote>
<p>当您认为代码准备就绪时，请将合并请求分配给审阅者。当审阅者认为代码可以包含在master分支中时，他们可以合并这些更改。当他们按下合并按钮时，GitLab会合并代码并创建一个合并提交，这样以后就可以很容易地看到这个事件。合并请求总是创建合并提交，即使分支可以在没有合并提交的情况下进行合并。这种合并策略在Git中被称为“无快进”（no fast-forward）。合并后，删除feature分支，因为不再需要它。在GitLab中，这种删除是合并时的一个选项</p>
<blockquote>
<p>Suppose that a branch is merged but a problem occurs and the issue is reopened. In this case, it is no problem to reuse the same branch name since the first branch was deleted when it was merged. At any time, there is at most one branch for every issue. It is possible that one feature branch solves more than one issue.</p>
</blockquote>
<p>假设一个分支被合并，但出现了一个问题，该问题被重新打开。在这种情况下，重用相同的分支名称没有问题，因为第一个分支在合并时被删除了。在任何时候，每个问题最多只有一个分支。一个feature分支可能解决多个问题</p>
<h2 id="Linking-and-closing-issues-from-merge-requests"><a href="#Linking-and-closing-issues-from-merge-requests" class="headerlink" title="Linking and closing issues from merge requests"></a>Linking and closing issues from merge requests</h2><p><img src="/imgs/gitlab-flow/gitlab_flow_close_issue_mr.png" alt></p>
<p>从合并请求中链接和关闭问题</p>
<blockquote>
<p>Link to issues by mentioning them in commit messages or the description of a merge request, for example, “Fixes #16” or “Duck typing is preferred. See #12.” GitLab then creates links to the mentioned issues and creates comments in the issues linking back to the merge request.</p>
</blockquote>
<p>通过在提交消息或合并请求的描述中提及问题来链接到问题，例如，“修复#16”或“Duck typing is preferred. See #12.”。GitLab然后创建指向上述问题的链接，并在链接回合并请求的问题中创建注释</p>
<blockquote>
<p>To automatically close linked issues, mention them with the words “fixes” or “closes,” for example, “fixes #14” or “closes #67.” GitLab closes these issues when the code is merged into the default branch.</p>
</blockquote>
<p>要自动关闭链接的问题，请用“fixes”或“closes”来提及它们，例如，“fixes #14”或“closes #67”。当代码被合并到默认分支时，GitLab会关闭这些问题</p>
<blockquote>
<p>If you have an issue that spans across multiple repositories, create an issue for each repository and link all issues to a parent issue.</p>
</blockquote>
<p>如果问题跨越多个存储库，请为每个存储库创建一个问题，并将所有问题链接到父问题</p>
<h2 id="Squashing-commits-with-rebase"><a href="#Squashing-commits-with-rebase" class="headerlink" title="Squashing commits with rebase"></a>Squashing commits with rebase</h2><p><img src="/imgs/gitlab-flow/gitlab_flow_rebase.png" alt></p>
<blockquote>
<p>With Git, you can use an interactive rebase (rebase -i) to squash multiple commits into one or reorder them. This functionality is useful if you want to replace a couple of small commits with a single commit, or if you want to make the order more logical.</p>
</blockquote>
<p>使用Git，您可以使用交互式基础(rebase -i)将多个提交压缩成一个或重新排序。如果您想用单个提交替换几个小提交，或者如果您想使顺序更符合逻辑，此功能非常有用</p>
<blockquote>
<p>However, you should never rebase commits you have pushed to a remote server. Rebasing creates new commits for all your changes, which can cause confusion because the same change would have multiple identifiers. It also causes merge errors for anyone working on the same branch because their history would not match with yours. Also, if someone has already reviewed your code, rebasing makes it hard to tell what changed since the last review.</p>
</blockquote>
<p>但是，您永远不应该将您已推送至远程服务器的提交进行rebase。rebase会为您的所有更改创建新的提交，这可能会导致混淆，因为相同的更改会有多个标识符。它还会导致在同一分支上工作的其他人出现合并错误，因为他们的历史记录与您的不匹配。此外，如果有人已经审查了您的代码，那么rebase会使您很难判断自上次审查以来发生了什么变化</p>
<blockquote>
<p>You should also never rebase commits authored by other people. Not only does this rewrite history, but it also loses authorship information. Rebasing prevents the other authors from being attributed and sharing part of the <code>git blame</code>.</p>
</blockquote>
<p>您也不应该改变由其他人编写的提交。这不仅重写了历史，而且还丢失了作者信息。Rebasing prevents the other authors from being attributed and sharing part of the <code>git blame</code></p>
<blockquote>
<p>If a merge involves many commits, it may seem more difficult to undo. You might think to solve this by squashing all the changes into one commit before merging, but as discussed earlier, it is a bad idea to rebase commits that you have already pushed. Fortunately, there is an easy way to undo a merge with all its commits. The way to do this is by reverting the merge commit. Preserving this ability to revert a merge is a good reason to always use the “no fast-forward” (—no-ff) strategy when you merge manually.</p>
</blockquote>
<p>如果合并涉及许多提交，那么撤销可能会更加困难。您可能会想在合并前将所有更改压缩成一个提交来解决这个问题，但是如前所述，rebase您已经推动的提交的基础是一个坏主意。幸运的是，有一种简单的方法可以撤消与其所有提交的合并。方法是恢复合并提交。保留这种恢复合并的能力是在手动合并时始终使用“无快进”(<code>--no-ff</code>)策略的一个很好的理由</p>
<blockquote>
<p>Note: If you revert a merge commit and then change your mind, revert the revert commit to redo the merge. Git does not allow you to merge the code again otherwise.</p>
</blockquote>
<p><strong>注意:如果您回复合并提交，然后改变主意，请恢复提交以重做合并。否则Git不允许您再次合并代码</strong></p>
<h2 id="Reducing-merge-commits-in-feature-branches"><a href="#Reducing-merge-commits-in-feature-branches" class="headerlink" title="Reducing merge commits in feature branches"></a>Reducing merge commits in feature branches</h2><p><img src="/imgs/gitlab-flow/gitlab_flow_merge_commits.png" alt></p>
<p>减少特征分支的合并提交</p>
<blockquote>
<p>Having lots of merge commits can make your repository history messy. Therefore, you should try to avoid merge commits in feature branches. Often, people avoid merge commits by just using rebase to reorder their commits after the commits on the master branch. Using rebase prevents a merge commit when merging master into your feature branch, and it creates a neat linear history. However, as discussed in the section about rebasing, you should never rebase commits you have pushed to a remote server. This restriction makes it impossible to rebase work in progress that you already shared with your team, which is something we recommend.</p>
</blockquote>
<p>有很多合并提交会使您的存储库历史变得混乱。因此，您应该尽量避免在feature分支中进行合并提交。通常，人们通过在master分支上提交之后使用rebase来重新排序提交来避免合并提交。使用rebase可防止在将master合并到feature分支时进行合并提交，并创建整洁的线性历史。但是，正如<a href="https://docs.gitlab.com/ee/topics/gitlab_flow.html#squashing-commits-with-rebase" target="_blank" rel="noopener">rebase一节</a>中讨论的，您永远不应该rebase您已经推送到远程服务器的提交。这一限制使得您无法对已经与您的团队共享的正在进行的工作进行重定基准，这是我们推荐的</p>
<blockquote>
<p>Rebasing also creates more work, since every time you rebase, you have to resolve similar conflicts. Sometimes you can reuse recorded resolutions (rerere), but merging is better since you only have to resolve conflicts once. Atlassian has a more thorough explanation of the tradeoffs between merging and rebasing on their blog.</p>
</blockquote>
<p>重定基准也会产生更多的工作，因为每次重定基准时，都必须解决类似的冲突。有时您可以重用ecorded resolutions(<code>rerere</code>)，但是合并更好的选择，因为您只需解决一次冲突。Atlassian在他们的<a href="https://www.atlassian.com/blog/git/git-team-workflows-merge-or-rebase" target="_blank" rel="noopener">博客</a>上对合并和重定基础之间的权衡有更透彻的解释</p>
<blockquote>
<p>A good way to prevent creating many merge commits is to not frequently merge master into the feature branch. There are three reasons to merge in master: utilizing new code, resolving merge conflicts, and updating long-running branches.</p>
</blockquote>
<p>防止创建许多合并提交的一个好方法是不要频繁地将master合并到feature分支中。在master中合并有三个原因:使用新代码、解决合并冲突和更新长期运行的分支</p>
<blockquote>
<p>If you need to utilize some code that was introduced in master after you created the feature branch, you can often solve this by just cherry-picking a commit.</p>
</blockquote>
<p>如果您需要利用在创建feature分支后master新引入的一些代码，您通常可以通过挑选提交来解决这个问题</p>
<blockquote>
<p>If your feature branch has a merge conflict, creating a merge commit is a standard way of solving this.</p>
</blockquote>
<p>如果您的feature分支有合并冲突，创建合并提交是解决这一问题的标准方法</p>
<blockquote>
<p>Note: Sometimes you can use .gitattributes to reduce merge conflicts. For example, you can set your changelog file to use the union merge driver so that multiple new entries don’t conflict with each other.</p>
</blockquote>
<p>注意:有时你可以使用<code>.gitattributes</code>文件来减少合并冲突。例如，您可以变更日志文件以使用<a href="https://git-scm.com/docs/gitattributes#gitattributes-union" target="_blank" rel="noopener">联合合并驱动程序</a>，以便多个新条目不会相互冲突</p>
<blockquote>
<p>The last reason for creating merge commits is to keep long-running feature branches up-to-date with the latest state of the project. The solution here is to keep your feature branches short-lived. Most feature branches should take less than one day of work. If your feature branches often take more than a day of work, try to split your features into smaller units of work.</p>
</blockquote>
<p>创建合并提交的最后一个原因是让长期运行的功能分支与项目的最新状态保持同步。这里的解决方案是让您的feature分支仅有短暂生命周期。大多数feature分支应该不到一天的工作时间。如果您的feature分支经常需要一天以上的工作时间，请尝试将您的功能分成更小的工作单元</p>
<blockquote>
<p>If you need to keep a feature branch open for more than a day, there are a few strategies to keep it up-to-date. One option is to use continuous integration (CI) to merge in master at the start of the day. Another option is to only merge in from well-defined points in time, for example, a tagged release. You could also use feature toggles to hide incomplete features so you can still merge back into master every day.</p>
</blockquote>
<p>如果您需要让一个feature分支保持开放一天以上，有几种策略可以让它保持最新。一种选择是在一天开始时使用连续集成（CI）合并到主服务器中。另一种选择是只从定义明确的时间点合并进来，例如，标记的版本。您也可以使用<a href="https://martinfowler.com/bliki/FeatureToggle.html" target="_blank" rel="noopener">功能切换</a>来隐藏不完整的功能，这样您仍然可以每天合并回master</p>
<blockquote>
<p>Note: Don’t confuse automatic branch testing with continuous integration. Martin Fowler makes this distinction in his article about feature branches:</p>
<p>“I’ve heard people say they are doing CI because they are running builds, perhaps using a CI server, on every branch with every commit. That’s continuous building, and a Good Thing, but there’s no integration, so it’s not CI.”</p>
</blockquote>
<p><strong>注意:不要混淆自动分支测试和持续集成。马丁·福勒在他关于特征分支的文章中做了这样的区分</strong></p>
<p><strong>“我听人们说他们在做CI，因为他们在每个分支上提交时运行构建程序，可能使用CI服务器。这种持续构建是一件好事，但是没有集成，所以它不是CI。”</strong></p>
<blockquote>
<p>In conclusion, you should try to prevent merge commits, but not eliminate them. Your codebase should be clean, but your history should represent what actually happened. Developing software happens in small, messy steps, and it is OK to have your history reflect this. You can use tools to view the network graphs of commits and understand the messy history that created your code. If you rebase code, the history is incorrect, and there is no way for tools to remedy this because they can’t deal with changing commit identifiers.</p>
</blockquote>
<p>总之，您应该尝试预防合并提交，但不要消除它们。您的代码库应该是干净的，但是您的历史应该代表实际发生的事情。软件开发是以小而混乱的步骤进行的，让你的历史来反映这一点是可以的。您可以使用工具查看提交的网络图，并理解创建代码的混乱历史。如果您重新设置代码的基础，历史是不正确的，并且工具没有办法补救这一点，因为它们不能处理更改提交标识符</p>
<h2 id="Commit-often-and-push-frequently"><a href="#Commit-often-and-push-frequently" class="headerlink" title="Commit often and push frequently"></a>Commit often and push frequently</h2><p>经常提交以及频繁推送</p>
<blockquote>
<p>Another way to make your development work easier is to commit often. Every time you have a working set of tests and code, you should make a commit. Splitting up work into individual commits provides context for developers looking at your code later. Smaller commits make it clear how a feature was developed, and they make it easy to roll back to a specific good point in time or to revert one code change without reverting several unrelated changes.</p>
</blockquote>
<p>让你的开发工作更容易的另一个方法是经常提交。每次你有了一套测试和代码后就应该提交。将工作划分成单次提交为以后开发人员查看您的代码提供了环境。较小的提交可以清楚地说明一个特征是如何开发的，并且可以很容易地回滚到一个特定的好时间点，或者在不需要恢复几个更改的情况下恢复一个代码更改</p>
<blockquote>
<p>Committing often also makes it easy to share your work, which is important so that everyone is aware of what you are working on. You should push your feature branch frequently, even when it is not yet ready for review. By sharing your work in a feature branch or a merge request, you prevent your team members from duplicating work. Sharing your work before it’s complete also allows for discussion and feedback about the changes, which can help improve the code before it gets to review.</p>
</blockquote>
<p>提交也会使得工作分享变得容易，这很重要，这样每个人都知道你在做什么。您应该经常推动您的feature分支，即使它还没有准备好进行审查。通过在feature分支或合并请求中共享您的工作，您可以防止团队成员重复工作。在工作完成之前共享您的工作还允许对变更进行讨论和反馈，这有助于在代码评审之前对其进行改进</p>
<h2 id="How-to-write-a-good-commit-message"><a href="#How-to-write-a-good-commit-message" class="headerlink" title="How to write a good commit message"></a>How to write a good commit message</h2><p><img src="/imgs/gitlab-flow/gitlab_flow_good_commit.png" alt></p>
<blockquote>
<p>A commit message should reflect your intention, not just the contents of the commit. It is easy to see the changes in a commit, so the commit message should explain why you made those changes. An example of a good commit message is: “Combine templates to reduce duplicate code in the user views.” The words “change,” “improve,” “fix,” and “refactor” don’t add much information to a commit message. For example, “Improve XML generation” could be better written as “Properly escape special characters in XML generation.” For more information about formatting commit messages, please see this excellent blog post by Tim Pope</p>
</blockquote>
<p>提交消息应该反映您的意图，而不仅仅是提交的内容。很容易看到提交中的更改，所以提交消息应该解释您为什么做出这些更改。一个好的提交消息的例子是:“组合模板以减少用户视图中的重复代码”。关键字“改变”、“改进”、“修复”和“重构”这些词不会给提交消息添加太多信息。例如，“改进XML生成”可以更好地写成“在XML生成中正确转义特殊字符”。有关格式化提交消息的更多信息，请参见蒂姆·波普的这篇精彩<a href="https://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html" target="_blank" rel="noopener">博客文章</a></p>
<h2 id="Testing-before-merging"><a href="#Testing-before-merging" class="headerlink" title="Testing before merging"></a>Testing before merging</h2><p>合并前测试</p>
<p><img src="/imgs/gitlab-flow/gitlab_flow_ci_mr.png" alt></p>
<blockquote>
<p>In old workflows, the continuous integration (CI) server commonly ran tests on the master branch only. Developers had to ensure their code did not break the master branch. When using GitLab flow, developers create their branches from this master branch, so it is essential that it never breaks. Therefore, each merge request must be tested before it is accepted. CI software like Travis CI and GitLab CI show the build results right in the merge request itself to make this easy.</p>
</blockquote>
<p>在旧的工作流中，连续集成服务器通常只在master分支上运行测试。开发人员必须确保他们的代码不会破坏master分支。当使用GitLab流时，开发人员从master分支创建他们的分支，所以它永远不会中断是非常重要的。因此，在接受每个合并请求之前，必须对其进行测试。像Travis CI和GitLab CI这样的CI软件会在合并请求本身中显示构建结果，以便于实现</p>
<blockquote>
<p>There is one drawback to testing merge requests: the CI server only tests the feature branch itself, not the merged result. Ideally, the server could also test the master branch after each change. However, retesting on every commit to master is computationally expensive and means you are more frequently waiting for test results. Since feature branches should be short-lived, testing just the branch is an acceptable risk. If new commits in master cause merge conflicts with the feature branch, merge master back into the branch to make the CI server re-run the tests. As said before, if you often have feature branches that last for more than a few days, you should make your issues smaller.</p>
</blockquote>
<p>测试合并请求有一个缺点：CI服务器只测试feature分支本身，而不测试合并结果。理想情况下，服务器也可以在每次更改后测试master分支。然而，每次提交给master时重新测试计算量很大，这意味着您更频繁地等待测试结果。因为feature分支应该是短期的，所以只测试分支是可以接受的风险。如果master服务器中的新提交导致与feature分支的合并冲突，请将master服务器合并回分支，以使CI服务器重新运行测试。如前所述，如果您经常有持续几天以上的feature分支，您应该将问题变小</p>
<h2 id="Working-with-feature-branches"><a href="#Working-with-feature-branches" class="headerlink" title="Working with feature branches"></a>Working with feature branches</h2><p>使用特征分支工作</p>
<p><img src="/imgs/gitlab-flow/gitlab_flow_git_pull.png" alt></p>
<blockquote>
<p>When creating a feature branch, always branch from an up-to-date master. If you know before you start that your work depends on another branch, you can also branch from there. If you need to merge in another branch after starting, explain the reason in the merge commit. If you have not pushed your commits to a shared location yet, you can also incorporate changes by rebasing on master or another feature branch. Do not merge from upstream again if your code can work and merge cleanly without doing so. Merging only when needed prevents creating merge commits in your feature branch that later end up littering the master history.</p>
</blockquote>
<p>创建feature分支时，始终使用最新的master分支代码。如果你在开始工作前知道你的工作依赖于另一个分支，你也可以从那个分支fork。如果启动后需要合并到另一个分支，请在合并提交中解释原因。如果您尚未将提交推送到共享位置，也可以通过在master分支或另一个feature分支上rebase合并更改。如果您的代码可以在不合并的情况下干净地工作和合并，请不要再从上游合并。只有在需要时合并才能防止在您的feature分支中创建合并提交，而合并提交最终会丢弃master历史记录</p>
]]></content>
      <categories>
        <category>版本控制</category>
        <category>规范</category>
        <category>托管平台</category>
        <category>workflow</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>gitlab-flow</tag>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]GitHub Flow</title>
    <url>/posts/a20843e9.html</url>
    <content><![CDATA[<p>原文地址：<a href="http://scottchacon.com/2011/08/31/github-flow.html" target="_blank" rel="noopener">GitHub Flow</a></p><h2 id="Issues-with-git-flow"><a href="#Issues-with-git-flow" class="headerlink" title="Issues with git-flow"></a>Issues with git-flow</h2><p>git-flow的问题</p><blockquote>
<p>I travel all over the place teaching Git to people and nearly every class and workshop I’ve done recently has asked me what I think about <a href="http://nvie.com/posts/a-successful-git-branching-model/" target="_blank" rel="noopener">git-flow</a>. I always answer that I think that it’s great - it has taken a system (Git) that has a million possible workflows and documented a well tested, flexible workflow that works for lots of developers in a fairly straightforward manner. It has become something of a standard so that developers can move between projects or companies and be familiar with this standardized workflow.</p>
</blockquote><a id="more"></a>


<p>我走遍各地教人们Git，几乎我最近做的每一堂课和研讨会都问我对git-flow的看法。我总是回答，我认为它是伟大的 - 它采用了一个有一百万种可能的工作流程的系统（Git），并记录了一个测试良好的，灵活的工作流程，以相当简单的方式为许多开发人员工作。它已经成为一种标准，开发人员可以在项目或公司之间移动，并熟悉这种标准化的工作流</p>
<blockquote>
<p>However, it does have its issues. I have heard a number of opinions from people along the lines of not liking that new feature branches are started off of develop rather than master, or the way it handles hotfixes, but those are fairly minor.</p>
</blockquote>
<p>然而，它确实有它的问题。我听到了很多人的意见，他们不喜欢新的特性分支是从develop开始的，而不是从master开始的，或者它处理hotfix的方式，但是这些都是相当小的问题</p>
<blockquote>
<p>One of the bigger issues for me is that it’s more complicated than I think most developers and development teams actually require. It’s complicated enough that a big <a href="https://github.com/nvie/gitflow" target="_blank" rel="noopener">helper script</a> was developed to help enforce the flow. Though this is cool, the issue is that it cannot be enforced in a Git GUI, only on the command line, so the only people who have to learn the complex workflow really well, because they have to do all the steps manually, are the same people who aren’t comfortable with the system enough to use it from the command line. This can be a huge problem.</p>
</blockquote>
<p>对我来说，一个更大的问题是它比我认为大多数开发人员和开发团队实际需要的要复杂。它已经足够复杂到需要开发一个大的助手脚本来帮助实施流程了。尽管这很酷，但问题是它不能在Git图形用户界面中强制执行，只能在命令行上强制执行，所以人们必须非常好地学习这个复杂的工作流程，因为必须手动完成所有步骤，如果对系统不太适应，将无法从命令行使用它。这可能是个大问题</p>
<blockquote>
<p>Both of these issues can be solved easily just by having a much more simplified process. At GitHub, we do not use git-flow. We use, and always have used, a much simpler Git workflow.</p>
</blockquote>
<p>这两个问题都可以通过简单得多的流程轻松解决。在GitHub，我们不使用git-flow。我们使用并且一直使用一个简单得多的Git工作流</p>
<blockquote>
<p>Its simplicity gives it a number of advantages. One is that it’s easy for people to understand, which means they can pick it up quickly and they rarely if ever mess it up or have to undo steps they did wrong. Another is that we don’t need a wrapper script to help enforce it or follow it, so using GUIs and such are not a problem.</p>
</blockquote>
<p>它的简单性给了它许多优点。一是人们很容易理解，这意味着他们可以很快学会，而且他们很少会把事情搞砸或者不得不撤销他们做错的步骤。另一个是，我们不需要辅助脚本来帮助执行或遵循它，所以可以通过图形用户界面使用</p>
<h2 id="GitHub-Flow"><a href="#GitHub-Flow" class="headerlink" title="GitHub Flow"></a>GitHub Flow</h2><blockquote>
<p>So, why don’t we use git-flow at GitHub? Well, the main issue is that we deploy all the time. The git-flow process is designed largely around the “release”. We don’t really have “releases” because we deploy to production every day - often several times a day. We can do so through our chat room robot, which is the same place our CI results are displayed. We try to make the process of testing and shipping as simple as possible so that every employee feels comfortable doing it.</p>
</blockquote>
<p>那么，为什么我们不在GitHub上使用git-flow呢？主要问题是我们一直在部署。git-flow主要是围绕“release”设计的。我们并没有真正的“release”，因为我们每天都部署到生产中 - 通常一天几次。我们可以通过聊天室机器人这样做，这也是我们的显示CI结果的地方。我们努力使测试和发布过程尽可能简单，以便每位员工都能轻松完成</p>
<blockquote>
<p>There are a number of advantages to deploying so regularly. If you deploy every few hours, it’s almost impossible to introduce large numbers of big bugs. Little issues can be introduced, but then they can be fixed and redeployed very quickly. Normally you would have to do a ‘hotfix’ or something outside of the normal process, but it’s simply part of our normal process - there is no difference in the GitHub flow between a hotfix and a very small feature.</p>
</blockquote>
<p>定期部署有很多好处。如果每隔几个小时部署一次，几乎不可能引入大量的大错误。可以引入一些小问题，但是可以很快修复和重新部署。通常情况下，您必须在正常流程之外做一个‘热修复’，但这只是我们正常流程的一部分 - 热修复在GitHub流程中是一个非常小的特性</p>
<blockquote>
<p>Another advantage of deploying all the time is the ability to quickly address issues of all kinds. We can respond to security issues that are brought to our attention or implement small but interesting feature requests incredibly quickly, yet we can use the exact same process to address those changes as we do to handle normal or even large feature development. It’s all the same process and it’s all very simple.</p>
</blockquote>
<p>持续部署的另一个优势是能够快速解决各种问题。我们可以对引起我们注意的安全问题做出响应，或者以惊人的速度实现小而有趣的特征请求，但是我们可以使用与处理正常甚至大的特征开发完全相同的过程来解决这些变化。这都是同一个过程，都很简单</p>
<h2 id="How-We-Do-It"><a href="#How-We-Do-It" class="headerlink" title="How We Do It"></a>How We Do It</h2><p>如何实现它</p>
<blockquote>
<p>So, what is GitHub Flow?</p>
<ul>
<li>Anything in the master branch is deployable</li>
<li>To work on something new, create a descriptively named branch off of master (ie: new-oauth2-scopes)</li>
<li>Commit to that branch locally and regularly push your work to the same named branch on the server</li>
<li>When you need feedback or help, or you think the branch is ready for merging, open a <a href="http://help.github.com/send-pull-requests/" target="_blank" rel="noopener">pull request</a></li>
<li>After someone else has reviewed and signed off on the feature, you can merge it into master</li>
<li>Once it is merged and pushed to ‘master’, you can and should deploy immediately</li>
</ul>
</blockquote>
<p>所以，什么是GitHub流？</p>
<ul>
<li>master分支中的任何东西都是可部署的</li>
<li>要开发新的东西，从master分支中创建一个描述性命名的分支(比如：new-oauth2-scopes)</li>
<li>在本地提交到该分支，并定期将您的工作推送到服务器上的同一个命名分支</li>
<li>当您需要反馈或帮助，或者您认为分支已经准备好合并时，可以提交一个推送请求（PR）</li>
<li>在其他人审阅并签署了该功能后，可以将其合并到master中</li>
<li>一旦它被合并并推送到”主服务器”，就可以并且应该立即部署</li>
</ul>
<blockquote>
<p>That is the entire flow. It is very simple, very effective and works for fairly large teams - GitHub is 35 employees now, maybe 15-20 of whom work on the same project (github.com) at the same time. I think that most development teams - groups that work on the same logical code at the same time which could produce conflicts - are around this size or smaller. Especially those that are progressive enough to be doing rapid and consistent deployments.</p>
</blockquote>
<p>这就是全部流程。它非常简单，非常有效，并且为相当大的团队工作 - GitHub现在有35名员工，其中可能有15-20人同时在同一个项目(github.com)上工作。我认为大多数开发团队 - 在同一时间处理同一逻辑代码的团队可能会产生冲突 - 都在这个规模或更小的范围内。尤其是那些进步到足以进行快速的一致性部署的公司</p>
<blockquote>
<p>So, let’s look at each of these steps in turn.</p>
</blockquote>
<p>让我们依次看看这些步骤</p>
<h3 id="anything-in-the-master-branch-is-deployable"><a href="#anything-in-the-master-branch-is-deployable" class="headerlink" title="anything in the master branch is deployable"></a>anything in the master branch is deployable</h3><blockquote>
<p>This is basically the only hard rule of the system. There is only one branch that has any specific and consistent meaning and we named it master. To us, this means that it has been deployed or at the worst will be deployed within hours. It’s incredibly rare that this gets rewound (the branch is moved back to an older commit to revert work) - if there is an issue, commits will be reverted or new commits will be introduced that fixes the issue, but the branch itself is almost never rolled back.</p>
</blockquote>
<p>这基本上是该系统唯一的硬性规定。只有一个分支具有任何特定和一致的含义，我们称之为“master”。对我们来说，这意味着它已经部署，或者最坏的情况是将在几小时内部署。这种情况非常罕见(分支被移回到旧的提交来恢复工作) - 如果有问题，提交将被恢复或者引入新的提交来修复问题，但是分支本身几乎从来没有被回滚过</p>
<blockquote>
<p>The master branch is stable and it is always, always safe to deploy from it or create new branches off of it. If you push something to master that is not tested or breaks the build, you break the social contract of the development team and you normally feel pretty bad about it. Every branch we push has tests run on it and reported into the chat room, so if you haven’t run them locally, you can simply push to a topic branch (even a branch with a single commit) on the server and wait for Jenkins to tell you if it passes everything.</p>
</blockquote>
<p>master分支是稳定的，从master分支部署或从master分支创建新分支总是安全的。如果你把一些未经测试或破坏构建的东西推给master，你就破坏了开发团队的约定，你应该为此感到非常难过。我们推送给master的每个分支都经过测试并报告给聊天室，所以如果您没有在本地运行它们，您只要简单地推送至服务器上的指定分支(甚至是具有单个提交的分支)，并等待Jenkins告诉您它是否通过了所有操作</p>
<blockquote>
<p>You could have a deployed branch that is updated only when you deploy, but we don’t do that. We simply expose the currently deployed SHA through the webapp itself and curl it if we need a comparison made.</p>
</blockquote>
<p>您可以拥有一个只在部署时才更新的已部署分支，但我们不会这样做。我们只需通过webapp公开当前部署的SHA，如果我们需要进行比较，就可以下载它</p>
<h3 id="create-descriptive-branches-off-of-master"><a href="#create-descriptive-branches-off-of-master" class="headerlink" title="create descriptive branches off of master"></a>create descriptive branches off of master</h3><blockquote>
<p>When you want to start work on anything, you create a descriptively named branch off of the stable master branch. Some examples in the GitHub codebase right now would be user-content-cache-key, submodules-init-task or redis2-transition. This has several advantages - one is that when you fetch, you can see the topics that everyone else has been working on. Another is that if you abandon a branch for a while and go back to it later, it’s fairly easy to remember what it was.</p>
</blockquote>
<p>当您想要开始任何工作时，您可以从稳定的master分支创建一个描述性命名的分支。GitHub代码库中的一些例子是用户内容缓存键、子模块初始化任务或redis2转换。这有几个优点 - 一是当你获取时，你可以看到其他人都在研究的主题。另一个是，如果你暂时放弃一个分支，然后再回到它，很容易记住它是什么</p>
<blockquote>
<p>This is nice because when we go to the GitHub branch list page we can easily see what branches have been worked on recently and roughly how much work they have on them.</p>
</blockquote>
<p>这很好，因为当我们转到GitHub分支列表页面时，我们可以很容易地看到哪些分支最近被处理过，以及它们在这些分支上有多少工作</p>
<p><img src="/imgs/github-flow/7988902c-d0a8-11e4-94c9-dc132461ffe4.png" alt></p>
<blockquote>
<p>It’s almost like a list of upcoming features with current rough status. This page is awesome if you’re not using it - it only shows you branches that have unique work on them relative to your currently selected branch and it sorts them so that the ones most recently worked on are at the top. If I get really curious, I can click on the ‘Compare’ button to see what the actual unified diff and commit list is that is unique to that branch.</p>
</blockquote>
<p>这几乎就像是一个当前粗略状态的即将推出的功能列表。如果你不使用它，这个页面会很棒 - 它只显示相对于你当前选择的分支在它们上面有独特工作的分支，它会对它们进行排序，使得最近工作的分支在顶部。如果我真的很好奇，我可以点击“比较”按钮，看看真正的统一差异和提交列表是哪个分支独有的</p>
<blockquote>
<p>So, as of this writing, we have 44 branches in our repository with unmerged work in them, but I can also see that only about 9 or 10 of them have been pushed to in the last week.</p>
</blockquote>
<p>因此，截至本文撰写之时，我们的存储库中有44个分支，其中有未合并的工作，但我也可以看到，在过去的一周中，只有大约9到10个分支被推送</p>
<h3 id="push-to-named-branches-constantly"><a href="#push-to-named-branches-constantly" class="headerlink" title="push to named branches constantly"></a>push to named branches constantly</h3><blockquote>
<p>Another big difference from git-flow is that we push to named branches on the server constantly. Since the only thing we really have to worry about is master from a deployment standpoint, pushing to the server doesn’t mess anyone up or confuse things - everything that is not master is simply something being worked on.</p>
</blockquote>
<p>与git-flow的另一大区别是，我们不断地在服务器上推送命名分支。因为从部署的角度来看，我们唯一真正需要担心的是部署时候的master，所以向服务器推送不会让任何人混乱或事物混淆 - 所有不是master的东西都只是正在处理的事情</p>
<blockquote>
<p>It also make sure that our work is always backed up in case of laptop loss or hard drive failure. More importantly, it puts everyone in constant communication. A simple ‘git fetch’ will basically give you a TODO list of what every is currently working on.</p>
</blockquote>
<p>它还能确保在笔记本电脑丢失或硬盘出现故障时，我们的工作始终得到备份。更重要的是，它让每个人都保持持续的沟通。一个简单的“git fetch”基本上会给你一个待办事项列表，列出每个人目前正在做的事情</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git fetch</span><br><span class="line">remote: Counting objects: 3032, done.</span><br><span class="line">remote: Compressing objects: 100% (947/947), done.</span><br><span class="line">remote: Total 2672 (delta 1993), reused 2328 (delta 1689)</span><br><span class="line">Receiving objects: 100% (2672/2672), 16.45 MiB | 1.04 MiB/s, done.</span><br><span class="line">Resolving deltas: 100% (1993/1993), completed with 213 local objects.</span><br><span class="line">From github.com:github/github</span><br><span class="line"> * [new branch]      charlock-linguist -&gt; origin/charlock-linguist</span><br><span class="line"> * [new branch]      enterprise-non-config -&gt; origin/enterprise-non-config</span><br><span class="line"> * [new branch]      fi-signup  -&gt; origin/fi-signup</span><br><span class="line">   2647a42..4d6d2c2  git-http-server -&gt; origin/git-http-server</span><br><span class="line"> * [new branch]      knyle-style-commits -&gt; origin/knyle-style-commits</span><br><span class="line">   157d2b0..d33e00d  master     -&gt; origin/master</span><br><span class="line"> * [new branch]      menu-behavior-act-i -&gt; origin/menu-behavior-act-i</span><br><span class="line">   ea1c5e2..dfd315a  no-inline-js-config -&gt; origin/no-inline-js-config</span><br><span class="line"> * [new branch]      svg-tests  -&gt; origin/svg-tests</span><br><span class="line">   87bb870..9da23f3  view-modes -&gt; origin/view-modes</span><br><span class="line"> * [new branch]      wild-renaming -&gt; origin/wild-renaming</span><br></pre></td></tr></table></figure>
<blockquote>
<p>It also lets everyone see, by looking at the GitHub Branch List page, what everyone else is working on so they can inspect them and see if they want to help with something.</p>
</blockquote>
<p>它还可以让每个人通过查看GitHub分支列表页面，看到其他人正在做什么，这样就可以检查并且看看他们是否需要帮忙</p>
<h3 id="open-a-pull-request-at-any-time"><a href="#open-a-pull-request-at-any-time" class="headerlink" title="open a pull request at any time"></a>open a pull request at any time</h3><blockquote>
<p>GitHub has an amazing code review system called <a href="http://help.github.com/send-pull-requests/" target="_blank" rel="noopener">Pull Requests</a> that I fear not enough people know about. Many people use it for open source work - fork a project, update the project, send a pull request to the maintainer. However, it can also easily be used as an internal code review system, which is what we do.</p>
</blockquote>
<p>GitHub有一个惊人的代码审查系统，叫做Pull Requests(PRs)，恐怕没有足够的人知道。许多人将它用于开源工作 - fork一个项目，更新项目，向维护者发送一个拉请求。然而，它也可以很容易地用作内部代码审查系统，这就是我们所做的</p>
<blockquote>
<p>Actually, we use it more as a branch conversation view more than a pull request. You can send pull requests from one branch to another in a single project (public or private) in GitHub, so you can use them to say “I need help or review on this” in addition to “Please merge this in”.</p>
</blockquote>
<p>实际上，我们更多地将其用作分支对话视图，而不是录取请求。您可以在GitHub中的单个项目(公共或私有)中将请求从一个分支发送到另一个分支，这样除了“请求合并”之外，您还可以使用它们来说“我需要帮助或审阅”</p>
<p><img src="/imgs/github-flow/61a2dcba-d0a8-11e4-9924-3576232053ee.png" alt></p>
<blockquote>
<p>Here you can see Josh cc’ing Brian for review and Brian coming in with some advice on one of the lines of code. Further down we can see Josh acknowledging Brian’s concerns and pushing more code to address them.</p>
</blockquote>
<p>在这里，你可以看到乔什给布莱恩发了评论，布莱恩进来了，并对其中一行代码提出了一些建议。在更远的地方，我们可以看到乔希承认布赖恩的担忧，并推动更多的代码来解决它们</p>
<p><img src="/imgs/github-flow/5054b4ba-d0a8-11e4-8d38-548ecf157018.png" alt></p>
<blockquote>
<p>Finally you can see that we’re still in the trial phase - this is not a deployment ready branch yet, we use the Pull Requests to review the code long before we actually want to merge it into master for deployment.</p>
</blockquote>
<p>最后，您可以看到，我们仍然处于试验阶段 - 这还不是一个部署就绪分支，我们使用PRs来检查代码，直到我们真正想要将它合并到master代码中进行部署</p>
<blockquote>
<p>If you are stuck in the progress of your feature or branch and need help or advice, or if you are a developer and need a designer to review your work (or vice versa), or even if you have little or no code but some screenshot comps or general ideas, you open a pull request. You can cc people in the GitHub system by adding in a @username, so if you want the review or feedback of specific people, you simply cc them in the PR message (as you saw Josh do above).</p>
</blockquote>
<p>如果你被困在你的特性或分支的进程中，需要帮助或建议，或者如果你是一个开发人员，需要一个设计者来回顾你的工作(反之亦然)，或者即使你只有很少或没有代码，但有一些截图或一般想法，你可以打开一个拉取请求。您可以在GitHub系统中添加@username来抄送人，所以如果您想要特定人员的评论或反馈，您只需在公关信息中抄送他们(正如您在上面看到的Josh所做的那样)</p>
<blockquote>
<p>This is cool because the Pull Request feature let’s you comment on individual lines in the unified diff, on single commits or on the pull request itself and pulls everything inline to a single conversation view. It also let you continue to push to the branch, so if someone comments that you forgot to do something or there is a bug in the code, you can fix it and push to the branch, GitHub will show the new commits in the conversation view and you can keep iterating on a branch like that.</p>
</blockquote>
<p>这很酷，因为PR功能让您可以在统一差异、单次提交或PR本身中对单独的行进行评论，并将所有内容内嵌到单个对话视图中。它还允许您继续推送到分支，因此如果有人评论您忘记做某事或代码中有错误，您可以修复它并推送到分支，GitHub将在对话视图中显示新提交，您可以继续这样迭代分支</p>
<blockquote>
<p>If the branch has been open for too long and you feel it’s getting out of sync with the master branch, you can merge master into your topic branch and keep going. You can easily see in the pull request discussion or commit list when the branch was last brought up to date with the ‘master’.</p>
</blockquote>
<p>如果分支已经打开太久，并且您觉得它与主分支不同步，您可以将主分支合并到您的主题分支中，然后继续。您可以很容易地在PR讨论或提交列表中看到分支最后一次更新为“master”时的情况</p>
<p><img src="/imgs/github-flow/2162f69e-d0a8-11e4-8c98-d2bb581f7152.png" alt></p>
<blockquote>
<p>When everything is really and truly done on the branch and you feel it’s ready to deploy, you can move on to the next step.</p>
</blockquote>
<p>当分支上的所有工作都真正完成，并且您觉得已经准备好部署时，您可以继续下一步</p>
<h3 id="merge-only-after-pull-request-review"><a href="#merge-only-after-pull-request-review" class="headerlink" title="merge only after pull request review"></a>merge only after pull request review</h3><blockquote>
<p>We don’t simply do work directly on master or work on a topic branch and merge it in when we think it’s done - we try to get signoff from someone else in the company. This is generally a +1 or emoji or “:shipit:” comment, but we try to get someone else to look at it.</p>
</blockquote>
<p>我们不只是直接在master上工作或者在主题分支上工作，当我们认为已经完成的时候，我们会把它合并进来 - 我们会试着从公司的其他人那里获得签名。这通常是+1或表情符号或“:shipit:”注释，但我们试图让其他人看它</p>
<p><img src="/imgs/github-flow/0ea37c4a-d0a8-11e4-8b61-7aa73b7e3b03.png" alt></p>
<blockquote>
<p>Once we get that, and the branch passes CI, we can merge it into master for deployment, which will automatically close the Pull Request when we push it.</p>
</blockquote>
<p>一旦我们得到它，并且分支已通过CI，我们就可以将它合并到master节点进行部署，当我们推送代码时，master将自动关闭PR功能</p>
<h3 id="deploy-immediately-after-review"><a href="#deploy-immediately-after-review" class="headerlink" title="deploy immediately after review"></a>deploy immediately after review</h3><p>…<br>…</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><blockquote>
<p>Git itself is fairly complex to understand, making the workflow that you use with it more complex than necessary is simply adding more mental overhead to everybody’s day. I would always advocate using the simplest possible system that will work for your team and doing so until it doesn’t work anymore and then adding complexity only as absolutely needed.</p>
</blockquote>
<p>Git本身很难理解，让您使用的工作流比必要的更复杂只会给每个人的一天增加更多的精神负担。我总是主张使用对你的团队有用的最简单的系统，这样做直到它不再工作，然后只在绝对需要的时候增加复杂性</p>
<blockquote>
<p>For teams that have to do formal releases on a longer term interval (a few weeks to a few months between releases), and be able to do hot-fixes and maintenance branches and other things that arise from shipping so infrequently, git-flow makes sense and I would highly advocate it’s use.</p>
</blockquote>
<p>对于那些必须在更长的时间间隔内(几周到几个月之间)进行正式发布，并且能够进行热修复和维护分支以及其他不频繁部署的团队来说，git-flow是有意义的，我会大力提倡使用它</p>
<blockquote>
<p>For teams that have set up a culture of shipping, who push to production every day, who are constantly testing and deploying, I would advocate picking something simpler like GitHub Flow.</p>
</blockquote>
<p>对于已经建立了部署文化的团队，他们每天都在推动生产，不断地测试和部署，我主张选择一些更简单的东西，比如GitHub Flow</p>
]]></content>
      <categories>
        <category>版本控制</category>
        <category>工具</category>
        <category>规范</category>
        <category>托管平台</category>
        <category>workflow</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>github-flow</tag>
        <tag>github</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]A successful Git branching model</title>
    <url>/posts/aae96086.html</url>
    <content><![CDATA[<p>原文地址：<a href="https://nvie.com/posts/a-successful-git-branching-model/" target="_blank" rel="noopener">A successful Git branching model</a></p><blockquote>
<p>In this post I present the development model that I’ve introduced for some of my projects (both at work and private) about a year ago, and which has turned out to be very successful. I’ve been meaning to write about it for a while now, but I’ve never really found the time to do so thoroughly, until now. I won’t talk about any of the projects’ details, merely about the branching strategy and release management.</p>
</blockquote><a id="more"></a>

<p>在这篇文章中，我介绍了大约一年前为我的一些项目(包括工作项目和私人项目)引入的开发模型，结果证明非常成功。一段时间以来，我一直想写这篇文章，但直到现在，我还没有真正找到时间彻底地写完。我不会谈论任何项目的细节，仅仅是分支策略和发布管理</p>
<p><img src="/imgs/gitflow/git-model@2x.png" alt></p>
<h2 id="Why-git"><a href="#Why-git" class="headerlink" title="Why git?"></a>Why git?</h2><p>为什么是git?</p>
<blockquote>
<p>For a thorough discussion on the pros and cons of Git compared to centralized source code control systems, see the web. There are plenty of flame wars going on there. As a developer, I prefer Git above all other tools around today. Git really changed the way developers think of merging and branching. From the classic CVS/Subversion world I came from, merging/branching has always been considered a bit scary (“beware of merge conflicts, they bite you!”) and something you only do every once in a while.</p>
</blockquote>
<p>有关Git相对于集中式源码控制系统的优缺点的详细讨论，请参见<a href="http://git.or.cz/gitwiki/GitSvnComparsion" target="_blank" rel="noopener">网站</a>。那里正在进行大量的战争。作为一名开发人员，我更喜欢Git，而不是现在的所有其他工具。Git确实改变了开发人员对合并和分支的想法。从我来自的经典CVS/Subversion世界来看，合并/分支一直被认为有点可怕(“当心合并冲突，它们会咬你！”)以及你偶尔才会做的事情</p>
<blockquote>
<p>But with Git, these actions are extremely cheap and simple, and they are considered one of the core parts of your daily workflow, really. For example, in CVS/Subversion books, branching and merging is first discussed in the later chapters (for advanced users), while in every Git book, it’s already covered in chapter 3 (basics).</p>
</blockquote>
<p>但是使用Git，这些操作非常便宜和简单，而且它们被认为是你日常工作流程的核心部分之一，真的。例如，在CVS/Subversion<a href="http://svnbook.red-bean.com/" target="_blank" rel="noopener">书籍</a>中，分支和合并首先在后面的章节中讨论(对于高级用户)，而在每本Git<a href="http://pragprog.com/titles/tsgit/pragmatic-version-control-using-git" target="_blank" rel="noopener">书籍</a>中，它已经在第3章(基础)中讨论过了</p>
<blockquote>
<p>As a consequence of its simplicity and repetitive nature, branching and merging are no longer something to be afraid of. Version control tools are supposed to assist in branching/merging more than anything else.</p>
</blockquote>
<p>由于它的简单性和重复性，分支和合并不再是什么可怕的事情。版本控制工具应该比任何其他工具都更有助于分支/合并</p>
<blockquote>
<p>Enough about the tools, let’s head onto the development model. The model that I’m going to present here is essentially no more than a set of procedures that every team member has to follow in order to come to a managed software development process.</p>
</blockquote>
<p>关于工具，我们先来看看开发模型。我将在这里展示的模型基本上只不过是一组程序，每个团队成员都必须遵循这些程序才能进入托管软件开发过程</p>
<h2 id="Decentralized-but-centralized"><a href="#Decentralized-but-centralized" class="headerlink" title="Decentralized but centralized"></a>Decentralized but centralized</h2><p>去中心化的同时进行中心化</p>
<blockquote>
<p>The repository setup that we use and that works well with this branching model, is that with a central “truth” repo. Note that this repo is only considered to be the central one (since Git is a DVCS, there is no such thing as a central repo at a technical level). We will refer to this repo as origin, since this name is familiar to all Git users.</p>
</blockquote>
<p>我们使用的存储库设置与这个分支模型配合得很好，那是一个中心“真正的”仓库。请注意，这种仓库只被认为是中间仓库(因为Git是DVCS的，所以在技术层面上不存在中心仓库)。我们将把这个仓库称为origin，因为这个名字是所有Git用户都熟悉的</p>
<p><img src="/imgs/gitflow/centr-decentr@2x.png" alt></p>
<blockquote>
<p>Each developer pulls and pushes to origin. But besides the centralized push-pull relationships, each developer may also pull changes from other peers to form sub teams. For example, this might be useful to work together with two or more developers on a big new feature, before pushing the work in progress to origin prematurely. In the figure above, there are subteams of Alice and Bob, Alice and David, and Clair and David.</p>
</blockquote>
<p>每一个开发人员都向origin拉取和推送代码。但是除了集中式的推拉关系之外，每个开发人员也可以从其他同事那里拉取变化来组成子项目。例如，在将正在进行的工作过早推向origin之前，与两个或更多的开发人员一起开发一个大的新特性可能会很有用。在上图中，有Alice和Bob、Alice和David、Clair和David的子项目</p>
<blockquote>
<p>Technically, this means nothing more than that Alice has defined a Git remote, named bob, pointing to Bob’s repository, and vice versa.</p>
</blockquote>
<p>从技术上讲，这仅仅意味着Alice已经定义了一个远程Git，名为bob，指向Bob的存储库，反之亦然</p>
<h2 id="The-main-branches"><a href="#The-main-branches" class="headerlink" title="The main branches"></a>The main branches</h2><p>主要分支</p>
<blockquote>
<p>At the core, the development model is greatly inspired by existing models out there. The central repo holds two main branches with an infinite lifetime:</p>
</blockquote>
<p>这个分支模型极大的受之前开发模型的启发。中央仓库仅持有两个最重要的分支:</p>
<ul>
<li>master</li>
<li>develop</li>
</ul>
<p><img src="/imgs/gitflow/main-branches@2x.png" alt></p>
<blockquote>
<p>The master branch at origin should be familiar to every Git user. Parallel to the master branch, another branch exists called develop.</p>
</blockquote>
<p>每个Git用户都应该熟悉origin的master分支。与master分支并行的是另一个分支，叫做develop</p>
<blockquote>
<p>We consider origin/master to be the main branch where the source code of HEAD always reflects a production-ready state.</p>
</blockquote>
<p>我们认为origin/master是主分支，其HEAD指针指向的源代码已经用于后续的生产环节</p>
<blockquote>
<p>We consider origin/develop to be the main branch where the source code of HEAD always reflects a state with the latest delivered development changes for the next release. Some would call this the “integration branch”. This is where any automatic nightly builds are built from.</p>
</blockquote>
<p>同时origin/develop也是主分支，其HEAD指针指向的源代码反映的是将用于下一个版本的最新交付的开发变更状态。有人称之为“集成分支”。这个分支可作用于自动构建</p>
<blockquote>
<p>When the source code in the develop branch reaches a stable point and is ready to be released, all of the changes should be merged back into master somehow and then tagged with a release number. How this is done in detail will be discussed further on.</p>
</blockquote>
<p>当develop分支中的源代码到达一个稳定点并准备发布时，所有的变更应该以某种方式合并回master，并且标记发布号。如何详细完成将在下面进一步讨论</p>
<blockquote>
<p>Therefore, each time when changes are merged back into master, this is a new production release by definition. We tend to be very strict at this, so that theoretically, we could use a Git hook script to automatically build and roll-out our software to our production servers everytime there was a commit on master.</p>
</blockquote>
<p>因此，每次将变更合并回master时，根据定义，这是一个新的生产版本。我们倾向于对此非常严格，所以理论上，在每次提交到master时，我们可以使用Git hook脚本来自动构建软件并将其部署到生产服务器上</p>
<h2 id="Supporting-branches"><a href="#Supporting-branches" class="headerlink" title="Supporting branches"></a>Supporting branches</h2><p>支持分支</p>
<blockquote>
<p>Next to the main branches master and develop, our development model uses a variety of supporting branches to aid parallel development between team members, ease tracking of features, prepare for production releases and to assist in quickly fixing live production problems. Unlike the main branches, these branches always have a limited life time, since they will be removed eventually.</p>
</blockquote>
<p>除了主分支master和develop之外，我们的开发模型还使用各种支持分支来帮助团队成员之间的并行开发，简化特性跟踪，为生产发布做准备，并帮助快速修复实时生产问题。与主分支不同，这些分支的生命周期总是有限的，因为它们最终会被移除</p>
<blockquote>
<p>The different types of branches we may use are:</p>
<ul>
<li>Feature branches</li>
<li>Release branches</li>
<li>Hotfix branches</li>
</ul>
</blockquote>
<p>我们可以使用的不同类型的分支有:</p>
<ul>
<li>特征分支</li>
<li>版本分支</li>
<li>热修复分支</li>
</ul>
<blockquote>
<p>Each of these branches have a specific purpose and are bound to strict rules as to which branches may be their originating branch and which branches must be their merge targets. We will walk through them in a minute.</p>
</blockquote>
<p>这些分支中的每一个都有特定的目的，并受严格规则的约束，即哪些分支可能是它们的起始分支，哪些分支必须是它们的合并目标</p>
<blockquote>
<p>By no means are these branches “special” from a technical perspective. The branch types are categorized by how we use them. They are of course plain old Git branches.</p>
</blockquote>
<p>从技术角度来看，这些分支绝不是“特殊的”。分支类型是根据我们如何使用它们来分类的。它们当然是普通的老式Git分支</p>
<h3 id="Feature-branches"><a href="#Feature-branches" class="headerlink" title="Feature branches"></a>Feature branches</h3><p>特征分支</p>
<blockquote>
<p>May branch off from: <strong>develop</strong><br>Must merge back into: <strong>develop</strong></p>
</blockquote>
<p>特征分支从develop分支fork过来，同时必须合并回develop分支</p>
<blockquote>
<p>Branch naming convention:</p>
<ul>
<li>anything except master, develop, release-<em>, or hotfix-</em></li>
</ul>
</blockquote>
<p>分支命名规范：<strong>可以是任何名字</strong>，除了<code>master, develop, release-*以及hotfix-*</code></p>
<blockquote>
<p>Feature branches (or sometimes called topic branches) are used to develop new features for the upcoming or a distant future release. When starting development of a feature, the target release in which this feature will be incorporated may well be unknown at that point. The essence of a feature branch is that it exists as long as the feature is in development, but will eventually be merged back into develop (to definitely add the new feature to the upcoming release) or discarded (in case of a disappointing experiment).</p>
</blockquote>
<p>特性分支(或有时称为主题分支)用于为即将到来或遥远的未来版本开发新特性。当开始开发一个特性时，这个特性将被包含在其中的目标版本在那个时候可能是未知的。特性分支的本质是，只要特性还在开发中，它就一直存在，但最终会被合并回develop中(在即将发布的版本中明确添加的新特性)或被丢弃(在实验令人失望的情况下)</p>
<blockquote>
<p>Feature branches typically exist in developer repos only, not in origin.</p>
</blockquote>
<p>特征分支通常只存在于开发人员的个人仓库中，而不存在于origin中</p>
<p><img src="/imgs/gitflow/fb@2x.png" alt></p>
<h4 id="Creating-a-feature-branch"><a href="#Creating-a-feature-branch" class="headerlink" title="Creating a feature branch"></a>Creating a feature branch</h4><p>创建特征分支</p>
<blockquote>
<p>When starting work on a new feature, branch off from the develop branch.</p>
</blockquote>
<p>当开始一个新特性的工作时，从fork develop分支开始</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git checkout -b myfeature develop</span><br><span class="line">Switched to a new branch &quot;myfeature&quot;</span><br></pre></td></tr></table></figure>
<h4 id="Incorporating-a-finished-feature-on-develop"><a href="#Incorporating-a-finished-feature-on-develop" class="headerlink" title="Incorporating a finished feature on develop"></a>Incorporating a finished feature on develop</h4><p>在develop中加入已完成的特征</p>
<blockquote>
<p>Finished features may be merged into the develop branch to definitely add them to the upcoming release:</p>
</blockquote>
<p>完成的功能可能会合并到develop分支中，以明确地将其添加到即将发布的版本中:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git checkout develop</span><br><span class="line">Switched to branch &apos;develop&apos;</span><br><span class="line"></span><br><span class="line">$ git merge --no-ff myfeature</span><br><span class="line">Updating ea1b82a..05e9557</span><br><span class="line">(Summary of changes)</span><br><span class="line"></span><br><span class="line">$ git branch -d myfeature</span><br><span class="line">Deleted branch myfeature (was 05e9557).</span><br><span class="line"></span><br><span class="line">$ git push origin develop</span><br></pre></td></tr></table></figure>
<blockquote>
<p>The —no-ff flag causes the merge to always create a new commit object, even if the merge could be performed with a fast-forward. This avoids losing information about the historical existence of a feature branch and groups together all commits that together added the feature. Compare:</p>
</blockquote>
<p><strong>虽然合并可以通过fast-forward来执行，但是最好是使用-no-ff标志使合并操作仅创建一个新的提交对象</strong>。这避免了丢失关于特征分支的历史存在的信息，并将所有一起添加该特征的提交组合在一起。比较如下:</p>
<p><img src="/imgs/gitflow/merge-without-ff@2x.png" alt></p>
<blockquote>
<p>In the latter case, it is impossible to see from the Git history which of the commit objects together have implemented a feature—you would have to manually read all the log messages. Reverting a whole feature (i.e. a group of commits), is a true headache in the latter situation, whereas it is easily done if the —no-ff flag was used.</p>
</blockquote>
<p>在后一种情况下，无法从Git历史中发现哪几次提交对象一起实现了一个特性 - 此时必须手动读取所有日志消息。同时，恢复整个功能(即一组提交)是一个真正令人头疼的问题，而如果使用-no-ff标志，这很容易做到（仅包含单次提交）</p>
<blockquote>
<p>Yes, it will create a few more (empty) commit objects, but the gain is much bigger than the cost.</p>
</blockquote>
<p>虽然它会创建更多(空的)提交对象，但是收益远大于成本</p>
<h3 id="Release-branches"><a href="#Release-branches" class="headerlink" title="Release branches"></a>Release branches</h3><p>版本分支</p>
<blockquote>
<p>May branch off from: <strong>develop</strong><br>Must merge back into: <strong>develop and master</strong></p>
</blockquote>
<p>版本分支可以从develop分支进行fork，它必须合并到develop和master分支</p>
<blockquote>
<p>Branch naming convention:</p>
<ul>
<li>release-*</li>
</ul>
</blockquote>
<p>分支命名规范：<strong>release-*</strong></p>
<blockquote>
<p>Release branches support preparation of a new production release. They allow for last-minute dotting of i’s and crossing t’s. Furthermore, they allow for minor bug fixes and preparing meta-data for a release (version number, build dates, etc.). By doing all of this work on a release branch, the develop branch is cleared to receive features for the next big release.</p>
</blockquote>
<p>release分支支持新产品发布的准备。它们允许在最后一分钟dotting of i’s and crossing t’s，此外，它们还允许小错误修复和为发布准备元数据（版本号、构建日期等）。在release分支上完成所有这些工作的同时，develop分支可以准备接收下一个大型release的特性</p>
<blockquote>
<p>The key moment to branch off a new release branch from develop is when develop (almost) reflects the desired state of the new release. At least all features that are targeted for the release-to-be-built must be merged in to develop at this point in time. All features targeted at future releases may not—they must wait until after the release branch is branched off.</p>
</blockquote>
<p>从develop中分出一个新的release分支的关键时刻是develop(几乎)反映了新版本的期望状态。至少所有针对待构建版本的特性都已经合并进develop分支。针对未来版本的所有特性不会加入进来 - 它们必须等到release分支分离之后</p>
<blockquote>
<p>It is exactly at the start of a release branch that the upcoming release gets assigned a version number—not any earlier. Up until that moment, the develop branch reflected changes for the “next release”, but it is unclear whether that “next release” will eventually become 0.3 or 1.0, until the release branch is started. That decision is made on the start of the release branch and is carried out by the project’s rules on version number bumping.</p>
</blockquote>
<p>只有在版本分支的开始，即将发布的版本才被分配了一个版本号 - 而不是更早。在此之前，develop分支反映了“下一个版本”变化，但是在版本分支开始之前，尚不清楚“下一个版本”最终会变成0.3还是1.0。这个决定是在版本分支开始时做出的，并由项目的版本号碰撞规则来执行</p>
<h4 id="Creating-a-release-branch"><a href="#Creating-a-release-branch" class="headerlink" title="Creating a release branch"></a>Creating a release branch</h4><p>创建版本分支</p>
<blockquote>
<p>Release branches are created from the develop branch. For example, say version 1.1.5 is the current production release and we have a big release coming up. The state of develop is ready for the “next release” and we have decided that this will become version 1.2 (rather than 1.1.6 or 2.0). So we branch off and give the release branch a name reflecting the new version number:</p>
</blockquote>
<p>release分支从develop分支中fork。例如，假设版本1.1.5是当前的生产版本，我们即将发布一个大版本。develop分支已经为“下一个版本”做好了准备，我们已经决定这将成为1.2版(而不是1.1.6或2.0版)。因此，从develop分支fork一个版本分支，并使用反映新版本号的名称:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git checkout -b release-1.2 develop</span><br><span class="line">Switched to a new branch &quot;release-1.2&quot;</span><br><span class="line"></span><br><span class="line">$ ./bump-version.sh 1.2</span><br><span class="line">Files modified successfully, version bumped to 1.2.</span><br><span class="line"></span><br><span class="line">$ git commit -a -m &quot;Bumped version number to 1.2&quot;</span><br><span class="line">[release-1.2 74d9424] Bumped version number to 1.2</span><br><span class="line">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>After creating a new branch and switching to it, we bump the version number. Here, bump-version.sh is a fictional shell script that changes some files in the working copy to reflect the new version. (This can of course be a manual change—the point being that some files change.) Then, the bumped version number is committed.</p>
</blockquote>
<p>在创建了一个新的分支并切换到它之后，我们会增加版本号。这里，bump-version.sh是一个虚构的shell脚本，它会更改工作副本中的一些文件以反映新版本(这当然可以是手动更改)。然后，提交新的版本分支</p>
<blockquote>
<p>This new branch may exist there for a while, until the release may be rolled out definitely. During that time, bug fixes may be applied in this branch (rather than on the develop branch). Adding large new features here is strictly prohibited. They must be merged into develop, and therefore, wait for the next big release.</p>
</blockquote>
<p>这个新的分支可能会在那里存在一段时间，直到发行版明确推出。在此期间，bug修复可能会应用于这个分支(而不是develop分支)。严禁在此添加大型新功能。它们必须被合并到develop中，然后等待下一个大版本</p>
<h4 id="Finishing-a-release-branch"><a href="#Finishing-a-release-branch" class="headerlink" title="Finishing a release branch"></a>Finishing a release branch</h4><p>结束版本分支</p>
<blockquote>
<p>When the state of the release branch is ready to become a real release, some actions need to be carried out. First, the release branch is merged into master (since every commit on master is a new release by definition, remember). Next, that commit on master must be tagged for easy future reference to this historical version. Finally, the changes made on the release branch need to be merged back into develop, so that future releases also contain these bug fixes.</p>
</blockquote>
<p>当release分支的状态准备好成为真正的版本时，需要执行一些操作。首先，release分支被合并到master中(因为根据定义，master上的每个提交都是新的release，请记住)。接下来，master上的提交必须被标记（tagged），以便于将来参考这个历史版本。最后，在release分支上所做的更改需要合并回develop中，以便将来的发布也包含这些bug修复</p>
<blockquote>
<p>The first two steps in Git:</p>
</blockquote>
<p>前两步Git操作如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git checkout master</span><br><span class="line">Switched to branch &apos;master&apos;</span><br><span class="line"></span><br><span class="line">$ git merge --no-ff release-1.2</span><br><span class="line">Merge made by recursive.</span><br><span class="line">(Summary of changes)</span><br><span class="line"></span><br><span class="line">$ git tag -a 1.2</span><br></pre></td></tr></table></figure>
<blockquote>
<p>The release is now done, and tagged for future reference.</p>
</blockquote>
<p>新版本完成后需要标记，以便后续参考</p>
<blockquote>
<p>Edit: You might as well want to use the -s or -u <key> flags to sign your tag cryptographically.</key></p>
</blockquote>
<p>新增：不妨使用-s或-u <key>标志对标签进行加密</key></p>
<blockquote>
<p>To keep the changes made in the release branch, we need to merge those back into develop, though. In Git:</p>
</blockquote>
<p>为了保持版本分支中的变更，需要进一步合并回develop分支</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git checkout develop</span><br><span class="line">Switched to branch &apos;develop&apos;</span><br><span class="line">$ git merge --no-ff release-1.2</span><br><span class="line">Merge made by recursive.</span><br><span class="line">(Summary of changes)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>This step may well lead to a merge conflict (probably even, since we have changed the version number). If so, fix it and commit.</p>
</blockquote>
<p>这一步很可能会导致合并冲突(甚至可能，因为我们已经更改了版本号)。如果存在，修复它并提交</p>
<blockquote>
<p>Now we are really done and the release branch may be removed, since we don’t need it anymore:</p>
</blockquote>
<p>完成上述操作后就可以移除版本分支了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git branch -d release-1.2</span><br><span class="line">Deleted branch release-1.2 (was ff452fe).</span><br></pre></td></tr></table></figure>
<h3 id="Hotfix-branches"><a href="#Hotfix-branches" class="headerlink" title="Hotfix branches"></a>Hotfix branches</h3><p>热修复分支</p>
<blockquote>
<p>May branch off from: <strong>master</strong><br>Must merge back into: <strong>develop and master</strong></p>
</blockquote>
<p>热修复分支可以从master分支进行fork，它必须合并到develop和master分支</p>
<blockquote>
<p>Branch naming convention:</p>
<ul>
<li>hotfix-*</li>
</ul>
</blockquote>
<p>分支命名规范：<strong>hotfix-*</strong></p>
<p><img src="/imgs/gitflow/hotfix-branches@2x.png" alt></p>
<blockquote>
<p>Hotfix branches are very much like release branches in that they are also meant to prepare for a new production release, albeit unplanned. They arise from the necessity to act immediately upon an undesired state of a live production version. When a critical bug in a production version must be resolved immediately, a hotfix branch may be branched off from the corresponding tag on the master branch that marks the production version.</p>
</blockquote>
<p>热修复分支非常类似于版本分支，因为它们也意味着为新的生产发布做准备，尽管是计划外的。它们产生于必须立即对实时生产版本的不期望状态采取行动。当生产版本中的关键错误必须立即解决时，热修复分支会从master分支上标记生产版本的相应标记中分离出来</p>
<blockquote>
<p>The essence is that work of team members (on the develop branch) can continue, while another person is preparing a quick production fix.</p>
</blockquote>
<p>本质上团队成员(在develop分支上)的工作可以继续，而另一个人正在准备快速的生产修复</p>
<h4 id="Creating-the-hotfix-branch"><a href="#Creating-the-hotfix-branch" class="headerlink" title="Creating the hotfix branch"></a>Creating the hotfix branch</h4><p>创建热修复分支</p>
<blockquote>
<p>Hotfix branches are created from the master branch. For example, say version 1.2 is the current production release running live and causing troubles due to a severe bug. But changes on develop are yet unstable. We may then branch off a hotfix branch and start fixing the problem:</p>
</blockquote>
<p>热修复分支是从master分支创建的。例如，假设版本1.2是当前运行的生产版本，由于一个严重的错误导致了问题。但是在develop分支上的变化仍然不稳定，我们可以fork一个热修复分支，并开始修复问题:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git checkout -b hotfix-1.2.1 master</span><br><span class="line">Switched to a new branch &quot;hotfix-1.2.1&quot;</span><br><span class="line"></span><br><span class="line">$ ./bump-version.sh 1.2.1</span><br><span class="line">Files modified successfully, version bumped to 1.2.1.</span><br><span class="line"></span><br><span class="line">$ git commit -a -m &quot;Bumped version number to 1.2.1&quot;</span><br><span class="line">[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1</span><br><span class="line">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Don’t forget to bump the version number after branching off!</p>
</blockquote>
<p>不要忘记在fork分支后修改版本号</p>
<blockquote>
<p>Then, fix the bug and commit the fix in one or more separate commits.</p>
</blockquote>
<p>然后修复bug并在一次或多次提交中提交</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git commit -m &quot;Fixed severe production problem&quot;</span><br><span class="line">[hotfix-1.2.1 abbe5d6] Fixed severe production problem</span><br><span class="line">5 files changed, 32 insertions(+), 17 deletions(-)</span><br></pre></td></tr></table></figure>
<h4 id="Finishing-a-hotfix-branch"><a href="#Finishing-a-hotfix-branch" class="headerlink" title="Finishing a hotfix branch"></a>Finishing a hotfix branch</h4><p>结束热修复分支</p>
<blockquote>
<p>When finished, the bugfix needs to be merged back into master, but also needs to be merged back into develop, in order to safeguard that the bugfix is included in the next release as well. This is completely similar to how release branches are finished.</p>
</blockquote>
<p>完成后，修复的bug需要合并回master，也需要合并回develop，以确保bugfix也包含在下一个版本中。这完全类似于release分支的完成方式</p>
<blockquote>
<p>First, update master and tag the release.</p>
</blockquote>
<p>首先，更新master并进行标记</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git checkout master</span><br><span class="line">Switched to branch &apos;master&apos;</span><br><span class="line"></span><br><span class="line">$ git merge --no-ff hotfix-1.2.1</span><br><span class="line">Merge made by recursive.</span><br><span class="line">(Summary of changes)</span><br><span class="line"></span><br><span class="line">$ git tag -a 1.2.1</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Edit: You might as well want to use the -s or -u <key> flags to sign your tag cryptographically.</key></p>
</blockquote>
<p>新增：不妨使用-s或-u <key>标志对标签进行加密签名</key></p>
<blockquote>
<p>Next, include the bugfix in develop, too:</p>
</blockquote>
<p>下一步，合并热修复分支到develop</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git checkout develop</span><br><span class="line">Switched to branch &apos;develop&apos;</span><br><span class="line"></span><br><span class="line">$ git merge --no-ff hotfix-1.2.1</span><br><span class="line">Merge made by recursive.</span><br><span class="line">(Summary of changes)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>The one exception to the rule here is that, <strong>when a release branch currently exists, the hotfix changes need to be merged into that release branch, instead of</strong> develop. Back-merging the bugfix into the release branch will eventually result in the bugfix being merged into develop too, when the release branch is finished. (If work in develop immediately requires this bugfix and cannot wait for the release branch to be finished, you may safely merge the bugfix into develop now already as well.)</p>
</blockquote>
<p><strong>这里存在一个额外的规则，当一个release分支当前存在时，修补程序更改需要合并到该release分支中，而不是develop</strong>。将bugfix合并到release分支中最终会导致bugfix也被合并到develop中。(如果develop分支的工作立即需要此bugfix，并且不能等待release分支完成，那么也可以将该bugfix安全地合并到现在的develop分支中)</p>
<blockquote>
<p>Finally, remove the temporary branch:</p>
</blockquote>
<p>最后，移除临时的热修复分支</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git branch -d hotfix-1.2.1</span><br><span class="line">Deleted branch hotfix-1.2.1 (was abbe5d6).</span><br></pre></td></tr></table></figure>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>总结</p>
<blockquote>
<p>While there is nothing really shocking new to this branching model, the “big picture” figure that this post began with has turned out to be tremendously useful in our projects. It forms an elegant mental model that is easy to comprehend and allows team members to develop a shared understanding of the branching and releasing processes.</p>
</blockquote>
<p>虽然这个分支模型没有什么真正令人震惊的新东西，但是这篇文章开头的“大图”在我们的项目中已经证明是非常有用的。它形成了一个优雅的脑图，易于理解，并允许团队成员对分支和发布过程形成共同的理解</p>
]]></content>
      <categories>
        <category>版本控制</category>
        <category>工具</category>
        <category>规范</category>
        <category>workflow</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>git-flow</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]Rich feature hierarchies for accurate object detection and semantic segmentation</title>
    <url>/posts/69fce0f5.html</url>
    <content><![CDATA[<p>R-CNN(Regions with CNN features, 具有CNN特征的区域)是早期最先在目标检测领域中使用卷积神经网络的模型之一，其结合了图像处理、机器学习和深度学习，在当时达到了非常好的结果</p><a id="more"></a>
<p>原文地址：<a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="noopener">Rich feature hierarchies for accurate object detection and semantic segmentation</a></p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>摘要</p>
<blockquote>
<p>Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012—achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also compare R-CNN to OverFeat, a recently proposed sliding-window detector based on a similar CNN architecture. We find that R-CNN outperforms OverFeat by a large margin on the 200-class ILSVRC2013 detection dataset. Source code for the complete system is available at <a href="http://www.cs.berkeley.edu/˜rbg/rcnn" target="_blank" rel="noopener">http://www.cs.berkeley.edu/˜rbg/rcnn</a>.</p>
</blockquote>
<p>在典型的PASCAL-VOC数据集上测得的目标检测性能在过去几年中趋于平稳。表现最好的方法是复杂的集成系统，通常将多个低级图像特征与高级上下文结合起来。在本文中，我们提出了一种简单且可扩展的检测算法，与之前VOC 2012的最佳结果相比，平均精度（mAP）提高了30%以上，mAP达到了53.3%。我们的方法结合了两个关键的见解：（1）可以将高容量卷积神经网络（CNNs）应用到自下而上的区域建议中，以便定位和分割对象；（2）当标记的训练数据稀少时，监督辅助任务的预训练，然后进行特定领域的微调，带来显著的性能提升。由于我们将区域建议与CNN结合起来，我们称之为R-CNN方法：具有CNN特征的区域。我们还将R-CNN与OverFeat进行了比较，OverFeat是最近提出的一种基于类似CNN架构的滑动窗口检测器。我们发现，在200类ILSVRC2013检测数据集上，R-CNN的性能大大优于OverFeat。完整系统的源代码位于<a href="https://github.com/rbgirshick/rcnn（Caffe+Matlib版本）" target="_blank" rel="noopener">https://github.com/rbgirshick/rcnn（Caffe+Matlib版本）</a></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>引言</p>
<blockquote>
<p>Features matter. The last decade of progress on various visual recognition tasks has been based considerably on the use of SIFT [29] and HOG [7]. But if we look at performance on the canonical visual recognition task, PASCAL VOC object detection [15], it is generally acknowledged that progress has been slow during 2010-2012, with small gains obtained by building ensemble systems and employing minor variants of successful methods.</p>
</blockquote>
<p>特征很重要。在过去的十年中，各种视觉识别任务的进展很大程度上是基于SIFT[29]和HOG[7]的使用。但是，如果我们看看标准视觉识别任务PASCAL VOC目标检测的性能[15]，人们普遍认为，2010-2012年期间进展缓慢，通过构建集成系统和采用已成功方法的微小变体获得的收益很小</p>
<blockquote>
<p>SIFT and HOG are blockwise orientation histograms, a representation we could associate roughly with complex cells in V1, the first cortical area in the primate visual pathway. But we also know that recognition occurs several stages downstream, which suggests that there might be hierarchical, multi-stage processes for computing features that are even more informative for visual recognition.</p>
</blockquote>
<p>SIFT和HOG是块方向的直方图，我们可以粗略地将其与灵长类视觉通路的第一个皮层V1中的复杂细胞联系起来。但我们也知道，识别发生在下游的几个阶段，这意味着可能有层次化的、多阶段的过程来计算特征，这些过程对于视觉识别的信息量更大</p>
<blockquote>
<p>Fukushima’s “neocognitron” [19], a biologically-inspired hierarchical and shift-invariant model for pattern recognition, was an early attempt at just such a process. The neocognitron, however, lacked a supervised training algorithm. Building on Rumelhart et al. [33], LeCun et al. [26] showed that stochastic gradient descent via backpropagation was effective for training convolutional neural networks (CNNs), a class of models that extend the neocognitron.</p>
</blockquote>
<p>Fukushima的“neocognitron”[19]是一种基于生物启发的层次和平移不变的模式识别模型，是对这一过程的早期尝试。然而，neocognitron缺乏一种有监督的训练算法。建立在Rumelhart等人[33]的基础上，LeCun等人[26]的结果表明通过反向传播的随机梯度下降对于训练卷积神经网络（CNNs）是有效的</p>
<blockquote>
<p>CNNs saw heavy use in the 1990s (e.g., [27]), but then fell out of fashion with the rise of support vector machines. In 2012, Krizhevsky et al. [25] rekindled interest in CNNs by showing substantially higher image classification accuracy on the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) [9, 10]. Their success resulted from training a large CNN on 1.2 million labeled images, together with a few twists on LeCun’s CNN (e.g., $\max(x, 0)$ rectifying non-linearities and “dropout” regularization).</p>
</blockquote>
<p>CNNs在20世纪90年代得到了广泛的应用（如[27]），但随后随着支持向量机的兴起而过时。2012年，Krizhevsky等人[25]通过在ImageNet大规模视觉识别挑战（ILSVRC）上显示更高的图像分类精度，重新燃起了人们对CNN的兴趣[9，10]。他们的成功来自于在120万张标签图片上训练一个大型CNN，以及在LeCun的CNN上的一些调整（例如使用$\max(x，0)$作为池化层函数和使用“随机失活”进行正则化）</p>
<blockquote>
<p>The significance of the ImageNet result was vigorously debated during the ILSVRC 2012 workshop. The central issue can be distilled to the following: To what extent do the CNN classification results on ImageNet generalize to object detection results on the PASCAL VOC Challenge?</p>
</blockquote>
<p>ImageNet结果的重要性在ILSVRC 2012研讨会期间受到了激烈的争论。核心问题可以归结为以下几个方面：ImageNet上的CNN分类结果可以在多大程度上泛化到PASCAL VOC挑战下的目标检测结果？</p>
<blockquote>
<p>We answer this question by bridging the gap between image classification and object detection. This paper is the first to show that a CNN can lead to dramatically higher object detection performance on PASCAL VOC as compared to systems based on simpler HOG-like features. To achieve this result, we focused on two problems: localizing objects with a deep network and training a high-capacity model with only a small quantity of annotated detection data.</p>
</blockquote>
<p>我们通过缩小图像分类和目标检测之间的差距来回答这个问题。本文首次表明，与基于简单HOG-like特征的系统相比，CNN可以显著提高PASCAL-VOC上的目标检测性能。为了达到这一目的，我们重点研究了两个问题：利用深度网络定位目标和利用少量带标注的检测数据训练高容量模型</p>
<blockquote>
<p>Unlike image classification, detection requires localizing (likely many) objects within an image. One approach frames localization as a regression problem. However, work from Szegedy et al. [38], concurrent with our own, indicates that this strategy may not fare well in practice (they report a mAP of 30.5% on VOC 2007 compared to the 58.5% achieved by our method). An alternative is to build a sliding-window detector. CNNs have been used in this way for at least two decades, typically on constrained object categories, such as faces [32, 40] and pedestrians [35]. In order to maintain high spatial resolution, these CNNs typically only have two convolutional and pooling layers. We also considered adopting a sliding-window approach. However, units high up in our network, which has five convolutional layers, have very large receptive fields (195 × 195 pixels) and strides (32×32 pixels) in the input image, which makes precise localization within the sliding-window paradigm an open technical challenge.</p>
</blockquote>
<p>与图像分类不同，检测需要在图像中定位（可能是许多）对象。一种方法是将定位作为一个回归问题。然而，Szegedy等人的工作[38]与我们的一致，表明这一策略在实践中可能效果不佳（他们报告的VOC 2007年的mAP为30.5%，而我们的方法实现的mAP为58.5%）。另一种方法是建立一个滑动窗口检测器。为了保持较高的空间分辨率，这些CNN通常只有两个卷积层和池化层。我们也考虑采用滑动窗口方法。然而，在我们的网络中，具有五个卷积层的单元在输入图像中具有非常大的感受野（195×195像素）和步长（32×32像素），这使得在滑动窗口模式中的精确定位成为一个公开的技术挑战</p>
<blockquote>
<p>Instead, we solve the CNN localization problem by operating within the “recognition using regions” paradigm [21], which has been successful for both object detection [39] and semantic segmentation [5]. At test time, our method generates around 2000 category-independent region proposals for the input image, extracts a fixed-length feature vector from each proposal using a CNN, and then classifies each region with category-specific linear SVMs. We use a simple technique (affine image warping) to compute a fixed-size CNN input from each region proposal, regardless of the region’s shape. Figure 1 presents an overview of our method and highlights some of our results. Since our system combines region proposals with CNNs, we dub the method R-CNN: Regions with CNN features.</p>
</blockquote>
<p>相反，我们通过在“使用区域的识别”范例[21]内操作来解决CNN定位问题，该范例在目标检测[39]和语义分割[5]方面都取得了成功。在测试时，我们的方法为输入图像生成大约2000个类别无关的区域建议，使用CNN从每个建议中提取一个固定长度的特征向量，然后使用类别特定的线性支持向量机对每个区域进行分类。我们使用一种简单的技术（仿射图像扭曲）来计算来自每个区域建议的固定大小的CNN输入，而不管该区域的形状如何。由于我们的系统将区域建议与CNNs结合起来，因此我们将R-CNN方法称为具有CNN特征的区域</p>
<blockquote>
<p>In this updated version of this paper, we provide a head-to-head comparison of R-CNN and the recently proposed OverFeat [34] detection system by running R-CNN on the 200-class ILSVRC2013 detection dataset. OverFeat uses a sliding-window CNN for detection and until now was the best performing method on ILSVRC2013 detection. We show that R-CNN significantly outperforms OverFeat, with a mAP of 31.4% versus 24.3%.</p>
</blockquote>
<p>在本文的更新版本中，我们通过在200类ILSVRC2013检测数据集上运行R-CNN，对R-CNN和最近提出的OverFeat[34]检测系统进行了比较。OverFeat使用滑动窗口CNN进行检测，迄今为止是ILSVRC2013检测中性能最好的方法。我们显示R-CNN的表现明显优于OverFeat，mAP为31.4%对24.3%</p>
<blockquote>
<p>A second challenge faced in detection is that labeled data is scarce and the amount currently available is insufficient for training a large CNN. The conventional solution to this problem is to use unsupervised pre-training, followed by supervised fine-tuning (e.g., [35]). The second principle contribution of this paper is to show that supervised pre-training on a large auxiliary dataset (ILSVRC), followed by domainspecific fine-tuning on a small dataset (PASCAL), is an effective paradigm for learning high-capacity CNNs when data is scarce. In our experiments, fine-tuning for detection improves mAP performance by 8 percentage points. After fine-tuning, our system achieves a mAP of 54% on VOC 2010 compared to 33% for the highly-tuned, HOG-based deformable part model (DPM) [17, 20]. We also point readers to contemporaneous work by Donahue et al. [12], who show that Krizhevsky’s CNN can be used (without finetuning) as a blackbox feature extractor, yielding excellent performance on several recognition tasks including scene classification, fine-grained sub-categorization, and domain adaptation.</p>
</blockquote>
<p>在检测中面临的第二个挑战是，标记数据是稀缺的，目前可用的数量不足以训练一个大型CNN。这个问题的传统解决方案是使用无监督的预训练，然后是有监督的微调（例如，[35]）。本文的第二个主要贡献是，在一个大的辅助数据集（ILSVRC）上进行监督预训练，然后在特定的小数据集（PASCAL）上进行特定领域的微调，是在数据稀少的情况下学习高容量CNN的有效范例。在我们的实验中，对检测进行微调可以将mAP性能提高8个百分点。经过微调后，我们的系统在VOC 2010上实现了54% mAP，相比之下，高度调整后的基于HOG的可变形零件模型（DPM）仅实现了33% mAP[17，20]。我们还将读者介绍同期Donahue等人[12]的作品，他们发现Krizhevsky的CNN可以（无需微调）用作黑盒特征提取器，在包括场景分类、细粒度子分类和域自适应在内的多个识别任务中产生优异的性能</p>
<blockquote>
<p>Our system is also quite efficient. The only class-specific computations are a reasonably small matrix-vector product and greedy non-maximum suppression. This computational property follows from features that are shared across all categories and that are also two orders of magnitude lower-dimensional than previously used region features (cf. [39]).</p>
</blockquote>
<p>我们的系统也很有效率。唯一的特定类的计算是一个合理的小矩阵向量积和贪婪非最大抑制。这种计算特性来自于所有类别共享的特征，并且这些特征的维数比以前使用的区域特征低两个数量级（参见[39]）</p>
<blockquote>
<p>Understanding the failure modes of our approach is also critical for improving it, and so we report results from the detection analysis tool of Hoiem et al. [23]. As an immediate consequence of this analysis, we demonstrate that a simple bounding-box regression method significantly reduces mislocalizations, which are the dominant error mode.</p>
</blockquote>
<p>了解该方法的失效模式对于改进该方法也至关重要，因此我们报告了Hoiem等人[23]的检测分析工具的结果。作为这一分析的直接结果，我们证明了一种简单的边界盒回归方法可以显著减少主要误差模式的错误定位</p>
<blockquote>
<p>Before developing technical details, we note that because R-CNN operates on regions it is natural to extend it to the task of semantic segmentation. With minor modifications, we also achieve competitive results on the PASCAL VOC segmentation task, with an average segmentation accuracy of 47.9% on the VOC 2011 test set.</p>
</blockquote>
<p>我们注意到由于R-CNN对区域进行操作，因此将其扩展到语义分割任务是很自然的。经过少量修改，我们在PASCAL VOC分割任务上也取得了有竞争力的结果，VOC 2011测试集的平均分割精度为47.9%</p>
<p><img src="/imgs/具有CNN特征的区域/figure-1.png" alt></p>
<blockquote>
<p>Figure 1: Object detection system overview. Our system (1) takes an input image, (2) extracts around 2000 bottom-up region proposals, (3) computes features for each proposal using a large convolutional neural network (CNN), and then (4) classifies each region using class-specific linear SVMs. R-CNN achieves a mean average precision (mAP) of 53.7% on PASCAL VOC 2010. For comparison, [39] reports 35.1% mAP using the same region proposals, but with a spatial pyramid and bag-of-visual-words approach. The popular deformable part models perform at 33.4%. On the 200-class ILSVRC2013 detection dataset, R-CNN’s mAP is 31.4%, a large improvement over OverFeat [34], which had the previous best result at 24.3%.</p>
</blockquote>
<p>图1：目标检测系统概述。我们的系统（1）获取输入图像，（2）提取大约2000个自下而上的区域建议，（3）使用大型卷积神经网络（CNN）计算每个建议的特征，然后（4）使用类特定的线性SVM对每个区域进行分类。R-CNN在PASCAL VOC 2010上达到了53.7%的平均精度（mAP）。相比之下，论文[39]在使用相同的区域建议，但使用空间金字塔和视觉词袋方法下得到了35.1 mAP。流行的可变形零件模型的性能为33.4%。在200类ILSVRC2013检测数据集上，R-CNN的mAP为31.4%，比OverFeat[34]有很大的改进，OverFeat[34]之前的最佳结果为24.3%</p>
<h2 id="Object-detection-with-R-CNN"><a href="#Object-detection-with-R-CNN" class="headerlink" title="Object detection with R-CNN"></a>Object detection with R-CNN</h2><p>使用R-CNN的目标检测</p>
<blockquote>
<p>Our object detection system consists of three modules. The first generates category-independent region proposals. These proposals define the set of candidate detections available to our detector. The second module is a large convolutional neural network that extracts a fixed-length feature vector from each region. The third module is a set of classspecific linear SVMs. In this section, we present our design decisions for each module, describe their test-time usage, detail how their parameters are learned, and show detection results on PASCAL VOC 2010-12 and on ILSVRC2013.</p>
</blockquote>
<p>我们的目标检测系统由三个模块组成。首先生成类别独立的区域建议。这些建议定义了可供我们的检测器使用的候选检测集。第二个模块是一个大型卷积神经网络，它从每个区域提取一个固定长度的特征向量。第三个模块是一组类特定的线性支持向量机。在本节中，我们将介绍每个模块的设计决策，描述它们的测试时间使用，详细说明如何学习它们的参数，并在PASCAL VOC 2010-12和ILSVRC2013上显示检测结果</p>
<h3 id="Module-design"><a href="#Module-design" class="headerlink" title="Module design"></a>Module design</h3><p>模块设计</p>
<blockquote>
<p><strong>Region proposals</strong>. A variety of recent papers offer methods for generating category-independent region proposals. Examples include: objectness [1], selective search [39], category-independent object proposals [14], constrained parametric min-cuts (CPMC) [5], multi-scale combinatorial grouping [3], and Cires¸an et al. [6], who detect mitotic cells by applying a CNN to regularly-spaced square crops, which are a special case of region proposals. While R-CNN is agnostic to the particular region proposal method, we use selective search to enable a controlled comparison with prior detection work (e.g., [39, 41]).</p>
</blockquote>
<p><strong>区域建议</strong>。最近的许多论文提供了生成类别独立区域建议的方法。示例包括：对象性[1]、选择性搜索[39]、与类别无关的目标建议[14]、约束参数最小割集（CPMC）[5]、多尺度组合分组[3]和Cires¸an等人[6]通过将CNN应用于规则间隔的方形作物来检测有丝分裂细胞（这是区域建议的一个特例）。虽然R-CNN不固定于特定的区域建议方法，但我们使用选择性搜索来保证能够和先前检测工作（例如，[39，41]）进行比较</p>
<blockquote>
<p><strong>Feature extraction</strong>. We extract a 4096-dimensional feature vector from each region proposal using the Caffe [24] implementation of the CNN described by Krizhevsky et al. [25]. Features are computed by forward propagating a mean-subtracted 227 × 227 RGB image through five convolutional layers and two fully connected layers. We refer readers to [24, 25] for more network architecture details.</p>
</blockquote>
<p><strong>特征提取</strong>。我们使用Krizhevsky等人[25]描述的CNN的Caffe[24]实现从每个区域建议中提取4096维特征向量。特征通过将227×227 RGB图像输入五个卷积层和两个完全连接层来计算。我们请读者参考[24，25]了解更多的网络架构细节</p>
<blockquote>
<p>In order to compute features for a region proposal, we must first convert the image data in that region into a form that is compatible with the CNN (its architecture requires inputs of a fixed 227 × 227 pixel size). Of the many possible transformations of our arbitrary-shaped regions, we opt for the simplest. Regardless of the size or aspect ratio of the candidate region, we warp all pixels in a tight bounding box around it to the required size. Prior to warping, we dilate the tight bounding box so that at the warped size there are exactly p pixels of warped image context around the original box (we use p = 16). Figure 2 shows a random sampling of warped training regions. Alternatives to warping are discussed in Appendix A.</p>
</blockquote>
<p>为了计算区域建议的特征，我们必须首先将该区域中的图像数据转换为与CNN兼容的形式（其架构要求输入固定的227×227像素大小）。在任意形状区域的许多可能变换中，我们选择最简单的。无论候选区域的大小或宽高比如何，我们都会将其周围紧边界框中的所有像素扭曲为所需的大小。在扭曲之前，我们会展开紧边界框，以便在扭曲大小下，原始框周围正好有p个扭曲图像上下文像素（我们使用p=16）。图2显示了扭曲训练区域的随机抽样。附录A中讨论了扭曲的替代方案</p>
<p><img src="/imgs/具有CNN特征的区域/figure-2.png" alt></p>
<blockquote>
<p>Figure 2: Warped training samples from VOC 2007 train.</p>
</blockquote>
<p>图2：来自VOC 2007训练集的扭曲训练样本</p>
<h3 id="Test-time-detection"><a href="#Test-time-detection" class="headerlink" title="Test-time detection"></a>Test-time detection</h3><blockquote>
<p>At test time, we run selective search on the test image to extract around 2000 region proposals (we use selective search’s “fast mode” in all experiments). We warp each proposal and forward propagate it through the CNN in order to compute features. Then, for each class, we score each extracted feature vector using the SVM trained for that class. Given all scored regions in an image, we apply a greedy non-maximum suppression (for each class independently) that rejects a region if it has an intersection-over-union (IoU) overlap with a higher scoring selected region larger than a learned threshold.</p>
</blockquote>
<p>在测试时，我们对测试图像运行选择性搜索以提取大约2000个区域建议（我们在所有实验中使用选择性搜索的“快速模式”）。我们扭曲每一个建议并通过CNN计算特征。然后，对于每一类，我们使用为该类训练的支持向量机对提取的特征向量进行评分。给定图像中的所有得分区域，我们应用一个贪婪非最大抑制（对于每一个独立的类），如果它与得分较高的选择区域的并集重叠上的交集比学习到的阈值高，则拒绝该区域</p>
<blockquote>
<p><strong>Run-time analysis</strong>. Two properties make detection efficient. First, all CNN parameters are shared across all categories. Second, the feature vectors computed by the CNN are low-dimensional when compared to other common approaches, such as spatial pyramids with bag-of-visual-word encodings. The features used in the UVA detection system [39], for example, are two orders of magnitude larger than ours (360k vs. 4k-dimensional).</p>
</blockquote>
<p><strong>运行时分析</strong>。两个特性使检测更有效。首先，所有CNN参数在所有类别中共享。其次，与其他常用方法相比（例如带有视觉文字编码包的空间金字塔），CNN计算出的特征向量是低维的。例如在UVA检测系统中使用的特征[39]比我们的大两个数量级（360k vs. 4k维）</p>
<blockquote>
<p>The result of such sharing is that the time spent computing region proposals and features (13s/image on a GPU or 53s/image on a CPU) is amortized over all classes. The only class-specific computations are dot products between features and SVM weights and non-maximum suppression. In practice, all dot products for an image are batched into a single matrix-matrix product. The feature matrix is typically 2000×4096 and the SVM weight matrix is 4096×N, where N is the number of classes.</p>
</blockquote>
<p>这种共享的结果是，计算区域建议和特征（GPU上的13s/图像或CPU上的53s/图像）所花费的时间在所有类中分摊。唯一的类具体计算是特征和SVM权重和非最大抑制之间的点积。实际上，图像的所有点积都被批处理成一个矩阵积。特征矩阵一般为2000×4096，支持向量机权重矩阵为4096×N，其中N为类数</p>
<blockquote>
<p>This analysis shows that R-CNN can scale to thousands of object classes without resorting to approximate techniques, such as hashing. Even if there were 100k classes, the resulting matrix multiplication takes only 10 seconds on a modern multi-core CPU. This efficiency is not merely the result of using region proposals and shared features. The UVA system, due to its high-dimensional features, would be two orders of magnitude slower while requiring 134GB of memory just to store 100k linear predictors, compared to just 1.5GB for our lower-dimensional features.</p>
</blockquote>
<p>该分析表明，R-CNN可以扩展到数千个对象类，而不诉诸近似技术，例如散列。即使有10万个类，在现代多核CPU上，矩阵乘法也只需要10秒。这种效率不仅仅是使用区域建议和共享特征的结果。由于其高维特性，UVA系统的速度将慢两个数量级，同时需要134GB的内存来存储100k个线性预测值，而我们的低维特征只需要1.5GB</p>
<blockquote>
<p>It is also interesting to contrast R-CNN with the recent work from Dean et al. on scalable detection using DPMs and hashing [8]. They report a mAP of around 16% on VOC 2007 at a run-time of 5 minutes per image when introducing 10k distractor classes. With our approach, 10k detectors can run in about a minute on a CPU, and because no approximations are made mAP would remain at 59% (Section 3.2).</p>
</blockquote>
<p>将R-CNN与Dean等人最近的研究进行对比也很有趣。关于使用DPMs和散列的可伸缩检测[8]。在测试10k个不同类别时，他们在VOC 2007上有大约16% mAP，每张图片的运行时间为5分钟。用我们的方法，10k检测器可以在CPU上运行大约一分钟，并且因为没有近似，mAP将保持在59%（第3.2节）</p>
<h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>训练</p>
<blockquote>
<p><strong>Supervised pre-training</strong>. We discriminatively pre-trained the CNN on a large auxiliary dataset (ILSVRC2012 classification) using image-level annotations only (bounding-box labels are not available for this data). Pre-training was performed using the open source Caffe CNN library [24]. In brief, our CNN nearly matches the performance of Krizhevsky et al. [25], obtaining a top-1 error rate 2.2 percentage points higher on the ILSVRC2012 classification validation set. This discrepancy is due to simplifications in the training process.</p>
</blockquote>
<p><strong>监督预训练</strong>。我们预先在一个大的辅助数据集（ILVRC2012分类）训练CNN模型，仅使用图像级别注释（边界框标签不可用于此数据）。使用开源Caffe CNN库进行了预训练[24]。简而言之，我们的CNN几乎与Krizhevsky等人[25]的表现相吻合。在ILSVRC2012分类验证集上获得top-1错误率2.2个百分点。这种差异是由于训练过程中的简化造成的</p>
<blockquote>
<p><strong>Domain-specific fine-tuning</strong>. To adapt our CNN to the new task (detection) and the new domain (warped proposal windows), we continue stochastic gradient descent (SGD) training of the CNN parameters using only warped region proposals. Aside from replacing the CNN’s ImageNet-specific 1000-way classification layer with a randomly initialized (N + 1)-way classification layer (where N is the number of object classes, plus 1 for background), the CNN architecture is unchanged. For VOC, N = 20 and for ILSVRC2013, N = 200. We treat all region proposals with ≥ 0.5 IoU overlap with a ground-truth box as positives for that box’s class and the rest as negatives. We start SGD at a learning rate of 0.001 (1/10th of the initial pre-training rate), which allows fine-tuning to make progress while not clobbering the initialization. In each SGD iteration, we uniformly sample 32 positive windows (over all classes) and 96 background windows to construct a mini-batch of size 128. We bias the sampling towards positive windows because they are extremely rare compared to background.</p>
</blockquote>
<p><strong>领域特定微调</strong>。为了使我们的CNN适应新任务（检测）和新领域（扭曲建议窗口），仅使用扭曲区域建议图片来继续通过随机梯度下降（SGD）训练CNN参数。除了用一个随机初始化的（N+1）大小的分类层（其中N是对象类的数量，加上1作为背景）替换CNN的ImageNet特定的1000方式分类层之外，CNN的架构没有改变。对于VOC，N=20；对于ILSVRC2013，N=200。我们将所有与先验框的IoU重叠度大于等于0.5的区域提案视为类的正样本，其余的则视为负样本。我们以0.001的学习率（初始预训练率的1/10）开始SGD，这允许微调在不破坏初始化的情况下取得进展。在每次SGD迭代中，我们都会统一采样32个正窗口（在所有类上）和96个背景窗口，以构造大小为128的小批量</p>
<blockquote>
<p><strong>Object category classifiers</strong>. Consider training a binary classifier to detect cars. It’s clear that an image region tightly enclosing a car should be a positive example. Similarly, it’s clear that a background region, which has nothing to do with cars, should be a negative example. Less clear is how to label a region that partially overlaps a car. We resolve this issue with an IoU overlap threshold, below which regions are defined as negatives. The overlap threshold, 0.3, was selected by a grid search over {0, 0.1, . . . , 0.5} on a validation set. We found that selecting this threshold carefully is important. Setting it to 0.5, as in [39], decreased mAP by 5 points. Similarly, setting it to 0 decreased mAP by 4 points. Positive examples are defined simply to be the ground-truth bounding boxes for each class.</p>
</blockquote>
<p><strong>对象类别分类器</strong>。考虑训练一个二值分类器来检测汽车。很明显，紧紧包围汽车的图像区域应该是一个正样本。同样很明显，与汽车无关的背景区域应该是一个负样本。不太清楚的是如何标记与汽车部分重叠的区域。我们用IoU重叠阈值来解决这个问题，低于这个阈值的区域被定义为负样本。重叠阈值0.3是通过在验证集上网格搜索{0, 0.1, . . . , 0.5}选定的。我们发现仔细选择这个阈值很重要。设置为0.5，如[39]所示，mAP减少了5个点。类似地，将其设置为0会使mAP减少4个点。正样本被定义为每个类的先验边界框</p>
<blockquote>
<p>Once features are extracted and training labels are applied, we optimize one linear SVM per class. Since the training data is too large to fit in memory, we adopt the standard hard negative mining method [17, 37]. Hard negative mining converges quickly and in practice mAP stops increasing after only a single pass over all images.</p>
</blockquote>
<p>一旦特征被提取和训练标签被应用，我们可以逐类优化线性支持向量机。由于训练数据太大，无法存储，我们采用标准负样本挖掘方法[17，37]。负样本挖掘收敛很快，在实际应用中，只需一次遍历所有图像，mAP就会停止增长</p>
<blockquote>
<p>In Appendix B we discuss why the positive and negative examples are defined differently in fine-tuning versus SVM training. We also discuss the trade-offs involved in training detection SVMs rather than simply using the outputs from the final softmax layer of the fine-tuned CNN.</p>
</blockquote>
<p>在附录B中，我们讨论了为什么在微调和支持向量机训练中，正负样本的定义不同。我们还讨论了训练检测支持向量机所涉及的权衡，而不是简单地使用微调CNN的最终softmax层的输出</p>
<h3 id="Results-on-PASCAL-VOC-2010-12"><a href="#Results-on-PASCAL-VOC-2010-12" class="headerlink" title="Results on PASCAL VOC 2010-12"></a>Results on PASCAL VOC 2010-12</h3><p>PASCAL VOC 2010-12上的结果</p>
<blockquote>
<p>Following the PASCAL VOC best practices [15], we validated all design decisions and hyperparameters on the VOC 2007 dataset (Section 3.2). For final results on the VOC 2010-12 datasets, we fine-tuned the CNN on VOC 2012 train and optimized our detection SVMs on VOC 2012 trainval. We submitted test results to the evaluation server only once for each of the two major algorithm variants (with and without bounding-box regression).</p>
</blockquote>
<p>遵循PASCAL VOC最佳实践[15]，我们验证了VOC 2007数据集上的所有设计决策和超参数（第3.2节）。对于VOC 2010-12数据集的最终结果，我们在VOC 2012训练验证集上对CNN进行了微调，并在VOC 2012训练验证集上优化了SVM检测器。对于两个主要的算法变体，我们只向评估服务器提交一次测试结果（有和没有边界框回归）</p>
<blockquote>
<p>Table 1 shows complete results on VOC 2010. We compare our method against four strong baselines, including SegDPM [18], which combines DPM detectors with the output of a semantic segmentation system [4] and uses additional inter-detector context and image-classifier rescoring. The most germane comparison is to the UVA system from Uijlings et al. [39], since our systems use the same region proposal algorithm. To classify regions, their method builds a four-level spatial pyramid and populates it with densely sampled SIFT, Extended OpponentSIFT, and RGBSIFT descriptors, each vector quantized with 4000-word codebooks. Classification is performed with a histogram intersection kernel SVM. Compared to their multi-feature, non-linear kernel SVM approach, we achieve a large improvement in mAP, from 35.1% to 53.7% mAP, while also being much faster (Section 2.2). Our method achieves similar performance (53.3% mAP) on VOC 2011/12 test.</p>
</blockquote>
<p>表1显示了VOC 2010的完整结果。我们将我们的方法与四个强基准进行比较，包括SegDPM[18]，它将DPM检测器与语义分割系统的输出相结合[4]，并使用额外的检测器间上下文和图像分类器重分类。与Uijlings等人[39]的UVA系统进行了最密切的比较，因为我们的系统使用相同的区域建议算法。为了对区域进行分类，他们的方法构建了一个四层空间金字塔，并用密集采样的SIFT、扩展的OpponentSIFT和RGBSIFT描述符对其进行填充，每个向量用4000字码本进行量化。利用直方图交集核SVM进行分类。与它们的多特征、非线性核支持向量机方法相比，我们在mAP上取得了很大的改进，从35.1%提高到53.7%，同时也快得多（第2.2节）。我们的方法在VOC 2011/12测试中达到了类似的性能（53.3%mAP）</p>
<p><img src="/imgs/具有CNN特征的区域/table-1.png" alt></p>
<blockquote>
<p><strong>Table 1: Detection average precision (%) on VOC 2010 test.</strong> R-CNN is most directly comparable to UVA and Regionlets since all methods use selective search region proposals. Bounding-box regression (BB) is described in Section C. At publication time, SegDPM was the top-performer on the PASCAL VOC leaderboard. †DPM and SegDPM use context rescoring not used by the other methods.</p>
</blockquote>
<p><strong>表1:VOC 2010试验的检测平均精度百分比</strong>。R-CNN最直接地可与UVA和Regionlets进行比较，因为这些方法都使用选择性搜索区域建议。边界框回归（BB）在C节中描述。在出版的时候，SegDPM是PASCAL VOC排行榜上的佼佼者。†DPM和SegDPM使用其他方法未使用的上下文重新排序</p>
<h3 id="Results-on-ILSVRC2013-detection"><a href="#Results-on-ILSVRC2013-detection" class="headerlink" title="Results on ILSVRC2013 detection"></a>Results on ILSVRC2013 detection</h3><p>在ILSVRC2013检测上的结果</p>
<blockquote>
<p>We ran R-CNN on the 200-class ILSVRC2013 detection dataset using the same system hyperparameters that we used for PASCAL VOC. We followed the same protocol of submitting test results to the ILSVRC2013 evaluation server only twice, once with and once without bounding-box regression.</p>
</blockquote>
<p>我们在200类ILSVRC2013检测数据集上运行R-CNN，使用与PASCAL VOC相同的系统超参数。我们遵循相同的协议，只向ILSVRC2013评估服务器提交两次测试结果，一次使用边界框回归，一次不使用边界框回归</p>
<blockquote>
<p>Figure 3 compares R-CNN to the entries in the ILSVRC 2013 competition and to the post-competition OverFeat result [34]. R-CNN achieves a mAP of 31.4%, which is significantly ahead of the second-best result of 24.3% from OverFeat. To give a sense of the AP distribution over classes, box plots are also presented and a table of perclass APs follows at the end of the paper in Table 8. Most of the competing submissions (OverFeat, NEC-MU, UvA-Euvision, Toronto A, and UIUC-IFP) used convolutional neural networks, indicating that there is significant nuance in how CNNs can be applied to object detection, leading to greatly varying outcomes.</p>
</blockquote>
<p>图3将R-CNN与ILSVRC 2013比赛的参赛作品以及赛后的OverFeat成绩进行了比较[34]。R-CNN获得了31.4%的mAP，明显领先于OverFeat的24.3%的第二好成绩。为了了解AP在类上的分布，本文还提供了方框图，并在表8中的文章末尾给出了一个perclass AP表。大多数竞争对手（OverFeat、NEC-MU、UvA-Euvision、Toronto A和UIUC-IFP）都使用了卷积神经网络，这表明CNNs如何应用于目标检测存在显著的细微差别，这会导致结果差异很大</p>
<blockquote>
<p>In Section 4, we give an overview of the ILSVRC2013 detection dataset and provide details about choices that we made when running R-CNN on it.</p>
</blockquote>
<p>在第4节中，我们概述了ILSVRC2013检测数据集，并提供了有关在其上运行R-CNN时所做选择的详细信息</p>
<p><img src="/imgs/具有CNN特征的区域/figure-3.png" alt></p>
<blockquote>
<p><strong>Figure 3: (Left) Mean average precision on the ILSVRC2013 detection test set</strong>. Methods preceeded by <em> use outside training data (images and labels from the ILSVRC classification dataset in all cases). <em>*(Right) Box plots for the 200 average precision values per method</em></em>. A box plot for the post-competition OverFeat result is not shown because per-class APs are not yet available (per-class APs for R-CNN are in Table 8 and also included in the tech report source uploaded to arXiv.org; see R-CNN-ILSVRC2013-APs.txt). The red line marks the median AP, the box bottom and top are the 25th and 75th percentiles. The whiskers extend to the min and max AP of each method. Each AP is plotted as a green dot over the whiskers (best viewed digitally with zoom).</p>
</blockquote>
<p>图3:（左）ILSVRC2013检测测试集的平均精度。有<em>前缀的方法使用外部训练数据（图像和标签来自ILSVRC分类数据集）。<em>*（右）每个方法200个平均精度值的方框图</em></em>。未显示赛后OverFeat成绩的方框图，因为每类AP尚不可用（R-CNN的每类AP见表8，也包括在上传至arXiv.org的技术报告源中；见R-CNN-ILSVRC2013-APs.txt）。红线标记中间AP，方框底部和顶部是25%和75%。晶须延伸至每种方法的最小和最大AP。每个AP都被标绘为胡须上的绿点（最好用数码变焦观看）</p>
<h2 id="Visualization-ablation-and-modes-of-error"><a href="#Visualization-ablation-and-modes-of-error" class="headerlink" title="Visualization, ablation, and modes of error"></a>Visualization, ablation, and modes of error</h2><p>可视化、消融和误差模式</p>
<h3 id="Visualizing-learned-features"><a href="#Visualizing-learned-features" class="headerlink" title="Visualizing learned features"></a>Visualizing learned features</h3><p>可视化学习到的特征</p>
<blockquote>
<p>First-layer filters can be visualized directly and are easy to understand [25]. They capture oriented edges and opponent colors. Understanding the subsequent layers is more challenging. Zeiler and Fergus present a visually attractive deconvolutional approach in [42]. We propose a simple (and complementary) non-parametric method that directly shows what the network learned.</p>
</blockquote>
<p>第一层滤波器可以直接可视化，并且易于理解[25]。它们捕捉定向的边缘和相对颜色。理解随后的层更具挑战性。Zeiler和Fergus在[42]中提出了一种具有视觉吸引力的反卷积方法。我们提出一个简单的（互补的）非参数方法，直接显示网络所学的内容</p>
<blockquote>
<p>The idea is to single out a particular unit (feature) in the network and use it as if it were an object detector in its own right. That is, we compute the unit’s activations on a large set of held-out region proposals (about 10 million), sort the proposals from highest to lowest activation, perform nonmaximum suppression, and then display the top-scoring regions. Our method lets the selected unit “speak for itself” by showing exactly which inputs it fires on. We avoid averaging in order to see different visual modes and gain insight into the invariances computed by the unit.</p>
</blockquote>
<p>其思想是在网络中挑出一个特定的单元（特征），并将其作为一个对象检测器来使用。也就是说，我们在一组大的held-out区域建议（大约1000万）上计算单元的激活，将建议从最高到最低的排序，执行非最大抑制，然后显示最高得分区域。我们的方法通过精确显示所选单元触发的输入，让所选单元“为自己说话”。我们避免了平均化以便能够观察不同的视觉模式，并深入了解由单位计算的不变性</p>
<blockquote>
<p>We visualize units from layer $pool_{5}$ , which is the max-pooled output of the network’s fifth and final convolutional layer. The $pool_{5}$ feature map is 6 ×6×256 = 9216-dimensional. Ignoring boundary effects, each $pool_{5}$ unit has a receptive field of 195×195 pixels in the original 227×227 pixel input. A central $pool_{5}$ unit has a nearly global view, while one near the edge has a smaller, clipped support.</p>
</blockquote>
<p>我们将第5个池化层中的单元可视化，这是网络第五层也是最后一层卷积的最大池输出。第5个pool的特征图为6×6×256=9216维。忽略边界效应，每个$pool_{5}$的单元在原始227×227像素输入中具有195×195像素的感受野。中心$pool_{5}$单元有一个几乎全局的视图，而靠近边缘的单元有一个更小的剪裁支持</p>
<blockquote>
<p>Each row in Figure 4 displays the top 16 activations for a $pool_{5}$ unit from a CNN that we fine-tuned on VOC 2007 trainval. Six of the 256 functionally unique units are visualized (Appendix D includes more). These units were selected to show a representative sample of what the network learns. In the second row, we see a unit that fires on dog faces and dot arrays. The unit corresponding to the third row is a red blob detector. There are also detectors for human faces and more abstract patterns such as text and triangular structures with windows. The network appears to learn a representation that combines a small number of class-tuned features together with a distributed representation of shape, texture, color, and material properties. The subsequent fully connected layer fc6 has the ability to model a large set of compositions of these rich features.</p>
</blockquote>
<p>图4中的每一行显示了一个CNN的$pool_{5}$单元的前16个激活，我们在VOC 2007 trainval上对其进行了微调。256个功能独特的单元中有6个是可视化的（附录D包括更多）。这些单元被选出来展示网络学习的代表性样本。在第二行中，我们看到一个单元在狗脸和点阵列上激活。与第三行相对应的单元是一个红块探测器。此外，还有人脸检测器和更抽象的模式，如文本和带窗口的三角形结构。该网络似乎学习了一种表示法，该表示法将少数经过类调整的特征与形状、纹理、颜色和材质特性的分布式表示法结合起来。随后的完全连接层fc6能够模拟这些丰富特征的大量组合</p>
<p><img src="/imgs/具有CNN特征的区域/figure-4.png" alt></p>
<blockquote>
<p><strong>Figure 4: Top regions for six $pool_{5}$ units</strong>. Receptive fields and activation values are drawn in white. Some units are aligned to concepts, such as people (row 1) or text (4). Other units capture texture and material properties, such as dot arrays (2) and specular reflections (6).</p>
</blockquote>
<p><strong>图4：6个$pool_{5}$单元的顶部区域</strong>。感受野和激活值以白色绘制。一些单元与概念对齐，例如人（第1行）或文本（4）。其他单位捕捉纹理和材质属性，如点阵列（2）和镜面反射（6）</p>
<h3 id="Ablation-studies"><a href="#Ablation-studies" class="headerlink" title="Ablation studies"></a>Ablation studies</h3><p>消融研究</p>
<p><img src="/imgs/具有CNN特征的区域/table-2.png" alt></p>
<blockquote>
<p><strong>Table 2: Detection average precision (%) on VOC 2007 test</strong>. Rows 1-3 show R-CNN performance without fine-tuning. Rows 4-6 show results for the CNN pre-trained on ILSVRC 2012 and then fine-tuned (FT) on VOC 2007 trainval. Row 7 includes a simple bounding-box regression (BB) stage that reduces localization errors (Section C). Rows 8-10 present DPM methods as a strong baseline. The first uses only HOG, while the next two use different feature learning approaches to augment or replace HOG.</p>
</blockquote>
<p><strong>表2：在VOC 2007测试集上的检测平均精度</strong>。行1-3显示了没有微调的R-CNN性能。行4-6显示了在ILSVRC 2012上预训练，然后在VOC 2007上微调（FT）的结果。第7行包含了一个简单的边界框回归（BB），这样能够减少定位误差（参考附录C）。第8-10行使用DPM方法作为基准线。第一个仅使用HOG特征，另外两个使用不同的特征学习方法来扩充或者替换HOG</p>
<blockquote>
<p><strong>Performance layer-by-layer, without fine-tuning</strong>. To understand which layers are critical for detection performance, we analyzed results on the VOC 2007 dataset for each of the CNN’s last three layers. Layer $pool_{5}$ was briefly described in Section 3.1. The final two layers are summarized below.</p>
</blockquote>
<p><strong>逐层性能，无需微调</strong>。为了了解哪些层对检测性能至关重要，我们分析了CNN最后三层中每个层在VOC 2007数据集中的结果。第3.1节简要介绍了池化层5。最后两层总结如下</p>
<blockquote>
<p>Layer $fc_{6}$ is fully connected to $pool_{5}$. To compute features, it multiplies a 4096×9216 weight matrix by the $pool_{5}$ feature map (reshaped as a 9216-dimensional vector) and then adds a vector of biases. This intermediate vector is component-wise half-wave rectified (x ← max(0, x)).</p>
</blockquote>
<p>$fc_{6}$是全连接到$pool_{5}$的。通过计算$pool_{5}$特征图（变形为9216维向量）和4096x9216大小权重矩阵的乘积，并加上偏执向量，最终得到该层的特征</p>
<blockquote>
<p>We start by looking at results from the CNN without fine-tuning on PASCAL, i.e. all CNN parameters were pre-trained on ILSVRC 2012 only. Analyzing performance layer-by-layer (Table 2 rows 1-3) reveals that features from fc7 generalize worse than features from fc6. This means that 29%, or about 16.8 million, of the CNN’s parameters can be removed without degrading mAP. More surprising is that removing both fc7 and fc6 produces quite good results even though pool5 features are computed using only 6% of the CNN’s parameters. Much of the CNN’s representational power comes from its convolutional layers, rather than from the much larger densely connected layers. This finding suggests potential utility in computing a dense feature map, in the sense of HOG, of an arbitrary-sized image by using only the convolutional layers of the CNN. This representation would enable experimentation with sliding-window detectors, including DPM, on top of pool5 features.</p>
</blockquote>
<p>现在开始在PASCAL数据集上研究没有微调的CNN的实现结果，比如所有CNN参数仅在ILSVRC 2012上进行过预训练。逐层分析性能（表2 1-3行）发现fc7层的特征泛化效果低于fc6。这意味着在没有降低mAP的情况下减少了29%，大约1680万个CNN参数。更惊讶的是，同时移除fc7和fc6也能够得到很好的结果，即使pool5的特征仅占所有CNN参数的6%。更多的CNN表示能力来自于卷积层而不是更大的全连接层。这一发现表明，仅使用CNN的卷积层，就HOG的意义而言，在计算任意大小图像的稠密特征图方面具有潜在的实用性。这也让我们能够在pool5特征的基础上，对滑动窗口检测器（包括DPM）进行实验</p>
<blockquote>
<p><strong>Performance layer-by-layer, with fine-tuning</strong>. We now look at results from our CNN after having fine-tuned its parameters on VOC 2007 trainval. The improvement is striking (Table 2 rows 4-6): fine-tuning increases mAP by 8.0 percentage points to 54.2%. The boost from fine-tuning is much larger for fc6 and fc7 than for pool5 , which suggests that the pool5 features learned from ImageNet are general and that most of the improvement is gained from learning domain-specific non-linear classifiers on top of them.</p>
</blockquote>
<p><strong>经过微调后的性能优化</strong>。在利用VOC 2007训练验证集对CNN进行微调后，我们现在来看看结果。改进是惊人的（表2第4-6行）：微调将mAP提高了8.0个百分点，达到54.2%。微调对fc6和fc7的提升要比pool5大得多，这表明从ImageNet学习到的pool5特性是通用的，而且大部分改进都是通过在它们上面学习领域特定的非线性分类器获得的</p>
<blockquote>
<p>The first DPM feature learning method, DPM ST [28], augments HOG features with histograms of “sketch token” probabilities. Intuitively, a sketch token is a tight distribution of contours passing through the center of an image patch. Sketch token probabilities are computed at each pixel by a random forest that was trained to classify 35×35 pixel patches into one of 150 sketch tokens or background.</p>
</blockquote>
<p>第一种DPM特征学习方法DPM ST[28]使用“草图标记”概率直方图来增强HOG特征。直观地说，草图标记是通过图像块中心的轮廓的紧密分布。草图标记概率由一个随机森林在每个像素处计算，该森林被训练为将35×35个像素块分类为150个草图标记或背景中的一个</p>
<blockquote>
<p>The second method, DPM HSC [31], replaces HOG with histograms of sparse codes (HSC). To compute an HSC, sparse code activations are solved for at each pixel using a learned dictionary of 100 7 × 7 pixel (grayscale) atoms. The resulting activations are rectified in three ways (full and both half-waves), spatially pooled, unit $l_{2}$ normalized, and then power transformed ($x ← sign(x)|x|^{α}$).</p>
</blockquote>
<p>第二种方法DPM-HSC[31]用稀疏码直方图（HSC）代替HOG。为了计算HSC，使用100个7×7像素（灰度）原子的学习字典来求解每个像素处的稀疏代码激活。由此产生的激活以三种方式（全波和半波）校正，空间合并，单位$l_{2}$标准化，然后进行功率变换（$x ← sign(x)|x|^{α}$）</p>
<blockquote>
<p>All R-CNN variants strongly outperform the three DPM baselines (Table 2 rows 8-10), including the two that use feature learning. Compared to the latest version of DPM, which uses only HOG features, our mAP is more than 20 percentage points higher: 54.2% vs. 33.7%—a 61% relative improvement. The combination of HOG and sketch tokens yields 2.5 mAP points over HOG alone, while HSC improves over HOG by 4 mAP points (when compared internally to their private DPM baselines—both use nonpublic implementations of DPM that underperform the open source version [20]). These methods achieve mAPs of 29.1% and 34.3%, respectively.</p>
</blockquote>
<p>所有R-CNN变体都强于三个DPM基线（表2第8-10行），包括使用功能学习的两个基线。与只使用HOG特性的DPM的最新版本相比，我们的mAP高出了20个百分点：54.2%对33.7%，相对提高了61%。HOG和sketch令牌的组合仅比HOG提高了2.5个mAP，而HSC比HOG提高了4个mAP（与它们的私有DPM基线相比，它们都使用了性能低于开源版本[20]的DPM的非公开实现）。这些方法分别得到29.1%和34.3%的图mAP</p>
<h3 id="Network-architectures"><a href="#Network-architectures" class="headerlink" title="Network architectures"></a>Network architectures</h3><p>网络架构</p>
<blockquote>
<p>Most results in this paper use the network architecture from Krizhevsky et al. [25]. However, we have found that the choice of architecture has a large effect on R-CNN detection performance. In Table 3 we show results on VOC 2007 test using the 16-layer deep network recently proposed by Simonyan and Zisserman [43]. This network was one of the top performers in the recent ILSVRC 2014 classification challenge. The network has a homogeneous structure consisting of 13 layers of 3 × 3 convolution kernels, with five max pooling layers interspersed, and topped with three fully-connected layers. We refer to this network as “O-Net” for OxfordNet and the baseline as “T-Net” for TorontoNet.</p>
</blockquote>
<p>本文中的大多数结果使用了Krizhevsky等人[25]的网络结构。然而，我们发现结构的选择对R-CNN的检测性能有很大的影响。在表3中，我们展示了使用Simonyan和Zisserman最近提出的16层深度网络进行的VOC 2007测试的结果[43]。该网络是最近ILSVRC 2014分类挑战赛中表现最好的网络之一。该网络结构由13层3×3卷积核组成，中间穿插5个最大池化层，顶部为3个完全连通层。我们把这个网络称为OxfordNet的“O-Net”，把TorontoNet的基线称为“T-Net”</p>
<p><img src="/imgs/具有CNN特征的区域/table-3.png" alt></p>
<blockquote>
<p>Table 3: Detection average precision (%) on VOC 2007 test for two different CNN architectures. The first two rows are results from Table 2 using Krizhevsky et al.’s architecture (T-Net). Rows three and four use the recently proposed 16-layer architecture from Simonyan and Zisserman (O-Net) [43].</p>
</blockquote>
<p><strong>表3：使用两种不同的CNN架构在VOC 2007上的检测平均精度（%）</strong>。前两行是表2使用Krizhevsky等人的架构（T-Net）得出的结果。第3行和第4行使用了Simonyan和Zisserman（O-Net）最近提出的16层体系结构[43]</p>
<blockquote>
<p>To use O-Net in R-CNN, we downloaded the publicly available pre-trained network weights for the VGG ILSVRC 16 layers model from the Caffe Model Zoo. We then fine-tuned the network using the same protocol as we used for T-Net. The only difference was to use smaller minibatches (24 examples) as required in order to fit within GPU memory. The results in Table 3 show that R-CNN with O-Net substantially outperforms R-CNN with T-Net, increasing mAP from 58.5% to 66.0%. However there is a considerable drawback in terms of compute time, with the forward pass of O-Net taking roughly 7 times longer than T-Net.</p>
</blockquote>
<p>为了在R-CNN中使用O-Net，我们从Caffe model Zoo下载了VGG ILSVRC 16层模型的公共预训练网络权重。然后，我们使用与T-Net相同的协议对网络进行微调。唯一的区别是根据需要使用更小的小批量（24个示例），以便适合GPU内存。表3的结果表明，使用O-Net的R-CNN明显优于使用T-Net的R-CNN，mAP从58.5%增加到66.0%。然而，在计算时间方面有一个相当大的缺点，即O-Net的前向通过时间大约是T-Net的7倍</p>
<h3 id="Detection-error-analysis"><a href="#Detection-error-analysis" class="headerlink" title="Detection error analysis"></a>Detection error analysis</h3><p>检测误差分析</p>
<blockquote>
<p>We applied the excellent detection analysis tool from Hoiem et al. [23] in order to reveal our method’s error modes, understand how fine-tuning changes them, and to see how our error types compare with DPM. A full summary of the analysis tool is beyond the scope of this paper and we encourage readers to consult [23] to understand some finer details (such as “normalized AP”). Since the analysis is best absorbed in the context of the associated plots, we present the discussion within the captions of Figure 5 and Figure 6.</p>
</blockquote>
<p>我们使用了Hoiem等人[23]优秀的检测分析工具。为了揭示我们方法的错误模式，理解微调如何更改它们，并查看我们的错误类型与DPM的比较。对分析工具的全面总结超出了本文的范围，我们鼓励读者参考[23]以了解一些更详细的信息（例如“规范化AP”）。由于分析最好是在相关图的上下文中进行，因此我们在图5和图6的标题中进行讨论</p>
<h3 id="Qualitative-results"><a href="#Qualitative-results" class="headerlink" title="Qualitative results"></a>Qualitative results</h3><p>定性结果</p>
<blockquote>
<p>Qualitative detection results on ILSVRC2013 are presented in Figure 8 and Figure 9 at the end of the paper. Each image was sampled randomly from the val2 set and all detections from all detectors with a precision greater than 0.5 are shown. Note that these are not curated and give a realistic impression of the detectors in action. More qualitative results are presented in Figure 10 and Figure 11, but these have been curated. We selected each image because it contained interesting, surprising, or amusing results. Here, also, all detections at precision greater than 0.5 are shown.</p>
</blockquote>
<p>ILSVRC2013的定性检测结果如文末图8和图9所示。每个图像从val2集合中随机采样，显示所有检测器精度大于0.5的所有检测结果。请注意，这些没有经过挑选。更多的定性结果如图10和图11所示，但这些结果已得到处理。我们选择每个图像是因为它包含有趣、令人惊讶或有趣的结果。这里还显示了精度大于0.5的所有检测</p>
<h2 id="The-ILSVRC2013-detection-dataset"><a href="#The-ILSVRC2013-detection-dataset" class="headerlink" title="The ILSVRC2013 detection dataset"></a>The ILSVRC2013 detection dataset</h2><p>ILSVRC2013检测数据集</p>
<blockquote>
<p>In Section 2 we presented results on the ILSVRC2013 detection dataset. This dataset is less homogeneous than PASCAL VOC, requiring choices about how to use it. Since these decisions are non-trivial, we cover them in this section.</p>
</blockquote>
<p>在第2节中，我们介绍了ILSVRC2013检测数据集的结果。这个数据集不如PASCAL VOC同质，需要选择如何使用它。由于这些决定是有意义的，我们将在本节介绍它们</p>
<h3 id="Dataset-overview"><a href="#Dataset-overview" class="headerlink" title="Dataset overview"></a>Dataset overview</h3><p>数据集概述</p>
<blockquote>
<p>The ILSVRC2013 detection dataset is split into three sets: train (395,918), val (20,121), and test (40,152), where the number of images in each set is in parentheses. The val and test splits are drawn from the same image distribution. These images are scene-like and similar in complexity (number of objects, amount of clutter, pose variability, etc.) to PASCAL VOC images. The val and test splits are exhaustively annotated, meaning that in each image all instances from all 200 classes are labeled with bounding boxes. The train set, in contrast, is drawn from the ILSVRC2013 classification image distribution. These images have more variable complexity with a skew towards images of a single centered object. Unlike val and test, the train images (due to their large number) are not exhaustively annotated. In any given train image, instances from the 200 classes may or may not be labeled. In addition to these image sets, each class has an extra set of negative images. Negative images are manually checked to validate that they do not contain any instances of their associated class. The negative image sets were not used in this work. More information on how ILSVRC was collected and annotated can be found in [11, 36].</p>
</blockquote>
<p>ILSVRC2013检测数据集分为三组：train（395918）、val（20121）和test（40152），每组中的图像数在括号中。val和test分割是从相同的图像分布中提取的。这些图像在PASCAL VOC图像中是复杂的（对象数量、杂波、姿态变化等）。val和test split是完全注释的，这意味着在每个图像中，所有200个类的所有实例都用边界框标记。相反，训练集是从ILSVRC2013分类图像分布中提取的。 这些图像具有更多的可变复杂度，歪斜朝向单个中心对象的图像。与val和test不同，训练图像（由于其数量庞大）没有完全注释。在任何给定的训练图像中，来自200个类的实例可以被标记，也可以不被标记。除了这些图像集之外，每个类还有一组额外的负样本图像。手动检查负样本图像，以验证它们不包含其关联类的任何实例。这项工作没有使用负样本图像集。关于ILSVRC是如何收集和注释的更多信息可以在[11，36]中找到</p>
<blockquote>
<p>The nature of these splits presents a number of choices for training R-CNN. The train images cannot be used for hard negative mining, because annotations are not exhaustive. Where should negative examples come from? Also, the train images have different statistics than val and test. Should the train images be used at all, and if so, to what extent? While we have not thoroughly evaluated a large number of choices, we present what seemed like the most obvious path based on previous experience.</p>
</blockquote>
<p>这些分离的性质为训练R-CNN提供了许多选择。训练图像不能用于hard negative mining，因为标注不完全。负样本应该从哪里来另外，训练图像与val和test有不同的统计特性。训练图像应该被使用吗？如果是的话，使用到什么程度？虽然我们没有对大量的选择进行彻底的评估，但根据以往的经验，我们提出了似乎是最明显的途径</p>
<blockquote>
<p>Our general strategy is to rely heavily on the val set and use some of the train images as an auxiliary source of positive examples. To use val for both training and validation, we split it into roughly equally sized “val1” and “val2” sets. Since some classes have very few examples in val (the smallest has only 31 and half have fewer than 110), it is important to produce an approximately class-balanced partition. To do this, a large number of candidate splits were generated and the one with the smallest maximum relative class imbalance was selected.2 Each candidate split was generated by clustering val images using their class counts as features, followed by a randomized local search that may improve the split balance. The particular split used here has a maximum relative imbalance of about 11% and a median relative imbalance of 4%. The val1/val2 split and code used to produce them will be publicly available to allow other researchers to compare their methods on the val splits used in this report.</p>
</blockquote>
<p>我们的总体策略是严重依赖于验证集，并使用一些训练图像作为正样本的辅助来源。为了使用val进行训练和验证，我们将其分成大小大致相同的“val1”和“val2”集。由于一些类在var中的例子很少（最小的只有31，有一半类小于110），因此产生一个近似的类平衡分区是很重要的。为此，生成了大量的候选分割，并选择了最小的相对最大类失衡的2个候选分割，通过使用类计数作为特征来聚类val图像生成每个候选分割，然后通过随机化局部搜索来改善分割平衡。这里使用的特定分割具有最大相对不平衡约11%和中值相对不平衡4%。val1/val2拆分和用于生成它们的代码将公开，以便其他研究人员可以比较他们在本报告中使用的val拆分方法</p>
<h3 id="Region-Proposals"><a href="#Region-Proposals" class="headerlink" title="Region Proposals"></a>Region Proposals</h3><p>区域建议</p>
<blockquote>
<p>We followed the same region proposal approach that was used for detection on PASCAL. Selective search [39] was run in “fast mode” on each image in val1, val2, and test (but not on images in train). One minor modification was required to deal with the fact that selective search is not scale invariant and so the number of regions produced depends on the image resolution. ILSVRC image sizes range from very small to a few that are several mega-pixels, and so we resized each image to a fixed width (500 pixels) before running selective search. On val, selective search resulted in an average of 2403 region proposals per image with a 91.6% recall of all ground-truth bounding boxes (at 0.5 IoU threshold). This recall is notably lower than in PASCAL, where it is approximately 98%, indicating significant room for improvement in the region proposal stage.</p>
</blockquote>
<p>我们遵循了用于PASCAL检测的相同区域建议方法。选择性搜索[39]在val1、val2和test中的每个图像上以“快速模式”运行（但不在训练中的图像上）。为了解决选择性搜索不具有尺度不变性的问题，需要做一个小的修改，因此产生的区域数取决于图像的分辨率。ILSVRC图像的大小从很小到几兆像素不等，因此在运行选择性搜索之前，我们将每个图像的大小调整为固定宽度（500像素）。 在val上，选择性搜索平均每幅图像产生2403个区域建议，91.6%的ground-truth边界框召回率（IoU阈值为0.5）。这一召回率明显低于PASCAL，约为98%，表明在区域建议阶段有很大的改进空间</p>
<p>…<br>…<br>…<br>…</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><blockquote>
<p>In recent years, object detection performance had stagnated. The best performing systems were complex ensembles combining multiple low-level image features with high-level context from object detectors and scene classifiers. This paper presents a simple and scalable object detection algorithm that gives a 30% relative improvement over the best previous results on PASCAL VOC 2012.</p>
</blockquote>
<p>近年来，目标检测性能停滞不前。性能最好的系统是将多个低级图像特征与来自目标检测器和场景分类器的高级上下文结合起来的复杂集合。本文提出了一种简单且可扩展的目标检测算法，与PASCAL VOC 2012上的最佳结果相比，相对提高了30%</p>
<blockquote>
<p>We achieved this performance through two insights. The first is to apply high-capacity convolutional neural networks to bottom-up region proposals in order to localize and segment objects. The second is a paradigm for training large CNNs when labeled training data is scarce. We show that it is highly effective to pre-train the network - with supervision - for a auxiliary task with abundant data (image classification) and then to fine-tune the network for the target task where data is scarce (detection). We conjecture that the “supervised pre-training/domain-specific finetuning” paradigm will be highly effective for a variety of data-scarce vision problems.</p>
</blockquote>
<p>我们通过两个观点实现了这一性能。首先，将大容量卷积神经网络应用于自下而上的区域建议，以便对对象进行定位和分割。第二种是在标记训练数据稀少的情况下训练大型CNN的范例。我们表明在数据稀缺的情况下，通过预训练网络，然后微调网络的目标任务是很有效的。我们推测“有监督的预训练/领域特定精细调整”范式对于各种数据稀缺的视觉问题将是非常有效的</p>
<blockquote>
<p>We conclude by noting that it is significant that we achieved these results by using a combination of classical tools from computer vision and deep learning (bottom-up region proposals and convolutional neural networks). Rather than opposing lines of scientific inquiry, the two are natural and inevitable partners.</p>
</blockquote>
<p>最后，我们注意到，通过使用计算机视觉和深度学习（自下而上的区域建议和卷积神经网络）的经典工具的组合来实现这些结果是非常重要的。这两者不是科学探究的界限，而是自然和不可避免的合作伙伴</p>
<h2 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h2><p>附录</p>
<h3 id="Object-proposal-transformations"><a href="#Object-proposal-transformations" class="headerlink" title="Object proposal transformations"></a>Object proposal transformations</h3><p>目标建议转换</p>
<p><img src="/imgs/具有CNN特征的区域/figure-7.png" alt></p>
<blockquote>
<p>Figure 7: Different object proposal transformations. (A) the original object proposal at its actual scale relative to the transformed CNN inputs; (B) tightest square with context; (C) tightest square without context; (D) warp. Within each column and example proposal, the top row corresponds to p = 0 pixels of context padding while the bottom row has p = 16 pixels of context padding.</p>
</blockquote>
<p>图7：不同的目标建议转换。（A）相对于转换后的CNN输入，其实际规模的原始目标建议；（B）结合背景的最紧正方形；（C）不结合背景的最紧正方形；（D）扭曲。在每列和示例建议中，第一行对应于p=0像素的上下文填充，而第二行对应于p=16像素的上下文填充</p>
<blockquote>
<p>The convolutional neural network used in this work requires a fixed-size input of 227 × 227 pixels. For detection, we consider object proposals that are arbitrary image rectangles. We evaluated two approaches for transforming object proposals into valid CNN inputs.</p>
</blockquote>
<p>本文所使用的卷积神经网络需要227×227像素的固定大小输入。对于检测，我们考虑的对象建议是任意图像矩形。我们评估了将目标建议转换为有效CNN输入的两种方法</p>
<blockquote>
<p>The first method (“tightest square with context”) encloses each object proposal inside the tightest square and then scales (isotropically) the image contained in that square to the CNN input size. Figure 7 column (B) shows this transformation. A variant on this method (“tightest square without context”) excludes the image content that surrounds the original object proposal. Figure 7 column (C) shows this transformation. The second method (“warp”) anisotropically scales each object proposal to the CNN input size. Figure 7 column (D) shows the warp transformation.</p>
</blockquote>
<p>第一种方法（“带上下文的最紧密的正方形”）将每个对象建议包含在最紧密的正方形中，然后（各向同性地）将该正方形中包含的图像缩放到CNN输入大小。 图7（B）列显示了这种转换。此方法的变体（“没有上下文的最紧正方形”）排除围绕原始对象方案的图像内容。图7（C）列显示了这种转换。第二种方法（“warp”）各向异性地将每个对象方案缩放到CNN输入大小。图7（D）列显示了扭曲变换</p>
<blockquote>
<p>For each of these transformations, we also consider including additional image context around the original object proposal. The amount of context padding (p) is defined as a border size around the original object proposal in the transformed input coordinate frame. Figure 7 shows p = 0 pixels in the top row of each example and p = 16 pixels in the bottom row. In all methods, if the source rectangle extends beyond the image, the missing data is replaced with the image mean (which is then subtracted before inputing the image into the CNN). A pilot set of experiments showed that warping with context padding (p = 16 pixels) outperformed the alternatives by a large margin (3-5 mAP points). Obviously more alternatives are possible, including using replication instead of mean padding. Exhaustive evaluation of these alternatives is left as future work.</p>
</blockquote>
<p>对于这些转换中的每一个，我们还考虑在原始对象方案周围包含额外的图像上下文。上下文填充量（p）定义为转换后的输入坐标框中原始对象建议周围的边框大小。图7显示了每个示例的顶行中的p=0像素和底行中的p=16像素。在所有方法中，如果源矩形超出图像，则用图像平均值替换丢失的数据（然后在将图像输入CNN之前减去图像平均值）。一组试验表明，使用上下文填充（p=16像素）进行扭曲比使用其他方法（3-5个mAP）的效果好得多。显然还有更多的选择，包括使用复制而不是平均填充。对这些备选方案的详尽评估将留待以后的工作</p>
<h3 id="Positive-vs-negative-examples-and-softmax"><a href="#Positive-vs-negative-examples-and-softmax" class="headerlink" title="Positive vs. negative examples and softmax"></a>Positive vs. negative examples and softmax</h3><p>正样本 vs. 负样本 和softmax</p>
<blockquote>
<p>Two design choices warrant further discussion. The first is: Why are positive and negative examples defined differently for fine-tuning the CNN versus training the object detection SVMs? To review the definitions briefly, for fine-tuning we map each object proposal to the ground-truth instance with which it has maximum IoU overlap (if any) and label it as a positive for the matched ground-truth class if the IoU is at least 0.5. All other proposals are labeled “background” (i.e., negative examples for all classes). For training SVMs, in contrast, we take only the ground-truth boxes as positive examples for their respective classes and label proposals with less than 0.3 IoU overlap with all instances of a class as a negative for that class. Proposals that fall into the grey zone (more than 0.3 IoU overlap, but are not ground truth) are ignored.</p>
</blockquote>
<p>有两种设计选择值得进一步讨论。第一个问题是：为什么对于微调CNN和训练目标检测支持向量机，正负样本的定义不同？为了简要地回顾这些定义，为了微调，我们将每个目标建议映射到其具有最大IOU重叠（如果有的话）的ground-truth实例，并且如果IoU至少为0.5，才将其标记为匹配的ground-truth类的正样本。所有其他建议都标为“背景”（即所有类别的负样本）。相比之下，对于SVM的培训，我们仅将ground-truth框作为其各自类的正样本，并将IoU重叠小于0.3的建议与类的所有实例标记为该类的负样本。属于灰色地带的提案（IoU重叠超过0.3，但不是ground-truth）被忽略</p>
<blockquote>
<p>Our hypothesis is that this difference in how positives and negatives are defined is not fundamentally important and arises from the fact that fine-tuning data is limited. Our current scheme introduces many “jittered” examples (those proposals with overlap between 0.5 and 1, but not ground truth), which expands the number of positive examples by approximately 30x. We conjecture that this large set is needed when fine-tuning the entire network to avoid overfitting. However, we also note that using these jittered examples is likely suboptimal because the network is not being fine-tuned for precise localization.</p>
</blockquote>
<p>我们的假设是，正样本和负样本的定义方式上的这种差异并不是根本上重要的，而是因为微调数据是有限的。我们目前的方案引入了许多“抖动”的例子（那些重叠在0.5和1之间的建议，但不是ground truth），它将正面例子的数量扩大了大约30x。我们推测在对整个网络进行微调以避免过度拟合时，需要这个大集合。然而，我们也注意到，使用这些不稳定的例子可能是次优的，因为网络并没有为精确的定位进行微调</p>
<blockquote>
<p>This leads to the second issue: Why, after fine-tuning, train SVMs at all? It would be cleaner to simply apply the last layer of the fine-tuned network, which is a 21-way softmax regression classifier, as the object detector. We tried this and found that performance on VOC 2007 dropped from 54.2% to 50.9% mAP. This performance drop likely arises from a combination of several factors including that the definition of positive examples used in fine-tuning does not emphasize precise localization and the softmax classifier was trained on randomly sampled negative examples rather than on the subset of “hard negatives” used for SVM training.</p>
</blockquote>
<p>这就引出了第二个问题：在微调之后，为什么还要训练SVM？简单地将微调网络的最后一层（21类Softmax回归分类器）用作目标检测器会更干净。我们尝试了一下，发现VOC 2007的性能从54.2%下降到了50.9%。这种性能下降可能是多种因素共同作用的结果，包括微调中使用的正样本的定义不强调精确定位，并且softmax分类器是在随机抽样的负样本上训练的，而不是在用于支持向量机训练的“hard positives”子集上训练的</p>
<blockquote>
<p>This result shows that it’s possible to obtain close to the same level of performance without training SVMs after fine-tuning. We conjecture that with some additional tweaks to fine-tuning the remaining performance gap may be closed. If true, this would simplify and speed up R-CNN training with no loss in detection performance.</p>
</blockquote>
<p>结果表明，经过微调后，无需对支持向量机进行训练，就可以获得接近相同水平的性能。我们推测，通过一些额外的微调，可以缩小剩余的性能差距。如果是真的，这将简化和加速R-CNN训练，而不会损失检测性能</p>
<h3 id="Bounding-box-regression"><a href="#Bounding-box-regression" class="headerlink" title="Bounding-box regression"></a>Bounding-box regression</h3><p>边界框回归</p>
<blockquote>
<p>We use a simple bounding-box regression stage to improve localization performance. After scoring each selective search proposal with a class-specific detection SVM, we predict a new bounding box for the detection using a class-specific bounding-box regressor. This is similar in spirit to the bounding-box regression used in deformable part models [17]. The primary difference between the two approaches is that here we regress from features computed by the CNN, rather than from geometric features computed on the inferred DPM part locations.</p>
</blockquote>
<p>我们使用一个简单的边界框回归阶段来提高定位性能。在用类特定的检测支持向量机对每个选择性搜索方案进行评分后，我们使用类特定的边界框回归器预测新的检测边界框。这在定义上类似于可变形零件模型中使用的边界框回归[17]。这两种方法的主要区别在于，这里我们从CNN计算的特征回归，而不是从根据推断的DPM零件位置计算的几何特征回归</p>
<blockquote>
<p>The input to our training algorithm is a set of N training pairs ${(P^{i}, G^{i})}_{i=1,…,N}$, where $P^{i}=(P^{i}_{x}, P^{i}_{y}, P^{i}_{w}, P^{i}_{h})$ specifies the pixel coordinates of the center of proposal $P^{i}$’s bounding box together with $P^{i}$’s width and height in pixels. Hence forth, we drop the superscript i unless it is needed. Each ground-truth bounding box G is specified in the same way: $G = (G_{x}, G_{y}, G_{w}, G_{h})$. Our goal is to learn a transformation that maps a proposed box P to a ground-truth box G.</p>
</blockquote>
<p>我们训练算法的输入是N个训练对${(P^{i}, G^{i})}_{i=1,…,N}$，其中$P^{i}=(P^{i}_{x}, P^{i}_{y}, P^{i}_{w}, P^{i}_{h})$，指定了建议$P^{i}$的中心像素坐标，以及$P^{i}$的宽和高。因此，除非需要，否则我们删除上标i。以相同的方式指定每个ground-truth边界框G：$G = (G_{x}, G_{y}, G_{w}, G_{h})$。我们的目标是学习将一个建议框$P$映射到一个ground-truth框G的转换</p>
<blockquote>
<p>We parameterize the transformation in terms of four functions $d_{x}(P), d_{y}(P), d_{w}(P), d_{h}(P)$. The first two specify a scale-invariant translation of the center of P’s bounding box, while the second two specify log-space translations of the width and height of P’s bounding box. After learning these functions, we can transform an input proposal P into a predicted ground-truth box $\hat{G}$ by applying the transformation</p>
</blockquote>
<p>我们将转换参数化为四个函数$d_{x}(P), d_{y}(P), d_{w}(P), d_{h}(P)$。前两个指定P的边界框中心的缩放不变平移，而后两个指定P的边界框宽度和高度的log空间平移。在学习这些函数之后，我们可以通过应用转换将输入建议P转换为预测的ground-truth框$\hat{G}$</p>
<p><img src="/imgs/具有CNN特征的区域/formula-1.png" alt></p>
<blockquote>
<p>Each function $d_{\star }(P)$ (where $\star $ is one of x, y, h, w) is modeled as a linear function of the pool5 features of proposal P, denoted by $\varnothing_{5}(P)$. (The dependence of $\varnothing_{5}(P)$ on the image data is implicitly assumed.) Thus we have $d_{\star }(P) = w^{T}_{\star} \varnothing_{5}(P)$, where $w_{\star }$ is a vector of learnable model parameters. We learn $w_{\star }$ by optimizing the regularized least squares objective (ridge regression):</p>
</blockquote>
<p>每个函数$d_{\star }(P)$被建模为建议P输入到模型的第5层池化层pool5的特征的线性函数，命名为$\varnothing_{5}(P)$（$\varnothing_{5}(P)$在图像数据中的依赖被隐式假定了）。因此，$d_{\star }(P) = w^{T}_{\star} \varnothing_{5}(P)$，其中$w_{\star }$是可学习模型参数的向量。通过优化正则化最小二乘目标（岭回归）来学习$w_{\star }$</p>
<p><img src="/imgs/具有CNN特征的区域/formula-2.png" alt></p>
<p>The regression targets $t_{\star }$ for the training pair (P, G) are defined as</p>
<p>训练对(p,G)的回归目标$t_{\star }$定义如下：</p>
<p><img src="/imgs/具有CNN特征的区域/formula-3.png" alt></p>
<blockquote>
<p>As a standard regularized least squares problem, this can be solved efficiently in closed form.</p>
</blockquote>
<p>作为一个标准的正则化最小二乘问题，它可以有效地用封闭形式求解</p>
<blockquote>
<p>We found two subtle issues while implementing bounding-box regression. The first is that regularization is important: we set λ = 1000 based on a validation set. The second issue is that care must be taken when selecting which training pairs (P, G) to use. Intuitively, if P is far from all ground-truth boxes, then the task of transforming P to a ground-truth box G does not make sense. Using examples like P would lead to a hopeless learning problem. Therefore, we only learn from a proposal P if it is nearby at least one ground-truth box. We implement “nearness” by assigning P to the ground-truth box G with which it has maximum IoU overlap (in case it overlaps more than one) if and only if the overlap is greater than a threshold (which we set to 0.6 using a validation set). All unassigned proposals are discarded. We do this once for each object class in order to learn a set of class-specific bounding-box regressors.</p>
</blockquote>
<p>在实现边界框回归时，我们发现了两个微妙的问题。首先，正则化很重要：我们基于验证集设置λ=1000。第二个问题是，在选择要使用的训练对（P，G）时必须小心。直观地说，如果P远离所有的真样本框，那么将P转换为真真值框G的任务就没有意义。使用像P这样的例子会导致一个无望的学习问题。因此，我们只能从一个方案P中学习，如果它至少在一个真样本框附近。我们实现“接近”通过分配P到真样本框G，当它和仅当重叠大于阈值（使用验证集设置为0.6）时，它具有最大的IoU重叠（某些情况下它重叠不止一个）。所有未分配的建议都将被丢弃。我们对每个对象类执行一次此操作，以便学习一组特定于类的边界框回归器</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>图像处理</category>
        <category>深度学习</category>
        <category>机器学习</category>
        <category>卷积神经网络</category>
        <category>翻译</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>AlexNet</tag>
        <tag>选择性搜索</tag>
        <tag>R-CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>颜色空间小结(RGB/YUV/HSV/Lab/...)</title>
    <url>/posts/cc213461.html</url>
    <content><![CDATA[<p>经常需要在不同的颜色空间下进行图像处理</p><h2 id="颜色空间"><a href="#颜色空间" class="headerlink" title="颜色空间"></a>颜色空间</h2><p>参考：</p><p><a href="https://baike.baidu.com/item/%E9%A2%9C%E8%89%B2%E7%A9%BA%E9%97%B4" target="_blank" rel="noopener">颜色空间</a></p><p><a href="https://zh.wikipedia.org/wiki/%E8%89%B2%E5%BD%A9%E7%A9%BA%E9%96%93" target="_blank" rel="noopener">色彩空間</a></p><blockquote>
<p>颜色空间（color space），又称为颜色模型（color model），是坐标系统和子空间的阐述，位于系统的每种颜色都有单个点表示</p>
</blockquote><a id="more"></a>




<p>换句话说，所有颜色都被颜色空间进行编码，每种颜色都可以使用基于该颜色模型的一组数字来描述。常用的颜色空间有：</p>
<ul>
<li><code>RGB</code></li>
<li><code>YUV</code></li>
<li><code>HSV</code></li>
<li><code>Lab</code></li>
</ul>
<h2 id="RGB"><a href="#RGB" class="headerlink" title="RGB"></a>RGB</h2><p>参考：</p>
<p><a href="https://baike.baidu.com/item/RGB" target="_blank" rel="noopener">RGB</a></p>
<p><a href="https://en.wikipedia.org/wiki/RGB_color_model#Color_depth" target="_blank" rel="noopener">RGB color model</a></p>
<p><code>RGB</code>颜色模型是一种加法颜色模型，其中红色、绿色和蓝色的光以各种方式相加以得到广泛的颜色阵列。模型的名称来自三种附加原色（红色、绿色和蓝色）的首字母。其主要作用于各种显示器（电脑/摄像机/手机等等）</p>
<p>用于<code>RGB</code>颜色的总位数通常称为颜色深度（<code>color depth</code>），每种颜色通常有<code>1、2、4、5、8</code>和<code>16</code>位编码</p>
<h2 id="YUV"><a href="#YUV" class="headerlink" title="YUV"></a>YUV</h2><p>参考：<a href="https://blog.csdn.net/u012005313/article/details/70304922" target="_blank" rel="noopener">YUV2RGB Opencv</a></p>
<h2 id="HSV"><a href="#HSV" class="headerlink" title="HSV"></a>HSV</h2><p>参考：</p>
<p><a href="https://en.wikipedia.org/wiki/HSL_and_HSV" target="_blank" rel="noopener">HSL and HSV</a></p>
<p><a href="https://baike.baidu.com/item/HSV/547122" target="_blank" rel="noopener">HSV （HSV颜色模型）</a></p>
<p><a href="https://blog.csdn.net/u012005313/article/details/46678883" target="_blank" rel="noopener">opencv HSV 颜色模型(H通道取值 &amp;&amp; CV_BGR2HSV＿FULL)</a></p>
<p><code>HSV</code>颜色模型由色调（<code>hue</code>）、饱和度（<code>saturation</code>）和明度（<code>value</code>）组成。其更符合人眼对于色彩的直观感受，因为人的视觉对亮度的敏感程度远强于对颜色浓淡的敏感程度</p>
<h2 id="Lab"><a href="#Lab" class="headerlink" title="Lab"></a>Lab</h2><p>参考：</p>
<p><a href="https://baike.baidu.com/item/%E9%A2%9C%E8%89%B2%E6%A8%A1%E5%9E%8B/7558583?fromtitle=Lab&amp;fromid=1514615" target="_blank" rel="noopener">Lab 颜色模型</a></p>
<p><a href="https://en.wikipedia.org/wiki/CIELAB_color_space" target="_blank" rel="noopener">CIELAB color space</a></p>
<p><code>Lab</code>颜色模型是由<code>CIE</code>（国际照明委员会）制定的一种色彩模式，它的色彩空间比<code>RGB</code>空间还要大。另外这种模式是以数字化方式来描述人的视觉感应，与设备无关，所以它弥补了<code>RGB</code>和<code>CMYK</code>必须依赖于设备色彩特性的不足</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>图像处理</category>
        <category>颜色空间</category>
      </categories>
      <tags>
        <tag>rgb</tag>
        <tag>hsv</tag>
        <tag>yuv</tag>
        <tag>lab</tag>
      </tags>
  </entry>
  <entry>
    <title>[OpenCV][纹理特征]如何计算不同方向下的高斯导数直方图</title>
    <url>/posts/b03366b0.html</url>
    <content><![CDATA[<p>学习<code>SelectiveSearch</code>算法时候，其纹理特征需要计算类<code>SIFT</code>特征，实现方式是计算每张图片<code>8</code>个方向上<code>10 bin</code>大小的高斯导数直方图</p><a id="more"></a>
<blockquote>
<p>$S_{texture}(r_{i}, r_{j})$ measures texture similarity. We represent texture using fast SIFT-like measurements as SIFT itself works well for material recognition [20]. We take Gaussian derivatives in eight orientations using $σ = 1$ for each colour channel. For each orientation for each colour channel we extract a histogram using a bin size of 10. This leads to a texture histogram $T_{i} = {t_{i}^{1}, …, t_{i}^{n}}$ for each region $r_{i}$ with dimensionality $n = 240$ when three colour channels are used. Texture histograms are normalised using the $L_{1}$ norm. Similarity is measured using histogram intersection:</p>
</blockquote>
<p><code>OpenCV</code>实现了<code>SelectiveSearch</code>算法，其通过图像旋转、<code>Scharr</code>滤波以及手动计算直方图的方式完成了纹理特征的计算。之前没有思考过如何完成不同方向下导数直方图的计算，学习里面代码实现不同方向下的导数直方图计算</p>
<p>源码地址：<code>opencv_contrib/modules/ximgproc/src/selectivesearchsegmentation.cpp</code></p>
<h2 id="完整流程"><a href="#完整流程" class="headerlink" title="完整流程"></a>完整流程</h2><ol>
<li>计算高斯导数</li>
<li>计算直方图</li>
<li>直方图连接</li>
</ol>
<h2 id="计算高斯导数"><a href="#计算高斯导数" class="headerlink" title="计算高斯导数"></a>计算高斯导数</h2><p>需要分别计算<code>8</code>个方向上的高斯导数，分别是</p>
<ol>
<li><code>x</code>轴正/负方向</li>
<li><code>y</code>轴正/负方向</li>
<li>图像逆时针<code>45</code>度旋转后<code>x</code>轴正/负方向</li>
<li>图像逆时针<code>45</code>度旋转后<code>y</code>轴正/负方向</li>
</ol>
<p>使用函数<code>Scharr</code>对图像进行高斯求导，然后通过阈值函数<code>threshold</code>获取正/负方向的求导结果</p>
<p>完成上述操作后将结果进行标准化（<code>[0,255]</code>），以便后续直方图的计算。实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 计算8个方向的高斯导数</span><br><span class="line"> * @param src CV_8UC1</span><br><span class="line"> * @param gauss_vector</span><br><span class="line"> */</span><br><span class="line">void calc_8_direction_guass(const Mat &amp;src, vector&lt;Mat&gt; &amp;gauss_vector) &#123;</span><br><span class="line">//    cout &lt;&lt; src.channels() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    Mat gauss, gauss_pos, gauss_neg;</span><br><span class="line">    Mat rotated, rotated_gauss;</span><br><span class="line">    Mat rotated_gauss_tmp;</span><br><span class="line"></span><br><span class="line">    // x轴，向左/向右</span><br><span class="line">    Scharr(src, gauss, CV_32F, 1, 0);</span><br><span class="line">    threshold(gauss, gauss_pos, 0, 0, THRESH_TOZERO);</span><br><span class="line">    threshold(gauss, gauss_neg, 0, 0, THRESH_TOZERO_INV);</span><br><span class="line">    gauss_vector.emplace_back(gauss_pos);</span><br><span class="line">    gauss_vector.emplace_back(gauss_neg);</span><br><span class="line"></span><br><span class="line">    // y轴，向上/向下</span><br><span class="line">    gauss.release();</span><br><span class="line">    Scharr(src, gauss, CV_32F, 0, 1);</span><br><span class="line"></span><br><span class="line">    gauss_pos.release();</span><br><span class="line">    gauss_neg.release();</span><br><span class="line">    threshold(gauss, gauss_pos, 0, 0, THRESH_TOZERO);</span><br><span class="line">    threshold(gauss, gauss_neg, 0, 0, THRESH_TOZERO_INV);</span><br><span class="line">    gauss_vector.emplace_back(gauss_pos);</span><br><span class="line">    gauss_vector.emplace_back(gauss_neg);</span><br><span class="line"></span><br><span class="line">    // 逆时针旋转45度</span><br><span class="line">    Point2f center(src.cols / 2.0f, src.rows / 2.0f);</span><br><span class="line">    Mat rot = cv::getRotationMatrix2D(center, 45.0, 1.0);</span><br><span class="line">    Rect bbox = cv::RotatedRect(center, src.size(), 45.0).boundingRect();</span><br><span class="line">    rot.at&lt;double&gt;(0, 2) += bbox.width / 2.0 - center.x;</span><br><span class="line">    rot.at&lt;double&gt;(1, 2) += bbox.height / 2.0 - center.y;</span><br><span class="line">    warpAffine(src, rotated, rot, bbox.size());</span><br><span class="line">//    cout &lt;&lt; rotated.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    // 计算x轴方向导数</span><br><span class="line">    Scharr(rotated, rotated_gauss, CV_32F, 1, 0);</span><br><span class="line"></span><br><span class="line">    // 顺时针旋转45度，获取原先图像大小</span><br><span class="line">    center = Point((int) (rotated.cols / 2.0), (int) (rotated.rows / 2.0));</span><br><span class="line">    rot = cv::getRotationMatrix2D(center, -45.0, 1.0);</span><br><span class="line">    warpAffine(rotated_gauss, rotated_gauss_tmp, rot, bbox.size());</span><br><span class="line">    gauss = rotated_gauss_tmp(Rect((bbox.width - src.cols) / 2,</span><br><span class="line">                                   (bbox.height - src.rows) / 2, src.cols, src.rows));</span><br><span class="line">    gauss_pos.release();</span><br><span class="line">    gauss_neg.release();</span><br><span class="line">    threshold(gauss, gauss_pos, 0, 0, THRESH_TOZERO);</span><br><span class="line">    threshold(gauss, gauss_neg, 0, 0, THRESH_TOZERO_INV);</span><br><span class="line">    gauss_vector.emplace_back(gauss_pos);</span><br><span class="line">    gauss_vector.emplace_back(gauss_neg);</span><br><span class="line"></span><br><span class="line">    // 重复上一步骤</span><br><span class="line">    rotated_gauss.release();</span><br><span class="line">    Scharr(rotated, rotated_gauss, CV_32F, 0, 1);</span><br><span class="line"></span><br><span class="line">    // 顺时针旋转45度，获取原先图像大小</span><br><span class="line">    center = Point((int) (rotated.cols / 2.0), (int) (rotated.rows / 2.0));</span><br><span class="line">    rot = cv::getRotationMatrix2D(center, -45.0, 1.0);</span><br><span class="line">    warpAffine(rotated_gauss, rotated_gauss_tmp, rot, bbox.size());</span><br><span class="line">    gauss = rotated_gauss_tmp(Rect((bbox.width - src.cols) / 2,</span><br><span class="line">                                   (bbox.height - src.rows) / 2, src.cols, src.rows));</span><br><span class="line">    gauss_pos.release();</span><br><span class="line">    gauss_neg.release();</span><br><span class="line">    threshold(gauss, gauss_pos, 0, 0, THRESH_TOZERO);</span><br><span class="line">    threshold(gauss, gauss_neg, 0, 0, THRESH_TOZERO_INV);</span><br><span class="line">    gauss_vector.emplace_back(gauss_pos);</span><br><span class="line">    gauss_vector.emplace_back(gauss_neg);</span><br><span class="line"></span><br><span class="line">    // Normalisze gaussiaans in 0-255 range (for faster computation of histograms)</span><br><span class="line">    // 缩放图像到0-255，方便直方图计算</span><br><span class="line">    for (int i = 0; i &lt; 8; i++) &#123;</span><br><span class="line">        double hmin, hmax;</span><br><span class="line">        minMaxLoc(gauss_vector[i], &amp;hmin, &amp;hmax);</span><br><span class="line"></span><br><span class="line">        Mat tmp;</span><br><span class="line">        gauss_vector[i].convertTo(tmp, CV_8U,</span><br><span class="line">                                  255 / (hmax - hmin),</span><br><span class="line">                                  -255 * hmin / (hmax - hmin));</span><br><span class="line">        gauss_vector[i] = tmp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>进行阈值函数操作后直接放入向量中，所以求导图像有正有负</li>
<li>标准化公式如下：</li>
</ul>
<script type="math/tex; mode=display">
y = \frac{255*(x-hmin)}{hmax-hmin}</script><h2 id="计算直方图"><a href="#计算直方图" class="headerlink" title="计算直方图"></a>计算直方图</h2><p>参考：<a href="https://www.zhujian.tech/posts/f1eacfb6.html#more">直方图</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 计算颜色直方图，图像取值固定为[0, 255]</span><br><span class="line"> * @param src CV_8UC1或CV_8UC3大小图像</span><br><span class="line"> * @param histograms 直方图向量</span><br><span class="line"> * @param bins 直方图大小</span><br><span class="line"> */</span><br><span class="line">void calc_color_hist(const Mat &amp;src, vector&lt;Mat&gt; &amp;histograms, int bins) &#123;</span><br><span class="line">    int channels = src.channels();</span><br><span class="line">    vector&lt;Mat&gt; img_planes;</span><br><span class="line">    if (channels == 3) &#123;</span><br><span class="line">        split(src, img_planes);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // gray</span><br><span class="line">        img_planes.emplace_back(src);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    float range[] = &#123;0, 256&#125;; //the upper boundary is exclusive</span><br><span class="line">    const float *histRange = &#123;range&#125;;</span><br><span class="line">    bool uniform = true, accumulate = false;</span><br><span class="line"></span><br><span class="line">    for (int i = 0; i &lt; channels; i++) &#123;</span><br><span class="line">        Mat hist, tranpose_hist;</span><br><span class="line">        calcHist(&amp;img_planes[i], 1, nullptr, Mat(), hist, 1, &amp;bins, &amp;histRange, uniform, accumulate);</span><br><span class="line">        //转置图像，得到一行数据</span><br><span class="line">        transpose(hist, tranpose_hist);</span><br><span class="line">        histograms.emplace_back(tranpose_hist);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用<code>OpenCV</code>函数<code>calcHist</code>得到的是<code>N</code>列大小的矩阵，为方便后续计算，将其转置成单行矩阵</p>
<h2 id="直方图连接"><a href="#直方图连接" class="headerlink" title="直方图连接"></a>直方图连接</h2><p>彩色图像有<code>3</code>个通道，每个通道有<code>8</code>个方向求导，共得到<code>3x8=24</code>个直方图</p>
<p>对每个求导图像计算<code>10 bin</code>大小的直方图，所以得到的纹理特征维数是<code>24x10=240</code>维</p>
<p>在连接各个直方图之前，可以先对其进行标准化（<code>[0,1]</code>），以便后续操作</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int main() &#123;</span><br><span class="line">    Mat src = imread(&quot;../lena.jpg&quot;);</span><br><span class="line">    Mat gray;</span><br><span class="line">    cvtColor(src, gray, COLOR_BGR2GRAY);</span><br><span class="line"></span><br><span class="line">    vector&lt;Mat&gt; img_planes;</span><br><span class="line">    split(src, img_planes);</span><br><span class="line"></span><br><span class="line">    // 得到3x8=24个高斯求导图像，取值范围在[0,255]</span><br><span class="line">    vector&lt;Mat&gt; gauss_vectors;</span><br><span class="line">    for (const Mat &amp;img: img_planes) &#123;</span><br><span class="line">        vector&lt;Mat&gt; gauss_vector;</span><br><span class="line">        calc_8_direction_guass(img, gauss_vector);</span><br><span class="line">        gauss_vectors.insert(gauss_vectors.end(), gauss_vector.begin(), gauss_vector.end());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 计算10 bin大小直方图</span><br><span class="line">    vector&lt;Mat&gt; hists;</span><br><span class="line">    for (const Mat &amp;img: gauss_vectors) &#123;</span><br><span class="line">        vector&lt;Mat&gt; hist;</span><br><span class="line">        calc_color_hist(img, hist, 10);</span><br><span class="line">        hists.insert(hists.end(), hist.begin(), hist.end());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 归一化直方图</span><br><span class="line">    for (const Mat &amp;img: hists) &#123;</span><br><span class="line">        Mat dst;</span><br><span class="line">        img.convertTo(dst, CV_32F, 1.0 / sum(img)[0]);</span><br><span class="line">        cout &lt;&lt; dst &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 按行连接所有矩阵</span><br><span class="line">    cv::Mat out;</span><br><span class="line">    cv::vconcat(hists, out);</span><br><span class="line">    cout &lt;&lt; out &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>图像处理</category>
        <category>编程语言</category>
        <category>直方图</category>
        <category>代码库</category>
        <category>特征</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>opencv</tag>
        <tag>颜色直方图</tag>
        <tag>纹理特征</tag>
      </tags>
  </entry>
  <entry>
    <title>[Convolvution][Correlation]卷积和相关的异同</title>
    <url>/posts/b79f94c7.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://www.zhihu.com/question/32067344" target="_blank" rel="noopener">卷积运算和相关运算的区别与物理含义?</a></p><p><a href="https://blog.csdn.net/Sunny_HQ/article/details/80875664" target="_blank" rel="noopener">通俗理解【卷】积+互相关与卷积</a></p><p><a href="https://stackoverflow.com/questions/20321296/convolution-vs-correlation/37847548#37847548" target="_blank" rel="noopener">Convolution Vs Correlation</a></p><a id="more"></a>



<p>学习<code>OpenCV</code>的<code>2</code>维线性滤波器<a href="https://docs.opencv.org/4.1.0/d4/dbd/tutorial_filter_2d.html" target="_blank" rel="noopener">filter2D</a>，发现一句话</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Correlation</span><br><span class="line"></span><br><span class="line">In a very general sense, correlation is an operation between every part of an image and an operator (kernel).</span><br></pre></td></tr></table></figure>
<p>之前有接触过<code>correlation</code>(相关)的存在，但是没有仔细理清相关和卷积的异同，以及与之衍生而来的互相关（<code>cross-correlation</code>）和滤波（<code>filter</code>）的概念</p>
<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>参考：<a href="https://blog.csdn.net/u012005313/article/details/84068337" target="_blank" rel="noopener">图像卷积</a></p>
<script type="math/tex; mode=display">
(f*g)(t) = \int_{-\infty }^{\infty } f(\tau )g(t - \tau)dt</script><p>卷积核需要先翻转<code>180</code>度。从信号处理的角度来看，翻转卷积核是为了表现累加信号的过程，即某一时刻的输出不仅包括当前信号的响应，还包括之前信号的响应</p>
<p>对于二维图像而言，图像卷积就是卷积核按步长对图像局部像素块进行加权求和的过程</p>
<h2 id="相关"><a href="#相关" class="headerlink" title="相关"></a>相关</h2><p>参考：</p>
<p><a href="https://en.wikipedia.org/wiki/Cross-correlation" target="_blank" rel="noopener">Cross-correlation</a></p>
<p><a href="https://en.wikipedia.org/wiki/Autocorrelation" target="_blank" rel="noopener">Autocorrelation</a></p>
<p>在信号处理中，相关（<code>corrlation</code>）是自身序列平移后的相似性度量</p>
<script type="math/tex; mode=display">
R(\tau) = \int_{-\infty }^{\infty }x(t )x(t - \tau)dt</script><p>互相关（<code>cross-correlation</code>）是两个序列相似性的度量，是一个序列相对于另一个序列位移的函数</p>
<script type="math/tex; mode=display">
(f*g)(t) = \int_{-\infty }^{\infty }f(\tau )g(\tau - t)dt</script><p>对于<code>2</code>维图像而言，互相关其计算方式和卷积一样，利用模板滑动图像进行点积操作，但不需要翻转卷积核</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><blockquote>
<ul>
<li>卷积运算，反映了事物的相互作用，并且这种相互作用受制于同一个影响因子。</li>
<li>相关运算，在于反应已有事物的内在关联，并不是事物之间的相互影响。</li>
</ul>
</blockquote>
<p>只有在内核沿<code>x</code>轴和<code>y</code>轴对称时，卷积操作和互相关操作一致，比如高斯卷积</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>图像处理</category>
        <category>图像滤波</category>
      </categories>
      <tags>
        <tag>卷积</tag>
        <tag>相关</tag>
      </tags>
  </entry>
  <entry>
    <title>[Canny][Laplacian][Sobel][Scharr]边缘检测</title>
    <url>/posts/e42851a1.html</url>
    <content><![CDATA[<p>边缘检测是图像处理的基本操作之一，其目的是去除图像多余信息，保留图像轮廓数据，以便后续的处理（检测、识别等等）</p><a id="more"></a>
<h2 id="降噪"><a href="#降噪" class="headerlink" title="降噪"></a>降噪</h2><p>边缘检测常常受噪声影响，所以通常先进行平滑处理，常用高斯滤波进行操作。参考：<a href="https://www.zhujian.tech/posts/80b530f2.html">高斯滤波</a></p>
<h2 id="求导"><a href="#求导" class="headerlink" title="求导"></a>求导</h2><p>参考：</p>
<p><a href="https://blog.csdn.net/u012005313/article/details/84068249" target="_blank" rel="noopener">图像梯度</a></p>
<p><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/opencv/[Sobel]%E5%9B%BE%E5%83%8F%E6%B1%82%E5%AF%BC.html" target="_blank" rel="noopener">[Sobel]图像求导</a></p>
<p><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/opencv/[Scharr]%E5%9B%BE%E5%83%8F%E6%B1%82%E5%AF%BC.html" target="_blank" rel="noopener">[Scharr]图像求导</a></p>
<p><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/opencv/[Laplacian]%E5%9B%BE%E5%83%8F%E6%B1%82%E5%AF%BC.html" target="_blank" rel="noopener">[Laplacian]图像求导</a></p>
<p>由于轮廓出现在像素值剧烈变化的位置，所以通过求导方式可以有效的保留轮廓信息。<code>OpenCV</code>实现了多个近似求导的算子，常用的一阶求导方法有<code>Sobel/Scharr</code>，以及二阶求导方法<code>Laplacian</code></p>
<ul>
<li>对于<code>Sobel</code>和<code>Scharr</code>而言，其均组合了平滑和差分功能，只不过相比较而言<code>Scharr</code>模板的中间系数较高，所以计算结果更加近似梯度计算</li>
<li>对于一阶求导和二阶求导算子而言，二阶导数除了能够找到候选的边缘像素，而且更容易区分像素变化的方向（递增和递减）以及剧烈程度。<code>OpenCV</code>提供的<code>Laplacian</code>算子模板仅专注于差分功能，能够得到更精细的边缘效果</li>
</ul>
<h2 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h2><p>相对于<code>Sobel/Scharr/Laplacian</code>算子，<code>Canny</code>算子是一个多步骤（包含滤波/求导/阈值等）组合在一起的边缘检测算法，其边缘检测实现效果也更加好</p>
<p>参考：<a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/opencv/[Canny]%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B.html" target="_blank" rel="noopener">[Canny]边缘检测</a></p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>对同一张图像进行高斯滤波（$5\times 5, \sigma=1.4$）和灰度转换后，分别进行<code>Sobel/Scharr/Laplacian/Canny</code>检测</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &quot;opencv2/imgproc.hpp&quot;</span><br><span class="line">#include &quot;opencv2/imgcodecs.hpp&quot;</span><br><span class="line">#include &quot;opencv2/highgui.hpp&quot;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">using namespace cv;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">Mat image, src, src_gray, grad;</span><br><span class="line">int ksize = 3;</span><br><span class="line">double scale = 1;</span><br><span class="line">double delta = 0;</span><br><span class="line">int ddepth = CV_16S;</span><br><span class="line">int lowThreshold = 40;</span><br><span class="line">int highThreshold = 120;</span><br><span class="line"></span><br><span class="line">void onSobel(int, void *) &#123;</span><br><span class="line">    Mat grad_x, grad_y;</span><br><span class="line">    Mat abs_grad_x, abs_grad_y;</span><br><span class="line">    Sobel(src_gray, grad_x, ddepth, 1, 0, ksize, scale, delta, BORDER_DEFAULT); // x方向求导</span><br><span class="line">    Sobel(src_gray, grad_y, ddepth, 0, 1, ksize, scale, delta, BORDER_DEFAULT); // y方向求导</span><br><span class="line"></span><br><span class="line">    // converting back to CV_8U</span><br><span class="line">    convertScaleAbs(grad_x, abs_grad_x);</span><br><span class="line">    convertScaleAbs(grad_y, abs_grad_y);</span><br><span class="line">    addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0, grad);                     // 近似计算图像梯度</span><br><span class="line"></span><br><span class="line">    const string winname = &quot;Sobel Edge Detector&quot;;</span><br><span class="line">    imshow(winname, grad);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void onScharr(int, void *) &#123;</span><br><span class="line">    Mat grad_x, grad_y;</span><br><span class="line">    Mat abs_grad_x, abs_grad_y;</span><br><span class="line">    Scharr(src_gray, grad_x, ddepth, 1, 0, scale, delta, BORDER_DEFAULT);       // x方向求导</span><br><span class="line">    Scharr(src_gray, grad_y, ddepth, 0, 1, scale, delta, BORDER_DEFAULT);       // y方向求导</span><br><span class="line"></span><br><span class="line">    // converting back to CV_8U</span><br><span class="line">    convertScaleAbs(grad_x, abs_grad_x);</span><br><span class="line">    convertScaleAbs(grad_y, abs_grad_y);</span><br><span class="line">    addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0, grad);                     // 近似计算图像梯度</span><br><span class="line"></span><br><span class="line">    const string winname = &quot;Scharr Edge Detector&quot;;</span><br><span class="line">    imshow(winname, grad);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void onLaplacian(int, void *) &#123;</span><br><span class="line">    Mat grad, abs_grad;</span><br><span class="line">    Laplacian(src_gray, grad, ddepth, ksize, scale, delta, BORDER_DEFAULT);</span><br><span class="line"></span><br><span class="line">    // converting back to CV_8U</span><br><span class="line">    convertScaleAbs(grad, abs_grad);</span><br><span class="line"></span><br><span class="line">    const string winname = &quot;Laplacian Edge Detector&quot;;</span><br><span class="line">    imshow(winname, abs_grad);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void onCanny(int, void *) &#123;</span><br><span class="line">    Mat dst, detected_edges;</span><br><span class="line"></span><br><span class="line">    Canny(src, detected_edges, lowThreshold, highThreshold, ksize);</span><br><span class="line">    dst = Scalar::all(0);</span><br><span class="line">    src.copyTo(dst, detected_edges);</span><br><span class="line"></span><br><span class="line">    const string winname = &quot;Canny Edge Detector&quot;;</span><br><span class="line">    imshow(winname, dst);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(int argc, char **argv) &#123;</span><br><span class="line">    string imageName = &quot;../lena.jpg&quot;;</span><br><span class="line">    // As usual we load our source image (src)</span><br><span class="line">    image = imread(imageName, IMREAD_COLOR); // Load an image</span><br><span class="line">    // Check if image is loaded fine</span><br><span class="line">    if (image.empty()) &#123;</span><br><span class="line">        printf(&quot;Error opening image: %s\n&quot;, imageName.c_str());</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // Remove noise by blurring with a Gaussian filter ( kernel size = 3 )</span><br><span class="line">    GaussianBlur(image, src, Size(5, 5), 1.4, 1.4, BORDER_DEFAULT);</span><br><span class="line">    // Convert the image to grayscale</span><br><span class="line">    cvtColor(src, src_gray, COLOR_BGR2GRAY);</span><br><span class="line"></span><br><span class="line">    double t0 = cv::getTickCount();</span><br><span class="line">    onSobel(0, nullptr);</span><br><span class="line">    double t1 = cv::getTickCount();</span><br><span class="line">    onScharr(0, nullptr);</span><br><span class="line">    double t2 = cv::getTickCount();</span><br><span class="line">    onLaplacian(0, nullptr);</span><br><span class="line">    double t3 = cv::getTickCount();</span><br><span class="line">    onCanny(0, nullptr);</span><br><span class="line">    double t4 = cv::getTickCount();</span><br><span class="line"></span><br><span class="line">    double tickFrequency = cv::getTickFrequency();</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; &quot;sobel: &quot; &lt;&lt; (t1 - t0) / tickFrequency &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;scharr: &quot; &lt;&lt; (t2 - t1) / tickFrequency &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;laplacian: &quot; &lt;&lt; (t3 - t2) / tickFrequency &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;canny: &quot; &lt;&lt; (t4 - t3) / tickFrequency &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    waitKey(0);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>设置模板大小为$3\times 3$，<code>scale=1, delta=0</code>，利用<code>L1</code>范数计算梯度</p>
<p>处理$512\times 512$大小图像<code>lena.jpg</code>如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sobel: 0.0693918</span><br><span class="line">scharr: 0.0310751</span><br><span class="line">laplacian: 0.0205793</span><br><span class="line">canny: 0.0435819</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/edge-detect/sobel-scharr.png" alt></p>
<p><img src="/imgs/edge-detect/laplacian-canny.png" alt></p>
<p>处理$512\times 512$大小图像<code>baboon.jpg</code>如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sobel: 0.0643578</span><br><span class="line">scharr: 0.0307268</span><br><span class="line">laplacian: 0.0180599</span><br><span class="line">canny: 0.0254213</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/edge-detect/sobel-scharr-2.png" alt></p>
<p><img src="/imgs/edge-detect/laplacian-canny-2.png" alt></p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>从试验结果中发现</p>
<ol>
<li><code>Sobel</code>算子的平滑效果优于<code>Scharr</code>算子，但是其求导精度低于后者</li>
<li><code>Laplacian</code>算子能够比<code>Sobel/Scharr</code>算子得到更精细的边缘轮廓</li>
<li>相比于<code>Laplacian</code>算子，<code>Canny</code>算子能够得到更加明确的边缘轮廓</li>
<li><code>Laplacian</code>算子仅注重于差分操作，所以其计算时间小于<code>Sobel/Scharr</code>算子</li>
<li><code>OpenCV</code>中的<code>Canny</code>算子使用多线程进行计算，所以其计算时间小于<code>Sobel/Scharr</code>算子</li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>图像处理</category>
        <category>边缘检测</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>canny</tag>
        <tag>laplacian</tag>
        <tag>sobel</tag>
        <tag>scharr</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]Histogram of Oriented Gradients</title>
    <url>/posts/26ac7011.html</url>
    <content><![CDATA[<p>方向梯度直方图（Histogram Of Oriented Gradients，简称为HOG）是常用的纹理特征之一，本篇文章简单易懂的讲解了HOG概念</p><a id="more"></a>
<p>原文地址：<a href="https://www.learnopencv.com/histogram-of-oriented-gradients/" target="_blank" rel="noopener">Histogram of Oriented Gradients</a></p>
<p><img src="/imgs/HOG/histogram-of-oriented-gradients.png" alt></p>
<blockquote>
<p>In this post, we will learn the details of the Histogram of Oriented Gradients (HOG) feature descriptor. We will learn what is under the hood and how this descriptor is calculated internally by OpenCV, MATLAB and other packages.</p>
</blockquote>
<p>在这篇文章中，我们将学习方向梯度直方图（HOG）特征描述的细节。我们将学习概念背后的内容，以及如何通过OpenCV、MATLAB和其他软件包在内部计算这个描述符</p>
<blockquote>
<p>This post is part of a series I am writing on Image Recognition and Object Detection.</p>
</blockquote>
<p>这篇文章是我正在写的关于图像识别和目标检测的系列文章的一部分</p>
<blockquote>
<p>The complete list of tutorials in this series is given below:</p>
<ol>
<li>Image recognition using traditional Computer Vision techniques : Part 1</li>
<li>Histogram of Oriented Gradients : Part 2</li>
<li>Example code for image recognition : Part 3</li>
<li>Training a better eye detector: Part 4a</li>
<li>Object detection using traditional Computer Vision techniques : Part 4b</li>
<li>How to train and test your own OpenCV object detector : Part 5</li>
<li><p>Image recognition using Deep Learning : Part 6</p>
<ul>
<li>Introduction to Neural Networks</li>
<li>Understanding Feedforward Neural Networks</li>
<li>Image Recognition using Convolutional Neural Networks</li>
</ul>
</li>
<li>Object detection using Deep Learning : Part 7</li>
</ol>
</blockquote>
<p>本系列教程的完整列表如下：</p>
<ol>
<li>使用传统计算机视觉技术的图像识别：Part 1</li>
<li>方向梯度直方图：Part 2</li>
<li>图像识别示例代码：Part 3</li>
<li>训练一个更好的眼睛探测器：Part 4a</li>
<li>基于传统计算机视觉技术的目标检测：Part 4b</li>
<li>如何训练和测试自己的OpenCV对象检测器：Part 5</li>
<li>基于深度学习的图像识别：Part 6<ul>
<li>神经网络介绍</li>
<li>理解前向神经网络</li>
<li>使用卷积神经网络进行图像识别</li>
</ul>
</li>
<li>使用深度学习的目标识别：Part 7</li>
</ol>
<blockquote>
<p>A lot many things look difficult and mysterious. But once you take the time to deconstruct them, the mystery is replaced by mastery and that is what we are after. If you are a beginner and are finding Computer Vision hard and mysterious, just remember the following</p>
<p>Q : How do you eat an elephant ?<br>A : One bite at a time!</p>
</blockquote>
<p>很多事情看起来既困难又神秘。但一旦你花时间去解构它们，神秘就被掌握所取代，这就是我们所追求的。如果你是一个初学者，发现计算机视觉很难而且很神秘，请记住以下几点</p>
<p><strong>问题：如何吃掉一头大象？</strong></p>
<p><strong>答案：一口一口的吃!</strong></p>
<h2 id="What-is-a-Feature-Descriptor"><a href="#What-is-a-Feature-Descriptor" class="headerlink" title="What is a Feature Descriptor"></a>What is a Feature Descriptor</h2><p>什么是特征描述符</p>
<blockquote>
<p>A feature descriptor is a representation of an image or an image patch that simplifies the image by extracting useful information and throwing away extraneous information.</p>
</blockquote>
<p>特征描述符是通过提取有用信息和丢弃无关信息来简化图像的图像或图像块的表示</p>
<blockquote>
<p>Typically, a feature descriptor converts an image of size width x height x 3 (channels ) to a feature vector / array of length n. In the case of the HOG feature descriptor, the input image is of size 64 x 128 x 3 and the output feature vector is of length 3780.</p>
</blockquote>
<p>通常，特征描述符将大小为宽x高x3（通道数）的图像转换为长度为n的特征向量/阵列。在HOG特征描述符的情况下，输入图像的大小为64x128x3，输出特征向量的长度为3780</p>
<blockquote>
<p>Keep in mind that HOG descriptor can be calculated for other sizes, but in this post I am sticking to numbers presented in the original paper so you can easily understand the concept with one concrete example.</p>
</blockquote>
<p>请记住，HOG描述符可以计算其他大小，但在本文中，我将坚持在原始论文中给出的数字，这样您就可以通过一个具体的例子轻松理解这个概念</p>
<blockquote>
<p>This all sounds good, but what is “useful” and what is “extraneous”？ To define “useful”, we need to know what is it “useful” for？ Clearly, the feature vector is not useful for the purpose of viewing the image. But, it is very useful for tasks like image recognition and object detection. The feature vector produced by these algorithms when fed into an image classification algorithms like Support Vector Machine (SVM) produce good results.</p>
</blockquote>
<p>这听起来不错，但什么是“有用的”和什么是“无关的”？要定义“有用”，我们需要知道它“有用”目的是什么？显然，特征向量对于查看图像是没有用处的。但是，它对于图像识别和目标检测等任务非常有用。将这些算法产生的特征向量输入到支持向量机（SVM）等图像分类算法中，可以得到较好的分类效果</p>
<blockquote>
<p>But, what kinds of “features” are useful for classification tasks? Let’s discuss this point using an example. Suppose we want to build an object detector that detects buttons of shirts and coats. A button is circular ( may look elliptical in an image ) and usually has a few holes for sewing. You can run an edge detector on the image of a button, and easily tell if it is a button by simply looking at the edge image alone. In this case, edge information is “useful” and color information is not. In addition, the features also need to have discriminative power. For example, good features extracted from an image should be able to tell the difference between buttons and other circular objects like coins and car tires.</p>
</blockquote>
<p>但是，什么样的“特征”对分类任务有用呢？让我们用一个例子来讨论这一点。假设我们想建立一个目标探测器来检测衬衫和外套的纽扣。按钮是圆形的（在图像中可能看起来是椭圆形的），通常有几个缝孔。你可以在按钮的图像上运行一个边缘检测器，只需简单地查看边缘图像就可以很容易地判断它是否是按钮。在这种情况下，边缘信息是“有用的”，而颜色信息则不是。此外，这些特征还需要有辨别力。例如，从图像中提取的良好特征应该能够区分按钮和其他圆形物体（如硬币和汽车轮胎）之间的区别</p>
<blockquote>
<p>In the HOG feature descriptor, the distribution (histograms) of directions of gradients (oriented gradients) are used as features. Gradients (x and y derivatives) of an image are useful because the magnitude of gradients is large around edges and corners (regions of abrupt intensity changes) and we know that edges and corners pack in a lot more information about object shape than flat regions.</p>
</blockquote>
<p>在HOG特征描述符中，使用梯度方向（定向梯度）的分布（直方图）作为特征。图像的梯度（x和y导数）是有用的，因为边缘和角落（强度突变区域）的梯度幅度很大，我们知道边缘和角落比平面区域包含更多关于目标形状的信息</p>
<h2 id="How-to-calculate-Histogram-of-Oriented-Gradients"><a href="#How-to-calculate-Histogram-of-Oriented-Gradients" class="headerlink" title="How to calculate Histogram of Oriented Gradients ?"></a>How to calculate Histogram of Oriented Gradients ?</h2><p>如何计算方向导数直方图?</p>
<blockquote>
<p>In this section, we will go into the details of calculating the HOG feature descriptor. To illustrate each step, we will use a patch of an image.</p>
</blockquote>
<p>在本节中，我们将详细讨论计算HOG特征描述符。为了说明每个步骤，我们将使用一个图像块</p>
<h3 id="Step-1-Preprocessing"><a href="#Step-1-Preprocessing" class="headerlink" title="Step 1: Preprocessing"></a>Step 1: Preprocessing</h3><p>第一步：预处理</p>
<blockquote>
<p>As mentioned earlier HOG feature descriptor used for pedestrian detection is calculated on a 64×128 patch of an image. Of course, an image may be of any size. Typically patches at multiple scales are analyzed at many image locations. The only constraint is that the patches being analyzed have a fixed aspect ratio. In our case, the patches need to have an aspect ratio of 1:2. For example, they can be 100×200, 128×256, or 1000×2000 but not 101×205.</p>
</blockquote>
<p>如前所述，用于行人检测的HOG特征描述符是在图像的64×128大小的块上计算的。当然，图像可以是任何大小。通常在多个图像位置分析多个尺度的图像块。唯一的限制是所分析的图像块具有固定的长宽比。在我们的例子中，补丁需要有1:2的长宽比。例如，它们可以是100×200、128×256或1000×2000，但不能是101×205</p>
<blockquote>
<p>To illustrate this point I have shown a large image of size 720×475. We have selected a patch of size 100×200 for calculating our HOG feature descriptor. This patch is cropped out of an image and resized to 64×128. Now we are ready to calculate the HOG descriptor for this image patch.</p>
</blockquote>
<p>为了说明这一点，我展示了一幅720×475的大图像。我们选择了一个大小为100×200的块来计算我们的HOG特征描述符。此图像块将从图像中裁剪并调整大小为64×128。现在我们可以计算这个图像块的HOG描述符了</p>
<p><img src="/imgs/HOG/hog-preprocessing.png" alt></p>
<blockquote>
<p>The paper by Dalal and Triggs also mentions gamma correction as a preprocessing step, but the performance gains are minor and so we are skipping the step.</p>
</blockquote>
<p>Dalal和Triggs的论文也提到gamma校正是一个预处理步骤，但是性能提高很小，所以我们跳过了这个步骤</p>
<h3 id="Step-2-Calculate-the-Gradient-Images"><a href="#Step-2-Calculate-the-Gradient-Images" class="headerlink" title="Step 2: Calculate the Gradient Images"></a>Step 2: Calculate the Gradient Images</h3><p>第二步：计算梯度图像</p>
<blockquote>
<p>To calculate a HOG descriptor, we need to first calculate the horizontal and vertical gradients; after all, we want to calculate the histogram of gradients. This is easily achieved by filtering the image with the following kernels.</p>
</blockquote>
<p>要计算HOG描述符，首先需要计算水平和垂直梯度；毕竟，我们要计算梯度的直方图。这很容易通过使用以下内核过滤图像来实现</p>
<p><img src="/imgs/HOG/gradient-kernels.png" alt></p>
<blockquote>
<p>We can also achieve the same results, by using Sobel operator in OpenCV with kernel size 1.</p>
</blockquote>
<p>在OpenCV中使用核大小为1的Sobel算子也可以得到同样的结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// C++ gradient calculation. </span><br><span class="line">// Read image</span><br><span class="line">Mat img = imread(&quot;bolt.png&quot;);</span><br><span class="line">img.convertTo(img, CV_32F, 1/255.0);</span><br><span class="line"> </span><br><span class="line">// Calculate gradients gx, gy</span><br><span class="line">Mat gx, gy; </span><br><span class="line">Sobel(img, gx, CV_32F, 1, 0, 1);</span><br><span class="line">Sobel(img, gy, CV_32F, 0, 1, 1);</span><br><span class="line">	</span><br><span class="line"># Python gradient calculation </span><br><span class="line"> </span><br><span class="line"># Read image</span><br><span class="line">im = cv2.imread(&apos;bolt.png&apos;)</span><br><span class="line">im = np.float32(im) / 255.0</span><br><span class="line"> </span><br><span class="line"># Calculate gradient </span><br><span class="line">gx = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=1)</span><br><span class="line">gy = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=1)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Next, we can find the magnitude and direction of gradient using the following formula</p>
</blockquote>
<p>下一步，我们可以用下面的公式找到梯度的大小和方向</p>
<script type="math/tex; mode=display">
g=\sqrt{g_{x}^{2} + g_{y}^{2}} \\
\theta = \arctan \frac{g_{y}}{g_{x}}</script><blockquote>
<p>If you are using OpenCV, the calculation can be done using the function cartToPolar as shown below.</p>
</blockquote>
<p>如果使用OpenCV，可以使用函数cartToPolar完成计算，如下所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// C++ Calculate gradient magnitude and direction (in degrees)</span><br><span class="line">Mat mag, angle; </span><br><span class="line">cartToPolar(gx, gy, mag, angle, 1); </span><br><span class="line"></span><br><span class="line"># Python Calculate gradient magnitude and direction ( in degrees ) </span><br><span class="line">mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>The figure below shows the gradients.</p>
</blockquote>
<p>下图显示了梯度结果</p>
<p><img src="/imgs/HOG/gradients.png" alt></p>
<blockquote>
<p>Left : Absolute value of x-gradient. Center : Absolute value of y-gradient. Right : Magnitude of gradient.</p>
</blockquote>
<p>左图：x轴方向梯度大小；中间：y轴方向梯度大小；右图：x-y轴梯度大小</p>
<blockquote>
<p>Notice, the x-gradient fires on vertical lines and the y-gradient fires on horizontal lines. The magnitude of gradient fires where ever there is a sharp change in intensity. None of them fire when the region is smooth. I have deliberately left out the image showing the direction of gradient because direction shown as an image does not convey much.</p>
</blockquote>
<p>注意，x轴梯度在垂直线上激发，y轴梯度在水平线上激发。梯度在像素强度剧烈变化的地方激发。当区域平滑时，它们都不会被激发。我故意忽略了显示梯度方向的图像，因为显示图像的方向传达不了太多信息</p>
<blockquote>
<p>The gradient image removed a lot of non-essential information ( e.g. constant colored background ), but highlighted outlines. In other words, you can look at the gradient image and still easily say there is a person in the picture.</p>
</blockquote>
<p>梯度图像去除了很多不必要的信息（如恒定的彩色背景），但突出了轮廓。换言之，看到梯度图像仍然可以很容易地发现有一个人在图片中</p>
<blockquote>
<p>At every pixel, the gradient has a magnitude and a direction. For color images, the gradients of the three channels are evaluated ( as shown in the figure above ). The magnitude of gradient at a pixel is the maximum of the magnitude of gradients of the three channels, and the angle is the angle corresponding to the maximum gradient.</p>
</blockquote>
<p>在每个像素处，梯度都有大小和方向。对于彩色图像，需要各自计算三个通道的梯度（如上图所示）。在一个像素处的梯度幅度是三个通道梯度的最大值，并且角度是对应于最大梯度的角度</p>
<h3 id="Step-3-Calculate-Histogram-of-Gradients-in-8x8-cells"><a href="#Step-3-Calculate-Histogram-of-Gradients-in-8x8-cells" class="headerlink" title="Step 3: Calculate Histogram of Gradients in 8x8 cells"></a>Step 3: Calculate Histogram of Gradients in 8x8 cells</h3><p>第三步：计算8x8个单元格中的梯度直方图</p>
<p><img src="/imgs/HOG/hog-cells.png" alt></p>
<blockquote>
<p>In this step, the image is divided into 8×8 cells and a histogram of gradients is calculated for each 8×8 cells.</p>
</blockquote>
<p>在这一步中，图像被分成8×8大小的单元格，并为每个8×8大小单元格计算梯度直方图</p>
<blockquote>
<p>We will learn about the histograms in a moment, but before we go there let us first understand why we have divided the image into 8×8 cells. One of the important reasons to use a feature descriptor to describe a patch of an image is that it provides a compact representation. An 8×8 image patch contains 8x8x3 = 192 pixel values. The gradient of this patch contains 2 values ( magnitude and direction ) per pixel which adds up to 8x8x2 = 128 numbers. By the end of this section we will see how these 128 numbers are represented using a 9-bin histogram which can be stored as an array of 9 numbers. Not only is the representation more compact, calculating a histogram over a patch makes this represenation more robust to noise. Individual graidents may have noise, but a histogram over 8×8 patch makes the representation much less sensitive to noise.</p>
</blockquote>
<p>我们稍后将学习直方图，但在我们开始学习之前，让我们先了解一下为什么我们将图像划分到8×8大小单元格。使用特征描述符描述图像的一个重要原因是它提供了一个紧凑的表示。8×8图像块包含8x8x3=192像素值。此图像块的梯度包含每个像素2个值（大小和方向），总计为8x8x2=128个数字。在本节结束时，我们将看到如何使用一个9-bin大小直方图来表示这128个数字，该直方图可以存储为一个由9个数字组成的数组。不仅表示更紧凑，计算一个补丁上的直方图使这种表示对噪声更具有鲁棒性。单个梯度可能有噪声，但是8×8大小图象块的直方图使表示对噪声的敏感性大大降低</p>
<blockquote>
<p>But why 8×8 patch ? Why not 32×32 ? It is a design choice informed by the scale of features we are looking for. HOG was used for pedestrian detection initially. 8×8 cells in a photo of a pedestrian scaled to 64×128 are big enough to capture interesting features ( e.g. the face, the top of the head etc. ).</p>
</blockquote>
<p>但是为什么是8×8补丁呢？为什么不是32×32？这是一个设计选择，由我们正在寻找的功能的规模所决定。HOG最初用于行人检测。一张行人照片中的8×8格放大到64×128，足以捕捉有趣的特征（如面部、头顶等）</p>
<blockquote>
<p>The histogram is essentially a vector ( or an array ) of 9 bins ( numbers ) corresponding to angles 0, 20, 40, 60 … 160.</p>
</blockquote>
<p>直方图本质上是一个由9个格（数字）组成的向量（或数组），对应于0、20、40、60…160的角度</p>
<blockquote>
<p>Let us look at one 8×8 patch in the image and see how the gradients look.</p>
</blockquote>
<p>让我们来看看图像中的一个8×8大小的补丁，看看梯度是什么样子的</p>
<p><img src="/imgs/HOG/hog-cell-gradients-768x432.png" alt></p>
<blockquote>
<p>Center : The RGB patch and gradients represented using arrows. Right : The gradients in the same patch represented as numbers</p>
</blockquote>
<p>左图：RGB块以及箭头表示的梯度；右图：用数值表示图像块各个像素的梯度大小和方向</p>
<blockquote>
<p>If you are a beginner in computer vision, the image in the center is very informative. It shows the patch of the image overlaid with arrows showing the gradient — the arrow shows the direction of gradient and its length shows the magnitude. Notice how the direction of arrows points to the direction of change in intensity and the magnitude shows how big the difference is.</p>
</blockquote>
<p>如果你是计算机视觉的初学者，左图的信息量很大。它表示图像块，上面覆盖着表示梯度的箭头 - 箭头表示梯度的方向，其长度表示大小。请注意箭头方向指向强度变化的方向，而大小显示了差异有多大</p>
<blockquote>
<p>On the right, we see the raw numbers representing the gradients in the 8×8 cells with one minor difference — the angles are between 0 and 180 degrees instead of 0 to 360 degrees. These are called “unsigned” gradients because a gradient and it’s negative are represented by the same numbers. In other words, a gradient arrow and the one 180 degrees opposite to it are considered the same. But, why not use the 0 – 360 degrees ? Empirically it has been shown that unsigned gradients work better than signed gradients for pedestrian detection. Some implementations of HOG will allow you to specify if you want to use signed gradients.</p>
</blockquote>
<p>右图中，我们看到代表8×8单元格中梯度的原始数字，只有一个微小的差异-角度在0到180度之间，而不是0到360度之间。这些称为“无符号”梯度，因为梯度和它的负数由相同的数字表示。换句话说，梯度箭头和与之相对的180度箭头被认为是相同的。但是，为什么不使用0-360度呢？经验表明，无符号梯度比有符号梯度更适合行人检测。HOG的一些实现允许您指定是否要使用带符号的渐变</p>
<blockquote>
<p>The next step is to create a histogram of gradients in these 8×8 cells. The histogram contains 9 bins corresponding to angles 0, 20, 40 … 160.</p>
</blockquote>
<p>下一步是在这些8×8单元格中创建梯度直方图。直方图包含9个对应于角度0、20、40…160的区域</p>
<blockquote>
<p>The following figure illustrates the process. We are looking at magnitude and direction of the gradient of the same 8×8 patch as in the previous figure. A bin is selected based on the direction, and the vote ( the value that goes into the bin ) is selected based on the magnitude. Let’s first focus on the pixel encircled in blue. It has an angle ( direction ) of 80 degrees and magnitude of 2. So it adds 2 to the 5th bin. The gradient at the pixel encircled using red has an angle of 10 degrees and magnitude of 4. Since 10 degrees is half way between 0 and 20, the vote by the pixel splits evenly into the two bins.</p>
</blockquote>
<p>下图说明了该过程。我们正在研究同一个8×8图像块的梯度大小和方向，如上图所示。根据方向选择一个bin，并根据大小选择投票（进入bin的值）。让我们首先关注蓝色圈出的像素。它的角度（方向）为80度，大小为2，所以第五个bin加2。使用红色圈出的像素的梯度角度为10度，大小为4。由于10度是0到20之间的一半，因此按像素进行的投票将均匀地分成两个容器</p>
<p><img src="/imgs/HOG/hog-histogram-1.png" alt></p>
<blockquote>
<p>There is one more detail to be aware of. If the angle is greater than 160 degrees, it is between 160 and 180, and we know the angle wraps around making 0 and 180 equivalent. So in the example below, the pixel with angle 165 degrees contributes proportionally to the 0 degree bin and the 160 degree bin.</p>
</blockquote>
<p>还有一个细节需要注意。如果角度大于160度，它在160到180之间，我们知道角度在0到180之间。因此在下面的例子中，角度为165度的像素值成比例的分配给0度和160度的bin</p>
<p><img src="/imgs/HOG/hog-histogram-2.png" alt></p>
<blockquote>
<p>The contributions of all the pixels in the 8×8 cells are added up to create the 9-bin histogram. For the patch above, it looks like this</p>
</blockquote>
<p>将8×8单元格中所有像素按分布相加，生成9-bin直方图。上面的图像块得到如下结果</p>
<p><img src="/imgs/HOG/histogram-8x8-cell.png" alt></p>
<blockquote>
<p>In our representation, the y-axis is 0 degrees. You can see the histogram has a lot of weight near 0 and 180 degrees, which is just another way of saying that in the patch gradients are pointing either up or down.</p>
</blockquote>
<p>在我们的表示中，y轴是0度。你可以看到直方图在0度和180度附近有很多权重值，换一种说法就是在图像块中梯度要么指向上，要么指向下</p>
<h3 id="Step-4-16x16-Block-Normalization"><a href="#Step-4-16x16-Block-Normalization" class="headerlink" title="Step 4: 16x16 Block Normalization"></a>Step 4: 16x16 Block Normalization</h3><p>第四步：16x16大小的块标准化</p>
<p><img src="/imgs/HOG/hog-16x16-block-normalization.png" alt></p>
<blockquote>
<p>In the previous step, we created a histogram based on the gradient of the image. Gradients of an image are sensitive to overall lighting. If you make the image darker by dividing all pixel values by 2, the gradient magnitude will change by half, and therefore the histogram values will change by half. Ideally, we want our descriptor to be independent of lighting variations. In other words, we would like to “normalize” the histogram so they are not affected by lighting variations.</p>
</blockquote>
<p>上一步中计算了图像的梯度直方图。图像的梯度对整体照明敏感。如果将所有像素值除以2使图像变暗，则梯度大小将更改一半，因此直方图值将更改一半。理想情况下，我们希望描述符独立于光照变化。换言之，我们希望”标准化”直方图，使其不受光照变化的影响</p>
<blockquote>
<p>Before I explain how the histogram is normalized, let’s see how a vector of length 3 is normalized.</p>
</blockquote>
<p>在解释直方图是如何标准化之前，让我们看看长度为3的向量是如何标准化的</p>
<blockquote>
<p>Let’s say we have an RGB color vector [ 128, 64, 32 ]. The length of this vector is $\sqrt{128^2 + 64^2 + 32^2} = 146.64$. This is also called the L2 norm of the vector. Dividing each element of this vector by 146.64 gives us a normalized vector [0.87, 0.43, 0.22]. Now consider another vector in which the elements are twice the value of the first vector 2 x [ 128, 64, 32 ] = [ 256, 128, 64 ]. You can work it out yourself to see that normalizing [ 256, 128, 64 ] will result in [0.87, 0.43, 0.22], which is the same as the normalized version of the original RGB vector. You can see that normalizing a vector removes the scale.</p>
</blockquote>
<p>假设我们有一个RGB颜色向量[128，64，32]。向量长度是$\sqrt{128^2 + 64^2 + 32^2} = 146.64$。这也被称为向量的L2范数。将这个向量的每个元素除以146.64，得到一个标准化向量[0.87，0.43，0.22]。现在考虑另一个向量，其中的元素是第一个向量的两倍：2x[128，64，32]=[256，128，64]。通过计算可知标准化[256，128，64]将得到[0.87，0.43，0.22]，这与原始RGB向量的标准化结果相同。所以标准化操作移除了尺度的影响</p>
<blockquote>
<p>Now that we know how to normalize a vector, you may be tempted to think that while calculating HOG you can simply normalize the 9×1 histogram the same way we normalized the 3×1 vector above. It is not a bad idea, but a better idea is to normalize over a bigger sized block of 16×16. A 16×16 block has 4 histograms which can be concatenated to form a 36 x 1 element vector and it can be normalized just the way a 3×1 vector is normalized. The window is then moved by 8 pixels ( see animation ) and a normalized 36×1 vector is calculated over this window and the process is repeated.</p>
</blockquote>
<p>现在我们知道了如何标准化向量，您可能会想，在计算HOG时，您可以简单地规范化9×1直方图，就像我们规范化上面的3×1向量一样。这不是个坏主意，但更好的办法是在更大的16×16的块上进行标准化。一个16x16大小的块有四个直方图，这些直方图可以连接起来形成一个36x1大小的向量，并且按照这种方式进行标准化。每次标准化将窗口移动8个像素（参见动画），并在此窗口上计算标准化的36×1矢量，然后重复该过程</p>
<h3 id="Step-5-Calculate-the-HOG-feature-vector"><a href="#Step-5-Calculate-the-HOG-feature-vector" class="headerlink" title="Step 5: Calculate the HOG feature vector"></a>Step 5: Calculate the HOG feature vector</h3><p>第5步：计算HOG特征向量</p>
<blockquote>
<p>To calculate the final feature vector for the entire image patch, the 36×1 vectors are concatenated into one giant vector. What is the size of this vector ? Let us calculate</p>
</blockquote>
<p>为了计算整个图像块的最终特征向量，将36×1的向量拼接成一个巨大的向量。这个向量的大小是多少？让我们计算一下</p>
<blockquote>
<ol>
<li>How many positions of the 16×16 blocks do we have ? There are 7 horizontal and 15 vertical positions making a total of 7 x 15 = 105 positions.</li>
<li>Each 16×16 block is represented by a 36×1 vector. So when we concatenate them all into one gaint vector we obtain a 36×105 = 3780 dimensional vector.</li>
</ol>
</blockquote>
<ol>
<li>我们16×16大小的图像块有多少个位置？共有7个水平位置和15个垂直位置（输入图像大小为64x128），共计7x15=105个位置</li>
<li>每个16×16块代表36×1向量，连接在一起得到了一个36×105=3780维大小的向量</li>
</ol>
<h2 id="Visualizing-Histogram-of-Oriented-Gradients"><a href="#Visualizing-Histogram-of-Oriented-Gradients" class="headerlink" title="Visualizing Histogram of Oriented Gradients"></a>Visualizing Histogram of Oriented Gradients</h2><p>可视化方向梯度直方图</p>
<blockquote>
<p>The HOG descriptor of an image patch is usually visualized by plotting the 9×1 normalized histograms in the 8×8 cells. See image on the side. You will notice that dominant direction of the histogram captures the shape of the person, especially around the torso and legs.</p>
</blockquote>
<p>图像块的HOG描述符通常是通过在8×8单元格中绘制9×1的归一化直方图来实现的。参考下面图片。你会注意到直方图的主导方向捕捉到了人的形状，尤其是躯干和腿部</p>
<blockquote>
<p>Unfortunately, there is no easy way to visualize the HOG descriptor in OpenCV.</p>
</blockquote>
<p>不幸的是，在OpenCV中没有简单的方法可以可视化HOG描述符</p>
<p><img src="/imgs/HOG/hog-visualization.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>图像处理</category>
        <category>编程语言</category>
        <category>直方图</category>
        <category>代码库</category>
        <category>特征</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>python</tag>
        <tag>opencv</tag>
        <tag>纹理特征</tag>
        <tag>HOG</tag>
        <tag>方向梯度直方图</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins]Pipeline工程配置NodeJS环境</title>
    <url>/posts/d521b4ea.html</url>
    <content><![CDATA[<p>利用<code>Jenkins Pipeline</code>工程编译<code>NodeJS</code>项目，出现<code>npm not found</code>问题</p><p>参考<a href="https://medium.com/@gustavo.guss/jenkins-starting-with-pipeline-doing-a-node-js-test-72c6057b67d4" target="_blank" rel="noopener">Jenkins Starting with Pipeline doing a Node.js test</a>，配置<code>NodeJS</code>开发环境</p><a id="more"></a>

<h2 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h2><p>首先下载<code>NodeJS</code>插件，进入<code>Manage Jenkins -&gt; Manage Plugins -&gt; Available</code>，搜索<code>NodeJS</code>插件并安装</p>
<p><img src="/imgs/jenkins-pipeline-nodejs/nodejs-plugin.png" alt></p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>插件安装完成后，进入<code>Manage Jenkins -&gt; Global Tool Configuration</code>，会出现<code>NodeJS</code>的配置选项</p>
<p><img src="/imgs/jenkins-pipeline-nodejs/nodejs-configure.png" alt></p>
<p>点击<code>NodeJS Insllation</code>，设置<code>Name</code>属性，选择要安装的<code>NodeJS</code>版本，以及待安装的全局软件，保存设置</p>
<p><img src="/imgs/jenkins-pipeline-nodejs/nodejs-installation.png" alt></p>
<h2 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h2><p>新建Pipeline工程test，在配置时输入如下脚本</p>
<p><img src="/imgs/jenkins-pipeline-nodejs/pipeline-script.png" alt></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">  agent any</span><br><span class="line">  tools &#123;nodejs &quot;node&quot;&#125;</span><br><span class="line"> </span><br><span class="line">  stages &#123;</span><br><span class="line">    stage(&apos;Example&apos;) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        sh &apos;npm config ls&apos;</span><br><span class="line">        sh &apos;&apos;&apos;</span><br><span class="line">            node -v</span><br><span class="line">            npm -v</span><br><span class="line">            gulp -v</span><br><span class="line">            hexo -v</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>使用之前配置的<code>NodeJS</code>节点<code>node</code></em></p>
<p>执行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Started by user zhujian</span><br><span class="line">Running in Durability level: MAX_SURVIVABILITY</span><br><span class="line">[Pipeline] Start of Pipeline</span><br><span class="line">[Pipeline] node</span><br><span class="line">Running on Jenkins in /home/zj/.jenkins/workspace/test</span><br><span class="line">[Pipeline] &#123;</span><br><span class="line">[Pipeline] stage</span><br><span class="line">[Pipeline] &#123; (Declarative: Tool Install)</span><br><span class="line">[Pipeline] tool</span><br><span class="line">Unpacking https://nodejs.org/dist/v13.1.0/node-v13.1.0-linux-x64.tar.gz to /home/zj/.jenkins/tools/jenkins.plugins.nodejs.tools.NodeJSInstallation/node on Jenkins</span><br><span class="line">$ /home/zj/.jenkins/tools/jenkins.plugins.nodejs.tools.NodeJSInstallation/node/bin/npm install -g hexo-cli gulp</span><br><span class="line">npm WARN deprecated fsevents@1.2.9: One of your dependencies needs to upgrade to fsevents v2: 1) Proper nodejs v10+ support 2) No more fetching binaries from AWS, smaller package size</span><br><span class="line">/home/zj/.jenkins/tools/jenkins.plugins.nodejs.tools.NodeJSInstallation/node/bin/gulp -&gt; /home/zj/.jenkins/tools/jenkins.plugins.nodejs.tools.NodeJSInstallation/node/lib/node_modules/gulp/bin/gulp.js</span><br><span class="line">/home/zj/.jenkins/tools/jenkins.plugins.nodejs.tools.NodeJSInstallation/node/bin/hexo -&gt; /home/zj/.jenkins/tools/jenkins.plugins.nodejs.tools.NodeJSInstallation/node/lib/node_modules/hexo-cli/bin/hexo</span><br><span class="line">npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.2 (node_modules/hexo-cli/node_modules/fsevents):</span><br><span class="line">npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.2: wanted &#123;&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;&#125; (current: &#123;&quot;os&quot;:&quot;linux&quot;,&quot;arch&quot;:&quot;x64&quot;&#125;)</span><br><span class="line">npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.9 (node_modules/gulp/node_modules/fsevents):</span><br><span class="line">npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.9: wanted &#123;&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;&#125; (current: &#123;&quot;os&quot;:&quot;linux&quot;,&quot;arch&quot;:&quot;x64&quot;&#125;)</span><br><span class="line"></span><br><span class="line">+ gulp@4.0.2</span><br><span class="line">+ hexo-cli@3.1.0</span><br><span class="line">added 382 packages from 508 contributors in 59.164s</span><br><span class="line">[Pipeline] envVarsForTool</span><br><span class="line">[Pipeline] &#125;</span><br><span class="line">[Pipeline] // stage</span><br><span class="line">[Pipeline] withEnv</span><br><span class="line">[Pipeline] &#123;</span><br><span class="line">[Pipeline] stage</span><br><span class="line">[Pipeline] &#123; (Example)</span><br><span class="line">[Pipeline] tool</span><br><span class="line">[Pipeline] envVarsForTool</span><br><span class="line">[Pipeline] withEnv</span><br><span class="line">[Pipeline] &#123;</span><br><span class="line">[Pipeline] sh</span><br><span class="line">+ npm config ls</span><br><span class="line">; cli configs</span><br><span class="line">metrics-registry = &quot;https://registry.npmjs.org/&quot;</span><br><span class="line">scope = &quot;&quot;</span><br><span class="line">user-agent = &quot;npm/6.12.1 node/v13.1.0 linux x64 ci/jenkins&quot;</span><br><span class="line"></span><br><span class="line">; node bin location = /home/zj/.jenkins/tools/jenkins.plugins.nodejs.tools.NodeJSInstallation/node/bin/node</span><br><span class="line">; cwd = /home/zj/.jenkins/workspace/test</span><br><span class="line">; HOME = /opt/tomcat</span><br><span class="line">; &quot;npm config ls -l&quot; to show all defaults.</span><br><span class="line"></span><br><span class="line">[Pipeline] sh</span><br><span class="line">+ node -v</span><br><span class="line">v13.1.0</span><br><span class="line">+ npm -v</span><br><span class="line">6.12.1</span><br><span class="line">+ gulp -v</span><br><span class="line">CLI version: 2.2.0</span><br><span class="line">Local version: Unknown</span><br><span class="line">+ hexo -v</span><br><span class="line">hexo-cli: 3.1.0</span><br><span class="line">os: Linux 4.15.0-64-generic linux x64</span><br><span class="line">node: 13.1.0</span><br><span class="line">v8: 7.8.279.17-node.19</span><br><span class="line">uv: 1.33.1</span><br><span class="line">zlib: 1.2.11</span><br><span class="line">brotli: 1.0.7</span><br><span class="line">ares: 1.15.0</span><br><span class="line">modules: 79</span><br><span class="line">nghttp2: 1.39.2</span><br><span class="line">napi: 5</span><br><span class="line">llhttp: 1.1.4</span><br><span class="line">openssl: 1.1.1d</span><br><span class="line">cldr: 35.1</span><br><span class="line">icu: 64.2</span><br><span class="line">tz: 2019a</span><br><span class="line">unicode: 12.1</span><br><span class="line">[Pipeline] &#125;</span><br><span class="line">[Pipeline] // withEnv</span><br><span class="line">[Pipeline] &#125;</span><br><span class="line">[Pipeline] // stage</span><br><span class="line">[Pipeline] &#125;</span><br><span class="line">[Pipeline] // withEnv</span><br><span class="line">[Pipeline] &#125;</span><br><span class="line">[Pipeline] // node</span><br><span class="line">[Pipeline] End of Pipeline</span><br><span class="line">Finished: SUCCESS</span><br></pre></td></tr></table></figure>
<p>在执行之前会先安装<code>NodeJS</code>，并安装预设置的应用</p>
]]></content>
      <categories>
        <category>编程</category>
        <category>工具</category>
        <category>编程语言</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>nodeJS</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>在Docker中运行Jenkins</title>
    <url>/posts/202ee452.html</url>
    <content><![CDATA[<p>打算在远程服务器上运行<code>Jenkins</code>，忽然发现<code>git</code>没有安装，搞了半天没有成功（<em>各种依赖问题，条件限制不能重启机器</em>），所以尝试通过<code>Docker</code>运行<code>Jenkins</code></p><a id="more"></a>
<h2 id="完整命令"><a href="#完整命令" class="headerlink" title="完整命令"></a>完整命令</h2><p>下面首先提供完整执行命令，再依次介绍其中<code>Jenkins</code>配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker run -d \</span><br><span class="line">  --restart=always \</span><br><span class="line">  -p 7070:8080 \</span><br><span class="line">  -p 50000:50000 \</span><br><span class="line">  -v jenkins_home:/var/jenkins_home \</span><br><span class="line">  --name jenkins \</span><br><span class="line">  jenkins/jenkins</span><br></pre></td></tr></table></figure>
<h2 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a>镜像</h2><p><code>Jenkins</code>提供了官方镜像 - <a href="https://hub.docker.com/r/jenkins/jenkins/" target="_blank" rel="noopener">jenkins/jenkins</a></p>
<ul>
<li>使用稳定版：<code>docker pull jenkins/jenkins:lts</code></li>
<li>使用最新版：<code>docker pull jenkins/jenkins</code></li>
</ul>
<h2 id="启动jenkins"><a href="#启动jenkins" class="headerlink" title="启动jenkins"></a>启动jenkins</h2><p><code>docker</code>命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker run -p 7070:8080 -p 50000:50000 jenkins/jenkins</span><br></pre></td></tr></table></figure>
<p>其可通过浏览器登录：<code>http://192.xx.xx.xx:7070/</code></p>
<h3 id="保存数据"><a href="#保存数据" class="headerlink" title="保存数据"></a>保存数据</h3><p><code>Jenkins</code>所有配置数据保存在路径<code>/var/jenkins_home</code>，可以使用一个卷保存配置数据，方便复用和移植操作</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker run -p 7070:8080 -p 50000:50000 -v jenkins_home:/var/jenkins_home jenkins/jenkins</span><br></pre></td></tr></table></figure>
<p><code>docker</code>会生成一个新卷<code>jenkins_home</code>，可通过<code>docker volume ls</code>查看</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker volume ls</span><br><span class="line">DRIVER              VOLUME NAME</span><br><span class="line">local               jenkins_home</span><br></pre></td></tr></table></figure>
<h3 id="后台运行"><a href="#后台运行" class="headerlink" title="后台运行"></a>后台运行</h3><p>添加参数<code>-d</code>，设置容器在后台运行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker run -d -p 7070:8080 -p 50000:50000 -v jenkins_home:/var/jenkins_home jenkins/jenkins</span><br></pre></td></tr></table></figure>
<p>可通过命令<code>docker logs CONTAINER_ID</code>查询输出日志（比如初始密码）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker logs b79</span><br><span class="line">Running from: /usr/share/jenkins/jenkins.war</span><br><span class="line">webroot: EnvVars.masterEnvVars.get(&quot;JENKINS_HOME&quot;)</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h2 id="设置执行器数量"><a href="#设置执行器数量" class="headerlink" title="设置执行器数量"></a>设置执行器数量</h2><p><code>jenkins</code>默认允许<code>2</code>个执行器，可通过<code>groovy</code>脚本设置。新建脚本<code>executors.groovy</code>如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import jenkins.model.*</span><br><span class="line">Jenkins.instance.setNumExecutors(5)</span><br></pre></td></tr></table></figure>
<p>新建<code>Dockerfile</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM jenkins/jenkins:lts</span><br><span class="line">COPY executors.groovy /usr/share/jenkins/ref/init.groovy.d/executors.groovy</span><br></pre></td></tr></table></figure>
<p>重新编译生成新的<code>Jenkins</code>镜像</p>
<h2 id="镜像升级"><a href="#镜像升级" class="headerlink" title="镜像升级"></a>镜像升级</h2><p>所有数据均保存在<code>/var/jenkins_home</code>，通过上节卷的方式保存数据，再次执行<code>docker pull jenkins/jenkins</code>即可升级到最新的<code>Jenkins</code></p>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>直方图</title>
    <url>/posts/f1eacfb6.html</url>
    <content><![CDATA[<p><strong>以下主要涉及颜色直方图的概念和计算</strong></p><p>最开始学习数字图像处理的时候就接触到了直方图的概念，也记录过<code>OpenCV 1.x/2.x</code>的直方图实现代码</p><a id="more"></a>

<ul>
<li><a href="https://blog.csdn.net/u012005313/article/details/51122712" target="_blank" rel="noopener">opencv 颜色直方图（灰度图，均衡化，对比，描绘颜色直方图）</a></li>
<li><a href="https://blog.csdn.net/u012005313/article/details/46916559" target="_blank" rel="noopener">opencv 灰度直方图 一维直方图</a></li>
</ul>
<p>颜色/纹理等特征通过直方图的形式能够有效的作用于图像检测/识别算法，所以打算再整理一下相关的概念和实现。参考：</p>
<ul>
<li><a href="https://docs.opencv.org/4.0.1/d4/d1b/tutorial_histogram_equalization.html" target="_blank" rel="noopener">Histogram Equalization</a></li>
<li><a href="https://docs.opencv.org/4.0.1/d8/dbc/tutorial_histogram_calculation.html" target="_blank" rel="noopener">Histogram Calculation</a></li>
<li><p><a href="https://docs.opencv.org/4.0.1/d8/dc8/tutorial_histogram_comparison.html" target="_blank" rel="noopener">Histogram Comparison</a></p>
</li>
<li><p>头文件地址：<code>/path/to/opencv-4.0.1/modules/imgproc/include/opencv2/imgproc.hpp</code></p>
</li>
<li>源文件地址：<code>/path/to/opencv-4.0.1/modules/imgproc/src/histogram.cpp</code></li>
</ul>
<h2 id="内容列表"><a href="#内容列表" class="headerlink" title="内容列表"></a>内容列表</h2><ul>
<li>什么是直方图？</li>
<li>直方图计算</li>
<li>直方图均衡</li>
<li>直方图比较</li>
</ul>
<h2 id="什么是直方图？"><a href="#什么是直方图？" class="headerlink" title="什么是直方图？"></a>什么是直方图？</h2><ul>
<li>直方图（<code>histogram</code>）统计不同强度下的像素数目。直方图的最小单位是<code>bin</code>（箱）</li>
<li>强度通常指像素颜色值（颜色直方图）。但并不将其限制为颜色强度值，可以是任何对描述图像有用的特征，比如纹理特征（纹理直方图）</li>
</ul>
<h3 id="颜色直方图示例"><a href="#颜色直方图示例" class="headerlink" title="颜色直方图示例"></a>颜色直方图示例</h3><p>假设图像及其像素灰度值大小如下：</p>
<p><img src="/imgs/直方图/Histogram_Calculation_Theory_Hist0.jpg" alt></p>
<p>灰度值的取值范围在<code>[0, 255]</code>，每<code>15</code>个强度值划为一组，共得到<code>16</code>个子块</p>
<script type="math/tex; mode=display">
[0,255]=[0,15]∪[16,31]∪....∪[240,255]</script><script type="math/tex; mode=display">
range=bin_{1} ∪ bin_{2} ∪ .... ∪ bin_{n}=15</script><p>统计每个子块中的像素个数，得到的就是颜色直方图。图形化显示如下（<code>x</code>轴表示<code>bin</code>，<code>y</code>轴表示像素个数）</p>
<p><img src="/imgs/直方图/Histogram_Calculation_Theory_Hist1.jpg" alt></p>
<h3 id="关键参数"><a href="#关键参数" class="headerlink" title="关键参数"></a>关键参数</h3><p>直方图有<code>3</code>个关键参数：</p>
<ul>
<li><code>dims</code>：要收集数据的参数数量。在上式灰度图像中，仅收集每个像素的强度值（灰度值），所以<code>dims=1</code></li>
<li><code>bins</code>：每个<code>dim</code>中根据强度级别划分的子块数。上式中，灰度值取值范围在<code>[0,255]</code>，每<code>15</code>个强度值划为一组，共得到<code>16</code>个<code>bin</code> - <code>bins=16</code></li>
<li><code>range</code>：要测量的值的取值范围。上式中，要测量灰度值，取值为<code>[0,255]</code></li>
</ul>
<h3 id="直方图的作用"><a href="#直方图的作用" class="headerlink" title="直方图的作用"></a>直方图的作用</h3><ul>
<li>它表示了图像强度分布</li>
<li>它量化了每个强度值的像素数</li>
</ul>
<p>所以使用直方图能够统计数据的全局信息</p>
<h2 id="直方图计算"><a href="#直方图计算" class="headerlink" title="直方图计算"></a>直方图计算</h2><p>参考：<a href="https://docs.opencv.org/4.0.1/d6/dc7/group__imgproc__hist.html#ga4b2b5fd75503ff9e6844cc4dcdaed35d" target="_blank" rel="noopener">calcHist() [1/3]</a></p>
<p>实现步骤如下：</p>
<ol>
<li>加载图像</li>
<li>分离彩色图像到<code>R/G/B</code>通道</li>
<li>计算每个通道的颜色直方图</li>
<li>在同一图上绘制<code>3</code>个颜色直方图</li>
</ol>
<p><code>OpenCV</code>提供了<a href="https://docs.opencv.org/4.0.1/d6/dc7/group__imgproc__hist.html#ga4b2b5fd75503ff9e6844cc4dcdaed35d" target="_blank" rel="noopener">cv::calcHist</a>用于直方图计算</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CV_EXPORTS void calcHist( const Mat* images, int nimages,</span><br><span class="line">                          const int* channels, InputArray mask,</span><br><span class="line">                          OutputArray hist, int dims, const int* histSize,</span><br><span class="line">                          const float** ranges, bool uniform = true, bool accumulate = false );</span><br></pre></td></tr></table></figure>
<ul>
<li><code>images</code>：原图数组。应该具有相同的深度（<code>CV_8U、CV_16U或CV_32F</code>）以及相同的尺寸。每个图像可以有任意数量的通道</li>
<li><code>nimages</code>：图像个数</li>
<li><code>channels</code>：用于计算直方图的<code>dims</code>通道列表。第一个列表值表示计算第一张图像的前几个通道；第二个列表值表示计算第二张图像的前几个通道，最后累加到一起得到直方图</li>
<li><code>mask</code>：可选。如果矩阵不是空的，它必须是一个<code>8</code>位数组，大小与<code>images[i]</code>相同。非零掩码元素标记会被直方图计数的数组元素（<em>比如仅计算图像中某一区域的直方图</em>）</li>
<li><code>hist</code>：输出直方图</li>
<li><code>dims</code>：直方图维数，必须是正数，不大于<code>CV_MAX_DIMS</code>（当前取值为<code>32</code>）</li>
<li><code>histSize</code>：每个维度的直方图大小数组</li>
<li><code>ranges</code>：每个图像的取值范围</li>
<li><code>uniform</code>：默认为<code>true</code>，表示每张图片计算的直方图是否一致</li>
<li><code>accumulate</code>：累积标志。如果已设置，直方图在分配时不会在开始时被清除。此功能使您能够从几组数组中计算出一个直方图，或者及时更新直方图</li>
</ul>
<p>示例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &quot;opencv2/highgui.hpp&quot;</span><br><span class="line">#include &quot;opencv2/imgcodecs.hpp&quot;</span><br><span class="line">#include &quot;opencv2/imgproc.hpp&quot;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">using namespace cv;</span><br><span class="line">int main(int argc, char** argv)</span><br><span class="line">&#123;</span><br><span class="line">    CommandLineParser parser( argc, argv, &quot;&#123;@input | ../data/lena.jpg | input image&#125;&quot; );</span><br><span class="line">    Mat src = imread( parser.get&lt;String&gt;( &quot;@input&quot; ), IMREAD_COLOR );</span><br><span class="line">    if( src.empty() )</span><br><span class="line">    &#123;</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line">    vector&lt;Mat&gt; bgr_planes;</span><br><span class="line">    split( src, bgr_planes );</span><br><span class="line">    int histSize = 256;</span><br><span class="line">    float range[] = &#123; 0, 256 &#125;; //the upper boundary is exclusive</span><br><span class="line">    const float* histRange = &#123; range &#125;;</span><br><span class="line">    bool uniform = true, accumulate = false;</span><br><span class="line">    Mat b_hist, g_hist, r_hist;</span><br><span class="line">    calcHist( &amp;bgr_planes[0], 1, 0, Mat(), b_hist, 1, &amp;histSize, &amp;histRange, uniform, accumulate );</span><br><span class="line">    calcHist( &amp;bgr_planes[1], 1, 0, Mat(), g_hist, 1, &amp;histSize, &amp;histRange, uniform, accumulate );</span><br><span class="line">    calcHist( &amp;bgr_planes[2], 1, 0, Mat(), r_hist, 1, &amp;histSize, &amp;histRange, uniform, accumulate );</span><br><span class="line">    int hist_w = 512, hist_h = 400;</span><br><span class="line">    int bin_w = cvRound( (double) hist_w/histSize );</span><br><span class="line">    Mat histImage( hist_h, hist_w, CV_8UC3, Scalar( 0,0,0) );</span><br><span class="line">    normalize(b_hist, b_hist, 0, histImage.rows, NORM_MINMAX, -1, Mat() );</span><br><span class="line">    normalize(g_hist, g_hist, 0, histImage.rows, NORM_MINMAX, -1, Mat() );</span><br><span class="line">    normalize(r_hist, r_hist, 0, histImage.rows, NORM_MINMAX, -1, Mat() );</span><br><span class="line">    for( int i = 1; i &lt; histSize; i++ )</span><br><span class="line">    &#123;</span><br><span class="line">        line( histImage, Point( bin_w*(i-1), hist_h - cvRound(b_hist.at&lt;float&gt;(i-1)) ),</span><br><span class="line">              Point( bin_w*(i), hist_h - cvRound(b_hist.at&lt;float&gt;(i)) ),</span><br><span class="line">              Scalar( 255, 0, 0), 2, 8, 0  );</span><br><span class="line">        line( histImage, Point( bin_w*(i-1), hist_h - cvRound(g_hist.at&lt;float&gt;(i-1)) ),</span><br><span class="line">              Point( bin_w*(i), hist_h - cvRound(g_hist.at&lt;float&gt;(i)) ),</span><br><span class="line">              Scalar( 0, 255, 0), 2, 8, 0  );</span><br><span class="line">        line( histImage, Point( bin_w*(i-1), hist_h - cvRound(r_hist.at&lt;float&gt;(i-1)) ),</span><br><span class="line">              Point( bin_w*(i), hist_h - cvRound(r_hist.at&lt;float&gt;(i)) ),</span><br><span class="line">              Scalar( 0, 0, 255), 2, 8, 0  );</span><br><span class="line">    &#125;</span><br><span class="line">    imshow(&quot;Source image&quot;, src );</span><br><span class="line">    imshow(&quot;calcHist Demo&quot;, histImage );</span><br><span class="line">    waitKey();</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="直方图均衡"><a href="#直方图均衡" class="headerlink" title="直方图均衡"></a>直方图均衡</h2><p>参考：</p>
<p><a href="https://en.wikipedia.org/wiki/Histogram_equalization" target="_blank" rel="noopener">Histogram equalization</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/89598106" target="_blank" rel="noopener">直方图均衡化</a></p>
<p>直方图均衡通过扩展像素取值范围，能够提高图像对比度</p>
<p>均衡意味着将一个分布(给定直方图)映射到另一个分布(更宽和更均匀的分布)，以便强度值分布在整个范围内</p>
<h3 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h3><p>第一步：统计灰度直方图</p>
<p>第二步：计算每一级灰度的概率</p>
<script type="math/tex; mode=display">
p_{x}(i) = p(x=i) = \frac {n_{i}}{n}, 0\leq i < L</script><p>其中$L$表示灰度级数（通常为$256$），$n$表示图像像素个数，$p_{x}(i)$表示直方图中像素值为$i$的概率</p>
<p>第三步：计算累积分布函数<code>cdf(cumulative distribution function)</code></p>
<script type="math/tex; mode=display">
cdf_{x}(i) = \sum_{j=0}^{i}p_{x}(j)</script><p>第四步：求取映射像素值</p>
<script type="math/tex; mode=display">
s_{i} = T(r_{i}) = round((L-1)*cdf_{x}(i) + 0.5)</script><ul>
<li>函数$T$表示映射函数</li>
<li>函数$round$表示去除小数部分取整数</li>
<li>$(L-1)*cdf_{x}(i)$表示将像素值扩展回原先的级数</li>
</ul>
<p>经过第四步计算完成后就能够得到直方图均衡后的结果</p>
<h3 id="OpenCV使用"><a href="#OpenCV使用" class="headerlink" title="OpenCV使用"></a>OpenCV使用</h3><p><code>OpenCV</code>提供了函数<a href="https://docs.opencv.org/4.0.1/d6/dc7/group__imgproc__hist.html#ga7e54091f0c937d49bf84152a16f76d6e" target="_blank" rel="noopener">equalizeHist()</a>进行直方图均衡化的操作</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CV_EXPORTS_W void equalizeHist( InputArray src, OutputArray dst );</span><br></pre></td></tr></table></figure>
<p>参数<code>src</code>是一个<code>8</code>位单通道图像，输出<code>dst</code>得到和原图同样大小和类型的结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">Mat src = imread(parser.get&lt;String&gt;(&quot;@input&quot;), IMREAD_COLOR);</span><br><span class="line">if (src.empty()) &#123;</span><br><span class="line">    cout &lt;&lt; &quot;Could not open or find the image!\n&quot; &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;Usage: &quot; &lt;&lt; argv[0] &lt;&lt; &quot; &lt;Input image&gt;&quot; &lt;&lt; endl;</span><br><span class="line">    return -1;</span><br><span class="line">&#125;</span><br><span class="line">cvtColor(src, src, COLOR_BGR2GRAY);</span><br><span class="line">Mat dst;</span><br><span class="line">equalizeHist(src, dst);</span><br><span class="line"></span><br><span class="line">imshow(&quot;Source image&quot;, src);</span><br><span class="line">imshow(&quot;Equalized Image&quot;, dst);</span><br><span class="line">waitKey();</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h2 id="直方图比较"><a href="#直方图比较" class="headerlink" title="直方图比较"></a>直方图比较</h2><p>参考：<a href="https://docs.opencv.org/4.0.1/d6/dc7/group__imgproc__hist.html#ga994f53817d621e2e4228fc646342d386" target="_blank" rel="noopener">HistCompMethods</a></p>
<p>直方图比较的目的是计算两个直方图的匹配程度</p>
<p><code>OpenCV</code>提供了四种比较方式</p>
<ol>
<li><code>Correlation</code></li>
<li><code>Chi-Square</code></li>
<li><code>Intersection</code>（直方图相交）</li>
<li><code>Bhattacharyya distance</code></li>
</ol>
<h3 id="直方图相交"><a href="#直方图相交" class="headerlink" title="直方图相交"></a>直方图相交</h3><p>计算公式如下：</p>
<script type="math/tex; mode=display">
d(H_{1}, H_{2}) = \sum_{I} \min (H_{1}(I), H_{2}(I))</script><p>$H_{1}$和$H_{2}$是两个直方图</p>
<h3 id="操作步骤-1"><a href="#操作步骤-1" class="headerlink" title="操作步骤"></a>操作步骤</h3><p>参考：<a href="https://blog.csdn.net/l740450789/article/details/47124643" target="_blank" rel="noopener">颜色直方图，HSV直方图</a></p>
<ol>
<li>加载两张比较图像</li>
<li>转换成<code>HSV</code>格式，计算<code>H-S</code>直方图</li>
<li>使用直方图比较方式进行计算</li>
<li>输出匹配数值</li>
</ol>
<p>将图像转换成<code>HSV</code>格式后再进行直方图比较，更能够符合人眼对颜色相似性的主观判断</p>
<h3 id="OpenCV示例"><a href="#OpenCV示例" class="headerlink" title="OpenCV示例"></a>OpenCV示例</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">    Mat src_base = imread(path);</span><br><span class="line">    Mat src_test = imread(path2);</span><br><span class="line">    if (src_base.empty() || src_test.empty()) &#123;</span><br><span class="line">        cout &lt;&lt; &quot;Could not open or find the images!\n&quot; &lt;&lt; endl;</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Mat hsv_base, hsv_test1;</span><br><span class="line">    cvtColor(src_base, hsv_base, COLOR_BGR2HSV);</span><br><span class="line">    cvtColor(src_test, hsv_test1, COLOR_BGR2HSV);</span><br><span class="line"></span><br><span class="line">    int h_bins = 50, s_bins = 60;</span><br><span class="line">    int histSize[] = &#123;h_bins, s_bins&#125;;</span><br><span class="line">    // hue varies from 0 to 179, saturation from 0 to 255</span><br><span class="line">    float h_ranges[] = &#123;0, 180&#125;;</span><br><span class="line">    float s_ranges[] = &#123;0, 256&#125;;</span><br><span class="line">    const float *ranges[] = &#123;h_ranges, s_ranges&#125;;</span><br><span class="line">    // Use the 0-th and 1-st channels</span><br><span class="line">    int channels[] = &#123;0, 1&#125;;</span><br><span class="line"></span><br><span class="line">    Mat hist_base, hist_test;</span><br><span class="line">    calcHist(&amp;hsv_base, 1, channels, Mat(), hist_base, 2, histSize, ranges, true, false);</span><br><span class="line">    normalize(hist_base, hist_base, 0, 1, NORM_MINMAX, -1, Mat());</span><br><span class="line"></span><br><span class="line">    calcHist(&amp;hsv_test1, 1, channels, Mat(), hist_test, 2, histSize, ranges, true, false);</span><br><span class="line">    normalize(hist_test, hist_test, 0, 1, NORM_MINMAX, -1, Mat());</span><br><span class="line"></span><br><span class="line">    double base_test = compareHist(hist_base, hist_test, HISTCMP_INTERSECT);</span><br><span class="line">    cout &lt;&lt; &quot;Method HISTCMP_INTERSECT : &quot; &lt;&lt; base_test &lt;&lt; endl;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h2 id="手动实现直方图计算"><a href="#手动实现直方图计算" class="headerlink" title="手动实现直方图计算"></a>手动实现直方图计算</h2><p>直方图计算主要涉及<code>cv::calcHist</code>和<code>cv::normalize</code>的使用。完整代码如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//</span><br><span class="line">// Created by zj on 19-11-24.</span><br><span class="line">//</span><br><span class="line"></span><br><span class="line">#include &quot;opencv2/highgui.hpp&quot;</span><br><span class="line">#include &quot;opencv2/imgcodecs.hpp&quot;</span><br><span class="line">#include &quot;opencv2/imgproc.hpp&quot;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;array&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line">using namespace cv;</span><br><span class="line"></span><br><span class="line">const static array&lt;Scalar, 3&gt; colors = &#123;</span><br><span class="line">        Scalar(255, 0, 0),</span><br><span class="line">        Scalar(0, 255, 0),</span><br><span class="line">        Scalar(0, 0, 255)</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 计算颜色直方图，图像取值固定为[0, 255]</span><br><span class="line"> * @param src CV_8UC1或CV_8UC3大小图像</span><br><span class="line"> * @param histograms 直方图向量</span><br><span class="line"> * @param bins 直方图大小</span><br><span class="line"> */</span><br><span class="line">void calc_color_hist(const Mat &amp;src, vector&lt;Mat&gt; &amp;histograms, int bins) &#123;</span><br><span class="line">    int channels = src.channels();</span><br><span class="line">    vector&lt;Mat&gt; img_planes;</span><br><span class="line">    if (channels == 3) &#123;</span><br><span class="line">        split(src, img_planes);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // gray</span><br><span class="line">        img_planes.emplace_back(src);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    float range[] = &#123;0, 256&#125;; //the upper boundary is exclusive</span><br><span class="line">    const float *histRange = &#123;range&#125;;</span><br><span class="line">    bool uniform = true, accumulate = false;</span><br><span class="line"></span><br><span class="line">    for (int i = 0; i &lt; channels; i++) &#123;</span><br><span class="line">        Mat hist;</span><br><span class="line">        calcHist(&amp;img_planes[i], 1, nullptr, Mat(), hist, 1, &amp;bins, &amp;histRange, uniform, accumulate);</span><br><span class="line">//        cout &lt;&lt; hist.type() &lt;&lt; endl;</span><br><span class="line">        histograms.emplace_back(hist);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 绘制直方图，首先对直方图标准化，再按比例绘制线条</span><br><span class="line"> */</span><br><span class="line">void draw_color_hist(const vector&lt;Mat&gt; &amp;histograms, Mat &amp;histImage, int bins) &#123;</span><br><span class="line">    int hist_w = 512, hist_h = 400;</span><br><span class="line">    histImage = Mat(hist_h, hist_w, CV_8UC3, Scalar(0, 0, 0));</span><br><span class="line"></span><br><span class="line">    int bin_w = cvRound((double) hist_w / bins);</span><br><span class="line">    for (int i = 0; i &lt; histograms.size(); i++) &#123;</span><br><span class="line">        Mat hist = histograms[i];</span><br><span class="line">        Mat hist_tmp;</span><br><span class="line">        // 标准化直方图，取值为[0.0, hist_h]</span><br><span class="line">        normalize(hist, hist_tmp, 0, histImage.rows, NORM_MINMAX, -1, Mat());</span><br><span class="line">//        cout &lt;&lt; hist_tmp.type() &lt;&lt; endl;</span><br><span class="line">        Scalar color = colors[i % colors.size()];</span><br><span class="line">        for (int i = 1; i &lt; bins; i++) &#123;</span><br><span class="line">            line(histImage,</span><br><span class="line">                 Point(bin_w * (i - 1), hist_h - cvRound(hist_tmp.at&lt;float&gt;(i - 1))),</span><br><span class="line">                 Point(bin_w * (i), hist_h - cvRound(hist_tmp.at&lt;float&gt;(i))),</span><br><span class="line">                 color,</span><br><span class="line">                 2, 8, 0);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 手动计算颜色直方图</span><br><span class="line"> * @param src CV_8UC1或CV_8UC3</span><br><span class="line"> * @param histograms 颜色直方图向量</span><br><span class="line"> * @param bins 直方图大小</span><br><span class="line"> */</span><br><span class="line">void calc_color_hist_manully(const Mat &amp;src, vector&lt;Mat&gt; &amp;histograms, int bins) &#123;</span><br><span class="line">    int channels = src.channels();</span><br><span class="line">    float ranges[] = &#123;0.0, 256.0&#125;;</span><br><span class="line">    // 计算每个bin的取值范围</span><br><span class="line">    double range = (ranges[1] - ranges[0]) / bins;</span><br><span class="line"></span><br><span class="line">    // 分离图像</span><br><span class="line">    vector&lt;Mat&gt; img_planes;</span><br><span class="line">    if (channels == 1) &#123;</span><br><span class="line">        img_planes.emplace_back(src);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // 分离3通道</span><br><span class="line">        split(src, img_planes);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 遍历所有通道，计算颜色直方图</span><br><span class="line">    for (int i = 0; i &lt; channels; i++) &#123;</span><br><span class="line">        Mat hist = Mat::zeros(1, bins, CV_32F);</span><br><span class="line">        auto *hdata = hist.ptr&lt;float&gt;(0);</span><br><span class="line"></span><br><span class="line">        Mat plane = img_planes[i];</span><br><span class="line">        // 遍历所有像素，从左到右，从上到下</span><br><span class="line">        for (int y = 0; y &lt; plane.rows; y++) &#123;</span><br><span class="line">            auto *pdata = plane.ptr&lt;uchar&gt;(y);</span><br><span class="line"></span><br><span class="line">            for (int x = 0; x &lt; plane.cols; x++) &#123;</span><br><span class="line">                hdata[cvFloor(static_cast&lt;int&gt;(pdata[x]) / range)] += 1;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        histograms.emplace_back(hist);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 绘制直方图，首先手动对直方图标准化，再按比例绘制线条</span><br><span class="line"> * @param histograms 直方图列表</span><br><span class="line"> * @param histImage 绘制直方图</span><br><span class="line"> * @param bins 直方图大小</span><br><span class="line"> */</span><br><span class="line">void draw_color_hist_manully(const vector&lt;Mat&gt; &amp;histograms, Mat &amp;histImage, int bins) &#123;</span><br><span class="line">    int hist_w = 512, hist_h = 400;</span><br><span class="line">    histImage = Mat(hist_h, hist_w, CV_8UC3, Scalar(0, 0, 0));</span><br><span class="line"></span><br><span class="line">    auto channels = histograms.size();</span><br><span class="line"></span><br><span class="line">    // 手动标准化直方图</span><br><span class="line">    vector&lt;Mat&gt; hist_tmps;</span><br><span class="line">    for (int i = 0; i &lt; channels; i++) &#123;</span><br><span class="line">        double min, max;</span><br><span class="line">        cv::minMaxLoc(histograms[i], &amp;min, &amp;max);</span><br><span class="line">        Mat hist_tmp = Mat::zeros(histograms[i].size(), CV_32F);</span><br><span class="line"></span><br><span class="line">        auto *hdata = histograms[i].ptr&lt;float&gt;(0);</span><br><span class="line">        auto *hdata_tmp = hist_tmp.ptr&lt;float&gt;(0);</span><br><span class="line">        for (int j = 0; j &lt; bins; j++) &#123;</span><br><span class="line">            hdata_tmp[j] = static_cast&lt;float&gt;(hist_h * (hdata[j] - min) / (max - min));</span><br><span class="line">        &#125;</span><br><span class="line">        hist_tmps.emplace_back(hist_tmp);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    int bin_w = cvRound(1.0 * hist_w / bins);</span><br><span class="line">    for (int i = 0; i &lt; channels; i++) &#123;</span><br><span class="line">        Scalar color = colors[i % colors.size()];</span><br><span class="line">        auto *hdata = hist_tmps[i].ptr&lt;float&gt;(0);</span><br><span class="line"></span><br><span class="line">        for (int j = 1; j &lt; bins; j++) &#123;</span><br><span class="line">            line(histImage,</span><br><span class="line">                 Point(bin_w * (j - 1), cvRound(hist_h - hdata[j - 1])),</span><br><span class="line">                 Point(bin_w * (j), cvRound(hist_h - hdata[j])),</span><br><span class="line">                 color,</span><br><span class="line">                 2, 8, 0);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(int argc, char **argv) &#123;</span><br><span class="line">    CommandLineParser parser(argc, argv, &quot;&#123;@input | ../lena.jpg | input image&#125;&quot;);</span><br><span class="line">    Mat src = imread(parser.get&lt;String&gt;(&quot;@input&quot;), IMREAD_COLOR);</span><br><span class="line">    if (src.empty()) &#123;</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">//    Mat gray;</span><br><span class="line">//    cvtColor(src, gray, COLOR_BGR2GRAY);</span><br><span class="line">//    src = gray;</span><br><span class="line"></span><br><span class="line">    int bins = 256;</span><br><span class="line">    vector&lt;Mat&gt; histograms, histograms2;</span><br><span class="line">    Mat histImage, histImage2;</span><br><span class="line"></span><br><span class="line">    // 调用OpenCV提供的直方图计算和标准化函数</span><br><span class="line">    double t1 = (double) getTickCount();</span><br><span class="line">    calc_color_hist(src, histograms, bins);</span><br><span class="line">    draw_color_hist(histograms, histImage, bins);</span><br><span class="line">    // 手动计算和标准化直方图</span><br><span class="line">    double t2 = (double) getTickCount();</span><br><span class="line">    calc_color_hist_manully(src, histograms2, bins);</span><br><span class="line">    draw_color_hist_manully(histograms2, histImage2, bins);</span><br><span class="line">    double t3 = (double) getTickCount();</span><br><span class="line"></span><br><span class="line">    double time1 = (t2 - t1) / getTickFrequency();</span><br><span class="line">    double time2 = (t3 - t2) / getTickFrequency();</span><br><span class="line">    cout &lt;&lt; time1 &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; time2 &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    // 判断绘制图像是否相等</span><br><span class="line">    cv::Mat diff = histImage != histImage2;</span><br><span class="line">    cout &lt;&lt; sum(diff) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    imshow(&quot;Source image&quot;, src);</span><br><span class="line">    imshow(&quot;OpenCV API&quot;, histImage);</span><br><span class="line">    imshow(&quot;手动实现&quot;, histImage2);</span><br><span class="line">    waitKey();</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/直方图/baboon.jpg" alt></p>
<p><img src="/imgs/直方图/draw_hist.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>图像处理</category>
        <category>编程语言</category>
        <category>直方图</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>opencv</tag>
        <tag>颜色直方图</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]Selective Search for Object Detection (C++/Python)</title>
    <url>/posts/815ea453.html</url>
    <content><![CDATA[<p>学习论文<code>Selective Search for Object Recognition</code>，在网上查找相关资料时发现这篇文章，对于选择性搜索算法及其特征提取方式概括的比较好，所以翻译下来以便后续的学习</p><a id="more"></a>
<p>原文地址：<a href="https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/" target="_blank" rel="noopener">Selective Search for Object Detection (C++ / Python)</a></p>
<blockquote>
<p>In this tutorial, we will understand an important concept called “Selective Search” in Object Detection. We will also share OpenCV code in C++ and Python.</p>
</blockquote>
<p>在本教程中，我们将了解一个重要的概念 - 基于选择性搜索的目标检测。文章末尾还包含了OpenCV示例</p>
<h2 id="Object-Detection-vs-Object-Recognition"><a href="#Object-Detection-vs-Object-Recognition" class="headerlink" title="Object Detection vs. Object Recognition"></a>Object Detection vs. Object Recognition</h2><p>目标检测 vs. 目标识别</p>
<blockquote>
<p>An object recognition algorithm identifies which objects are present in an image. It takes the entire image as an input and outputs class labels and class probabilities of objects present in that image. For example, a class label could be “dog” and the associated class probability could be 97%.</p>
</blockquote>
<p>目标识别算法识别图像中存在的对象。它将整个图像作为输入，并输出该图像中对象的类标签和类概率。例如，类标签可以是”dog”，其关联的类概率为97%</p>
<blockquote>
<p>On the other hand, an object detection algorithm not only tells you which objects are present in the image, it also outputs bounding boxes (x, y, width, height) to indicate the location of the objects inside the image.</p>
</blockquote>
<p>另一方面，目标检测算法不仅告诉您图像中存在哪些对象，还输出边界框（x，y，width，height）以指示对象在图像中的位置</p>
<blockquote>
<p>At the heart of all object detection algorithms is an object recognition algorithm. Suppose we trained an object recognition model which identifies dogs in image patches. This model will tell whether an image has a dog in it or not. It does not tell where the object is located.</p>
</blockquote>
<p>所有目标检测算法的核心是目标识别算法。假设我们训练了一个目标识别模型，在图像块中识别狗。这个模型将判断图像中是否有狗，但它不知道狗的位置</p>
<blockquote>
<p>To localize the object, we have to select sub-regions (patches) of the image and then apply the object recognition algorithm to these image patches. The location of the objects is given by the location of the image patches where the class probability returned by the object recognition algorithm is high.</p>
</blockquote>
<p>为了定位目标，我们必须选择图像的子区域（小块），然后将目标识别算法应用于这些图像块。目标的位置由目标识别算法返回的类概率较高的图像块的位置给出</p>
<blockquote>
<p>The most straightforward way to generate smaller sub-regions (patches) is called the Sliding Window approach. However, the sliding window approach has several limitations. These limitations are overcome by a class of algorithms called the “Region Proposal” algorithms. Selective Search is one of the most popular Region Proposal algorithms.</p>
</blockquote>
<p>生成较小子区域（块）的最直接的方法称为滑动窗口方法。然而，滑动窗口方法有一些局限，而这些局限已经被”区域建议”算法所克服。选择性搜索是最流行的区域建议算法之一</p>
<p><img src="/imgs/译-Selective-Search-for-Object-Detection-C-Python/object-recognition-dogs-768x436.jpg" alt></p>
<h2 id="Sliding-Window-Algorithm"><a href="#Sliding-Window-Algorithm" class="headerlink" title="Sliding Window Algorithm"></a>Sliding Window Algorithm</h2><p>滑动窗口算法</p>
<blockquote>
<p>In the sliding window approach, we slide a box or window over an image to select a patch and classify each image patch covered by the window using the object recognition model. It is an exhaustive search for objects over the entire image. Not only do we need to search all possible locations in the image, we have to search at different scales. This is because object recognition models are generally trained at a specific scale (or range of scales). This results into classifying tens of thousands of image patches.</p>
</blockquote>
<p>在滑动窗口方法中，我们将一个盒子或窗口滑动到一个图像上，选择一小块，并使用目标识别模型对窗口覆盖的每个图像块进行分类。它是对整个图像上的对象进行穷举搜索。我们不仅需要搜索图像中所有可能的位置，还需要在不同的尺度上进行搜索。这是因为目标识别模型通常是在特定的尺度（或尺度范围）下训练的。这将导致数万个图像块被分类</p>
<blockquote>
<p>The problem doesn’t end here. Sliding window approach is good for fixed aspect ratio objects such as faces or pedestrians. Images are 2D projections of 3D objects. Object features such as aspect ratio and shape vary significantly based on the angle at which image is taken. The sliding window approach because computationally very expensive when we search for multiple aspect ratios.</p>
</blockquote>
<p>问题还没有结束。滑动窗口方法适用于固定长宽比的物体，如人脸或行人。图像是三维物体的二维投影。对象特征，如纵横比和形状，根据拍摄图像的角度有很大的变化。滑动窗口方法，因为当我们搜索多个纵横比时，计算非常昂贵</p>
<h2 id="Region-Proposal-Algorithms"><a href="#Region-Proposal-Algorithms" class="headerlink" title="Region Proposal Algorithms"></a>Region Proposal Algorithms</h2><p>区域建议算法</p>
<blockquote>
<p>The problems we have discussed so far can be solved using region proposal algorithms. These methods take an image as the input and output bounding boxes corresponding to all patches in an image that are most likely to be objects. These region proposals can be noisy, overlapping and may not contain the object perfectly but amongst these region proposals, there will be a proposal which will be very close to the actual object in the image. We can then classify these proposals using the object recognition model. The region proposals with the high probability scores are locations of the object.</p>
</blockquote>
<p>到目前为止，我们讨论的问题可以用区域建议算法来解决。这些方法将图像作为输入，输出图像中最可能是目标的所有块相对应的边界框。这些区域建议可能是有噪声的，重叠的，并且可能不完全包含对象，但是在这些区域建议中，将有一个建议非常接近图像中的实际对象。然后我们可以使用目标识别模型对这些建议进行分类。高概率得分的区域建议就是目标的位置</p>
<blockquote>
<p>Region proposal algorithms identify prospective objects in an image using segmentation. In segmentation, we group adjacent regions which are similar to each other based on some criteria such as color, texture etc. Unlike the sliding window approach where we are looking for the object at all pixel locations and at all scales, region proposal algorithm work by grouping pixels into a smaller number of segments. So the final number of proposals generated are many times less than sliding window approach. This reduces the number of image patches we have to classify. These generated region proposals are of different scales and aspect ratios.</p>
</blockquote>
<p>区域建议算法通过分割识别期望的对象。在分割过程中，我们根据颜色、纹理等准则组合彼此相似的相邻区域。与滑动窗口方法不同，滑动窗口方法是在所有像素位置和所有尺度上查找对象，区域建议算法通过将像素分组成更小的段来工作。因此，最终生成的建议数比滑动窗口方法少许多倍。这减少了我们需要分类的图像块的数量。这些生成的区域建议具有不同的比例和纵横比</p>
<blockquote>
<p>An important property of a region proposal method is to have a very high recall. This is just a fancy way of saying that the regions that contain the objects we are looking have to be in our list of region proposals. To accomplish this our list of region proposals may end up having a lot of regions that do not contain any object. In other words, it is ok for the region proposal algorithm to produce a lot of false positives so long as it catches all the true positives. Most of these false positives will be rejected by object recognition algorithm. The time it takes to do the detection goes up when we have more false positives and the accuracy is affected slightly. But having a high recall is still a good idea because the alternative of missing the regions containing the actual objects severely impacts the detection rate.</p>
</blockquote>
<p>区域建议方法的一个重要特性是具有很高的召回率。这只是一种奇特的说法，即包含我们正在寻找的对象的区域必须在我们的区域建议列表中。为了实现这一点，我们的区域建议列表可能会有很多区域不包含任何对象。换句话说，区域建议算法只要能够捕捉到所有的真阳性，产生大量的假阳性是可以接受的。因为这些假阳性大多会被目标识别算法拒绝。当我们有更多的假阳性并且准确度受到轻微影响时，检测所需的时间就会增加。但是高召回率仍然是一个好主意，因为丢失包含实际对象的区域会严重影响检测率</p>
<blockquote>
<p>Several region proposal methods have been proposed such as</p>
<ol>
<li>Objectness</li>
<li>Constrained Parametric Min-Cuts for Automatic Object Segmentation</li>
<li>Category Independent Object Proposals</li>
<li>Randomized Prim</li>
<li>Selective Search</li>
</ol>
<p>Amongst all these region proposal methods Selective Search is most commonly used because it is fast and has a very high recall.</p>
</blockquote>
<p>有如下几种区域建议算法：</p>
<ol>
<li><a href="http://groups.inf.ed.ac.uk/calvin/objectness/" target="_blank" rel="noopener">Objectness</a></li>
<li><a href="http://www.maths.lth.se/matematiklth/personal/sminchis/code/cpmc/index.html" target="_blank" rel="noopener">Constrained Parametric Min-Cuts for Automatic Object Segmentation</a></li>
<li><a href="http://vision.cs.uiuc.edu/proposals/" target="_blank" rel="noopener">Category Independent Object Porposals</a></li>
<li><a href="http://www.vision.ee.ethz.ch/~smanenfr/rp/index.html" target="_blank" rel="noopener">Randomized Prim</a></li>
<li><a href="http://koen.me/research/selectivesearch/" target="_blank" rel="noopener">Selective Search</a></li>
</ol>
<p>在所有这些区域建议方法中，选择性搜索是最常用的，因为它速度快，召回率高</p>
<p><img src="/imgs/译-Selective-Search-for-Object-Detection-C-Python/object-recognition-false-positives-true-positives-768x436.jpg" alt></p>
<blockquote>
<p>Blue Boxes: False Positives; Green Boxes: True Positives</p>
</blockquote>
<p>蓝色框：假阳性；绿色框：真阳性</p>
<h2 id="Selective-Search-for-Object-Recognition"><a href="#Selective-Search-for-Object-Recognition" class="headerlink" title="Selective Search for Object Recognition"></a>Selective Search for Object Recognition</h2><p>作用于目标识别的选择性搜索</p>
<h3 id="What-is-Selective-Search"><a href="#What-is-Selective-Search" class="headerlink" title="What is Selective Search?"></a>What is Selective Search?</h3><p>什么是选择性搜索？</p>
<blockquote>
<p>Selective Search is a region proposal algorithm used in object detection. It is designed to be fast with a very high recall. It is based on computing hierarchical grouping of similar regions based on color, texture, size and shape compatibility.</p>
</blockquote>
<p>选择性搜索是一种用于目标检测的区域建议算法。它的速度很快，召回率很高。它基于颜色、纹理、大小和形状兼容性计算相似区域的分层分组</p>
<blockquote>
<p>Selective Search starts by over-segmenting the image based on intensity of the pixels using a graph-based segmentation method by Felzenszwalb and Huttenlocher. The output of the algorithm is shown below. The image on the right contains segmented regions represented using solid colors.</p>
</blockquote>
<p>选择性搜索从基于像素强度的图像过度分割开始，使用Felzenszwalb和Huttenlocher实现的基于图的分割方法，该算法输出如下所示。右侧的图像包含使用纯色表示的分段区域</p>
<p><img src="/imgs/译-Selective-Search-for-Object-Detection-C-Python/breakfast-768x512.jpg" alt>  <img src="/imgs/译-Selective-Search-for-Object-Detection-C-Python/breakfast_fnh-768x512.jpg" alt></p>
<blockquote>
<p>Can we use segmented parts in this image as region proposals? The answer is no and there are two reasons why we cannot do that:</p>
<ol>
<li>Most of the actual objects in the original image contain 2 or more segmented parts</li>
<li>Region proposals for occluded objects such as the plate covered by the cup or the cup filled with coffee cannot be generated using this method</li>
</ol>
</blockquote>
<p>我们可以用这个图像中的分割部分作为区域建议吗？答案是否定的，不能这样做的原因有两个：</p>
<ol>
<li>原始图像中的大多数实际对象包含2个或更多分段部分</li>
<li>无法使用此方法生成被遮挡对象的区域建议，例如杯子覆盖的板或装满咖啡的杯子</li>
</ol>
<blockquote>
<p>If we try to address the first problem by further merging the adjacent regions similar to each other we will end up with one segmented region covering two objects.</p>
</blockquote>
<p>如果我们试图通过进一步合并彼此相似的相邻区域来解决第一个问题，我们最终将得到一个覆盖两个对象的分段区域</p>
<blockquote>
<p>Perfect segmentation is not our goal here. We just want to predict many region proposals such that some of them should have very high overlap with actual objects.</p>
</blockquote>
<p>完美的分割并不是我们的目标。我们只想预测许多区域提案，以便其中一些提案与实际对象有很高的重叠</p>
<blockquote>
<p>Selective search uses oversegments from Felzenszwalb and Huttenlocher’s method as an initial seed. An oversegmented image looks like this.</p>
</blockquote>
<p>选择性搜索使用来自Felzenszwalb和Huttenlocher的方法得到的过度分段作为初始种子。过度分段图像如下所示：</p>
<p><img src="/imgs/译-Selective-Search-for-Object-Detection-C-Python/oversegmented-image.png" alt></p>
<blockquote>
<p>Selective Search algorithm takes these oversegments as initial input and performs the following steps</p>
<ol>
<li>Add all bounding boxes corresponding to segmented parts to the list of regional proposals</li>
<li>Group adjacent segments based on similarity</li>
<li>Go to step 1</li>
</ol>
</blockquote>
<p>选择性搜索算法将这些分段作为初始输入，并执行以下步骤:</p>
<ol>
<li>将与分段部分相对应的所有边界框添加到区域方案列表中</li>
<li>基于相似度组合相邻分段</li>
<li>回到第一步</li>
</ol>
<blockquote>
<p>At each iteration, larger segments are formed and added to the list of region proposals. Hence we create region proposals from smaller segments to larger segments in a bottom-up approach. This is what we mean by computing “hierarchical” segmentations using Felzenszwalb and Huttenlocher’s oversegments.</p>
</blockquote>
<p>在每次迭代中，都会形成较大的分段并将其添加到区域建议列表中。因此，我们采用自下而上的方法，从较小的部分到较大的部分创建区域建议。这就是我们所说的使用Felzenszwalb和Huttenlocher的过度分段计算“层次”分段</p>
<p><img src="/imgs/译-Selective-Search-for-Object-Detection-C-Python/hierarchical-segment.png" alt></p>
<blockquote>
<p>This image shows the initial, middle and last step of the hierarchical segmentation process.</p>
</blockquote>
<p>上述图像显示了分层分割过程的初始、中间和最后一步</p>
<h2 id="Similarity"><a href="#Similarity" class="headerlink" title="Similarity"></a>Similarity</h2><p>相似度</p>
<blockquote>
<p>Let’s dive deeper into how do we calculate the similarity between two regions.</p>
</blockquote>
<p>让我们深入探讨如何计算两个区域之间的相似度</p>
<blockquote>
<p>Selective Search uses 4 similarity measures based on color, texture, size and shape compatibility.</p>
</blockquote>
<p>选择性搜索使用基于颜色、纹理、大小和形状兼容性的4种相似性度量</p>
<h3 id="Color-Similarity"><a href="#Color-Similarity" class="headerlink" title="Color Similarity"></a>Color Similarity</h3><p>颜色相似度</p>
<blockquote>
<p>A color histogram of 25 bins is calculated for each channel of the image and histograms for all channels are concatenated to obtain a color descriptor resulting into a 25×3 = 75-dimensional color descriptor.</p>
</blockquote>
<p>为图像的每个通道计算25个bin的颜色直方图，并将所有通道的直方图连接起来，以获得25×3＝75维的颜色描述符</p>
<blockquote>
<p>Color similarity of two regions is based on histogram intersection and can be calculated as:</p>
</blockquote>
<p>两个区域的颜色相似度基于直方图相交，可计算为：</p>
<script type="math/tex; mode=display">
s_{color}(r_{i},r_{j})=\sum_{k=1}^{n}\min(c_{i}^{k}, c_{j}^{k})</script><blockquote>
<p>$c_{i}^{k}$ is the histogram value for $k^{th}$ bin in color descriptor.</p>
</blockquote>
<p>$c_{i}^{k}$表示颜色描述符中第$k$个bin的直方图值</p>
<h3 id="Texture-Similarity"><a href="#Texture-Similarity" class="headerlink" title="Texture Similarity"></a>Texture Similarity</h3><p>纹理相似度</p>
<blockquote>
<p>Texture features are calculated by extracting Gaussian derivatives at 8 orientations for each channel. For each orientation and for each color channel, a 10-bin histogram is computed resulting into a 10x8x3 = 240-dimensional feature descriptor.</p>
</blockquote>
<p>纹理特征是通过提取每个通道8个方向上的高斯导数来计算的。对于每个方向和每个颜色通道，计算10个bin的直方图，得到10x8x3=240维特征描述符</p>
<blockquote>
<p>Texture similarity of two regions is also calculated using histogram intersections.</p>
</blockquote>
<p>两个区域的纹理相似度也使用直方图相交计算：</p>
<script type="math/tex; mode=display">
s_{texture}(r_{i}, r_{j}) = \sum_{k=1}^{n} \min (t_{i}^{k}, t_{j}^{k})</script><blockquote>
<p>$t_{i}^{k}$ is the histogram value for $k^{th}$ bin in texture descriptor</p>
</blockquote>
<p>$t_{i}^{k}$表示纹理描述符中第$k$个bin的直方图值</p>
<h3 id="Size-Similarity"><a href="#Size-Similarity" class="headerlink" title="Size Similarity"></a>Size Similarity</h3><p>大小相似度</p>
<blockquote>
<p>Size similarity encourages smaller regions to merge early. It ensures that region proposals at all scales are formed at all parts of the image. If this similarity measure is not taken into consideration a single region will keep gobbling up all the smaller adjacent regions one by one and hence region proposals at multiple scales will be generated at this location only. Size similarity is defined as:</p>
</blockquote>
<p>大小相似度鼓励较小的区域尽早合并。它确保在图像的所有部分形成所有比例的区域建议。如果不考虑这种相似性度量，则单个区域将逐个吞噬所有较小的相邻区域，因此仅在此位置生成多个尺度的区域建议。大小相似度定义如下：</p>
<script type="math/tex; mode=display">
s_{size}(r_{i}, r_{j}) = 1 - \frac {size(r_{i}) + size(r_{j})}{size(im)}</script><blockquote>
<p>where $size(im)$ is size of image in pixels</p>
</blockquote>
<p>其中$size(im)$指的是图像的像素大小</p>
<h3 id="Shape-Compatibility"><a href="#Shape-Compatibility" class="headerlink" title="Shape Compatibility"></a>Shape Compatibility</h3><p>形状兼容度</p>
<blockquote>
<p>Shape compatibility measures how well two regions ($r_i$ and $r_j$) fit into each other. If $r_i$ fits into $r_j$ we would like to merge them in order to fill gaps and if they are not even touching each other they should not be merged.</p>
</blockquote>
<p>形状兼容度判定两个区域（$r_{i}$和$r_{j}$）的匹配程度。如果$r_{i}$与$r_{j}$相匹配，希望将它们合并能够填补框的空白，如果它们甚至没有相互接触，则不应合并</p>
<blockquote>
<p>Shape compatibility is defined as:</p>
</blockquote>
<p>形状兼容度定义如下：</p>
<script type="math/tex; mode=display">
s_{fill}(r_{i},r_{j}) = 1 - \frac{size(BB_{ij}) - size(r_{i}) - size(r_{j})}{size(im)}</script><blockquote>
<p>where $size(BB_{ij})$ is a bounding box around $r_{i}$ and $r_{j}$</p>
</blockquote>
<p>其中$size(BB_{ij})$是围绕$r_{i}$和$r_{j}$的边界框</p>
<h3 id="Final-Similarity"><a href="#Final-Similarity" class="headerlink" title="Final Similarity"></a>Final Similarity</h3><blockquote>
<p>The final similarity between two regions is defined as a linear combination of aforementioned 4 similarities.</p>
</blockquote>
<p>两个区域之间的最终相似度定义为上述4个相似度的线性组合</p>
<script type="math/tex; mode=display">
s(r_{i}, r_{j}) = a_{1}s_{color}(r_{i}, r_{j}) + a_{2}s_{texture}(r_{i}, r_{j}) + a_{3}s_{size}(r_{i}, r_{j}) + a_{4}s_{fill}(r_{i}, r_{j})</script><blockquote>
<p>where $r_i$ and $r_j$ are two regions or segments in the image and $a_i \in {0, 1}$ denotes if the similarity measure is used or not.</p>
</blockquote>
<p>其中$r_i$和$r_j$是图像中的两个区域或段，$a_{i}\in {0，1}$表示是否使用了相似性度量</p>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>结果</p>
<blockquote>
<p>Selective Search implementation in OpenCV gives thousands of region proposals arranged in decreasing order of objectness. For clarity, we are sharing results with top 200-250 boxes drawn over the image. In general 1000-1200 proposals are good enough to get all the correct region proposals.</p>
</blockquote>
<p>OpenCV中的选择性搜索实现给出了数千个按目标降序排列的区域建议。为了清晰起见，我们将与图像上绘制的前200-250个框共享结果。总的来说，1000-1200份建议足以得到所有正确的区域建议</p>
<p><img src="/imgs/译-Selective-Search-for-Object-Detection-C-Python/result.png" alt></p>
<h2 id="Selective-Search-Code"><a href="#Selective-Search-Code" class="headerlink" title="Selective Search Code"></a>Selective Search Code</h2><p>选择性搜索实现代码</p>
<p><code>OpenCV</code>提供了选择性搜索算法的使用示例，包含了<code>C++</code>版本和<code>Python</code>版本</p>
<ul>
<li><code>/path/to/opencv_contrib/modules/ximgproc/samples/selectivesearchsegmentation_demo.cpp</code></li>
<li><code>/path/to/opencv_contrib/modules/ximgproc/samples/selectivesearchsegmentation_demo.py</code></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>图像处理</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
        <category>翻译</category>
        <category>目标检测</category>
        <category>目标识别</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>python</tag>
        <tag>opencv</tag>
        <tag>选择性搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]作用于目标识别的选择性搜索</title>
    <url>/posts/1cb6a408.html</url>
    <content><![CDATA[<p>论文下载地址：<a href="http://xueshu.baidu.com/usercenter/paper/show?paperid=b689fcf3ed998dfbb4213687367b6175&amp;site=xueshu_se" target="_blank" rel="noopener">Selective Search for Object Recognition</a></p><p>摘要</p><blockquote>
<p>This paper addresses the problem of generating possible object locations for use in object recognition. We introduce Selective Search which combines the strength of both an exhaustive search and segmentation. Like segmentation, we use the image structure to guide our sampling process. Like exhaustive search, we aim to capture all possible object locations. Instead of a single technique to generate possible object locations, we diversify our search and use a variety of complementary image partitionings to deal with as many image conditions as possible. Our Selective Search results in a small set of data-driven, class-independent, high quality locations, yielding 99% recall and a Mean Average Best Overlap of 0.879 at 10,097 locations. The reduced number of locations compared to an exhaustive search enables the use of stronger machine learning techniques and stronger appearance models for object recognition. In this paper we show that our selective search enables the use of the powerful Bag-of-Words model for recognition. The Selective Search software is made publicly available[1].</p>
</blockquote><a id="more"></a>


<p>本文讨论了在目标识别中生成可能的目标位置的问题。我们引入了选择性搜索，它结合了穷举搜索和分割的优点。像分割一样，我们使用图像结构来指导采样过程；像穷举搜索一样，我们的目标是捕获所有可能的目标位置。我们不再使用单一的技术来生成可能的目标位置，而是使搜索多样化，并使用各种互补的图像分割来处理尽可能多的图像条件。选择性搜索算法能够得到一组数据驱动的、与类无关的、高质量的位置，在10097个位置产生99%的召回率和0.879的平均最佳重叠。与穷举搜索相比，位置数目的减少使得能够使用更强的机器学习技术和更强的外观模型进行目标识别。在本文中，我们证明了我们的选择性搜索能够使用强大的单词袋模型进行识别。<em>选择性搜索软件已开源（Matlab版本）</em></p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><blockquote>
<p>For a long time, objects were sought to be delineated before their identification. This gave rise to segmentation, which aims for a unique partitioning of the image through a generic algorithm, where there is one part for all object silhouettes in the image. Research on this topic has yielded tremendous progress over the past years [3, 6, 13, 26]. But images are intrinsically hierarchical: In Figure 1a the salad and spoons are inside the salad bowl, which in turn stands on the table. Furthermore, depending on the context the term table in this picture can refer to only the wood or include everything on the table. Therefore both the nature of images and the different uses of an object category are hierarchical. This prohibits the unique partitioning of objects for all but the most specific purposes. Hence for most tasks multiple scales in a segmentation are a necessity. This is most naturally addressed by using a hierarchical partitioning, as done for example by Arbelaez et al[3].</p>
</blockquote>
<p>很长一段时间以来，人们一直在寻找物体的轮廓，然后才对其进行辨认。这就产生了分割，其目的是通过一种通用算法对图像进行分割，即图像中所有目标轮廓都能得到一个分割图像。近年来，对这一课题的研究取得了巨大的进展。但是图像本质上是分层的：在图1a中，沙拉和勺子在沙拉碗中，而沙拉碗又位于桌子上。此外，根据上下文的不同，本图中的术语表可以仅仅指木材或者包括表上的所有内容。因此，图像的性质和对象类别的不同用途都是层次性的。这禁止对对象进行唯一的分割，但仅限于最特定的用途。因此，对于大多数任务来说，在一个分段中使用多个尺度是必要的。最自然的解决方法是使用分层分区，如Arbelaez等人所做的那样</p>
<blockquote>
<p>Besides that a segmentation should be hierarchical, a generic solution for segmentation using a single strategy may not exist at all. There are many conflicting reasons why a region should be grouped together: In Figure 1b the cats can be separated using colour, but their texture is the same. Conversely, in Figure 1c the chameleon is similar to its surrounding leaves in terms of colour, yet its texture differs. Finally, in Figure 1d, the wheels are wildly different from the car in terms of both colour and texture, yet are enclosed by the car. Individual visual features therefore cannot resolve the ambiguity of segmentation.</p>
</blockquote>
<p>此外，分割也应该是分层的，使用单个策略进行分割的通用解决方案可能根本不存在。将一个区域组合在一起有许多相互矛盾的原因：在图1b中，猫可以用颜色分开，但它们的纹理是相同的。相反，在图1c中，变色龙的颜色与其周围的叶子相似，但其纹理不同。最后，在图1d中，车轮在颜色和质地上与汽车有着天壤之别，但却被汽车所包围因此，单个视觉特征无法解决分割的模糊性</p>
<blockquote>
<p>And, finally, there is a more fundamental problem. Regions with very different characteristics, such as a face over a sweater, can only be combined into one object after it has been established that the object at hand is a human. Hence without prior recognition it is hard to decide that a face and a sweater are part of one object[29].</p>
</blockquote>
<p>最后还有一个更根本的问题。具有非常不同特征的区域，例如毛衣上的脸，只有在确定旁边的物体是人之后，才能组合成一个物体。因此，如果没有事先的识别，很难确定一张脸和一件毛衣是一个物体的一部分</p>
<blockquote>
<p>This has led to the opposite of the traditional approach: to do localisation through the identification of an object. This recent approach in object recognition has made enormous progress in less than a decade [8, 12, 16, 35]. With an appearance model learned from examples, an exhaustive search is performed where every location within the image is examined as to not miss any potential object location [8, 12, 16, 35].</p>
</blockquote>
<p>这导致了与传统方法相反的情况：通过识别对象来进行本地化。最近这种目标识别方法在不到十年的时间里取得了巨大的进步。通过从样本中学习得到外观模型，执行穷举搜索以检查图像中的每个位置，确保不会遗漏任何潜在的对象位置</p>
<blockquote>
<p>However, the exhaustive search itself has several drawbacks. Searching every possible location is computationally infeasible. The search space has to be reduced by using a regular grid, fixed scales, and fixed aspect ratios. In most cases the number of locations to visit remains huge, so much that alternative restrictions need to be imposed. The classifier is simplified and the appearance model needs to be fast. Furthermore, a uniform sampling yields many boxes for which it is immediately clear that they are not supportive of an object. Rather then sampling locations blindly using an exhaustive search, a key question is: Can we steer the sampling by a data-driven analysis?</p>
</blockquote>
<p>然而，穷举搜索本身有几个缺点。因为搜索每个可能的位置在计算上是不可行的，所以必须通过使用规则网格、固定比例和固定纵横比来减少搜索空间。在大多数情况下可能的位置仍然很多，以至于需要实施其他限制。该方法需要简化分类器结构以快速建立外观模型。此外，均匀采样会产生许多框，很明显它们无法识别具体目标。如何不再盲目地使用穷举搜索进行采样，关键问题是：我们能否通过数据驱动的分析来控制采样？</p>
<blockquote>
<p>In this paper, we aim to combine the best of the intuitions of segmentation and exhaustive search and propose a data-driven selective search. Inspired by bottom-up segmentation, we aim to exploit the structure of the image to generate object locations. Inspired by exhaustive search, we aim to capture all possible object locations. Therefore, instead of using a single sampling technique, we aim to diversify the sampling techniques to account for as many image conditions as possible. Specifically, we use a data-driven grouping-based strategy where we increase diversity by using a variety of complementary grouping criteria and a variety of complementary colour spaces with different invariance properties. The set of locations is obtained by combining the locations of these complementary partitionings. Our goal is to generate a class-independent, data-driven, selective search strategy that generates a small set of high-quality object locations.</p>
</blockquote>
<p>在本文中，我们的目标是结合分割的直观性和穷举搜索，提出一个数据驱动的选择性搜索算法。受自底向上分割的启发，我们的目标是利用图像的结构来生成目标位置；受穷举搜索的启发，我们的目标是捕获所有可能的目标位置。因此，不是使用单一的采样技术，而是使采样技术多样化，以尽可能多地考虑图像条件。具体来说，我们使用基于数据驱动的分组策略，通过使用各种互补分组准则和具有不同不变性的各种互补颜色空间来增加多样性。通过组合这些互补分区的位置来获得位置集。我们的目标是生成一个独立于类的、数据驱动的、有选择的搜索策略，该策略生成一小组高质量的对象位置</p>
<blockquote>
<p>Our application domain of selective search is object recognition. We therefore evaluate on the most commonly used dataset for this purpose, the Pascal VOC detection challenge which consists of 20 object classes. The size of this dataset yields computational constraints for our selective search. Furthermore, the use of this dataset means that the quality of locations is mainly evaluated in terms of bounding boxes. However, our selective search applies to regions as well and is also applicable to concepts such as “grass”.</p>
</blockquote>
<p>选择性搜索的应用领域是目标识别。因此，我们评估了最常用的数据集，Pascal VOC检测挑战，包括20个对象类。这个数据集的大小为我们的选择性搜索产生了计算约束。此外，使用该数据集意味着位置的质量主要根据边界框来评估。然而，选择性搜索也适用于”草”等概念的区域分割</p>
<blockquote>
<p>In this paper we propose selective search for object recognition. Our main research questions are: (1) What are good diversification strategies for adapting segmentation as a selective search strategy? (2) How effective is selective search in creating a small set of high-quality locations within an image? (3) Can we use selective search to employ more powerful classifiers and appearance models for object recognition?</p>
</blockquote>
<p>本文中，我们提出作用于目标识别的选择性搜索算法。主要研究问题是:(1) 什么样的多样化策略可以作为选择性搜索策略来适应分割？(2) 选择性搜索在图像中创建一小部分高质量位置的效果如何？(3) 我们可以使用选择性搜索部署更强大的分类器和外观模型来进行对象识别吗？</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/figure-1.png" alt></p>
<blockquote>
<p>Figure 1: There is a high variety of reasons that an image region forms an object. In (b) the cats can be distinguished by colour, not texture. In (c) the chameleon can be distinguished from the surrounding leaves by texture, not colour. In (d) the wheels can be part of the car because they are enclosed, not because they are similar in texture or colour. Therefore, to find objects in a structured way it is necessary to use a variety of diverse strategies. Furthermore, an image is intrinsically hierarchical as there is no single scale for which the complete table, salad bowl, and salad spoon can be found in (a).</p>
</blockquote>
<p>图1：图像区域形成目标的原因多种多样。在（b）中的猫可以用颜色而不是质地来区分。在（c）中的变色龙可以区别于周围叶子的纹理，而不是颜色。在（d）中，车轮可以是汽车的一部分，因为它们是封闭的而不是因为它们的质地或颜色相似。因此，要以结构化的方式找到对象，必须使用多种多样的策略。此外，图像本质上是分层的，因为在（a）中找不到完整的桌子、沙拉碗和沙拉勺</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><blockquote>
<p>We confine the related work to the domain of object recognition and divide it into three categories: Exhaustive search, segmentation, and other sampling strategies that do not fall in either category.</p>
</blockquote>
<p>我们将相关工作局限于目标识别领域，并将其分为三类：穷举搜索、分割和其他不属于这两类的采样策略</p>
<h3 id="穷举搜索"><a href="#穷举搜索" class="headerlink" title="穷举搜索"></a>穷举搜索</h3><blockquote>
<p>As an object can be located at any position and scale in the image, it is natural to search everywhere [8, 16, 36]. However, the visual search space is huge, making an exhaustive search computationally expensive. This imposes constraints on the evaluation cost per location and/or the number of locations considered. Hence most of these sliding window techniques use a coarse search grid and fixed aspect ratios, using weak classifiers and economic image features such as HOG [8, 16, 36]. This method is often used as a preselection step in a cascade of classifiers [16, 36].</p>
</blockquote>
<p>由于目标可以位于图像中的任何位置和比例，因此很自然地需要搜索每一个位置。然而，视觉搜索空间巨大，使得穷举搜索在计算上非常昂贵。这对每个地点的评估成本和/或所考虑的地点数量施加了限制。因此，这些滑动窗口技术大多使用粗搜索网格和固定长宽比，使用弱分类器和经济图像特征，如HOG。此方法通常用作分类器级联中的预选步骤</p>
<blockquote>
<p>Related to the sliding window technique is the highly successful part-based object localisation method of Felzenszwalb et al. [12]. Their method also performs an exhaustive search using a linear SVM and HOG features. However, they search for objects and object parts, whose combination results in an impressive object detection performance.</p>
</blockquote>
<p>与滑动窗口技术相关的是Felzenszwalb等人非常成功的基于part的目标定位方法。他们的方法还使用线性SVM和HOG特征进行穷举搜索。但是，它们搜索目标和目标部件，它们的组合会产生令人印象深刻的目标检测性能</p>
<blockquote>
<p>Lampert et al. [17] proposed using the appearance model to guide the search. This both alleviates the constraints of using a regular grid, fixed scales, and fixed aspect ratio, while at the same time reduces the number of locations visited. This is done by directly searching for the optimal window within the image using a branch and bound technique. While they obtain impressive reslts for linear classifiers, [1] found that for non-linear classifiers the method in practice still visits over a 100,000 windows per image.</p>
</blockquote>
<p>Lampert等人提出了利用外观模型来指导搜索。这既减轻了使用规则网格、固定比例和固定纵横比的限制，同时也减少了访问的位置数。这是通过使用分支定界技术直接搜索图像中的最佳窗口来完成的。虽然他们使用线性分类器就获得了令人印象深刻的结果，然而即使使用非线性分类器，该方法在实践中仍然需要访问超过100000个窗口每幅图像</p>
<blockquote>
<p>Instead of a blind exhaustive search or a branch and bound search, we propose selective search. We use the underlying image structure to generate object locations. In contrast to the discussed methods, this yields a completely class-independent set of locations. Furthermore, because we do not use a fixed aspect ratio, our method is not limited to objects but should be able to find stuff like “grass” and “sand” as well (this also holds for [17]). Finally, we hope to generate fewer locations, which should make the problem easier as the variability of samples becomes lower. And more importantly, it frees up computational power which can be used for stronger machine learning techniques and more powerful appearance models.</p>
</blockquote>
<p>我们提出了选择性搜索，取代了盲穷举搜索或分枝定界搜索。我们使用底层图像结构来生成目标位置，与所讨论的方法相比，这产生了一个完全的类别独立的位置集。此外，由于我们不使用固定的长宽比，我们的方法不仅限于目标，而且应该能够找到”草”和”沙”之类的东西（这也适用于[17]）。最后，我们希望生成更少的位置，这将使问题更容易，因为样本的可变性变得更低。更重要的是，它释放了计算能力，可以用于更强大的机器学习技术和更强大的外观模型</p>
<h3 id="分割"><a href="#分割" class="headerlink" title="分割"></a>分割</h3><blockquote>
<p>Both Carreira and Sminchisescu [4] and Endres and Hoiem [9] propose to generate a set of class independent object hypotheses using segmentation. Both methods generate multiple foreground/background segmentations, learn to predict the likelihood that a foreground segment is a complete object, and use this to rank the segments. Both algorithms show a promising ability to accurately delineate objects within images, confirmed by [19] who achieve state-of-the-art results on pixel-wise image classification using [4]. As common in segmentation, both methods rely on a single strong algorithm for identifying good regions. They obtain a variety of locations by using many randomly initialised foreground and background seeds. In contrast, we explicitly deal with a variety of image conditions by using different grouping criteria and different representations. This means a lower computational investment as we do not have to invest in the single best segmentation strategy, such as using the excellent yet expensive contour detector of [3]. Furthermore, as we deal with different image conditions separately, we expect our locations to have a more consistent quality. Finally, our selective search paradigm dictates that the most interesting question is not how our regions compare to [4, 9], but rather how they can complement each other.</p>
</blockquote>
<p>Carreira和Sminchisescu[4]以及Endres和Hoiem[9]均建议采用分割法产生一组独立的目标假设。两种方法都生成了多个前景/背景分割，学习预测前景分割是完整目标的可能性，并使用该方法来排序分割。这两种算法都显示了在图像中精确描绘物体的能力，得到了[19]的证实，他们使用[4]在像素级图像分类方面取得了最好的成果。这两种方法在分割中都很常见，都依赖于单一的强算法来识别好的区域。他们通过使用许多随机初始化的前景和背景种子来获得各种位置。相反，我们通过使用不同的分组标准和不同的表示来显式地处理各种图像条件。这意味着更低的计算投资，因为我们不必投资于单一的最佳分割策略，例如使用优秀但昂贵的轮廓检测器[3]。另外，当我们处理不同的图像条件时，我们希望我们的位置具有更高的一致性。最后，我们的选择性搜索范式表明，最有趣的问题不是我们的区域与[4，9]相比如何，而是它们如何能够互补</p>
<blockquote>
<p>Gu et al. [15] address the problem of carefully segmenting and recognizing objects based on their parts. They first generate a set of part hypotheses using a grouping method based on Arbelaez et al. [3]. Each part hypothesis is described by both appearance and shape features. Then, an object is recognized and carefully delineated by using its parts, achieving good results for shape recognition. In their work, the segmentation is hierarchical and yields segments at all scales. However, they use a single grouping strategy whose power of discovering parts or objects is left unevaluated. In this work, we use multiple complementary strategies to deal with as many image conditions as possible. We include the locations generated using [3] in our evaluation.</p>
</blockquote>
<p>Gu等人[15]解决了基于物体的各个部分进行精细分割和目标识别的问题。他们首先使用基于Arbelaez等人的分组方法生成一组部分假设[3]。每个零件假设都通过外观和形状特征进行描述。然后，利用物体的各个部分对其进行识别和细致的划分，取得了良好的形状识别效果。在他们的工作中，分割是分层的并且在所有的尺度上产生。然而，它们使用单一的分组策略，其发现部分或目标的能力没有得到评估。在这项工作中，我们使用多种互补策略来处理尽可能多的图像条件。我们在评估中包含了使用[3]生成的位置</p>
<h3 id="其他采样策略"><a href="#其他采样策略" class="headerlink" title="其他采样策略"></a>其他采样策略</h3><blockquote>
<p>Alexe et al. [2] address the problem of the large sampling space of an exhaustive search by proposing to search for any object, independent of its class. In their method they train a classifier on the object windows of those objects which have a well-defined shape (as opposed to stuff like “grass” and “sand”). Then instead of a full exhaustive search they randomly sample boxes to which they apply their classifier. The boxes with the highest “objectness” measure serve as a set of object hypotheses. This set is then used to greatly reduce the number of windows evaluated by class-specific object detectors. We compare our method with their work.</p>
</blockquote>
<p>Alexe等人[2]通过提出搜索与类无关的对象来解决穷举搜索中采样空间大的问题。在他们的方法中，他们在具有明确形状对象的目标窗口上训练分类器（而不是像”草”和”沙”这样的东西）。然后，他们不再进行穷举搜索，而是随机采样。具有最高”对象性”度量的框用作一组对象假设。然后使用该集合可以大大减少由类特定对象检测器计算的窗口数。我们把我们的方法和他们的工作进行比较</p>
<blockquote>
<p>Another strategy is to use visual words of the Bag-of-Words model to predict the object location. Vedaldi et al. [34] use jumping windows [5], in which the relation between individual visual words and the object location is learned to predict the object location in new images. Maji and Malik [23] combine multiple of these relations to predict the object location using a Hough-transform, after which they randomly sample windows close to the Hough maximum. In contrast to learning, we use the image structure to sample a set of class-independent object hypotheses.</p>
</blockquote>
<p>另一种策略是利用视觉词汇袋模型来预测对象的位置。Vedaldi等人[34]使用跳跃窗口[5]，学习单个视觉词和对象位置之间的关系，以预测新图像中的对象位置。Maji和Malik[23]将这些关系中的多个结合起来，用Hough变换预测对象位置，然后随机采样接近Hough最大值的窗口。与学习相比，我们使用图像结构来采样一组与类无关的对象假设</p>
<blockquote>
<p>To summarize, our novelty is as follows. Instead of an exhaustive search [8, 12, 16, 36] we use segmentation as selective search yielding a small set of class independent object locations. In contrast to the segmentation of [4, 9], instead of focusing on the best segmentation algorithm [3], we use a variety of strategies to deal with as many image conditions as possible, thereby severely reducing computational costs while potentially capturing more objects accurately. Instead of learning an objectness measure on randomly sampled boxes [2], we use a bottom-up grouping procedure to generate good object locations.</p>
</blockquote>
<p>总而言之，我们的新颖之处如下。与穷举搜索[8，12，16，36]不同的是，我们使用分割作为选择性搜索，生成一组与类无关的对象位置。与文献[4,9]中的分割方法不同，我们没有关注最佳分割算法[3]，而是使用多种策略来处理尽可能多的图像条件，从而在可能准确地捕获更多对象的同时大大降低了计算成本。我们使用自底向上的分组过程来生成好的目标位置，而不是在随机抽样的框上学习目标度量[2]</p>
<h2 id="选择性搜索"><a href="#选择性搜索" class="headerlink" title="选择性搜索"></a>选择性搜索</h2><blockquote>
<p>In this section we detail our selective search algorithm for object recognition and present a variety of diversification strategies to deal with as many image conditions as possible. A selective search algorithm is subject to the following design considerations:</p>
</blockquote>
<p>在这一节中，我们详细介绍了目标识别的选择性搜索算法，并提出了各种各样的策略来处理尽可能多的图像条件。选择性搜索算法需要考虑以下设计因素：</p>
<blockquote>
<p>Capture All Scales. Objects can occur at any scale within the image. Furthermore, some objects have less clear boundaries then other objects. Therefore, in selective search all object scales have to be taken into account, as illustrated in Figure 2. This is most naturally achieved by using an hierarchical algorithm.</p>
</blockquote>
<p><strong>捕获全尺度</strong>。对象可以在图像中以任何比例出现。此外，一些对象的边界比其他对象的边界更不清晰。因此，在选择性搜索中必须考虑所有对象比例，如图2所示。最自然的方法是使用分层算法</p>
<blockquote>
<p>Diversification. There is no single optimal strategy to group regions together. As observed earlier in Figure 1, regions may form an object because of only colour, only texture, or because parts are enclosed. Furthermore, lighting conditions such as shading and the colour of the light may influence how regions form an object. Therefore instead of a single strategy which works well in most cases, we want to have a diverse set of strategies to deal with all cases.</p>
</blockquote>
<p><strong>多元化</strong>。没有一个单一的最优策略可以将区域组合在一起。如图1所示，区域可以形成一个对象，因为只有颜色，只有纹理，或因为部分是封闭的。此外，诸如阴影和光的颜色等照明条件可能影响区域形成对象的方式。因此，我们希望有一套不同的策略来处理所有的情况，而不是一个在大多数情况下都很有效的单一策略</p>
<blockquote>
<p>Fast to Compute. The goal of selective search is to yield a set of possible object locations for use in a practical object recognition framework. The creation of this set should not become a computational bottleneck, hence our algorithm should be reasonably fast.</p>
</blockquote>
<p><strong>快速计算</strong>。选择性搜索的目的是产生一组可能的目标位置，用于实际的目标识别框架。这个集合的创建不应该成为计算瓶颈，因此我们的算法应该相当快</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/figure-2.png" alt></p>
<blockquote>
<p>Figure 2: Two examples of our selective search showing the necessity of different scales. On the left we find many objects at different scales. On the right we necessarily find the objects at different scales as the girl is contained by the tv.</p>
</blockquote>
<p>图2：选择性搜索的两个例子显示了不同尺度的必要性。在左图中发现了许多不同比例的物体。在右图中能找到不同尺度的物体，即使女孩出现在电视中</p>
<h3 id="按层次分组的选择性搜索"><a href="#按层次分组的选择性搜索" class="headerlink" title="按层次分组的选择性搜索"></a>按层次分组的选择性搜索</h3><blockquote>
<p>We take a hierarchical grouping algorithm to form the basis of our selective search. Bottom-up grouping is a popular approach to segmentation [6, 13], hence we adapt it for selective search. Because the process of grouping itself is hierarchical, we can naturally generate locations at all scales by continuing the grouping process until the whole image becomes a single region. This satisfies the condition of capturing all scales.</p>
</blockquote>
<p>我们采用分层分组算法作为选择性搜索的基础。自底向上分组是一种流行的分割方法[6，13]，因此我们将其用于选择性搜索。由于分组过程本身是分层的，所以我们可以通过继续分组过程自然地在所有尺度上生成位置，直到整个图像变成一个区域。这满足捕获所有尺度的条件</p>
<blockquote>
<p>As regions can yield richer information than pixels, we want to use region-based features whenever possible. To get a set of small starting regions which ideally do not span multiple objects, we use the fast method of Felzenszwalb and Huttenlocher [13], which [3] found well-suited for such purpose.</p>
</blockquote>
<p>由于区域可以产生比像素更丰富的信息，因此我们希望尽可能使用基于区域的特征。为了得到一组理想情况下不跨越多个对象的小起始区域，我们使用了Felzenszwalb和Huttenlocher[13]的快速方法，这种方法在文章[3]中已证明非常符合这样的要求</p>
<blockquote>
<p>Our grouping procedure now works as follows. We first use [13] to create initial regions. Then we use a greedy algorithm to iteratively group regions together: First the similarities between all neighbouring regions are calculated. The two most similar regions are grouped together, and new similarities are calculated between the resulting region and its neighbours. The process of grouping the most similar regions is repeated until the whole image becomes a single region. The general method is detailed in Algorithm 1.</p>
</blockquote>
<p>现在我们的分组过程如下，首先使用[13]来创建初始区域。然后利用贪心算法对区域进行迭代分组：首先计算所有相邻区域之间的相似度。将两个最相似的区域组合在一起，并计算结果区域与其相邻区域之间的新相似性。重复组合最相似的区域，直到整个图像变成一个区域为止。方法在算法1中详细说明</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/alg-1.png" alt></p>
<blockquote>
<ul>
<li><strong>Algorithm 1</strong>: Hierarchical Grouping Algorithm</li>
<li><strong>Input</strong>: (colour)image</li>
<li><strong>Output</strong>: Set of object location hypotheses $L$</li>
<li>Obtain initial regions $R={r_{1},…,r_{n}}$ using [13]</li>
<li>Initialise similarity set $S=\varnothing $</li>
<li><strong>foreach</strong> <em>Neighbouring region pair $(r_{i},r_{j})$</em> <strong>do</strong><br>  Calculate similarity $s(r_{i},r_{j})$<br>  $S = S \cup s(r_{i},r_{j})$</li>
<li><strong>while</strong> $S\neq \varnothing $ <strong>do</strong><br>  Get highest similarity $s(r_{i},r_{j}) = max(S)$<br>  Merge corresponding regions $r_{t} = r_{i} \cup r_{j}$<br>  Remove similarities regarding $r_{i}: S = S\setminus s(r_{i},r_{\ast })$<br>  Remove similarities regarding $r_{i}: S = S\setminus s(r_{\ast }, r_{j})$<br>  Calculate similarity set $S_{t}$ between $r_{t}$ and its neighbours<br>  $S = S \cup S_{t}$<br>  $R = R \cup r_{t}$</li>
<li>Extract object location boxes $L$ from all regions in $R$ </li>
</ul>
</blockquote>
<ul>
<li><strong>算法1</strong>：分层分组算法</li>
<li><strong>输入</strong>：（彩色）图像</li>
<li><strong>输出</strong>：一组目标定位假设$L$</li>
<li>使用论文[13]的方法获取初始区域$R={r_{1},…,r_{n}}$</li>
<li>初始化相似集$S=\varnothing $（空集）</li>
<li><strong>foreach</strong> 相邻区域对$(r_{i},r_{j})$ <strong>do</strong><ul>
<li>计算相似度$s(r_{i},r_{j})$</li>
<li>$S = S \cup s(r_{i},r_{j})$（并集）</li>
</ul>
</li>
<li><strong>while</strong> $S\neq \varnothing $ <strong>do</strong><ul>
<li>获取最高相似度$s(r_{i},r_{j}) = max(S)$</li>
<li>合并相应的区域$r_{t} = r_{i} \cup r_{j}$ </li>
<li>移除与$r_{i}$相关的相似度：$S = S\setminus s(r_{i},r_{\ast })$</li>
<li>移除与$r_{j}$相关的相似度：$S = S\setminus s(r_{\ast },r_{j})$</li>
<li>计算新区域$r_{t}$与周围区域的相似集$S_{t}$</li>
<li>$S = S \cup S_{t}$ （每次操作后相似集$S$都会减少，最后仅包含一个区域，就是整个图像） </li>
<li>$R = R \cup r_{t}$（每次操作后区域集R均会增加，自底而上不断的组合可能的目标位置）</li>
</ul>
</li>
<li>从$R$中的所有区域提取目标位置框$L$</li>
</ul>
<blockquote>
<p>For the similarity $s(r_{i},r_{j})$ between region $r_{i}$ and $r_{j}$ we want a variety of complementary measures under the constraint that they are fast to compute. In effect, this means that the similarities should be based on features that can be propagated through the hierarchy, i.e. when merging region $r_{i}$ and $r_{j}$ into $r_{t}$, the features of region $r_{t}$ need to be calculated from the features of $r_{i}$ and $r_{j}$ without accessing the image pixels.</p>
</blockquote>
<p>对于区域$r_{i}$和区域$r_{j}$之间的相似性$s(r_{i}，r_{j})$，我们希望在它们快速计算的约束下仍有各种互补措施。实际上，这意味着相似性应该基于可以通过层次结构传播的特征，也就是说，当将区域$r_{i}$和$r_{j}$合并为$r_{t}$时，区域$r_{t}$的特征可以在不访问图像像素的情况下从$r_{i}$和$r_{j}$的特征中计算出来</p>
<h3 id="多元化策略"><a href="#多元化策略" class="headerlink" title="多元化策略"></a>多元化策略</h3><blockquote>
<p>The second design criterion for selective search is to diversify the sampling and create a set of complementary strategies whose locations are combined afterwards. We diversify our selective search (1) by using a variety of colour spaces with different invariance properties, (2) by using different similarity measures $s_{ij}$, and (3) by varying our starting regions.</p>
</blockquote>
<p>选择性搜索的第二个设计准则是使采样多样化，并创建一组互补策略，然后将其位置组合起来。选择性搜索多样化策略如下：（1）使用具有不同不变性的各种颜色空间；（2）使用不同的相似性度量$s_{ij}$，以及（3）改变我们的起始区域</p>
<blockquote>
<p>Complementary Colour Spaces. We want to account for different scene and lighting conditions. Therefore we perform our hierarchical grouping algorithm in a variety of colour spaces with a range of invariance properties. Specifically, we the following colour spaces with an increasing degree of invariance: (1) RGB, (2) the intensity (grey-scale image) I, (3) Lab, (4) the rg channels of normalized RGB plus intensity denoted as rgI, (5) HSV, (6) normalized RGB denoted as rgb, (7) C [14] which is an opponent colour space where intensity is divided out, and finally (8) the Hue channel H from HSV. The specific invariance properties are listed in Table 1.</p>
</blockquote>
<p><strong>互补颜色空间</strong>。我们要考虑不同的场景和照明条件。因此，我们在一系列具有不变性的颜色空间中执行我们的分层分组算法。具体地说，我们用一个不断增加的不变性度来表示下列颜色空间：（1）RGB，（2）强度（灰度图像）I，（3）Lab，（4）归一化RGB的rg通道加上强度，表示为rgI，（5）HSV，（6）归一化RGB，表示为rgb，（7）C[14]是与强度的颜色空间，最后（8）HSV的色调通道H。表1列出了具体的不变性属性</p>
<blockquote>
<p>Of course, for images that are black and white a change of colour space has little impact on the final outcome of the algorithm. For these images we rely on the other diversification methods for ensuring good object locations.</p>
</blockquote>
<p>当然，对于黑白图像，颜色空间的变化对算法的最终结果影响不大。对于这些图像，我们依赖其他多样化的方法来确保良好的目标位置</p>
<blockquote>
<p>In this paper we always use a single colour space throughout the algorithm, meaning that both the initial grouping algorithm of [13] and our subsequent grouping algorithm are performed in this colour space.</p>
</blockquote>
<p>在本文中，我们在整个算法中始终使用单一颜色空间，这意味着[13]的初始分组算法和我们的后续分组算法都在该颜色空间中执行</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/table-1.png" alt></p>
<blockquote>
<p>Table 1: The invariance properties of both the individual colour channels and the colour spaces used in this paper, sorted by degree of invariance. A “+/-“ means partial invariance. A fraction 1/3 means that one of the three colour channels is invariant to said property.</p>
</blockquote>
<p>表一：本文中使用的单个颜色通道和颜色空间的不变性，按不变性程度排序。”+/-“表示部分不变性。分数1/3表示三个颜色通道中的一个对所述属性不变</p>
<blockquote>
<p>Complementary Similarity Measures. We define four complementary, fast-to-compute similarity measures. These measures are all in range [0,1] which facilitates combinations of these measures.</p>
</blockquote>
<p><strong>互补相似度量</strong>。我们定义了四个互补的、快速计算相似度的度量。这些测量值都在[0,1]范围内，这有助于这些测量值的组合</p>
<blockquote>
<p>$S_{colour}(r_{i}, r_{j})$ measures colour similarity. Specifically, for each region we obtain one-dimensional colour histograms for each colour channel using 25 bins, which we found to work well. This leads to a colour histogram $C_{i}={c_{i}^{1}, …, c_{i}^{n}}$ for each region $r_{i}$ with dimensionality $n = 75$ when three colour channels are used. The colour histograms are normalised using the $L_{1}$ norm. Similarity is measured using the histogram intersection:</p>
</blockquote>
<p>$S_{colour}(r_{i}, r_{j})$ 测量颜色相似性。具体来说，对于每个区域，我们使用25个bin获得每个颜色通道的一维颜色直方图，我们发现效果很好。所以三通道彩色直方图$C_{i}={C_{i}^{1},…,C_{i}^{n}}$的维度为$n=75$。彩色直方图使用$L_{1}$标准化。相似性通过直方图相交来测量：</p>
<script type="math/tex; mode=display">
S_{colour}(r_{i}, r_{j})=\sum_{k=1}^{n} \min(c_{i}^{k}, c_{j}^{k})</script><blockquote>
<p>The colour histograms can be efficiently propagated through the hierarchy by</p>
</blockquote>
<p>颜色直方图可以通过以下方式在层次结构中有效传播</p>
<script type="math/tex; mode=display">
C_{t}=\frac{size(r_{i})\times C_{i} + size(r_{j})\times C_{j}}{size(r_{i}) + size(r_{j})}</script><blockquote>
<p>The size of a resulting region is simply the sum of its constituents: $size(r_{t}) = size(r_{i})+size(r_{j})$</p>
</blockquote>
<p>结果区域的大小只是其成分的总和: $size(r_{t}) = size(r_{i})+size(r_{j})$</p>
<blockquote>
<p>$S_{texture}(r_{i}, r_{j})$ measures texture similarity. We represent texture using fast SIFT-like measurements as SIFT itself works well for material recognition [20]. We take Gaussian derivatives in eight orientations using $σ = 1$ for each colour channel. For each orientation for each colour channel we extract a histogram using a bin size of 10. This leads to a texture histogram $T_{i} = {t_{i}^{1}, …, t_{i}^{n}}$ for each region $r_{i}$ with dimensionality $n = 240$ when three colour channels are used. Texture histograms are normalised using the $L_{1}$ norm. Similarity is measured using histogram intersection:</p>
</blockquote>
<p>$S_{texture}(r_{i}, r_{j})$ 测量纹理相似性。我们使用快速的类SIFT测量来表示纹理，因为SIFT本身对材料识别很有效[20]。我们采用八个方向的高斯导数，每个颜色通道使用$σ=1$。对于每个颜色通道的每个方向，我们使用10个bin来提取直方图。所以三通道区域$r_{i}$的纹理直方图$T{i}={T{i}^{1}，…，T{i}^{n}}$的维度为$n=240$。纹理直方图使用$L_{1}$进行规范化。相似性通过直方图相交来测量：</p>
<script type="math/tex; mode=display">
S_{texture}(r_{i}, r_{j}) = \sum_{k=1}^{n} \min (t_{i}^{k}, t_{j}^{k})</script><blockquote>
<p>Texture histograms are efficiently propagated through the hierarchy in the same way as the colour histograms.</p>
</blockquote>
<p>纹理直方图在层次结构中的传播方式与颜色直方图相同</p>
<blockquote>
<p>$S_{size}(r_{i}, r_{j})$ encourages small regions to merge early. This forces regions in $S$, i.e. regions which have not yet been merged, to be of similar sizes throughout the algorithm. This is desirable because it ensures that object locations at all scales are created at all parts of the image. For example, it prevents a single region from gobbling up all other regions one by one, yielding all scales only at the location of this growing region and nowhere else. $S_{size}(r_{i},r_{j})$ is defined as the fraction of the image that $r_{i}$ and $r_{j}$ jointly occupy:</p>
</blockquote>
<p>$S_{size}(r_{i}, r_{j})$ 鼓励小区域尽早合并。这迫使$S$中的区域（即尚未合并的区域）在整个算法中具有相似的大小。这是可取的，因为它可以确保在图像的所有部分创建所有比例的对象位置（<em>每次分层分组算法能够产生一个假设目标位置</em>）。例如，它防止单个区域一个接一个地吞食所有其他区域，只在这个区域位置附近产生所有候选的目标位置。$S_{size}(r_{i}, r_{j})$定义为$r_{i}$和$r_{j}$共同占用的图像的分数：</p>
<script type="math/tex; mode=display">
S_{size}(r_{i}, r_{j})=1 - \frac{size(r_{i}) + size(r_{j})}{size(im)}</script><blockquote>
<p>where $size(im)$ denotes the size of the image in pixel.</p>
</blockquote>
<p>其中$size(im)$表示图像的像素大小</p>
<blockquote>
<p>$S_{fill}(r_{i}, r_{j})$ measures how well region $r_{i}$ and $r_{j}$ fit into each other. The idea is to fill gaps: if $r_{i}$ is contained in $r_{j}$ it is logical to merge these first in order to avoid any holes. On the other hand, if $r_{i}$ and $r_{j}$ are hardly touching each other they will likely form a strange region and should not be merged. To keep the measure fast, we use only the size of the regions and of the containing boxes. Specifically, we define $BB_{ij}$ to be the tight bounding box around $r_{i}$ and $r_{j}$. Now $S_{fill}(r_{i},r_{j})$ is the fraction of the image contained in $BB_{ij}$ which is not covered by the regions of $r_{i}$ and $r_{j}$:</p>
</blockquote>
<p>$S_{fill}(r_{i}, r_{j})$ 测量区域$r_{i}$和$r_{j}$的匹配程度。理想情况下是两个区域能够填补相互的空白：如果$r_{i}$包含在$r_{j}$中，那么首先合并这两个区域以避免大的空白出现是合乎逻辑的。换句话说，如果$r_{i}$和$r_{j}$几乎不接触在一起，那么他们将形成一个奇怪的区域，不应该被合并。为了保持度量的快速性，我们只使用区域和包含框的大小。具体来说，我们将$BB_{ij}$定义为$r_{i}$和$r_{j}$周围的紧边界框。现在$S_{fill}(r_{i},r_{j})$表示$BB_{ij}$中没有被$r_{i}$和$r_{j}$所覆盖的区域占整个图像的比例：</p>
<script type="math/tex; mode=display">
fill(r_{i},r_{j})=1 - \frac {size(BB_{ij})-size(r_{i})-size(r_{j})}{size(im)}</script><blockquote>
<p>We divide by $size(im)$ for consistency with Equation 4. Note that this measure can be efficiently calculated by keeping track of the bounding boxes around each region, as the bounding box around two regions can be easily derived from these.</p>
</blockquote>
<p>$size(im)$表示图像像素个数。请注意，通过跟踪每个区域周围的边界框，可以有效地计算此度量，因为两个区域周围的边界框很容易从中导出。</p>
<blockquote>
<p>In this paper, our final similarity measure is a combination of the above four:</p>
</blockquote>
<p>在本文中，我们的最终相似性度量是上述四项的组合：</p>
<script type="math/tex; mode=display">
s(r_{i},r_{j})=a_{1}s_{colour}(r_{i},r_{j})+a_{2}s_{texture}(r_{i},r_{j})+a_{d}s_{size}(r_{i},r_{j})+a_{r}s_{fill}(r_{i},r_{j})</script><blockquote>
<p>where $a_{i}∈{0,1}$ denotes if the similarity measure is used or not. As we aim to diversify our strategies, we do not consider any weighted similarities.</p>
</blockquote>
<p>其中$a_{i}$取值为$0$或者$1$，表明是否使用此项相似度度量。由于我们的目标是使我们的战略多样化，我们不考虑任何加权相似性</p>
<blockquote>
<p>Complementary Starting Regions. A third diversification strategy is varying the complementary starting regions. To the best of our knowledge, the method of [13] is the fastest, publicly available algorithm that yields high quality starting locations. We could not find any other algorithm with similar computational efficiency so we use only this oversegmentation in this paper. But note that different starting regions are (already) obtained by varying the colour spaces, each which has different invariance properties. Additionally, we vary the threshold parameter $k$ in [13].</p>
</blockquote>
<p><strong>互补起始区域</strong>。第三个多样化战略是改变互补的起始区域。据我们所知，[13]的方法是最快的、公开可用的算法，能够产生高质量的起始位置。我们找不到任何其他算法具有类似的计算效率，所以本文只使用这种过度分割方法。但是请注意，不同的起始区域是通过改变颜色空间获得的，每个颜色空间具有不同的不变性。此外，我们可以改变文章[13]中的阈值参数$k$以获得不同的起始空间</p>
<h3 id="组合位置"><a href="#组合位置" class="headerlink" title="组合位置"></a>组合位置</h3><blockquote>
<p>In this paper, we combine the object hypotheses of several variations of our hierarchical grouping algorithm. Ideally, we want to order the object hypotheses in such a way that the locations which are most likely to be an object come first. This enables one to find a good trade-off between the quality and quantity of the resulting object hypothesis set, depending on the computational efficiency of the subsequent feature extraction and classification method.</p>
</blockquote>
<p>在本文中，我们结合了我们的分层分组算法的几种变体的目标假设。理想情况下，我们希望对目标假设进行排序，以便最有可能是目标的位置排在第一位。这使得人们能够根据后续特征提取和分类方法的计算效率，在结果目标假设集的质量和数量之间找到一个很好的折衷</p>
<blockquote>
<p>We choose to order the combined object hypotheses set based on the order in which the hypotheses were generated in each individual grouping strategy. However, as we combine results from up to 80 different strategies, such order would too heavily emphasize large regions. To prevent this, we include some randomness as follows. Given a grouping strategy $j$, let $r_{i}^{j}$ be the region which is created at position $i$ in the hierarchy, where $i = 1$ represents the top of the hierarchy (whose corresponding region covers the complete image). We now calculate the position value $v_{i}^{j}$ as $RND×i$, where $RND$ is a random number in range [0,1]. The final ranking is obtained by ordering the regions using $v_{i}^{j}$.</p>
</blockquote>
<p>根据假设集在每个单独分组策略中的生成顺序来得到最终的假设目标顺序。然而，当我们将多达80种不同策略的结果结合起来时，这种顺序将过于强调大区域。为了防止这种情况，我们增加一些随机性。给定一个分组策略$j$，$r_{i}^{j}$表示在该分组分层计算中第$i$次创建的假设区域，其中$i=1$表示该次分层的顶部（其对应的区域覆盖整个图像）。现在将位置值$v_{i}^{j}$计算为$RND\times i$，其中$RND$是[0,1]范围内的随机数。最后的排名是通过对区域按$v_{i}^{j}$排序获得的</p>
<p>个人解析：</p>
<ol>
<li>每次子单独的分组策略中都能生成一个假设集，组合这些假设集得到最终的目标假设集</li>
<li>单个假设集的位置都是按从大到小排序，所以使用随机数RND重新排列单个假设集中的假设目标位置</li>
</ol>
<blockquote>
<p>When we use locations in terms of bounding boxes, we first rank all the locations as detailed above. Only afterwards we filter out lower ranked duplicates. This ensures that duplicate boxes have a better chance of obtaining a high rank. This is desirable because if multiple grouping strategies suggest the same box location, it is likely to come from a visually coherent part of the image.</p>
</blockquote>
<p>当我们使用边界框中的位置时，我们首先按照上面的详细说明排列所有位置。只有在这之后我们才能过滤出排名较低的重复项。这样可以确保重复框有更好的机会获得高等级。这是可取的，因为如果多个分组策略建议相同的框位置，则它很可能来自图像的视觉连贯部分</p>
<p>个人解析：不同的假设集中可能会提出相同的边界框，通过上述方法打乱假设集的目标位置后再进行过滤</p>
<h2 id="使用选择性搜索进行目标识别"><a href="#使用选择性搜索进行目标识别" class="headerlink" title="使用选择性搜索进行目标识别"></a>使用选择性搜索进行目标识别</h2><blockquote>
<p>This paper uses the locations generated by our selective search for object recognition. This section details our framework for object recognition.</p>
</blockquote>
<p>本文利用选择性搜索产生的位置进行目标识别。本节详细介绍目标识别框架</p>
<blockquote>
<p>Two types of features are dominant in object recognition: histograms of oriented gradients (HOG) [8] and bag-of-words [7, 27]. HOG has been shown to be successful in combination with the partbased model by Felzenszwalb et al. [12]. However, as they use an exhaustive search, HOG features in combination with a linear classifier is the only feasible choice from a computational perspective. In contrast, our selective search enables the use of more expensive and potentially more powerful features. Therefore we use bag-of-words for object recognition [16, 17, 34]. However, we use a more powerful (and expensive) implementation than [16, 17, 34] by employing a variety of colour-SIFT descriptors [32] and a finer spatial pyramid division [18].</p>
</blockquote>
<p>在对象识别中，两类特征占主导地位：方向梯度直方图（HOG）[8]和单词包[7，27]。Felzenszwalb等人证明了将HOG与基于部分的模型结合起来是成功的[12]。然而，由于它们使用穷举搜索，从计算角度来看，HOG特征与线性分类器结合是唯一可行的选择。相比之下，我们的选择性搜索能够使用更昂贵和潜在更强大的功能。因此，我们使用单词包进行对象识别[16，17，34]。然而，我们使用比[16，17，34]更强大（和昂贵）的实现，通过使用各种颜色筛选描述符[32]和更精细的空间金字塔分割[18]</p>
<blockquote>
<p>Specifically we sample descriptors at each pixel on a single scale (σ = 1.2). Using software from [32], we extract SIFT [21] and two colour SIFTs which were found to be the most sensitive for detecting image structures, Extended OpponentSIFT [31] and RGB-SIFT [32]. We use a visual codebook of size 4,000 and a spatial pyramid with 4 levels using a 1x1, 2x2, 3x3. and 4x4 division. This gives a total feature vector length of 360,000. In image classification, features of this size are already used [25, 37]. Because a spatial pyramid results in a coarser spatial subdivision than the cells which make up a HOG descriptor, our features contain less information about the specific spatial layout of the object. Therefore, HOG is better suited for rigid objects and our features are better suited for deformable object types.</p>
</blockquote>
<p>具体来说，我们在单个尺度上对每个像素的描述符进行采样（σ=1.2）。利用文献[32]中的软件，我们提取了SIFT[21]和两个对检测图像结构最敏感的颜色筛：扩展OpponentSIFT[31]和RGB-SIFT[32]。我们使用4000大小的视觉码本和4层空间金字塔，使用1x1、2x2、3x3和4x4分区。这使得特征向量的总长度为360000。在图像分类中，已经使用了这种大小的特征[25，37]。由于空间金字塔比构成HOG描述符的单元产生更粗糙的空间细分，因此我们的特征包含的关于对象的特定空间布局的信息更少。因此，HOG更适合于刚性对象，而我们的特征更适合于可变形对象类型</p>
<blockquote>
<p>As classifier we employ a Support Vector Machine with a histogram intersection kernel using the Shogun Toolbox [28]. To apply the trained classifier, we use the fast, approximate classification strategy of [22], which was shown to work well for Bag-of-Words in [30].</p>
</blockquote>
<p>作为分类器，我们使用使用Shogun工具箱[28]部署了一个支持向量机和一个直方图相交核。为了应用训练的分类器，我们使用了[22]的快速、近似分类策略，这在[30]中被证明是很好的</p>
<blockquote>
<p>Our training procedure is illustrated in Figure 3. The initial positive examples consist of all ground truth object windows. As initial negative examples we select from all object locations generated by our selective search that have an overlap of 20% to 50% with a positive example. To avoid near-duplicate negative examples, a negative example is excluded if it has more than 70% overlap with another negative. To keep the number of initial negatives per class below 20,000, we randomly drop half of the negatives for the classes car, cat, dog and person. Intuitively, this set of examples can be seen as difficult negatives which are close to the positive examples. This means they are close to the decision boundary and are therefore likely to become support vectors even when the complete set of negatives would be considered. Indeed, we found that this selection of training examples gives reasonably good initial classification models.</p>
</blockquote>
<p>训练步骤如图3所示。最初的正面例子由所有真值目标窗口组成。作为最初的负样本实例，从选择性搜索生成的所有目标位置中选择与正样本实例重叠20%到50%的位置。为了避免近似重复的负样本，如果负样本实例与另一负样本实例的重叠超过70%，则将其排除。为了使每类的初始负样本数保持在20000个以下，我们随机舍弃一半的汽车、猫、狗和人的负样本。直觉上，这组示例可以被看作是很接近于正样本的负样本。这意味着它们接近于决策边界，因此，即使考虑到全套否定，它们也很可能成为支持向量。事实上，我们发现这种训练示例的选择提供了相当好的初始分类模型。</p>
<blockquote>
<p>Then we enter a retraining phase to iteratively add hard negative examples (e.g. [12]): We apply the learned models to the training set using the locations generated by our selective search. For each negative image we add the highest scoring location. As our initial training set already yields good models, our models converge in only two iterations.</p>
</blockquote>
<p>然后我们进入一个再训练阶段，迭代添加新的负样本（例如[12]）：使用选择性搜索生成的位置将学习到的模型应用到训练集。对于每一张负样本图片，我们都会加上得分最高的位置。由于我们的初始训练集已经产生了好的模型，我们的模型只在两次迭代中收敛</p>
<blockquote>
<p>For the test set, the final model is applied to all locations generated by our selective search. The windows are sorted by classifier score while windows which have more than 30% overlap with a higher scoring window are considered near-duplicates and are removed.</p>
</blockquote>
<p>对于测试集，最终模型将应用于我们的选择性搜索生成的所有位置。窗口按分类器得分排序，与得分较高的窗口重叠超过30%的窗口被视为接近重复项并被删除</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/figure-3.png" alt></p>
<blockquote>
<p>Figure 3: The training procedure of our object recognition pipeline. As positive learning examples we use the ground truth. As negatives we use examples that have a 20-50% overlap with the positive examples. We iteratively add hard negatives using a retraining phase.</p>
</blockquote>
<p>图3：目标识别训练过程。通过标注数据作为正样本；使用与正样本有20-50%的重叠的数据作为负样本。在继续训练阶段反复添加错误分类样本</p>
<h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><blockquote>
<p>In this section we evaluate the quality of our selective search. We divide our experiments in four parts, each spanning a separate subsection:</p>
</blockquote>
<p>在本节中，我们将评估选择性搜索的质量。把实验分成四个部分，每个部分跨越一个单独的子章节：</p>
<blockquote>
<p>Diversification Strategies. We experiment with a variety of colour spaces, similarity measures, and thresholds of the initial regions, all which were detailed in Section 3.2. We seek a trade-off between the number of generated object hypotheses, computation time, and the quality of object locations. We do this in terms of bounding boxes. This results in a selection of complementary techniques which together serve as our final selective search method.</p>
</blockquote>
<p><strong>多样化策略</strong>。使用各种颜色空间、相似性度量和初始区域阈值进行实验，所有这些都在第3.2节中详细说明。寻求在生成的目标假设数量、计算时间和目标位置质量之间的权衡。我们是通过边界框完成的。这导致了互补技术的选择，这些技术共同作为我们的最终选择搜索方法</p>
<blockquote>
<p>Quality of Locations. We test the quality of the object location hypotheses resulting from the selective search.</p>
</blockquote>
<p><strong>位置质量</strong>。我们测试了由选择性搜索产生的目标定位假设的质量</p>
<blockquote>
<p>Object Recognition. We use the locations of our selective search in the Object Recognition framework detailed in Section 4. We evaluate performance on the Pascal VOC detection challenge.</p>
</blockquote>
<p><strong>目标识别</strong>。我们在第4节详述的目标识别框架中使用选择性搜索得到的位置。在Pascal VOC检测挑战中评估性能</p>
<blockquote>
<p>An upper bound of location quality. We investigate how well our object recognition framework performs when using an object hypothesis set of “perfect” quality. How does this compare to the locations that our selective search generates?</p>
</blockquote>
<p><strong>定位质量的上限</strong>。我们研究了目标识别框架在使用“完美”质量的对象假设集时的性能，这与选择性搜索生成的位置相比如何？</p>
<blockquote>
<p>To evaluate the quality of our object hypotheses we define the Average Best Overlap (ABO) and Mean Average Best Overlap (MABO) scores, which slightly generalises the measure used in [9]. To calculate the Average Best Overlap for a specific class $c$, we calculate the best overlap between each ground truth annotation $g_{i}^{c} ∈ G^{c}$ and the object hypotheses $L$ generated for the corresponding image, and average:</p>
</blockquote>
<p>为了评估目标假设的质量，定义了平均最佳重叠（ABO）和均值平均最佳重叠（MABO）分数，这稍微概括了[9]中使用的测量方法。为了计算特定类$c$的平均最佳重叠，我们计算每个正确标注注释$g_{i}^{c}∈G^{c}$与为相应图像生成的对象假设$L$之间的最佳重叠，并且平均：</p>
<script type="math/tex; mode=display">
ABO=\frac {1}{|C^{c}|} \sum_{g_{i}^{c}\in G^{c}} \max_{l_{j}\in L} Overlap(g_{i}^{c}, l_{j})</script><blockquote>
<p>The Overlap score is taken from [11] and measures the area of the intersection of two regions divided by its union:</p>
</blockquote>
<p>重叠分数公式取自[11]，测量两个区域的相交面积除以其并集：</p>
<script type="math/tex; mode=display">
Overlap(g_{i}^{c}, l_{j})=\frac {area(g_{i}^{c})\cap area(1_{j})}{area(g_{i}^{c})\cup area(1_{j})}</script><blockquote>
<p>Analogously to Average Precision and Mean Average Precision, Mean Average Best Overlap is now defined as the mean ABO over all classes.</p>
</blockquote>
<p>与平均精度和平均精度均值类似，均值平均最佳重叠现在定义为所有类的均值ABO</p>
<blockquote>
<p>Other work often uses the recall derived from the Pascal Overlap Criterion to measure the quality of the boxes [1, 16, 34]. This criterion considers an object to be found when the Overlap of Equation 8 is larger than 0.5. However, in many of our experiments we obtain a recall between 95% and 100% for most classes, making this measure too insensitive for this paper. However, we do report this measure when comparing with other work.</p>
</blockquote>
<p>其他的工作经常使用来自Pascal重叠标准来测量框的质量[1，16，34]。当上式的重叠度大于0.5时，该准则认为找到了一个物体。然而，在我们的许多实验中，对于大多数类，我们获得了95%到100%的召回率，这使得本文对这个度量太不敏感了。但是在与其他工作进行比较时，我们还是报告了这一结果</p>
<blockquote>
<p>To avoid overfitting, we perform the diversification strategies experiments on the Pascal VOC 2007 TRAIN+VAL set. Other experiments are done on the Pascal VOC 2007 TEST set. Additionally, our object recognition system is benchmarked on the Pascal VOC 2010 detection challenge, using the independent evaluation server.</p>
</blockquote>
<p>为避免过拟合，我们在Pascal VOC 2007 TRAIN+VAL集上进行了多样化策略实验。此外，我们的目标识别系统以帕斯卡VOC 2010检测挑战作为基准，使用独立的评估服务器</p>
<h3 id="多样化策略"><a href="#多样化策略" class="headerlink" title="多样化策略"></a>多样化策略</h3><blockquote>
<p>In this section we evaluate a variety of strategies to obtain good quality object location hypotheses using a reasonable number of boxes computed within a reasonable amount of time.</p>
</blockquote>
<p>在这一部分中，我们评估了各种策略，以使用在合理时间内计算出的合理数量的框来获得高质量的目标位置假设</p>
<h4 id="平面-vs-分层"><a href="#平面-vs-分层" class="headerlink" title="平面 vs. 分层"></a>平面 vs. 分层</h4><blockquote>
<p>In the description of our method we claim that using a full hierarchy is more natural than using multiple flat partitionings by changing a threshold. In this section we test whether the use of a hierarchy also leads to better results. We therefore compare the use of [13] with multiple thresholds against our proposed algorithm. Specifically, we perform both strategies in RGB colour space. For [13], we vary the threshold from k = 50 to k = 1000 in steps of 50. This range captures both small and large regions. Additionally, as a special type of threshold, we include the whole image as an object location because quite a few images contain a single large object only. Furthermore, we also take a coarser range from k = 50 to k = 950 in steps of 100. For our algorithm, to create initial regions we use a threshold of k = 50, ensuring that both strategies have an identical smallest scale. Additionally, as we generate fewer regions, we combine results using k = 50 and k = 100. As similarity measure S we use the addition of all four similarities as defined in Equation 6. Results are in table 2.</p>
</blockquote>
<p>在我们方法的描述中，我们声称使用完整的层次结构比通过更改阈值使用多个平面分区更自然。在本节中，我们将测试层次结构的使用是否也会导致更好的结果。因此，我们将[13]的多阈值使用与我们提出的算法进行了比较。具体来说，我们在RGB颜色空间中执行这两种策略。对于[13]，我们将阈值从k=50变为k=1000，步长为50。这一范围涵盖了小区域和大区域。另外，作为一种特殊的阈值类型，我们将整个图像作为一个对象位置，因为很多图像只包含一个大对象。此外，我们还采取了一个较粗的范围从k=50到k=950的步骤100。对于我们的算法，为了创建初始区域，我们使用k=50的阈值，确保两种策略具有相同的最小尺度。此外，由于生成的区域较少，我们使用k=50和k=100合并结果。作为相似性度量，我们使用等式6中定义的所有四个相似性的相加。结果见表2</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/table-2.png" alt></p>
<blockquote>
<p>Table 2: A comparison of multiple flat partitionings against hierarchical partitionings for generating box locations shows that for the hierarchical strategy the Mean Average Best Overlap (MABO) score is consistently higher at a similar number of locations.</p>
</blockquote>
<p>表2：多个平面分区与用于生成框位置的分层分区的比较表明，对于分层策略，在相同数量的位置处，平均最佳重叠（MABO）得分始终较高</p>
<blockquote>
<p>As can be seen, the quality of object hypotheses is better for our hierarchical strategy than for multiple flat partitionings: At a similar number of regions, our MABO score is consistently higher. Moreover, the increase in MABO achieved by combining the locations of two variants of our hierarchical grouping algorithm is much higher than the increase achieved by adding extra thresholds for the flat partitionings. We conclude that using all locations from a hierarchical grouping algorithm is not only more natural but also more effective than using multiple flat partitionings.</p>
</blockquote>
<p>可以看出，对于目标假设的质量而言，我们的分层策略比多个平面分区要好：在相同数量的区域，我们的MABO得分始终较高。此外，通过组合分层分组算法中两个变体的位置所实现的MABO的增加远远高于通过为平面分区添加额外阈值所实现的增加。我们的结论是，与使用多个平面分区相比，使用分层分组算法中的所有位置不仅更自然，而且更有效</p>
<h4 id="独立的多样化策略"><a href="#独立的多样化策略" class="headerlink" title="独立的多样化策略"></a>独立的多样化策略</h4><blockquote>
<p>In this paper we propose three diversification strategies to obtain good quality object hypotheses: varying the colour space, varying the similarity measures, and varying the thresholds to obtain the starting regions. This section investigates the influence of each strategy. As basic settings we use the RGB colour space, the combination of all four similarity measures, and threshold k = 50. Each time we vary a single parameter. Results are given in Table 3.</p>
</blockquote>
<p>在本文中，我们提出了三种多元化策略来获得高质量的目标假设：改变颜色空间，改变相似度，并改变阈值以获得起始区域。这一部分考察了每种策略的影响。作为基本设置，我们使用RGB颜色空间，四种相似性度量的组合，阈值k=50。每次我们改变一个参数。结果见表3。</p>
<blockquote>
<p>We start examining the combination of similarity measures on the left part of Table 3. Looking first at colour, texture, size, and fill individually, we see that the texture similarity performs worst with a MABO of 0.581, while the other measures range between 0.63 and 0.64. To test if the relatively low score of texture is due to our choice of feature, we also tried to represent texture by Local Binary Patterns [24]. We experimented with 4 and 8 neighbours on different scales using different uniformity/consistency of the patterns (see [24]), where we concatenate LBP histograms of the individual colour channels. However, we obtained similar results (MABO of 0.577). We believe that one reason of the weakness of texture is because of object boundaries: When two segments are separated by an object boundary, both sides of this boundary will yield similar edge-responses, which inadvertently increases similarity.</p>
</blockquote>
<p>我们开始检查表3左边的相似性度量的组合。首先分别观察颜色、纹理、大小和填充，我们发现纹理相似性在MABO为0.581时表现最差，而其他度量在0.63到0.64之间。为了测试纹理得分是否较低是因为我们选择了特征，我们还尝试用局部二值模式来表示纹理[24]。我们使用不同均匀性/一致性的图案（见[24]）在不同尺度上对4个和8个邻域进行了实验，在这些邻域中我们连接了各个颜色通道的LBP直方图。然而，我们得到了类似的结果（MABO为0.577）。 我们认为，纹理弱的一个原因是由于对象边界：当两个分割被一个对象边界分开时，该边界的两边将产生相似的边缘响应，这在不经意间增加了相似性</p>
<blockquote>
<p>While the texture similarity yields relatively few object locations, at 300 locations the other similarity measures still yield a MABO higher than 0.628. This suggests that when comparing individual strategies the final MABO scores in table 3 are good indicators of trade-off between quality and quantity of the object hypotheses. Another observation is that combinations of similarity measures generally outperform the single measures. In fact, using all four similarity measures perform best yielding a MABO of 0.676.</p>
</blockquote>
<p>虽然纹理相似性产生的对象位置相对较少，但在300个位置，其他相似性度量仍然产生高于0.628的MABO。这表明，在比较个体策略时，表3中的最终MABO得分是衡量目标假设的质量和数量的良好指标。另一个观察结果是，相似性度量的组合通常优于单一度量。事实上，使用所有四个相似性度量可以获得0.676的MABO</p>
<blockquote>
<p>Looking at variations in the colour space in the top-right of Table 3, we observe large differences in results, ranging from a MABO of 0.615 with 125 locations for the C colour space to a MABO of 0.693 with 463 locations for the HSV colour space. We note that Lab-space has a particularly good MABO score of 0.690 using only 328 boxes. Furthermore, the order of each hierarchy is effective: using the first 328 boxes of HSV colour space yields 0.690 MABO, while using the first 100 boxes yields 0.647 MABO. This shows that when comparing single strategies we can use only the MABO scores to represent the trade-off between quality and quantity of the object hypotheses set. We will use this in the next section when finding good combinations.</p>
</blockquote>
<p>观察表3右上角颜色空间的变化，我们观察到结果上的巨大差异，从C颜色空间125个位置的MABO为0.615到HSV颜色空间463个位置的MABO为0.693。我们注意到Lab空间只有328个框，MABO得分为0.690。此外，每个层次的顺序是有效的：使用前328个框的HSV颜色空间产生0.690 MABO，而使用前100框能够产生0.647 MABO。这表明，在比较单一策略时，我们只能使用MABO分数来表示对象假设集的质量和数量之间的权衡。在下一节中，我们将在找到好的组合时使用这个</p>
<blockquote>
<p>Experiments on the thresholds of [13] to generate the starting regions show, in the bottom-right of Table 3, that a lower initial threshold results in a higher MABO using more object locations.</p>
</blockquote>
<p>在表3的右下角，对生成起始区域的阈值[13]的实验表明，较低的初始阈值导致使用更多对象位置的较高MABO</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/table-3.png" alt></p>
<blockquote>
<p>Table 3: Mean Average Best Overlap for box-based object hypotheses using a variety of segmentation strategies. (C)olour, (S)ize, and (F)ill perform similar. (T)exture by itself is weak. The best combination is as many diverse sources as possible.</p>
</blockquote>
<p>表3：使用各种分割策略的基于框的对象假设的平均最佳重叠。(C)颜色，(S)大小，和(F)填充表现相似。(T)纹理本身是弱的。最好的组合是尽可能多的不同来源</p>
<h4 id="多样化策略的组合"><a href="#多样化策略的组合" class="headerlink" title="多样化策略的组合"></a>多样化策略的组合</h4><blockquote>
<p>We combine object location hypotheses using a variety of complementary grouping strategies in order to get a good quality set of object locations. As a full search for the best combination is computationally expensive, we perform a greedy search using the MABO score only as optimization criterion. We have earlier observed that this score is representative for the trade-off between the number of locations and their quality.</p>
</blockquote>
<p>为了得到高质量的目标定位集合，我们使用多种互补的分组策略来组合目标定位假设。由于对最佳组合的完全搜索在计算上是昂贵的，因此我们仅使用MABO得分作为优化准则来执行贪婪搜索。我们早些时候观察到，这个分数代表了定位数量和质量之间的权衡</p>
<blockquote>
<p>From the resulting ordering we create three configurations: a single best strategy, a fast selective search, and a quality selective search using all combinations of individual components, i.e. colour space, similarities, thresholds, as detailed in Table 4. The greedy search emphasizes variation in the combination of similarity measures. This confirms our diversification hypothesis: In the quality version, next to the combination of all similarities, Fill and Size are taken separately. The remainder of this paper uses the three strategies in Table 4.</p>
</blockquote>
<p>根据得到结果排序，我们创建了三种配置：单一最佳策略、快速选择性搜索以及在单个组件上执行所有组合（即颜色空间、相似性、阈值）的高质量选择性搜索，如表4所示。贪婪搜索强调相似性度量组合的变化。这证实了我们的多样化假设：在高质量版本中，在所有相似性的组合旁边，填充和大小是分开的。本文的其余部分使用表4中的三种策略</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/table-4.png" alt></p>
<blockquote>
<p>Table 4: Our selective search methods resulting from a greedy search. We take all combinations of the individual diversification strategies selected, resulting in 1, 8, and 80 variants of our hierarchical grouping algorithm. The Mean Average Best Overlap (MABO) score keeps steadily rising as the number of windows increase.</p>
</blockquote>
<p>表4：贪婪搜索产生的选择性搜索方法。我们采用所选择的各个多样化策略的所有组合，得到我们的分层分组算法的1、8和80个变体。均值平均最佳重叠（MABO）分数随着窗口数的增加而稳步上升</p>
<h3 id="定位质量"><a href="#定位质量" class="headerlink" title="定位质量"></a>定位质量</h3><blockquote>
<p>In this section we evaluate our selective search algorithms in terms of both Average Best Overlap and the number of locations on the Pascal VOC 2007 TEST set. We first evaluate box-based locations and afterwards briefly evaluate region-based locations.</p>
</blockquote>
<p>在本节中，我们将根据平均最佳重叠和Pascal VOC 2007测试集上的定位数来评估我们的选择性搜索算法。我们首先评估基于框的定位，然后简单评估基于区域的定位</p>
<h4 id="基于框的定位"><a href="#基于框的定位" class="headerlink" title="基于框的定位"></a>基于框的定位</h4><blockquote>
<p>We compare with the sliding window search of [16], the sliding window search of [12] using the window ratio’s of their models, the jumping windows of [34], the “objectness” boxes of [2], the boxes around the hierarchical segmentation algorithm of [3], the boxes around the regions of [9], and the boxes around the regions of [4]. From these algorithms, only [3] is not designed for finding object locations. Yet [3] is one of the best contour detectors publicly available, and results in a natural hierarchy of regions. We include it in our evaluation to see if this algorithm designed for segmentation also performs well on finding good object locations. Furthermore, [4, 9] are designed to find good object regions rather then boxes. Results are shown in Table 5 and Figure 4.</p>
</blockquote>
<p>与文献[16]的滑动窗口搜索、文献[12]的滑动窗口搜索、文献[34]的跳跃窗口、文献[2]的“对象”框、文献[3]的层次分割算法框、文献[9]的区域框和文献[4]的区域框进行了比较。从这些算法中，只有[3]不是为寻找目标位置而设计的。然而[3]是公开可用的最好的轮廓检测器之一，能够得到区域的自然层次结构。我们将其包含在我们的评估中，看看这个为分割而设计的算法是否也能很好地找到好的目标位置。此外，[4，9]的设计是为了找到好的对象区域，而不是框。结果如表5和图4所示</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/table-5.png" alt></p>
<blockquote>
<p>Table 5: Comparison of recall, Mean Average Best Overlap (MABO) and number of window locations for a variety of methods on the Pascal 2007 TEST set.</p>
</blockquote>
<p>表5：Pascal 2007测试集上各种方法的召回率、均值平均最佳重叠（MABO）和窗口位置数的比较</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/figure-4.png" alt></p>
<blockquote>
<p>Figure 4: Trade-off between quality and quantity of the object hypotheses in terms of bounding boxes on the Pascal 2007 TEST set. The dashed lines are for those methods whose quantity is expressed is the number of boxes per class. In terms of recall “Fast” selective search has the best trade-off. In terms of Mean Average Best Overlap the “Quality” selective search is comparable with [4, 9] yet is much faster to compute and goes on longer resulting in a higher final MABO of 0.879.</p>
</blockquote>
<p>图4：根据Pascal 2007测试集上的边界框，在对象假设的质量和数量之间进行权衡。虚线用于那些其数量表示为每个类的框数的方法。在召回方面，”快速”选择性搜索有最好的权衡。就平均最佳重叠而言，”质量”选择搜索与[4，9]相当，但计算速度更快，持续时间更长，最终MABO更高，为0.879</p>
<blockquote>
<p>As shown in Table 5, our “Fast” and “Quality” selective search methods yield a close to optimal recall of 98% and 99% respectively. In terms of MABO, we achieve 0.804 and 0.879 respectively. To appreciate what a Best Overlap of 0.879 means, Figure 5 shows for bike, cow, and person an example location which has an overlap score between 0.874 and 0.884. This illustrates that our selective search yields high quality object locations.</p>
</blockquote>
<p>如表5所示，我们的”快速”和”高质量”的选择性搜索方法分别产生了98%和99%的接近最优召回率。在MABO方面，我们分别达到了0.804和0.879。为了理解0.879的最佳重叠意味着什么，图5为自行车、奶牛和人显示了一个重叠得分介于0.874和0.884之间的示例位置。这说明我们的选择性搜索可以产生高质量的对象位置</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/figure-5.png" alt></p>
<blockquote>
<p>Figure 5: Examples of locations for objects whose Best Overlap score is around our Mean Average Best Overlap of 0.879. The green boxes are the ground truth. The red boxes are created using the “Quality” selective search.</p>
</blockquote>
<p>图5：目标的定位示例，其最佳重叠分数约为我们的平均最佳重叠的0.879。绿色的框是正确标注。红色框是使用”质量”选择性搜索创建的</p>
<blockquote>
<p>Furthermore, note that the standard deviation of our MABO scores is relatively low: 0.046 for the fast selective search, and 0.039 for the quality selective search. This shows that selective search is robust to difference in object properties, and also to image condition often related with specific objects (one example is indoor/outdoor lighting).</p>
</blockquote>
<p>此外请注意，我们的MABO分数的标准差相对较低：快速选择性搜索为0.046，质量选择性搜索为0.039。这表明选择性搜索对对象特性的差异以及通常与特定对象相关的图像条件（例如室内/室外照明）具有鲁棒性</p>
<blockquote>
<p>If we compare with other algorithms, the second highest recall is at 0.940 and is achieved by the jumping windows [34] using 10,000 boxes per class. As we do not have the exact boxes, we were unable to obtain the MABO score. This is followed by the exhaustive search of [12] which achieves a recall of 0.933 and a MABO of 0.829 at 100,352 boxes per class (this number is the average over all classes). This is significantly lower then our method while using at least a factor of 10 more object locations.</p>
</blockquote>
<p>如果我们与其他算法相比，第二高的召回率是0.940，并且是通过跳跃窗口[34]来实现的，每个类使用10000个框。由于我们没有确切的框，我们无法获得MABO分数。接下来是对[12]的详尽搜索，在每个类100352个框（这个数字是所有类的平均值）时，召回率为0.933，MABO为0.829。这明显低于我们的方法，尽管使用了至少10倍以上的对象定位因子</p>
<blockquote>
<p>Note furthermore that the segmentation methods of [4, 9] have a relatively high standard deviation. This illustrates that a single strategy can not work equally well for all classes. Instead, using multiple complementary strategies leads to more stable and reliable results.</p>
</blockquote>
<p>此外，注意[4，9]的分割方法具有相对较高的标准差。这说明一个策略不能对所有类都同样有效。相反，使用多种互补策略可以获得更稳定可靠的结果</p>
<blockquote>
<p>If we compare the segmentation of Arbelaez [3] with a the single best strategy of our method, they achieve a recall of 0.752 and a MABO of 0.649 at 418 boxes, while we achieve 0.875 recall and 0.698 MABO using 286 boxes. This suggests that a good segmentation algorithm does not automatically result in good object locations in terms of bounding boxes.</p>
</blockquote>
<p>如果我们将Arbelaez[3]的分割与我们方法的单一最佳策略进行比较，它们在418个框中实现了0.752的召回率和0.649的MABO，而我们在286个框中实现了0.875的召回率和0.698的MABO。这表明，一个好的分割算法并不能自动地在边界框方面产生好的对象位置</p>
<blockquote>
<p>Figure 4 explores the trade-off between the quality and quantity of the object hypotheses. In terms of recall, our “Fast” method outperforms all other methods. The method of [16] seems competitive for the 200 locations they use, but in their method the number of boxes is per class while for our method the same boxes are used for all classes. In terms of MABO, both the object hypotheses generation method of [4] and [9] have a good quantity/quality trade-off for the up to 790 object-box locations per image they generate. However, these algorithms are computationally 114 and 59 times more expensive than our “Fast” method.</p>
</blockquote>
<p>图4探讨了目标假设的质量和数量之间的权衡。在召回方面，我们的“快速”方法优于所有其他方法。[16]的方法对于他们使用的200个位置来说似乎很有竞争力，但是在他们的方法中，框的数量是每个类的，而对于我们的方法，框作用于所有类。就MABO而言，[4]和[9]的目标假设生成方法对于生成的每幅图像多达790个对象框位置，都具有良好的数量/质量权衡。然而，这些算法的计算成本是我们的“快速”方法的114倍和59倍</p>
<blockquote>
<p>Interestingly, the “objectness” method of [2] performs quite well in terms of recall, but much worse in terms of MABO. This is most likely caused by their non-maximum suppression, which suppresses windows which have more than an 0.5 overlap score with an existing, higher ranked window. And while this significantly improved results when a 0.5 overlap score is the definition of finding an object, for the general problem of finding the highest quality locations this strategy is less effective and can even be harmful by eliminating better locations.</p>
</blockquote>
<p>有趣的是，[2]的“目标”方法在召回方面表现得很好，但在MABO方面表现得更差。这最有可能是由它们的非最大抑制引起的，这抑制了具有超过0.5的重叠分数的窗口以及现有的、更高等级的窗口。尽管当0.5的重叠分数是寻找目标的定义时，这显著地改善了结果，但是对于寻找最高质量位置的通用问题，这一策略效率较低，甚至通过消除更好的位置而有害</p>
<blockquote>
<p>Figure 6 shows for several methods the Average Best Overlap per class. It is derived that the exhaustive search of [12] which uses 10 times more locations which are class specific, performs similar to our method for the classes bike, table, chair, and sofa, for the other classes our method yields the best score. In general, the classes with the highest scores are cat, dog, horse, and sofa, which are easy largely because the instances in the dataset tend to be big. The classes with the lowest scores are bottle, person, and plant, which are difficult because instances tend to be small. Nevertheless, cow, sheep, and tv are not bigger than person and yet can be found quite well by our algorithm.</p>
</blockquote>
<p>图6显示了几个方法中每个类的平均最佳重叠。结果表明，对[12]的穷举搜索使用了10倍以上的特定于类的位置，其性能与我们对自行车、桌子、椅子和沙发类的方法相似，对于其他类，我们的方法产生最佳分数。通常，得分最高的类是cat、dog、horse和sofa，因为数据集中的实例往往很大。得分最低的班级是瓶类、人类和植物类，这类很难识别因为实例集往往很小。然而，牛、羊和电视都不比人大，而且我们的算法也能很好地找到它们</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/figure-6.png" alt></p>
<blockquote>
<p>Figure 6: The Average Best Overlap scores per class for several method for generating box-based object locations on Pascal VOC 2007 TEST. For all classes but table our “Quality” selective search yields the best locations. For 12 out of 20 classes our “Fast” selective search outperforms the expensive [4, 9]. We always outperform [2].</p>
</blockquote>
<p>图6：Pascal VOC 2007测试中生成基于框的目标位置的几种方法的逐类平均最佳重叠分数。对于除了表以外的所有类，我们的“质量”选择性搜索会产生最佳位置。对于20个类中的12个，我们的“快速”选择性搜索优于昂贵的[4，9]。我们总是胜过[2]</p>
<blockquote>
<p>To summarize, selective search is very effective in finding a high quality set of object hypotheses using a limited number of boxes, where the quality is reasonable consistent over the object classes. The methods of [4] and [9] have a similar quality/quantity trade-off for up to 790 object locations. However, they have more variation over the object classes. Furthermore, they are at least 59 and 13 times more expensive to compute for our “Fast” and “Quality” selective search methods respectively, which is a problem for current dataset sizes for object recognition. In general, we conclude that selective search yields the best quality locations at 0.879 MABO while using a reasonable number of 10,097 class-independent object locations.</p>
</blockquote>
<p>总而言之，选择性搜索在使用有限数量的框来寻找高质量的目标假设集方面非常有效，其中搜索质量在所有目标类别上是合理一致的。[4]和[9]的方法对于多达790个目标位置具有类似的质量/数量权衡。但是，它们在对象类上有更多的变化。此外，对于我们的“快速”和“质量”选择性搜索方法来说，它们的计算成本分别高出59倍和13倍，这是当前目标识别数据集大小的一个问题。一般来说，我们的结论是，选择搜索在0.879 MABO处产生最佳质量的位置，同时使用10097个类无关的对象位置的合理数目</p>
<h4 id="基于区域的定位"><a href="#基于区域的定位" class="headerlink" title="基于区域的定位"></a>基于区域的定位</h4><blockquote>
<p>In this section we examine how well the regions that our selective search generates captures object locations. We do this on the segmentation part of the Pascal VOC 2007 TEST set. We compare with the segmentation of [3] and with the object hypothesis regions of both [4, 9]. Table 6 shows the results. Note that the number of regions is larger than the number of boxes as there are almost no exact duplicates.</p>
</blockquote>
<p>在本节中，我们将检查选择性搜索生成的区域捕获对象位置的效果。我们在Pascal VOC 2007测试集的分割部分执行此操作。我们比较了[3]的分割和[4，9]的目标假设区域。结果如表6所示。请注意，区域数大于框数，因为几乎没有完全重复的区域</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/table-6.png" alt></p>
<blockquote>
<p>Table 6: Comparison of algorithms to find a good set of potential object locations in terms of regions on the segmentation part of Pascal 2007 TEST.</p>
</blockquote>
<p>表6：根据Pascal 2007测试的分割部分，比较能够找到一组好的潜在目标位置的算法</p>
<blockquote>
<p>The object regions of both [4, 9] are of similar quality as our “Fast” selective search, 0.665 MABO and 0.679 MABO respectively where our “Fast” search yields 0.666 MABO. While [4, 9] use fewer regions these algorithms are respectively 114 and 59 times computationally more expensive. Our “Quality” selective search generates 22,491 regions and is respectively 25 and 13 times faster than [4, 9], and has by far the highest score of 0.730 MABO.</p>
</blockquote>
<p>文章[4，9]的目标区域质量与我们的“快速”选择性搜索相似，分别为0.665和0.679 MABO，其中我们的“快速”搜索产生0.666 MABO。虽然[4，9]使用较少的区域，但这些算法的计算成本分别是前者的114倍和59倍。我们的“质量”选择性搜索产生22491个区域，分别比[4,9]快25和13倍，目前最高得分为0.730 MABO</p>
<blockquote>
<p>Figure 7 shows the Average Best Overlap of the regions per class. For all classes except bike, our selective search consistently has relatively high ABO scores. The performance for bike is disproportionally lower for region-locations instead of object-locations, because bike is a wire-frame object and hence very difficult to accurately delineate.</p>
</blockquote>
<p>图7显示了每个类区域的平均最佳重叠。对于除自行车以外的所有类别，我们的选择性搜索始终具有相对较高的ABO分数。由于自行车是一个线框物体，因此很难准确地描绘出来，因此自行车在区域定位上的性能比目标定位上的性能低得多</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/figure-7.png" alt></p>
<blockquote>
<p>Figure 7: Comparison of the Average Best Overlap Scores per class between our method and others on the Pascal 2007 TEST set. Except for train, our “Quality” method consistently yields better Average Best Overlap scores.</p>
</blockquote>
<p>图7:Pascal 2007测试集上我们的方法和其他方法的平均最佳重叠分数的比较。除了火车类别之外，我们的“质量”方法始终能获得更好的平均最佳重叠分数</p>
<blockquote>
<p>If we compare our method to others, the method of [9] is better for train, for the other classes our “Quality” method yields similar or better scores. For bird, boat, bus, chair, person, plant, and tv scores are 0.05 ABO better. For car we obtain 0.12 higher ABO and for bottle even 0.17 higher ABO. Looking at the variation in ABO scores in table 6, we see that selective search has a slightly lower variation than the other methods: 0.093 MABO for “quality” and 0.108 for [9]. However, this score is biased because of the wire-framed bicycle: without bicycle the difference becomes more apparent. The standard deviation for the “quality” selective search becomes 0.058, and 0.100 for [9]. Again, this shows that by relying on multiple complementary strategies instead of a single strategy yields more stable results.</p>
</blockquote>
<p>如果我们将我们的方法与其他方法进行比较，[9]的方法更适合训练，对于其他类别，我们的“质量”方法可以得到相似或更好的分数。鸟、船、公共汽车、椅子、人、植物和电视的得分比其他算法高出0.05 ABO。对于汽车，我们高出0.12 ABO，对于瓶子，甚至高出0.17 大小ABO。通过观察表6中ABO得分的方差，我们发现选择性搜索的方差比其他方法略低：“质量”选择性搜索有0.093 MABO，文章[9]有0.108。然而因为铁丝线框自行车的影响，这个分数是有偏差的：除去自行车后差异会变得更加明显。“质量”选择性搜索的标准差变为0.058，而[9]的标准差变为0.100。这再次表明依靠多种互补策略而不是单一策略可以产生更稳定的结果</p>
<blockquote>
<p>Figure 8 shows several example segmentations from our method and [4, 9]. In the first image, the other methods have problems keeping the white label of the bottle and the book apart. In our case, one of our strategies ignores colour while the “fill” similarity (Eq. 5) helps grouping the bottle and label together. The missing bottle part, which is dusty, is already merged with the table before this bottle segment is formed, hence “fill” will not help here. The second image is an example of a dark image on which our algorithm has generally strong results due to using a variety of colour spaces. In this particular image, the partially intensity invariant Lab colour space helps to isolate the car. As we do not use the contour detection method of [3], our method sometimes generates segments with an irregular border, which is illustrated by the third image of a cat. The final image shows a very difficult example, for which only [4] provides an accurate segment.</p>
</blockquote>
<p>图8显示了我们的方法和[4，9]中的几个示例分割。在第一张图片中，其他方法无法将瓶子和书本的白色标签分开。在我们的例子中，我们的策略之一是忽略颜色，而“填充”相似性（公式5）有助于将瓶子和标签组合在一起。缺少的瓶子部分充满灰尘，所以在瓶子分割组合之前已经合并到桌子，因此“填充”不起作用。第二幅图像是一幅深色图像的例子，由于使用了多种颜色空间，我们的算法通常有很强的效果。在这个特殊的图像中，部分强度不变的Lab颜色空间有助于隔离汽车。由于我们没有使用[3]中的轮廓检测方法，我们的方法有时会生成具有不规则边界的线段，如猫的第三幅图像所示。最后的图像显示了一个非常困难的例子，只有[4]提供了一个精确的分割</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/figure-8.png" alt></p>
<blockquote>
<p>Figure 8: A qualitative comparison of selective search, [4], and [9]. For our method we observe: ignoring colour allows finding the bottle, multiple colour spaces help in dark images (car), and not using [3] sometimes result in irregular borders such as the cat.</p>
</blockquote>
<p>图8：选择性搜索与[4]和[9]的定性比较。对于我们的方法，我们观察到：忽略颜色可以找到瓶子，多个颜色空间有助于深色图像（汽车），不使用[3]有时会导致不规则的边界，如猫</p>
<blockquote>
<p>Now because of the nature of selective search, rather than pitting methods against each other, it is more interesting to see how they can complement each other. As both [4, 9] have a very different algorithm, the combination should prove effective according to our diversification hypothesis. Indeed, as can be seen in the lower part of Table 6, combination with our “Fast” selective search leads to 0.737 MABO at 6,438 locations. This is a higher MABO using less locations than our “quality” selective search. A combination of [4, 9] with our “quality” sampling leads to 0.758 MABO at 25,355 locations. This is a good increase at only a modest extra number of locations.</p>
</blockquote>
<p>现在，因为选择性搜索的本质不是将方法相互对立，所以更有趣的是看看它们如何能够相互补充。由于[4,9]都有一个非常不同的算法，根据我们的多样化假设，这种组合应该证明是有效的。事实上，如表6的下半部分所示，结合我们的“快速”选择性搜索，在6438个位置找到0.737 MABO。这是一个比我们的“质量”选择性搜索更高的MABO，而且拥有更少的定位。结合[4，9]和我们的“质量”方法进行采样，在25355个地点得到0.758 MABO。在只有少量额外定位的情况下是一个很好的增长</p>
<blockquote>
<p>To conclude, selective search is highly effective for generating object locations in terms of regions. The use of a variety of strategies makes it robust against various image conditions as well as the object class. The combination of [4], [9] and our grouping algorithms into a single selective search showed promising improvements. Given these improvements, and given that there are many more different partitioning algorithms out there to use in a selective search, it will be interesting to see how far our selective search paradigm can still go in terms of computational efficiency, number of object locations, and the quality of object locations.</p>
</blockquote>
<p>综上所述，选择性搜索对于根据区域生成目标位置而言是非常有效的。多种策略的使用使得它对各种图像条件和对象类都具有鲁棒性。将[4]、[9]和我们的分组算法组合成一个单一的选择性搜索显示出有希望的改进。考虑到这些改进，以及有更多不同的分区算法可用于选择性搜索，看看我们的选择性搜索范式在计算效率、目标定位数量和质量方面还能走多远</p>
<h2 id="目标识别"><a href="#目标识别" class="headerlink" title="目标识别"></a>目标识别</h2><blockquote>
<p>In this section we will evaluate our selective search strategy for object recognition using the Pascal VOC 2010 detection task.</p>
</blockquote>
<p>在本节中，我们将使用Pascal VOC 2010检测任务评估用于目标识别的选择性搜索策略</p>
<blockquote>
<p>Our selective search strategy enables the use of expensive and powerful image representations and machine learning techniques. In this section we use selective search inside the Bag-of-Words based object recognition framework described in Section 4. The reduced number of object locations compared to an exhaustive search make it feasible to use such a strong Bag-of-Words implementation.</p>
</blockquote>
<p>我们的选择性搜索策略能够使用昂贵而强大的图像表示和机器学习技术。本节中我们在第4部分描述的基于词袋的目标识别框架中使用选择性搜索。与穷举搜索相比，目标定位数量的减少使得使用这样一个强大的词袋实现成为可能</p>
<blockquote>
<p>To give an indication of computational requirements: The pixel-wise extraction of three SIFT variants plus visual word assignmenttakes around 10 seconds and is done once per image. The final round of SVM learning takes around 8 hours per class on a GPU for approximately 30,000 training examples [33] resulting from two rounds of mining negatives on Pascal VOC 2010. Mining hard negatives is done in parallel and takes around 11 hours on 10 machines for a single round, which is around 40 seconds per image. This is divided into 30 seconds for counting visual word frequencies and 0.5 seconds per class for classification. Testing takes 40 seconds for extracting features, visual word assignment, and counting visual word frequencies, after which 0.5 seconds is needed per class for classification. For comparison, the code of [12] (without cascade, just like our version) needs for testing slightly less than 4 seconds per image per class. For the 20 Pascal classes this makes our framework faster during testing.</p>
</blockquote>
<p>给出计算要求的指示：三个SIFT变体的像素级提取加上视觉单词分配大约需要10秒，并且每个图像执行一次。最后一轮的SVM学习在GPU上花费大约8个小时一个类，大约30000个训练示例（33），进行两轮PASCAL VOC 2010的负样本挖掘。挖掘hard negatives是并行进行的，每一轮需要在10台机器花费大约11个小时，每张图片大约40秒。这被分为30秒用于统计可视单词频率，0.5秒用于分类。测试需要40秒来提取特征、可视化单词分配和统计可视化单词的频率，之后每个类需要0.5秒来进行分类。为了进行比较，[12]的代码（没有级联，就像我们的版本一样）需要对每个类的每个图像进行不到4秒的测试。对于20个Pascal类而言，我们的框架在测试期间更快</p>
<blockquote>
<p>We evaluate results using the official evaluation server. This evaluation is independent as the test data has not been released. We compare with the top-4 of the competition. Note that while all methods in the top-4 are based on an exhaustive search using variations on part-based model of [12] with HOG-features, our method differs substantially by using selective search and Bag-of-Words features. Results are shown in Table 7.</p>
</blockquote>
<p>我们使用官方评估服务器评估结果。此评估是独立的，因为测试数据尚未发布。我们和比赛的前4名进行比较。请注意，虽然排名前4位的所有方法都是基于使用具有HOG特征的[12]的基于part的模型的变体的穷举搜索，但是我们的方法通过使用选择性搜索和词袋特征而有本质的不同。结果见表7</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/table-7.png" alt></p>
<blockquote>
<p>Table 7: Results from the Pascal VOC 2010 detection task test set. Our method is the only object recognition system based on Bag-of-Words. It has the best scores for 9, mostly non-rigid object categories, where the difference is up to 0.056 AP. The other methods are based on part-based HOG features, and perform better on most rigid object classes.</p>
</blockquote>
<p>表7:Pascal VOC 2010检测任务测试集的结果。我们的方法是唯一一个基于词袋的目标识别系统。它有9个最好的分数，大多是非刚性物体类别，其中差异高达0.056 AP。其他方法基于基于部分的HOG特征，并且在大多数刚性目标类上执行得更好</p>
<blockquote>
<p>It is shown that our method yields the best results for the classes plane, cat, cow, table, dog, plant, sheep, sofa, and tv. Except table, sofa, and tv, these classes are all non-rigid. This is expected, as Bag-of-Words is theoretically better suited for these classes than the HOG-features. Indeed, for the rigid classes bike, bottle, bus, car, person, and train the HOG-based methods perform better. The exception is the rigid class tv. This is presumably because our selective search performs well in locating tv’s, see Figure 6.</p>
</blockquote>
<p>结果表明，该方法对平面类、猫类、牛类、桌子类、狗类、植物类、羊类、沙发类、电视类的学习效果最好。除了桌子、沙发和电视，这些类都是非刚性的。这是意料之中的，因为理论上，词袋比HOG特性更适合这些类。事实上，对于刚性类，比如自行车、瓶子、公共汽车、汽车、人和火车，基于HOG的方法表现得更好。除了tv是个意外。这可能是因为我们的选择性搜索在电视定位上表现良好，见图6</p>
<blockquote>
<p>In the Pascal 2011 challenge there are several entries wich achieve significantly higher scores than our entry. These methods use Bag-of-Words as additional information on the locations found by their part-based model, yielding better detection accuracy. Interestingly, however, by using Bag-of-Words to detect locations our method achieves a higher total recall for many classes [10].</p>
</blockquote>
<p>在2011年Pascal挑战赛中，有几个参赛者的得分明显高于我们的参赛者。这些方法使用词袋作为基于部分模型发现的定位i的附加信息，从而获得更好的检测精度。然而，有趣的是，通过使用词袋来检测定位，我们的方法对许多类实现了更高的总召回率[10]</p>
<blockquote>
<p>Finally, our selective search enabled participation to the detection task of the ImageNet Large Scale Visual Recognition Challenge 2011 (ILSVRC2011) as shown in Table 8. This dataset contains 1,229,413 training images and 100,000 test images with 1,000 different object categories. Testing can be accelerated as features extracted from the locations of selective search can be reused for all classes. For example, using the fast Bag-of-Words framework of [30], the time to extract SIFT-descriptors plus two colour variants takes 6.7 seconds and assignment to visual words takes 1.7 seconds. Using a 1x1, 2x2, and 3x3 spatial pyramid division it takes 14 seconds to get all 172,032 dimensional features. Classification in a cascade on the pyramid levels then takes 0.3 seconds per class. For 1,000 classes, the total process then takes 323 seconds per image for testing. In contrast, using the part-based framework of [12] it takes 3.9 seconds per class per image, resulting in 3900 seconds per image for testing. This clearly shows that the reduced number of locations helps scaling towards more classes.</p>
</blockquote>
<p>最后，我们的选择性搜索使我们能够参与ImageNet大规模视觉识别挑战2011（ILSVRC2011）的检测任务，如表8所示。该数据集包含1229413个训练图像和100000个具有1000个不同对象类别的测试图像。测试可以加速，因为从选择性搜索位置提取的特征可以对所有类重用。例如，使用[30]的快速词袋框架，提取SIFT描述符和两个颜色变体所需的时间为6.7秒，而指定给可视化单词所需的时间为1.7秒。使用1x1、2x2和3x3空间金字塔分割，需要14秒才能获得所有172032维特征。在金字塔级别上进行级联分类，每个类需要0.3秒。对于1000个类，测试每张图片的过程需要323秒。相反，使用[12]中基于部件的框架，每个类的每个图像需要3.9秒，因此测试完所有图像需要3900秒。这清楚地表明，减少的位置数量有助于向更多类扩展</p>
<blockquote>
<p>We conclude that compared to an exhaustive search, selective search enables the use of more expensive features and classifiers and scales better as the number of classes increase.</p>
</blockquote>
<p>我们的结论是，与穷举搜索相比，选择性搜索能够使用更昂贵的特征和分类器，并且随着类数的增加，搜索的规模会更好</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/table-8.png" alt></p>
<blockquote>
<p>Table 8: Results for ImageNet Large Scale Visual Recognition Challenge 2011 (ILSVRC2011). Hierarchical error penalises mistakes less if the predicted class is semantically similar to the real class according to the WordNet hierarchy.</p>
</blockquote>
<p>表8:ImageNet 2011年大规模视觉识别挑战赛（ILSVRC2011）结果。根据WordNet的层次结构，如果预测的类在语义上与实际类相似，那么层次错误对错误的惩罚较小</p>
<h2 id="Pascal-VOC-2012"><a href="#Pascal-VOC-2012" class="headerlink" title="Pascal VOC 2012"></a>Pascal VOC 2012</h2><blockquote>
<p>Because the Pacal VOC 2012 is the latest and perhaps final VOC dataset, we briefly present results on this dataset to facilitate comparison with our work in the future. We present quality of boxes using the TRAIN+VAL set, the quality of segments on the segmentation part of TRAIN+VAL, and our localisation framework using a Spatial Pyramid of 1x1, 2x2, 3x3, and 4x4 on the TEST set using the official evaluation server.</p>
</blockquote>
<p>因为Pacal VOC 2012是最新的，也许是最终的VOC数据集，我们简要介绍了这个数据集的结果，以便于与我们未来的工作进行比较。我们使用TRAIN+VAL集呈现框的质量，在TRAIN+VAL的分割部分呈现分割质量，以及使用官方评估服务器在测试集上使用1x1、2x2、3x3和4x4的空间金字塔的定位框架</p>
<blockquote>
<p>Results for the location quality are presented in table 9. We see that for the box-locations the results are slightly higher than in Pascal VOC 2007. For the segments, however, results are worse. This is mainly because the 2012 segmentation set is considerably more difficult.</p>
</blockquote>
<p>定位质量结果见表9。我们看到，对于框定位，结果略高于Pascal VOC 2007。然而，对于分割而言，结果更糟。这主要是因为2012年的分割设置要困难得多</p>
<blockquote>
<p>For the 2012 detection challenge, the Mean Average Precision is 0.350. This is similar to the 0.351 MAP obtained on Pascal VOC 2010.</p>
</blockquote>
<p>对于2012年的检测挑战，均值平均精度为0.350。这与Pascal VOC 2010上获得的0.351 MAP相似</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/table-9.png" alt></p>
<blockquote>
<p>Table 9: Quality of locations on Pascal VOC 2012 TRAIN+VAL.</p>
</blockquote>
<p>表9:Pascal VOC 2012 TRAIN+VAL上的定位质量</p>
<h2 id="定位质量的上限"><a href="#定位质量的上限" class="headerlink" title="定位质量的上限"></a>定位质量的上限</h2><blockquote>
<p>In this experiment we investigate how close our selective search locations are to the optimal locations in terms of recognition accuracy for Bag-of-Words features. We do this on the Pascal VOC 2007 TEST set.</p>
</blockquote>
<p>在这个实验中，我们研究了我们的选择性搜索定位与最佳定位的接近程度，以确定词袋特征的识别精度。我们在PASCAL VOC 2007测试集上完成</p>
<blockquote>
<p>The red line in Figure 9 shows the MAP score of our object recognition system when the top n boxes of our “quality” selective search method are used. The performance starts at 0.283 MAP using the first 500 object locations with a MABO of 0.758. It rapidly increases to 0.356 MAP using the first 3000 object locations with a MABO of 0.855, and then ends at 0.360 MAP using all 10,097 object locations with a MABO of 0.883.</p>
</blockquote>
<p>图9中的红线显示了使用“质量”选择性搜索方法得到的前n个框时，我们的目标识别系统的MAP成绩。使用MABO为0.758的前500个对象位置能够得到0.293 MAP的性能。使用前3000个目标定位（MABO为0.855）能够快速增加到0.356 MAP，最后使用所有10097个目标位置（MABO为0.883）能够得到0.360 MAP</p>
<p><img src="/imgs/作用于目标识别的选择性搜索/figure-9.png" alt></p>
<blockquote>
<p>Figure 9: Theoretical upper limit for the box selection within our object recognition framework. The red curve denotes the performance using the top n locations of our “quality” selective search method, which has a MABO of 0.758 at 500 locations, 0.855 at 3000 locations, and 0.883 at 10,000 locations. The magenta curve denotes the performance using the same top n locations but now combined with the ground truth, which is the upper limit of location quality (MABO = 1). At 10,000 locations, our object hypothesis set is close to optimal in terms of object recognition accuracy.</p>
</blockquote>
<p>图9：目标识别框架中选择框的理论上限。红色曲线表示使用我们的“质量”选择性搜索方法的前n个位置的性能，该方法在500个位置的MABO为0.758，在3000个位置的MABO为0.855，在10000个位置的MABO为0.883。洋红色曲线表示使用相同的前n个位置的性能，同时结合了ground truth，这是定位质量的上限（MABO=1）。在10000个位置，我们的目标假设集在目标识别精度方面接近最优</p>
<blockquote>
<p>The magenta line shows the performance of our object recognition system if we include the ground truth object locations to our hypotheses set, representing an object hypothesis set of “perfect” quality with a MABO score of 1. When only the ground truth boxes are used a MAP of 0.592 is achieved, which is an upper bound of our object recognition system. However, this score rapidly declines to 0.437 MAP using as few as 500 locations per image. Remarkably, when all 10,079 boxes are used the performance drops to 0.377 MAP, only 0.017 MAP more than when not including the ground truth. This shows that at 10,000 object locations our hypotheses set is close to what can be optimally achieved for our recognition framework. The most likely explanation is our use of SIFT, which is designed to be shift invariant [21]. This causes approximate boxes, of a quality visualised in Figure 5, to be still good enough. However, the small gap between the “perfect” object hypotheses set of 10,000 boxes and ours suggests that we arrived at the point where the degree of invariance for Bag-of-Words may have an adverse effect rather than an advantageous one.</p>
</blockquote>
<p>如果我们在假设集中包含了ground truth目标定位，那么洋红线表明了我们的目标识别系统的性能，表示了一个具有“完美”质量（MABO分数为1）目标假设集。当只使用ground truth框时，可以得到0.592 MAP，这是我们的目标识别系统的上限。然而，当每张图像仅有500个定位时，这一得分迅速下降到0.437 MAP。值得注意的是，当使用所有10079个盒子时，性能下降到0.377 MAP，仅比不包括ground truth多0.017 MAP。这表明，拥有10000个目标定位时，我们的假设集接近于我们的识别框架所能达到的最佳效果。最有可能的解释是我们使用了SIFT，它被设计为移位不变量[21]。这就导致了图5所示质量近似框仍然足够好。然而，10000个框的“完美”目标假设集和我们的假设集之间的小差距表明，我们到达了这样一个点：对词袋的不变性程度可能产生不利影响，而不是有利影响</p>
<blockquote>
<p>The decrease of the “perfect” hypothesis set as the number of boxes becomes larger is due to the increased difficulty of the problem: more boxes means a higher variability, which makes the object recognition problem harder. Earlier we hypothesized that an exhaustive search examines all possible locations in the image, which makes the object recognition problem hard. To test if selective search alleviates the problem, we also applied our Bag-of-Words object recognition system on an exhaustive search, using the locations of [12]. This results in a MAP of 0.336, while the MABO was 0.829 and the number of object locations 100,000 per class. The same MABO is obtained using 2,000 locations with selective search. At 2,000 locations, the object recognition accuracy is 0.347. This shows that selective search indeed makes the problem easier compared to exhaustive search by reducing the possible variation in locations.</p>
</blockquote>
<p>随着框数量的增加，“完美”假设集的减少是由于问题难度的增加：盒子越多意味着可变性越高，这使得目标识别问题更加困难。之前我们假设一个详尽的搜索检查能够得到图像中所有可能位置，这使得目标识别问题变得困难。为了测试选择性搜索是否缓解了这个问题，我们还使用了我们的词袋目标识别系统，使用了[12]中的位置进行穷举搜索。这将得到0.336 MAP，而MABO为0.829，每个类的目标定位数为100000。使用2000个定位的选择性搜索可以得到相同的MABO。在2000个定位中目标识别精度为0.347。这表明，通过减少定位的可能，选择性搜索确实比穷举搜索更容易解决问题</p>
<blockquote>
<p>To conclude, there is a trade-off between quality and quantity of object hypothesis and the object recognition accuracy. High quality object locations are necessary to recognise an object in the first place. Being able to sample fewer object hypotheses without sacrificing quality makes the classification problem easier and helps to improves results. Remarkably, at a reasonable 10,000 locations, our object hypothesis set is close to optimal for our Bag-of-Words recognition system. This suggests that our locations are of such quality that features with higher discriminative power than is normally found in Bag-of-Words are now required.</p>
</blockquote>
<p>总之，目标假设的质量与目标识别的准确性之间存在着一种权衡关系。高质量的物体定位是识别物体所必需的。能够在不牺牲质量的情况下对较少的目标假设进行采样，使得分类问题变得更容易，并有助于改进结果。值得注意的是，在10000个定位上，我们的目标假设集接近于我们的词袋识别系统的最优值。这表明我们的定位特征拥有比通常在词袋中发现的具有更高辨别力</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><blockquote>
<p>This paper proposed to adapt segmentation for selective search. We observed that an image is inherently hierarchical and that there are a large variety of reasons for a region to form an object. Therefore a single bottom-up grouping algorithm can never capture all possible object locations. To solve this we introduced selective search, where the main insight is to use a diverse set of complementary and hierarchical grouping strategies. This makes selective search stable, robust, and independent of the object-class, where object types range from rigid (e.g. car) to non-rigid (e.g. cat), and theoretically also to amorphous (e.g. water).</p>
</blockquote>
<p>本文提出了一种适用于选择性搜索的分割方法。我们观察到，图像本身是分层的，一个区域形成一个对象有很多原因。因此，单一的自底向上分组算法永远无法捕获所有可能的目标位置。为了解决这个问题，我们引入了选择性搜索，其中的主要观点是使用一组不同的互补和分层的分组策略。这使得选择性搜索稳定、健壮，并且独立于对象类，其中对象类型从刚性（例如car）到非刚性（例如cat），理论上也适用于非晶态（例如water）</p>
<blockquote>
<p>In terms of object windows, results show that our algorithm is superior to the “objectness” of [2] where our fast selective search reaches a quality of 0.804 Mean Average Best Overlap at 2,134 locations. Compared to [4, 9], our algorithm has a similar trade-off between quality and quantity of generated windows with around 0.790 MABO for up to 790 locations, the maximum that they generate. Yet our algorithm is 13-59 times faster. Additionally, it creates up to 10,097 locations per image yielding a MABO as high as 0.879.</p>
</blockquote>
<p>在目标窗口方面，我们的算法优于[2]，在2134个位置，我们的快速选择性搜索达到0.804的平均最佳重叠质量。与[ 4, 9 ]相比，我们的算法在生成窗口的质量和数量上有相似的权衡，最多790个位置，大约0.790 MABO。然而我们的算法快13-59倍。此外，它可以为每个图像创建多达10097个位置，产生高达0.879的MABO</p>
<blockquote>
<p>In terms of object regions, a combination of our algorithm with [4, 9] yields a considerable jump in quality (MABO increases from 0.730 to 0.758), which shows that by following our diversification paradigm there is still room for improvement.</p>
</blockquote>
<p>在目标区域方面，将我们的算法与[4，9]相结合，在质量上有了相当大的提升（MABO从0.730增加到0.758），这表明，遵循我们的多样化模式仍有改进的空间</p>
<blockquote>
<p>Finally, we showed that selective search can be successfully used to create a good Bag-of-Words based localisation and recognition system. In fact, we showed that quality of our selective search locations are close to optimal for our version of Bag-of-Words based object recognition.</p>
</blockquote>
<p>最后，我们证明了选择性搜索可以成功地用于创建一个良好的基于词袋的定位和识别系统。事实上，我们已经证明了我们的选择性搜索定位的质量对于我们的基于词袋的目标识别来说是接近最优的</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>图像处理</category>
        <category>机器学习</category>
        <category>目标分割</category>
        <category>翻译</category>
        <category>目标检测</category>
        <category>目标识别</category>
      </categories>
      <tags>
        <tag>选择性搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>基于图的图像分割-OpenCV源码</title>
    <url>/posts/18052054.html</url>
    <content><![CDATA[<p><code>OpenCV</code>在模块<code>opencv_contrib</code>中实现了基于图的图像分割算法，其实现和作者提供的工程源码略有差别</p><a id="more"></a>
<p>下面首先解析源码，然后通过示例验证分割效果</p>
<ul>
<li>官网参考文档：<a href="https://docs.opencv.org/4.0.1/dd/d19/classcv_1_1ximgproc_1_1segmentation_1_1GraphSegmentation.html" target="_blank" rel="noopener">cv::ximgproc::segmentation::GraphSegmentation Class Reference</a></li>
<li>头文件<code>segmentation.hpp - /path/to/include/opencv4/opencv2/ximgproc/segmentation.hpp</code></li>
<li>源文件<code>graphsegmentation.cpp - /path/to/opencv_contrib/modules/ximgproc/src/graphsegmentation.cpp</code></li>
<li>实现示例<code>graphsegmentation_demo.cpp - /path/to/opencv_contrib/modules/ximgproc/samples/graphsegmentation_demo.cpp</code></li>
</ul>
<p><code>OpenCV</code>源码比较复杂，抽取相应实现到<a href="https://github.com/zjZSTU/GraphLib/tree/master/cplusplus/samples/graphsegmentation" target="_blank" rel="noopener">GraphLib/cplusplus/samples/graphsegmentation</a></p>
<h2 id="命令空间"><a href="#命令空间" class="headerlink" title="命令空间"></a>命令空间</h2><p>算法位于命令空间<code>cv::ximgproc::segmentation</code>中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">namespace cv &#123;</span><br><span class="line">    namespace ximgproc &#123;</span><br><span class="line">        namespace segmentation &#123;</span><br></pre></td></tr></table></figure>
<h2 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a>并查集</h2><p><code>OpenCV</code>实现了并查集操作，定义了并查集元素类<code>PointSetElement</code>以及并查集操作类<code>PointSet</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class PointSetElement &#123;</span><br><span class="line">    public:</span><br><span class="line">        int p;</span><br><span class="line">        int size;</span><br><span class="line"></span><br><span class="line">        PointSetElement() &#123; &#125;</span><br><span class="line"></span><br><span class="line">        PointSetElement(int p_) &#123;</span><br><span class="line">            p = p_;</span><br><span class="line">            size = 1;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">// An object to manage set of points, who can be fusionned</span><br><span class="line">class PointSet &#123;</span><br><span class="line">    public:</span><br><span class="line">        PointSet(int nb_elements_);</span><br><span class="line">        ~PointSet();</span><br><span class="line"></span><br><span class="line">        int nb_elements;</span><br><span class="line"></span><br><span class="line">        // Return the main point of the point&apos;s set</span><br><span class="line">        int getBasePoint(int p);</span><br><span class="line"></span><br><span class="line">        // Join two sets of points, based on their main point</span><br><span class="line">        void joinPoints(int p_a, int p_b);</span><br><span class="line"></span><br><span class="line">        // Return the set size of a set (based on the main point)</span><br><span class="line">        int size(unsigned int p) &#123; return mapping[p].size; &#125;</span><br><span class="line"></span><br><span class="line">    private:</span><br><span class="line">        PointSetElement* mapping;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>对于<code>PointSetElement</code>而言，定义了分量大小$size$以及当前像素点在最小生成树中的父指针$p$</p>
<p>对于<code>PointSet</code>而言，有两个成员和<code>3</code>个函数</p>
<ul>
<li><code>nb_elements</code>：分量个数</li>
<li><code>mapping</code>：点集元素指针</li>
<li><code>getBasePoint(int p)</code>：得到元素所属分量的根节点坐标</li>
<li><code>joinPoints(int p_a, int p_b)</code>：合并两个分量</li>
<li><code>size(unsigned int p)</code>：返回元素<code>p</code>所在分量个数</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PointSet::PointSet(int nb_elements_) &#123;</span><br><span class="line">    nb_elements = nb_elements_;</span><br><span class="line"></span><br><span class="line">    mapping = new PointSetElement[nb_elements];</span><br><span class="line"></span><br><span class="line">    for ( int i = 0; i &lt; nb_elements; i++) &#123;</span><br><span class="line">        mapping[i] = PointSetElement(i);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PointSet::~PointSet() &#123;</span><br><span class="line">    delete [] mapping;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int PointSet::getBasePoint( int p) &#123;</span><br><span class="line"></span><br><span class="line">        int base_p = p;</span><br><span class="line"></span><br><span class="line">    while (base_p != mapping[base_p].p) &#123;</span><br><span class="line">        base_p = mapping[base_p].p;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // Save mapping for faster acces later</span><br><span class="line">    mapping[p].p = base_p;</span><br><span class="line"></span><br><span class="line">    return base_p;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void PointSet::joinPoints(int p_a, int p_b) &#123;</span><br><span class="line"></span><br><span class="line">    // Always target smaller set, to avoid redirection in getBasePoint</span><br><span class="line">    if (mapping[p_a].size &lt; mapping[p_b].size)</span><br><span class="line">        swap(p_a, p_b);</span><br><span class="line"></span><br><span class="line">    mapping[p_b].p = p_a;</span><br><span class="line">    mapping[p_a].size += mapping[p_b].size;</span><br><span class="line"></span><br><span class="line">    nb_elements--;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>在构造函数中，通过输入的参数<code>nb_elements_</code>创建指针空间，初始化每个点集元素的父指针指向自身</li>
<li>函数<code>getBasePoint</code>查询根节点，使用了路径压缩进行优化</li>
<li>函数<code>joinPoints</code>合并两个分量，累加两个分量个数到根节点。与工程实现不同的是，这里比较<code>size</code>大小进行合并</li>
</ul>
<h2 id="边"><a href="#边" class="headerlink" title="边"></a>边</h2><p>定义类<code>Edge</code>保存边信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Edge &#123;</span><br><span class="line">    public:</span><br><span class="line">        int from;</span><br><span class="line">        int to;</span><br><span class="line">        float weight;</span><br><span class="line"></span><br><span class="line">        bool operator &lt;(const Edge&amp; e) const &#123;</span><br><span class="line">            return weight &lt; e.weight;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>包含两个顶点坐标以及边权重，同时重写比较函数，可作用于边集排序</p>
<h2 id="图分割算法"><a href="#图分割算法" class="headerlink" title="图分割算法"></a>图分割算法</h2><p><code>OpenCV</code>定义了一个图分割算法声明类<code>GraphSegemntation</code>以及一个图分割算法实现类<code>GraphSegmentationImpl</code></p>
<h3 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h3><p>图分割算法声明类<code>GraphSegmentation</code>位于<code>segmentation.hpp</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class CV_EXPORTS_W GraphSegmentation : public Algorithm &#123;</span><br><span class="line">    public:</span><br><span class="line">        /** @brief Segment an image and store output in dst</span><br><span class="line">            @param src The input image. Any number of channel (1 (Eg: Gray), 3 (Eg: RGB), 4 (Eg: RGB-D)) can be provided</span><br><span class="line">            @param dst The output segmentation. It&apos;s a CV_32SC1 Mat with the same number of cols and rows as input image, with an unique, sequential, id for each pixel.</span><br><span class="line">        */</span><br><span class="line">        CV_WRAP virtual void processImage(InputArray src, OutputArray dst) = 0;</span><br><span class="line"></span><br><span class="line">        CV_WRAP virtual void setSigma(double sigma) = 0;</span><br><span class="line">        CV_WRAP virtual double getSigma() = 0;</span><br><span class="line"></span><br><span class="line">        CV_WRAP virtual void setK(float k) = 0;</span><br><span class="line">        CV_WRAP virtual float getK() = 0;</span><br><span class="line"></span><br><span class="line">        CV_WRAP virtual void setMinSize(int min_size) = 0;</span><br><span class="line">        CV_WRAP virtual int getMinSize() = 0;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">/** @brief Creates a graph based segmentor</span><br><span class="line">    @param sigma The sigma parameter, used to smooth image</span><br><span class="line">    @param k The k parameter of the algorythm</span><br><span class="line">    @param min_size The minimum size of segments</span><br><span class="line">    */</span><br><span class="line">CV_EXPORTS_W Ptr&lt;GraphSegmentation&gt; createGraphSegmentation(double sigma=0.5, float k=300, int min_size=100);</span><br></pre></td></tr></table></figure>
<p>声明了对外提供的接口，同时提供了创建图分割类对象的辅助函数<code>createGraphSegmentation</code></p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>图分割算法实现类<code>GraphSegmentationImpl</code>位于<code>segmentation.hpp</code>，其继承了接口类<code>GraphSegmentation</code>并实现了分割算法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class GraphSegmentationImpl : public GraphSegmentation &#123;</span><br><span class="line">    public:</span><br><span class="line">        GraphSegmentationImpl() &#123;</span><br><span class="line">            sigma = 0.5;</span><br><span class="line">            k = 300;</span><br><span class="line">            min_size = 100;</span><br><span class="line">            name_ = &quot;GraphSegmentation&quot;;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ~GraphSegmentationImpl() CV_OVERRIDE &#123;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        virtual void processImage(InputArray src, OutputArray dst) CV_OVERRIDE;</span><br><span class="line"></span><br><span class="line">        virtual void setSigma(double sigma_) CV_OVERRIDE &#123; if (sigma_ &lt;= 0) &#123; sigma_ = 0.001; &#125; sigma = sigma_; &#125;</span><br><span class="line">        virtual double getSigma() CV_OVERRIDE &#123; return sigma; &#125;</span><br><span class="line"></span><br><span class="line">        virtual void setK(float k_) CV_OVERRIDE &#123; k = k_; &#125;</span><br><span class="line">        virtual float getK() CV_OVERRIDE &#123; return k; &#125;</span><br><span class="line"></span><br><span class="line">        virtual void setMinSize(int min_size_) CV_OVERRIDE &#123; min_size = min_size_; &#125;</span><br><span class="line">        virtual int getMinSize() CV_OVERRIDE &#123; return min_size; &#125;</span><br><span class="line"></span><br><span class="line">        virtual void write(FileStorage&amp; fs) const CV_OVERRIDE &#123;</span><br><span class="line">            fs &lt;&lt; &quot;name&quot; &lt;&lt; name_</span><br><span class="line">            &lt;&lt; &quot;sigma&quot; &lt;&lt; sigma</span><br><span class="line">            &lt;&lt; &quot;k&quot; &lt;&lt; k</span><br><span class="line">            &lt;&lt; &quot;min_size&quot; &lt;&lt; (int)min_size;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        virtual void read(const FileNode&amp; fn) CV_OVERRIDE &#123;</span><br><span class="line">            CV_Assert( (String)fn[&quot;name&quot;] == name_ );</span><br><span class="line"></span><br><span class="line">            sigma = (double)fn[&quot;sigma&quot;];</span><br><span class="line">            k = (float)fn[&quot;k&quot;];</span><br><span class="line">            min_size = (int)(int)fn[&quot;min_size&quot;];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    private:</span><br><span class="line">        double sigma;</span><br><span class="line">        float k;</span><br><span class="line">        int min_size;</span><br><span class="line">        String name_;</span><br><span class="line"></span><br><span class="line">        // Pre-filter the image</span><br><span class="line">        void filter(const Mat &amp;img, Mat &amp;img_filtered);</span><br><span class="line"></span><br><span class="line">        // Build the graph between each pixels</span><br><span class="line">        void buildGraph(Edge **edges, int &amp;nb_edges, const Mat &amp;img_filtered);</span><br><span class="line"></span><br><span class="line">        // Segment the graph</span><br><span class="line">        void segmentGraph(Edge * edges, const int &amp;nb_edges, const Mat &amp; img_filtered, PointSet **es);</span><br><span class="line"></span><br><span class="line">        // Remove areas too small</span><br><span class="line">        void filterSmallAreas(Edge *edges, const int &amp;nb_edges, PointSet *es);</span><br><span class="line"></span><br><span class="line">        // Map the segemented graph to a Mat with uniques, sequentials ids</span><br><span class="line">        void finalMapping(PointSet *es, Mat &amp;output);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p><code>public</code>函数包括</p>
<ul>
<li><code>processImage</code>：图像分割</li>
</ul>
<p><code>private</code>函数包括：</p>
<ul>
<li><code>filter</code>：高斯滤波</li>
<li><code>buildgraph</code>：创建边集</li>
<li><code>segmentGraph</code>：<code>Kruskal</code>算法得到最小生成树</li>
<li><code>filterSmallAreas</code>：合并小分量</li>
<li><code>finalMapping</code>：创建输出图</li>
</ul>
<p>另外<code>createGraphSegmentation</code>创建了分割类对象</p>
<h4 id="createGraphSegmentation"><a href="#createGraphSegmentation" class="headerlink" title="createGraphSegmentation"></a>createGraphSegmentation</h4><p>创建类对象，赋值高斯滤波参数<code>sigma</code>，阈值函数参数<code>k</code>，最小分量大小<code>min_size</code>，最后返回对象指针</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Ptr&lt;GraphSegmentation&gt; createGraphSegmentation(double sigma, float k, int min_size) &#123;</span><br><span class="line"></span><br><span class="line">    Ptr&lt;GraphSegmentation&gt; graphseg = makePtr&lt;GraphSegmentationImpl&gt;();</span><br><span class="line"></span><br><span class="line">    graphseg-&gt;setSigma(sigma);</span><br><span class="line">    graphseg-&gt;setK(k);</span><br><span class="line">    graphseg-&gt;setMinSize(min_size);</span><br><span class="line"></span><br><span class="line">    return graphseg;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h4><p>首先将输入图像转换成浮点类型，再调用高斯滤波函数<code>GaussianBlur</code>进行处理</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void GraphSegmentationImpl::filter(const Mat &amp;img, Mat &amp;img_filtered) &#123;</span><br><span class="line"></span><br><span class="line">    Mat img_converted;</span><br><span class="line"></span><br><span class="line">    // Switch to float</span><br><span class="line">    img.convertTo(img_converted, CV_32F);</span><br><span class="line"></span><br><span class="line">    // Apply gaussian filter</span><br><span class="line">    GaussianBlur(img_converted, img_filtered, Size(0, 0), sigma, sigma);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输入卷积核大小为$Size(0,0)$，参考<a href="https://www.zhujian.tech/posts/80b530f2.html">getGaussianKernel</a>，表示根据<code>sigma</code>值计算卷积核大小</p>
<h4 id="buildgraph"><a href="#buildgraph" class="headerlink" title="buildgraph"></a>buildgraph</h4><p>从左到右，从上到下的遍历像素点，计算当前顶点和<strong>上/下/左/右</strong>顶点的边</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for (int delta = -1; delta &lt;= 1; delta += 2) &#123;</span><br><span class="line">    for (int delta_j = 0, delta_i = 1; delta_j &lt;= 1; delta_j++ || delta_i--) &#123;</span><br><span class="line"></span><br><span class="line">        int i2 = i + delta * delta_i;</span><br><span class="line">        int j2 = j + delta * delta_j;</span><br></pre></td></tr></table></figure>
<p><code>i2/j2</code>取值为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">i2 = -1 j2 = 0</span><br><span class="line">i2 = 0 j2 = -1</span><br><span class="line">i2 = 1 j2 = 0</span><br><span class="line">i2 = 0 j2 = 1</span><br></pre></td></tr></table></figure>
<p>边权重通过计算相邻像素点之间的$L2$距离获得</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for ( int channel = 0; channel &lt; nb_channels; channel++) &#123;</span><br><span class="line">    tmp_total += pow(p[j * nb_channels + channel] - p2[j2 * nb_channels + channel], 2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>创建的边集会出现重复边的情况（<em>对无向图而言，虽然通过属性<code>from/to</code>明确了初始点和终止点</em>），不过在后续操作中都会使用到</p>
<h4 id="segmentGraph"><a href="#segmentGraph" class="headerlink" title="segmentGraph"></a>segmentGraph</h4><p>通过<code>Kruskal</code>算法实现分量的合并。首先进行边集排序，类<code>Edge</code>重写了比较函数，所以按权值升序排序</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">std::sort(edges, edges + nb_edges);</span><br></pre></td></tr></table></figure>
<p>然后创建并查集类<code>PointSet</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">*es = new PointSet(img_filtered.cols * img_filtered.rows);</span><br></pre></td></tr></table></figure>
<p>并设置阈值函数，初始时每个分量个数为<code>1</code>，所以阈值大小为<code>k</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">float* thresholds = new float[total_points];</span><br><span class="line"></span><br><span class="line">for (int i = 0; i &lt; total_points; i++)</span><br><span class="line">    thresholds[i] = k;</span><br></pre></td></tr></table></figure>
<p>遍历所有边，判断两个顶点是否位于同一分量。如果不是，判断是否满足边界条件。如果不是，合并两分量，更新阈值并设置边权重为<code>0</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for ( int i = 0; i &lt; nb_edges; i++) &#123;</span><br><span class="line">    int p_a = (*es)-&gt;getBasePoint(edges[i].from);</span><br><span class="line">    int p_b = (*es)-&gt;getBasePoint(edges[i].to);</span><br><span class="line"></span><br><span class="line">    if (p_a != p_b) &#123;</span><br><span class="line">        if (edges[i].weight &lt;= thresholds[p_a] &amp;&amp; edges[i].weight &lt;= thresholds[p_b]) &#123;</span><br><span class="line">            (*es)-&gt;joinPoints(p_a, p_b);</span><br><span class="line">            p_a = (*es)-&gt;getBasePoint(p_a);</span><br><span class="line">            thresholds[p_a] = edges[i].weight + k / (*es)-&gt;size(p_a);</span><br><span class="line"></span><br><span class="line">            edges[i].weight = 0;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>由于边集存在重复边的情况，所以将已使用的边权值设置为<code>0</code>之后，还有另一条相同的无向边存在</em></p>
<h4 id="filterSmallAreas"><a href="#filterSmallAreas" class="headerlink" title="filterSmallAreas"></a>filterSmallAreas</h4><p>再次遍历所有边，合并小分量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void GraphSegmentationImpl::filterSmallAreas(Edge *edges, const int &amp;nb_edges, PointSet *es) &#123;</span><br><span class="line">    for ( int i = 0; i &lt; nb_edges; i++) &#123;</span><br><span class="line">        if (edges[i].weight &gt; 0) &#123;</span><br><span class="line">            int p_a = es-&gt;getBasePoint(edges[i].from);</span><br><span class="line">            int p_b = es-&gt;getBasePoint(edges[i].to);</span><br><span class="line"></span><br><span class="line">            if (p_a != p_b &amp;&amp; (es-&gt;size(p_a) &lt; min_size || es-&gt;size(p_b) &lt; min_size)) &#123;</span><br><span class="line">                es-&gt;joinPoints(p_a, p_b);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="finalMapping"><a href="#finalMapping" class="headerlink" title="finalMapping"></a>finalMapping</h4><p>本函数作用于最后的不同分量颜色设置，输入参数为合并操作后的点集<code>PointSet *es</code>以及单通道图像<code>Mat &amp;output</code>。同一分量的像素点赋值同一个值，像素值从<code>0</code>开始递增</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &quot;opencv2/ximgproc/segmentation.hpp&quot;</span><br><span class="line">#include &quot;opencv2/highgui.hpp&quot;</span><br><span class="line">#include &quot;opencv2/core.hpp&quot;</span><br><span class="line">#include &quot;opencv2/imgproc.hpp&quot;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">using namespace cv;</span><br><span class="line">using namespace cv::ximgproc::segmentation;</span><br><span class="line"></span><br><span class="line">Scalar hsv_to_rgb(Scalar);</span><br><span class="line"></span><br><span class="line">Scalar color_mapping(int);</span><br><span class="line"></span><br><span class="line">static void help() &#123;</span><br><span class="line">    std::cout &lt;&lt; std::endl &lt;&lt;</span><br><span class="line">              &quot;A program demonstrating the use and capabilities of a particular graph based image&quot; &lt;&lt; std::endl &lt;&lt;</span><br><span class="line">              &quot;segmentation algorithm described in P. Felzenszwalb, D. Huttenlocher,&quot; &lt;&lt; std::endl &lt;&lt;</span><br><span class="line">              &quot;             \&quot;Efficient Graph-Based Image Segmentation\&quot;&quot; &lt;&lt; std::endl &lt;&lt;</span><br><span class="line">              &quot;International Journal of Computer Vision, Vol. 59, No. 2, September 2004&quot; &lt;&lt; std::endl &lt;&lt; std::endl &lt;&lt;</span><br><span class="line">              &quot;Usage:&quot; &lt;&lt; std::endl &lt;&lt;</span><br><span class="line">              &quot;./graphsegmentation_demo input_image output_image [simga=0.5] [k=300] [min_size=100]&quot; &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Scalar hsv_to_rgb(Scalar c) &#123;</span><br><span class="line">    Mat in(1, 1, CV_32FC3);</span><br><span class="line">    Mat out(1, 1, CV_32FC3);</span><br><span class="line"></span><br><span class="line">    float *p = in.ptr&lt;float&gt;(0);</span><br><span class="line">    p[0] = (float) c[0] * 360.0f;</span><br><span class="line">    p[1] = (float) c[1];</span><br><span class="line">    p[2] = (float) c[2];</span><br><span class="line"></span><br><span class="line">    cvtColor(in, out, COLOR_HSV2RGB);</span><br><span class="line"></span><br><span class="line">    Scalar t;</span><br><span class="line">    Vec3f p2 = out.at&lt;Vec3f&gt;(0, 0);</span><br><span class="line">    t[0] = (int) (p2[0] * 255);</span><br><span class="line">    t[1] = (int) (p2[1] * 255);</span><br><span class="line">    t[2] = (int) (p2[2] * 255);</span><br><span class="line"></span><br><span class="line">    return t;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Scalar color_mapping(int segment_id) &#123;</span><br><span class="line">    double base = (double) (segment_id) * 0.618033988749895 + 0.24443434;</span><br><span class="line"></span><br><span class="line">    return hsv_to_rgb(Scalar(fmod(base, 1.2), 0.95, 0.80));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(int argc, char **argv) &#123;</span><br><span class="line">    if (argc &lt; 2 || argc &gt; 6) &#123;</span><br><span class="line">        help();</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Ptr&lt;GraphSegmentation&gt; gs = createGraphSegmentation();</span><br><span class="line">    if (argc &gt; 3)</span><br><span class="line">        gs-&gt;setSigma(atof(argv[3]));</span><br><span class="line">    if (argc &gt; 4)</span><br><span class="line">        gs-&gt;setK((float) atoi(argv[4]));</span><br><span class="line">    if (argc &gt; 5)</span><br><span class="line">        gs-&gt;setMinSize(atoi(argv[5]));</span><br><span class="line">    if (!gs) &#123;</span><br><span class="line">        std::cerr &lt;&lt; &quot;Failed to create GraphSegmentation Algorithm.&quot; &lt;&lt; std::endl;</span><br><span class="line">        return -2;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Mat input, output, output_image;</span><br><span class="line">    input = imread(argv[1]);</span><br><span class="line">    if (!input.data) &#123;</span><br><span class="line">        std::cerr &lt;&lt; &quot;Failed to load input image&quot; &lt;&lt; std::endl;</span><br><span class="line">        return -3;</span><br><span class="line">    &#125;</span><br><span class="line">    gs-&gt;processImage(input, output);</span><br><span class="line"></span><br><span class="line">    double min, max;</span><br><span class="line">    minMaxLoc(output, &amp;min, &amp;max);</span><br><span class="line"></span><br><span class="line">    int nb_segs = (int) max + 1;</span><br><span class="line">    std::cout &lt;&lt; nb_segs &lt;&lt; &quot; segments&quot; &lt;&lt; std::endl;</span><br><span class="line">    output_image = Mat::zeros(output.rows, output.cols, CV_8UC3);</span><br><span class="line"></span><br><span class="line">    uint *p;</span><br><span class="line">    uchar *p2;</span><br><span class="line">    for (int i = 0; i &lt; output.rows; i++) &#123;</span><br><span class="line">        p = output.ptr&lt;uint&gt;(i);</span><br><span class="line">        p2 = output_image.ptr&lt;uchar&gt;(i);</span><br><span class="line"></span><br><span class="line">        for (int j = 0; j &lt; output.cols; j++) &#123;</span><br><span class="line">            Scalar color = color_mapping(p[j]);</span><br><span class="line">            p2[j * 3] = (uchar) color[0];</span><br><span class="line">            p2[j * 3 + 1] = (uchar) color[1];</span><br><span class="line">            p2[j * 3 + 2] = (uchar) color[2];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    imwrite(argv[2], output_image);</span><br><span class="line">    std::cout &lt;&lt; &quot;Image written to &quot; &lt;&lt; argv[2] &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先解析命令行参数，创建图像分割类对象并初始化参数</p>
<p>然后图像分割函数进行基于图的图像分割，输出单通道灰度图像</p>
<p>最后将创建<code>3</code>通道图像并赋值，同一分量的像素点设置相同的值。与论文提供的实现不同，为了使得分量间的颜色更加有区别，进行<code>HSV</code>颜色空间和<code>RGB</code>颜色空间的转换</p>
<p><img src="/imgs/基于图的图像分割-OpenCV源码/beach.png" alt></p>
<p><code>sigma=0.5, k=500, min_size=50</code></p>
<p><img src="/imgs/基于图的图像分割-OpenCV源码/beach_opencv.png" alt></p>
<p><code>sigma=0.5, k=300, min_size=100</code></p>
<p><img src="/imgs/基于图的图像分割-OpenCV源码/beach_opencv2.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>图像处理</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
        <category>目标分割</category>
        <category>数据结构</category>
        <category>图</category>
        <category>树</category>
        <category>最小生成树</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>opencv</tag>
        <tag>并查集</tag>
        <tag>kruskal</tag>
        <tag>基于图的图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>基于图的图像分割-工程源码</title>
    <url>/posts/a4b1a6d9.html</url>
    <content><![CDATA[<p>基于图的图像分割算法的作者提供了工程源码：<a href="http://cs.brown.edu/people/pfelzens/segment/" target="_blank" rel="noopener">Graph Based Image Segmentation</a></p><a id="more"></a>
<h2 id="工程结构"><a href="#工程结构" class="headerlink" title="工程结构"></a>工程结构</h2><p>工程结构如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── convolve.h</span><br><span class="line">├── COPYING</span><br><span class="line">├── disjoint-set.h                   - 并查集实现</span><br><span class="line">├── filter.h                         - 高斯滤波实现</span><br><span class="line">├── image.h                          - 图像数据类实现</span><br><span class="line">├── imconv.h</span><br><span class="line">├── imutil.h</span><br><span class="line">├── Makefile</span><br><span class="line">├── misc.h</span><br><span class="line">├── pnmfile.h                        - PPM文件解析</span><br><span class="line">├── README</span><br><span class="line">├── segment.cpp                      - main函数，解析命令行参数，调用图像加载，图像分割以及图像保存函数</span><br><span class="line">├── segment-graph.h                  - Kruskal算法实现</span><br><span class="line">└── segment-image.h                  - 图像分割功能实现入口：调用高斯滤波算法，创建边集，调用Kruskal算法，合并小分量以及图像赋值</span><br></pre></td></tr></table></figure>
<h2 id="关键元素解析"><a href="#关键元素解析" class="headerlink" title="关键元素解析"></a>关键元素解析</h2><h3 id="PPM"><a href="#PPM" class="headerlink" title="PPM"></a>PPM</h3><p>作者假定输入图像为<code>PPM</code>格式，具体参考<a href="https://www.zhujian.tech/posts/6cbcc636.html">PPM文件解析</a></p>
<p><em>文件中得到的图像数据是一个一维行向量</em></p>
<h3 id="image"><a href="#image" class="headerlink" title="image"></a>image</h3><p>图像数据类，保存图像长宽和字节数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">template &lt;class T&gt;</span><br><span class="line">class image &#123;</span><br><span class="line"> public:</span><br><span class="line">  /* create an image */</span><br><span class="line">  image(const int width, const int height, const bool init = true);</span><br><span class="line"></span><br><span class="line">  /* delete an image */</span><br><span class="line">  ~image();</span><br><span class="line"></span><br><span class="line">  /* init an image */</span><br><span class="line">  void init(const T &amp;val);</span><br><span class="line"></span><br><span class="line">  /* copy an image */</span><br><span class="line">  image&lt;T&gt; *copy() const;</span><br><span class="line">  </span><br><span class="line">  /* get the width of an image. */</span><br><span class="line">  int width() const &#123; return w; &#125;</span><br><span class="line">  </span><br><span class="line">  /* get the height of an image. */</span><br><span class="line">  int height() const &#123; return h; &#125;</span><br><span class="line">  </span><br><span class="line">  /* image data. */</span><br><span class="line">  T *data;</span><br><span class="line">  </span><br><span class="line">  /* row pointers. */</span><br><span class="line">  T **access;</span><br><span class="line">  </span><br><span class="line"> private:</span><br><span class="line">  int w, h;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="rgb"><a href="#rgb" class="headerlink" title="rgb"></a>rgb</h3><p>结构体<code>rgb</code>保存单个彩色像素</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct &#123; uchar r, g, b; &#125; rgb;</span><br></pre></td></tr></table></figure>
<h3 id="edge"><a href="#edge" class="headerlink" title="edge"></a>edge</h3><p>结构体<code>edge</code>保存边坐标和边权重</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct &#123;</span><br><span class="line">    float w;</span><br><span class="line">    int a, b;</span><br><span class="line">&#125; edge;</span><br></pre></td></tr></table></figure>
<p>构建边集时，创建一维<code>edge</code>类型数组<code>edges</code>，大小为<code>width * height * 4</code>，保存当前顶点与<code>右上、右中、右下和中下顶点</code>所连的边</p>
<h3 id="uni-elt"><a href="#uni-elt" class="headerlink" title="uni_elt"></a>uni_elt</h3><p>结构体<code>uni_elt</code>保存每个分量的秩（用于合并优化）、父指针以及分量大小</p>
<h3 id="universe"><a href="#universe" class="headerlink" title="universe"></a>universe</h3><p>类<code>universe</code>实现并查集数据结构，初始化对象时输入分量个数，每个分量保存为<code>eni_elt</code>，同时保存最终分量数目。利用路径压缩和按秩合并进行优化</p>
<p>并查集具体概念参考：<a href="https://www.zhujian.tech/posts/3eedae4a.html#more">[数据结构][图算法]并查集</a></p>
<h2 id="关键函数解析"><a href="#关键函数解析" class="headerlink" title="关键函数解析"></a>关键函数解析</h2><p><img src="/imgs/基于图的图像分割-工程源码/key-function.png" alt></p>
<ul>
<li><code>main</code>：入口程序，解析命令行参数（<code>sigma/k/min_size/input_path/output_path</code>），完成图像分割<ul>
<li><code>loadPPM</code>：加载<code>PPM</code>文件，返回<code>image&lt;rgb&gt;</code>对象</li>
<li><code>segment_image</code>：首先将彩色图像分离，分别进行高斯滤波，然后创建边集<code>edges</code>，再调用<code>segment_graph</code>函数进行分量合并，对返回的并查集对象<code>u</code>再次进行分量合并，去除小分量影响，最后通过随机颜色对图像赋值<ul>
<li><code>smooth</code>：高斯过滤</li>
<li><code>segment_graph</code>：<code>Kruskal</code>算法实现，完成图像合并</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p><img src="/imgs/基于图的图像分割-工程源码/beach.png" alt></p>
<p><code>sigma=0.5, k=500, min_size=50</code></p>
<p><img src="/imgs/基于图的图像分割-工程源码/beach_seg.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>图像处理</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>目标分割</category>
        <category>数据结构</category>
        <category>图</category>
        <category>树</category>
        <category>最小生成树</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>并查集</tag>
        <tag>kruskal</tag>
        <tag>基于图的图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>[数据结构][图算法]并查集</title>
    <url>/posts/3eedae4a.html</url>
    <content><![CDATA[<p>之前在<a href="https://www.zhujian.tech/posts/95d609b4.html">数据结构-图5</a>中实现了图的最小生成树，主要参考的是<code>《大话数据结构》</code>中的相关内容。在<code>Kruskal</code>算法实现中通过函数<code>Find</code>就能检查两个分量之间是否相连，效率很高，当时觉得这种实现很神奇，今天才发现这是一种专门的数据结构实现 - 并查集（<code>disjoint set</code>）</p><a id="more"></a>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>参考：</p>
<p><a href="https://en.wikipedia.org/wiki/Disjoint-set_data_structure" target="_blank" rel="noopener">Disjoint-set data structure</a></p>
<p>并查集（<code>disjoint set</code>，也称为<code>union-find set</code>或<code>merge-find set</code>）是一个元素集合，保存了划分为若干个不相交（不重叠）的元素子集</p>
<p>并查集的操作效率接近常量时间，其操作包括</p>
<ul>
<li>添加新的集合</li>
<li>合并现有的集合</li>
<li>确定元素是否在同一集合中</li>
</ul>
<p>从树结构的角度看，并查集就是一个森林，每个子集就是一颗树</p>
<p>在图最小生成树的<code>Kruskal</code>算法实现中，并查集起着关键作用</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>并查集中每个元素包含了两个成员：一是元素<code>ID</code>，二是父指针</p>
<p>利用一个一维数组表示元素集，数组下标表示每个元素，数组值表示父指针</p>
<ul>
<li>最开始的数组值可以置为空（<em>或者赋值为当前下标值</em>），表示自己就是根节点</li>
<li>比较两个元素是否在同一集合中，可以通过函数<code>Find</code>遍历指针，直到根节点。如果两个元素所在的树的根节点相同，表示在同一集合中</li>
<li>合并两个元素时，首先判断是否在同一集合中，如果不再，则将其中一个根节点置为另一个根节点的孩子</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void MiniSpanTree_Kruskal(GraphAdjList G) &#123;</span><br><span class="line">    ...</span><br><span class="line">    // 并查集，数组下标表示顶点，赋值表示父节点下标</span><br><span class="line">    int parent[MAXVEX] = &#123;&#125;;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">    ...</span><br><span class="line">    // 升序遍历</span><br><span class="line">    for (i = 0; i &lt; G.numEdges; i++) &#123;</span><br><span class="line">        n = Find(parent, edges[i].begin);</span><br><span class="line">        m = Find(parent, edges[i].end);</span><br><span class="line">        // 判断两个分量是否同属一个</span><br><span class="line">        if (n != m) &#123;</span><br><span class="line">            parent[n] = m;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int Find(int *parent, int f) &#123;</span><br><span class="line">    // 遍历分量</span><br><span class="line">    while (parent[f] &gt; 0) &#123;</span><br><span class="line">        f = parent[f];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return f;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="查找优化"><a href="#查找优化" class="headerlink" title="查找优化"></a>查找优化</h2><p>针对并查集中查找元素根节点函数<code>Find</code>有<code>2</code>种优化方式：</p>
<ol>
<li>路径压缩（<code>path compression</code>）</li>
<li>路径减半（<code>path halving</code>）</li>
</ol>
<h3 id="路径压缩"><a href="#路径压缩" class="headerlink" title="路径压缩"></a>路径压缩</h3><p>其实现方式是将树结构压平，使得子节点指针均指向根节点，这样能够加快元素的查询操作</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function Find(x)</span><br><span class="line">    if x.parent != x</span><br><span class="line">        x.parent := Find(x.parent)</span><br><span class="line">    return x.parent</span><br></pre></td></tr></table></figure>
<h3 id="路径减半"><a href="#路径减半" class="headerlink" title="路径减半"></a>路径减半</h3><p>其实现方式是将节点父指针指向祖父节点</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function Find(x)</span><br><span class="line">    while x.parent != x</span><br><span class="line">        x.parent := x.parent.parent</span><br><span class="line">        x := x.parent</span><br><span class="line">    return x</span><br></pre></td></tr></table></figure>
<p><strong>注意：此时根节点父指针应该指向自己</strong></p>
<h2 id="合并优化"><a href="#合并优化" class="headerlink" title="合并优化"></a>合并优化</h2><p>有两种方式可作用于子集合并操作，通过<code>size</code>或<code>rank</code>来优化</p>
<h3 id="union-by-rank"><a href="#union-by-rank" class="headerlink" title="union by rank"></a>union by rank</h3><p>秩（<code>rank</code>）优化作用于子集合并操作，总是将较短树附加到较高树的根上。因此，生成的树不比原始树高。在高度相等的情况下，生成的树才会比原始树高一个节点</p>
<p>在每个元素中再添加一个成员<code>rank</code>。一个集合最初只有一个元素，所以秩为零</p>
<ul>
<li>如果两个集合具有相同的秩，任选其中一个作为根节点，结果集的秩加<code>1</code></li>
<li>如果两个集合具有不同的秩，较大<code>rank</code>值的子集作为根节点，结果集的秩不变</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function Union(x, y)</span><br><span class="line">    xRoot := Find(x)</span><br><span class="line">    yRoot := Find(y)</span><br><span class="line"></span><br><span class="line">    // x and y are already in the same set</span><br><span class="line">    if xRoot == yRoot            </span><br><span class="line">        return</span><br><span class="line"></span><br><span class="line">    // x and y are not in same set, so we merge them</span><br><span class="line">    if xRoot.rank &lt; yRoot.rank</span><br><span class="line">        xRoot, yRoot := yRoot, xRoot // swap xRoot and yRoot</span><br><span class="line">    // merge yRoot into xRoot</span><br><span class="line">    yRoot.parent := xRoot</span><br><span class="line">    if xRoot.rank == yRoot.rank:</span><br><span class="line">        xRoot.rank := xRoot.rank + 1</span><br></pre></td></tr></table></figure>
<h3 id="union-by-size"><a href="#union-by-size" class="headerlink" title="union by size"></a>union by size</h3><p>大小（<code>size</code>）优化的原理和<code>rank</code>优化类似，通过新成员<code>size</code>保存每个子集的元素个数。每次都选择较大<code>size</code>的子集作为根节点，并加上另一个子集的<code>size</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function Union(x, y)</span><br><span class="line">    xRoot := Find(x)</span><br><span class="line">    yRoot := Find(y)</span><br><span class="line"></span><br><span class="line">    // x and y are already in the same set</span><br><span class="line">    if xRoot == yRoot            </span><br><span class="line">        return</span><br><span class="line"></span><br><span class="line">    // x and y are not in same set, so we merge them</span><br><span class="line">    if xRoot.size &lt; yRoot.size</span><br><span class="line">        xRoot, yRoot := yRoot, xRoot // swap xRoot and yRoot</span><br><span class="line"></span><br><span class="line">    // merge yRoot into xRoot</span><br><span class="line">    yRoot.parent := xRoot</span><br><span class="line">    xRoot.size := xRoot.size + yRoot.size</span><br></pre></td></tr></table></figure>
<h2 id="类实现"><a href="#类实现" class="headerlink" title="类实现"></a>类实现</h2><p>下面创建类来实现并查集，通过路径压缩和<code>rank</code>合并来优化</p>
<ul>
<li>新建结构体<code>disjoint_set_element</code>，保存父指针和<code>rank</code></li>
<li>新建类<code>DisjointSet</code>，保存元素数组，实现查找和合并操作</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//</span><br><span class="line">// Created by zj on 19-10-31.</span><br><span class="line">//</span><br><span class="line"></span><br><span class="line">#ifndef CPLUSPLUS_DISJOINSET_H</span><br><span class="line">#define CPLUSPLUS_DISJOINSET_H</span><br><span class="line"></span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;memory&gt;</span><br><span class="line"></span><br><span class="line">typedef struct disjoint_set_element &#123;</span><br><span class="line">    int parentPoint;</span><br><span class="line">    int rank;</span><br><span class="line">&#125; ds_element;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class DisjointSet &#123;</span><br><span class="line">public:</span><br><span class="line">    DisjointSet(const int num);</span><br><span class="line"></span><br><span class="line">    ~DisjointSet();</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 利用路径压缩优化</span><br><span class="line">     * @param x 起始节点</span><br><span class="line">     * @return 根节点</span><br><span class="line">     */</span><br><span class="line">    int find(int x);</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 子集合并，利用rank进行优化</span><br><span class="line">     * @param x 根节点</span><br><span class="line">     * @param y 根节点</span><br><span class="line">     * @return 连接成功，返回true；连接失败或者原节点在同一个子集中，返回false</span><br><span class="line">     */</span><br><span class="line">    bool join(int x, int y);</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 返回集合数</span><br><span class="line">     */</span><br><span class="line">    int getSetNum() &#123;</span><br><span class="line">        return this-&gt;num;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">    ds_element *elements;</span><br><span class="line">    // 子集数</span><br><span class="line">    int num;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#endif //CPLUSPLUS_DISJOINSET_H</span><br><span class="line"></span><br><span class="line">//</span><br><span class="line">// Created by zj on 19-10-31.</span><br><span class="line">//</span><br><span class="line"></span><br><span class="line">#include &quot;DisjointSet.h&quot;</span><br><span class="line"></span><br><span class="line">DisjointSet::DisjointSet(const int num) &#123;</span><br><span class="line">    elements = new ds_element[num];</span><br><span class="line">    this-&gt;num = num;</span><br><span class="line"></span><br><span class="line">    for (int i = 0; i &lt; num; i++) &#123;</span><br><span class="line">        elements[i].rank = 0;</span><br><span class="line">        elements[i].parentPoint = i;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DisjointSet::~DisjointSet() &#123;</span><br><span class="line">    delete[] elements;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int DisjointSet::find(int x) &#123;</span><br><span class="line">    if (elements[x].parentPoint != x) &#123;</span><br><span class="line">        elements[x].parentPoint = find(elements[x].parentPoint);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return elements[x].parentPoint;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">bool DisjointSet::join(int x, int y) &#123;</span><br><span class="line">    if (x == y) &#123;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 保证节点x的rank大于等于节点y</span><br><span class="line">    if (elements[x].rank &lt; elements[y].rank) &#123;</span><br><span class="line">        int tmp = x;</span><br><span class="line">        x = y;</span><br><span class="line">        y = tmp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    elements[y].parentPoint = x;</span><br><span class="line">    if (elements[x].rank == elements[y].rank) &#123;</span><br><span class="line">        elements[x].rank += 1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    this-&gt;num--;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Kruskal算法实现"><a href="#Kruskal算法实现" class="headerlink" title="Kruskal算法实现"></a>Kruskal算法实现</h2><p>通过上节定义的并查集完成<code>Kruskal</code>算法，分别通过邻接矩阵和邻接表实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void AdjacencyTableUndirectedGraph::MiniSpanTree_Kruskal(GraphAdjList G) &#123;</span><br><span class="line">    int i, j, k, n, m;</span><br><span class="line">    EdgeNode *e;</span><br><span class="line">    std::array&lt;Edge, MAXEDGE&gt; edges = &#123;&#125;;</span><br><span class="line">    DisjointSet disjointSet(G.numVertexes);</span><br><span class="line"></span><br><span class="line">    // 将边集赋值给edges</span><br><span class="line">    k = 0;</span><br><span class="line">    for (i = 0; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        e = G.adjList[i].firstEdge;</span><br><span class="line"></span><br><span class="line">        while (e != nullptr) &#123;</span><br><span class="line">            if (e-&gt;adjvex &gt; i) &#123;</span><br><span class="line">                Edge edge;</span><br><span class="line">                edge.begin = i;</span><br><span class="line">                edge.end = e-&gt;adjvex;</span><br><span class="line">                edge.weight = e-&gt;weight;</span><br><span class="line"></span><br><span class="line">                edges[k] = edge;</span><br><span class="line">                k++;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            e = e-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // 按权值升序排序</span><br><span class="line">    std::sort(edges.begin(), edges.begin() + G.numEdges, less_second);</span><br><span class="line"></span><br><span class="line">    int weight = 0;</span><br><span class="line">    // 升序遍历</span><br><span class="line">    for (i = 0; i &lt; G.numEdges; i++) &#123;</span><br><span class="line">        n = disjointSet.find(edges[i].begin);</span><br><span class="line">        m = disjointSet.find(edges[i].end);</span><br><span class="line">        if (disjointSet.join(n, m)) &#123;</span><br><span class="line">            printf(&quot;(%d, %d) %d\n&quot;, edges[i].begin, edges[i].end, edges[i].weight);</span><br><span class="line">            weight += edges[i].weight;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; &quot;MST权值和为：&quot; &lt;&lt; weight &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">bool AdjacencyTableUndirectedGraph::less_second(Edge x, Edge y) &#123;</span><br><span class="line">    return x.weight &lt; y.weight;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>完整代码参考：<a href="https://github.com/zjZSTU/GraphLib" target="_blank" rel="noopener">zjZSTU/GraphLib</a></p>
]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据结构</category>
        <category>图</category>
        <category>树</category>
        <category>最小生成树</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>并查集</tag>
        <tag>kruskal</tag>
        <tag>邻接矩阵</tag>
        <tag>邻接表</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins][Nginx]反向代理</title>
    <url>/posts/7c823af7.html</url>
    <content><![CDATA[<p>当前<code>jenkins</code>通过<code>tomcat</code>进行托管，登录路径为</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">localhost:8080/jenkins/</span><br></pre></td></tr></table></figure><a id="more"></a>

<p>下面通过<code>nginx</code>进行反向代理，简化登录路径</p>
<h2 id="nginx配置"><a href="#nginx配置" class="headerlink" title="nginx配置"></a>nginx配置</h2><p>修改<code>nginx</code>配置文件<code>/etc/nginx/conf.d/default.conf</code>，增加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">...</span><br><span class="line">    location /jenkins/ &#123;</span><br><span class="line">	    proxy_pass http://localhost:8080;</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>刷新<code>nginx</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo nginx -t</span><br><span class="line">$ sudo nginx -s reload</span><br></pre></td></tr></table></figure>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>配置完<code>nginx</code>后，就可以使用以下<code>URL</code>进行登录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost/jenkins/</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]The Boost Graph Library(BGL)</title>
    <url>/posts/af977180.html</url>
    <content><![CDATA[<p>原文地址：<a href="https://www.boost.org/doc/libs/1_71_0/libs/graph/doc/index.html" target="_blank" rel="noopener">The Boost Graph Library (BGL)</a></p><blockquote>
<p>Graphs are mathematical abstractions that are useful for solving many types of problems in computer science. Consequently, these abstractions must also be represented in computer programs. A standardized generic interface for traversing graphs is of utmost importance to encourage reuse of graph algorithms and data structures. Part of the Boost Graph Library is a generic interface that allows access to a graph’s structure, but hides the details of the implementation. This is an “open” interface in the sense that any graph library that implements this interface will be interoperable with the BGL generic algorithms and with other algorithms that also use this interface. The BGL provides some general purpose graph classes that conform to this interface, but they are not meant to be the “only” graph classes; there certainly will be other graph classes that are better for certain situations. We believe that the main contribution of the The BGL is the formulation of this interface.</p>
</blockquote><a id="more"></a>

<p>图是数学抽象，对解决计算机科学中的许多问题都很有用。因此，这些抽象也必须在计算机程序中表示出来。一个用于遍历图的标准化通用接口对于鼓励图算法和数据结构的重用至关重要。Boost图库的一部分是一个通用接口，它允许访问图的结构，但隐藏了实现的细节。这是一个”开放”接口，因为实现此接口的任何图库都可以与BGL通用算法和使用此接口的其他算法进行互操作。BGL提供了一些符合这个接口的通用图类，但它们并不是”唯一”的图类；当然还有其他图类更适合某些情况。我们相信BGL的主要贡献是这个接口的模式</p>
<blockquote>
<p>The BGL graph interface and graph components are generic, in the same sense as the Standard Template Library (STL) [2]. In the following sections, we review the role that generic programming plays in the STL and compare that to how we applied generic programming in the context of graphs.</p>
</blockquote>
<p>BGL的图接口和图组件是通用的，其含义与标准模板库（STL）相同。在下面的小节中，我们将回顾泛型编程在STL中所起的作用，并将其与我们如何在图上下文中应用泛型编程进行比较</p>
<blockquote>
<p>Of course, if you are already familiar with generic programming, please dive right in! Here’s the Table of Contents. For distributed-memory parallelism, you can also look at the Parallel BGL.</p>
</blockquote>
<p>当然，如果你已经熟悉通用编程，请直接跳过去！这是<a href="https://www.boost.org/doc/libs/1_71_0/libs/graph/doc/table_of_contents.html" target="_blank" rel="noopener">目录</a>。对于分布式内存并行，您还可以查看<a href="https://www.boost.org/doc/libs/1_71_0/libs/graph_parallel/doc/html/index.html" target="_blank" rel="noopener">并行BGL</a></p>
<blockquote>
<p>The source for the BGL is available as part of the Boost distribution, which you can download from here.</p>
</blockquote>
<p>BGL的源代码是boost发行版的一部分，可以从这里<a href="http://sourceforge.net/project/showfiles.php?group_id=7586" target="_blank" rel="noopener">下载</a></p>
<h2 id="How-to-Build-the-BGL"><a href="#How-to-Build-the-BGL" class="headerlink" title="How to Build the BGL"></a>How to Build the BGL</h2><p>如何构建BGL</p>
<blockquote>
<p>DON’T! The Boost Graph Library is a header-only library and does not need to be built to be used. The only exceptions are the GraphViz input parser and the GraphML parser.</p>
</blockquote>
<p>不需要！Boost图库是一个只包含头文件的库，不需要构建就可以使用。唯一的例外是<a href="https://www.boost.org/doc/libs/1_71_0/libs/graph/doc/read_graphviz.html" target="_blank" rel="noopener">GraphViz输入解析器</a>和<a href="https://www.boost.org/doc/libs/1_71_0/libs/graph/doc/read_graphml.html" target="_blank" rel="noopener">GraphML解析器</a></p>
<blockquote>
<p>When compiling programs that use the BGL, be sure to compile with optimization. For instance, select “Release” mode with Microsoft Visual C++ or supply the flag -O2 or -O3 to GCC.</p>
</blockquote>
<p>在编译使用BGL的程序时，一定要进行优化编译。例如，如果使用微软Visual C++，选择”Release”模式；如果使用GCC，提供-O2或-O3标志</p>
<h2 id="Genericity-in-STL"><a href="#Genericity-in-STL" class="headerlink" title="Genericity in STL"></a>Genericity in STL</h2><p>STL中的泛型</p>
<blockquote>
<p>There are three ways in which the STL is generic.</p>
</blockquote>
<p>STL有三种通用方法</p>
<h3 id="Algorithm-Data-Structure-Interoperability"><a href="#Algorithm-Data-Structure-Interoperability" class="headerlink" title="Algorithm/Data-Structure Interoperability"></a>Algorithm/Data-Structure Interoperability</h3><p>算法/数据结构互操作性</p>
<blockquote>
<p>First, each algorithm is written in a data-structure neutral way, allowing a single template function to operate on many different classes of containers. The concept of an iterator is the key ingredient in this decoupling of algorithms and data-structures. The impact of this technique is a reduction in the STL’s code size from O(M*N) to O(M+N), where M is the number of algorithms and N is the number of containers. Considering a situation of 20 algorithms and 5 data-structures, this would be the difference between writing 100 functions versus only 25 functions! And the differences continues to grow faster and faster as the number of algorithms and data-structures increase.</p>
</blockquote>
<p>首先，每个算法都不倾向于具体数据结构，允许单个模板函数在许多不同的容器类上操作。迭代器的概念是算法和数据结构解耦的关键因素。这种技术的影响是将STL的代码大小从O(M*N)减少到O(M+N)，其中M是算法的数量，N是容器的数量。考虑到20个算法和5个数据结构的情况，这将是写100个函数和只写25个函数的区别！随着算法和数据结构数量的增加，这种差异继续以越来越快的速度增长。</p>
<h3 id="Extension-through-Function-Objects"><a href="#Extension-through-Function-Objects" class="headerlink" title="Extension through Function Objects"></a>Extension through Function Objects</h3><p>通过函数对象的扩展</p>
<blockquote>
<p>The second way that STL is generic is that its algorithms and containers are extensible. The user can adapt and customize the STL through the use of function objects. This flexibility is what makes STL such a great tool for solving real-world problems. Each programming problem brings its own set of entities and interactions that must be modeled. Function objects provide a mechanism for extending the STL to handle the specifics of each problem domain.</p>
</blockquote>
<p>STL通用的第二种方式是它的算法和容器是可扩展的。用户可以通过使用函数对象来调整和定制STL。这种灵活性使得STL成为解决现实世界问题的伟大工具。每个编程问题都有自己的一组必须建模的实体和交互。函数对象提供了一种扩展STL以处理每个问题域的细节的机制</p>
<h3 id="Element-Type-Parameterization"><a href="#Element-Type-Parameterization" class="headerlink" title="Element Type Parameterization"></a>Element Type Parameterization</h3><p>元素类型参数化</p>
<blockquote>
<p>The third way that STL is generic is that its containers are parameterized on the element type. Though hugely important, this is perhaps the least “interesting” way in which STL is generic. Generic programming is often summarized by a brief description of parameterized lists such as std::list<t>. This hardly scratches the surface!</t></p>
</blockquote>
<p>STL泛型的第三种方式是在元素类型上对其容器进行参数化。尽管这非常重要，但这可能是STL通用的最不”有趣”的方式。泛型编程通常通过对参数化列表（如<code>std::list&lt;T&gt;</code>）的简要描述来总结。这使得理解内部实现更加困难！ </p>
<h2 id="Genericity-in-the-Boost-Graph-Library"><a href="#Genericity-in-the-Boost-Graph-Library" class="headerlink" title="Genericity in the Boost Graph Library"></a>Genericity in the Boost Graph Library</h2><p>Boost图库中的泛型</p>
<blockquote>
<p>Like the STL, there are three ways in which the BGL is generic.</p>
</blockquote>
<p>与STL一样，BGL有三种通用方式</p>
<h3 id="Algorithm-Data-Structure-Interoperability-1"><a href="#Algorithm-Data-Structure-Interoperability-1" class="headerlink" title="Algorithm/Data-Structure Interoperability"></a>Algorithm/Data-Structure Interoperability</h3><p>算法/数据结构互操作性</p>
<blockquote>
<p>First, the graph algorithms of the BGL are written to an interface that abstracts away the details of the particular graph data-structure. Like the STL, the BGL uses iterators to define the interface for data-structure traversal. There are three distinct graph traversal patterns: traversal of all vertices in the graph, through all of the edges, and along the adjacency structure of the graph (from a vertex to each of its neighbors). There are separate iterators for each pattern of traversal.</p>
</blockquote>
<p>首先，BGL的图算法被写入一个接口，该接口抽象出特定图数据结构的细节。与STL一样，BGL使用迭代器定义数据结构遍历的接口。有三种不同的图遍历模式：遍历图中的所有顶点、遍历所有边以及沿着图的邻接结构（从一个顶点到它的每个邻接顶点）。每个遍历模式都有独立的迭代器</p>
<blockquote>
<p>This generic interface allows template functions such as breadth_first_search() to work on a large variety of graph data-structures, from graphs implemented with pointer-linked nodes to graphs encoded in arrays. This flexibility is especially important in the domain of graphs. Graph data-structures are often custom-made for a particular application. Traditionally, if programmers want to reuse an algorithm implementation they must convert/copy their graph data into the graph library’s prescribed graph structure. This is the case with libraries such as LEDA, GTL, Stanford GraphBase; it is especially true of graph algorithms written in Fortran. This severely limits the reuse of their graph algorithms.</p>
</blockquote>
<p>此通用接口允许模板函数（比如<a href="https://www.boost.org/doc/libs/1_71_0/libs/graph/doc/breadth_first_search.html" target="_blank" rel="noopener">breaddth_first_search</a>）处理各种图数据结构，从使用指针链接节点实现的图到在数组中编码的图。这种灵活性在图领域中尤其重要。图数据结构通常是为特定应用程序定制的。传统上，如果程序员想要重用一个算法实现，他们必须将他们的图数据转换/复制到图库的指定图结构中。LEDA、GTL、Stanford GraphBase等库就是这样；用Fortran编写的图算法尤其如此。这严重限制了它们的图算法的重用</p>
<blockquote>
<p>In contrast, custom-made (or even legacy) graph structures can be used as-is with the generic graph algorithms of the BGL, using external adaptation (see Section How to Convert Existing Graphs to the BGL). External adaptation wraps a new interface around a data-structure without copying and without placing the data inside adaptor objects. The BGL interface was carefully designed to make this adaptation easy. To demonstrate this, we have built interfacing code for using a variety of graph structures (LEDA graphs, Stanford GraphBase graphs, and even Fortran-style arrays) in BGL graph algorithms.</p>
</blockquote>
<p>相比之下，定制的（甚至是遗留的）图结构可以与BGL的通用图算法一起使用，使用外部自适应（参见<a href="https://www.boost.org/doc/libs/1_71_0/libs/graph/doc/leda_conversion.html" target="_blank" rel="noopener">如何将现有图转换为BGL</a>）。外部自适应在数据结构周围包装一个新接口，而无需复制，也无需将数据放置在适配器对象中。BGL接口经过精心设计，使这种调整变得容易。为了演示这一点，我们构建了接口代码，用于在BGL图算法中使用各种图结构（LEDA图、Stanford GraphBase图，甚至Fortran样式的数组）</p>
<h3 id="Extension-through-Visitors"><a href="#Extension-through-Visitors" class="headerlink" title="Extension through Visitors"></a>Extension through Visitors</h3><p>通过Visitors扩展</p>
<blockquote>
<p>Second, the graph algorithms of the BGL are extensible. The BGL introduces the notion of a visitor, which is just a function object with multiple methods. In graph algorithms, there are often several key “event points” at which it is useful to insert user-defined operations. The visitor object has a different method that is invoked at each event point. The particular event points and corresponding visitor methods depend on the particular algorithm. They often include methods like start_vertex(), discover_vertex(), examine_edge(), tree_edge(), and finish_vertex().</p>
</blockquote>
<p>其次，BGL的图算法是可扩展的。BGL引入了visitor的概念，它只是一个带有多个方法的函数对象。在图算法中，通常有几个关键的”事件点”，在这些点上插入用户定义的操作是有用的。visitor对象有一个在每个事件点调用的不同方法。特定的事件点和相应的访问者方法取决于特定的算法。它们通常包括start_vertex()、discover_vertex()、examine_edge()、tree_edge()和finish_vertex()等方法</p>
<h3 id="Vertex-and-Edge-Property-Multi-Parameterization"><a href="#Vertex-and-Edge-Property-Multi-Parameterization" class="headerlink" title="Vertex and Edge Property Multi-Parameterization"></a>Vertex and Edge Property Multi-Parameterization</h3><p>顶点和边属性多参数化</p>
<blockquote>
<p>The third way that the BGL is generic is analogous to the parameterization of the element-type in STL containers, though again the story is a bit more complicated for graphs. We need to associate values (called “properties”) with both the vertices and the edges of the graph. In addition, it will often be necessary to associate multiple properties with each vertex and edge; this is what we mean by multi-parameterization. The STL std::list<t> class has a parameter T for its element type. Similarly, BGL graph classes have template parameters for vertex and edge “properties”. A property specifies the parameterized type of the property and also assigns an identifying tag to the property. This tag is used to distinguish between the multiple properties which an edge or vertex may have. A property value that is attached to a particular vertex or edge can be obtained via a property map. There is a separate property map for each property.</t></p>
</blockquote>
<p>BGL提供的第三种通用的方式类似于STL容器中元素类型的参数化，不过对于图来说，这个过程还是有点复杂。我们需要将值（称为”属性”）与图的顶点和边相关联。此外，通常需要将多个属性与每个顶点和边关联起来；这就是我们所说的多参数化。STL std::list<t>类的元素类型有一个参数T。类似地，BGL图类具有顶点和边”属性”的模板参数。属性指定属性的参数化类型，并为属性指定标识标记。此标记用于区分边或顶点可能具有的多个属性。附加到特定顶点或边的特性值可以通过特性映射获得。每个属性都有一个单独的属性映射</t></p>
<blockquote>
<p>Traditional graph libraries and graph structures fall down when it comes to the parameterization of graph properties. This is one of the primary reasons that graph data-structures must be custom-built for applications. The parameterization of properties in the BGL graph classes makes them well suited for re-use.</p>
</blockquote>
<p>传统的图库和图结构在对图的属性进行参数化时会出现故障。这是图数据结构必须为应用程序定制的主要原因之一。BGL图类中属性的参数化使它们非常适合重用</p>
<h2 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h2><p>算法</p>
<blockquote>
<p>The BGL algorithms consist of a core set of algorithm patterns (implemented as generic algorithms) and a larger set of graph algorithms. The core algorithm patterns are</p>
<pre><code>* Breadth First Search
* Depth First Search
* Uniform Cost Search
</code></pre></blockquote>
<p>BGL算法由一组核心的算法模式（作为通用算法实现）和一组较大的图算法组成。核心算法模式是</p>
<ul>
<li>广度优先搜索</li>
<li>深度优先搜索</li>
<li>成本一致搜索</li>
</ul>
<blockquote>
<p>By themselves, the algorithm patterns do not compute any meaningful quantities over graphs; they are merely building blocks for constructing graph algorithms. The graph algorithms in the BGL currently include</p>
<pre><code>* Dijkstra&#39;s Shortest Paths
* Bellman-Ford Shortest Paths
* Johnson&#39;s All-Pairs Shortest Paths
* Kruskal&#39;s Minimum Spanning Tree
* Prim&#39;s Minimum Spanning Tree
* Connected Components
* Strongly Connected Components
* Dynamic Connected Components (using Disjoint Sets)
* Topological Sort
* Transpose
* Reverse Cuthill Mckee Ordering
* Smallest Last Vertex Ordering
* Sequential Vertex Coloring
</code></pre></blockquote>
<p>算法模式本身并不计算图上任何有意义的量；它们只是构造图算法的构造块。BGL中的图算法目前包括</p>
<ul>
<li>Dijkstra最短路径</li>
<li>Bellman-Ford最短路径</li>
<li>Johnson全对最短路径</li>
<li>Kruskal最小生成树</li>
<li>Prim最小生成树</li>
<li>连通分量</li>
<li>强连通分量</li>
<li>动态连通分量 (使用不相交集)</li>
<li>拓扑排序</li>
<li>转置</li>
<li>反向卡特希尔麦基排序</li>
<li>最小最后顶点排序</li>
<li>序列顶点染色</li>
</ul>
<h2 id="Data-Structures"><a href="#Data-Structures" class="headerlink" title="Data Structures"></a>Data Structures</h2><p>数据结构</p>
<blockquote>
<p>The BGL currently provides two graph classes and an edge list adaptor:</p>
<pre><code>* adjacency_list
* adjacency_matrix
* edge_list
</code></pre></blockquote>
<p>BGL目前提供两个图类和一个边缘列表适配器：</p>
<ul>
<li><a href="https://www.boost.org/doc/libs/1_71_0/libs/graph/doc/adjacency_list.html" target="_blank" rel="noopener">邻接表</a></li>
<li><a href="https://www.boost.org/doc/libs/1_71_0/libs/graph/doc/adjacency_matrix.html" target="_blank" rel="noopener">邻接矩阵</a></li>
<li><a href="https://www.boost.org/doc/libs/1_71_0/libs/graph/doc/edge_list.html" target="_blank" rel="noopener">边列表</a></li>
</ul>
<blockquote>
<p>The adjacency_list class is the general purpose “swiss army knife” of graph classes. It is highly parameterized so that it can be optimized for different situations: the graph is directed or undirected, allow or disallow parallel edges, efficient access to just the out-edges or also to the in-edges, fast vertex insertion and removal at the cost of extra space overhead, etc.</p>
</blockquote>
<p>邻接表类是图类的通用”瑞士军刀”。它是高度参数化的，因此可以针对不同的情况进行优化：图是有向或无向的，允许或不允许平行边，有效地访问外部边或内部边，以额外的空间开销为代价快速插入和移除顶点等</p>
<blockquote>
<p>The adjacency_matrix class stores edges in a $|V| \times |V|$ matrix (where $|V|$ is the number of vertices). The elements of this matrix represent edges in the graph. Adjacency matrix representations are especially suitable for very dense graphs, i.e., those where the number of edges approaches $|V|^2$.</p>
</blockquote>
<p>邻接矩阵类将边存储在$|V| \times |V|$矩阵中（其中$|V|$是顶点数）。这个矩阵的元素表示图中的边。邻接矩阵表示特别适合于非常稠密的图，即边数接近$|V|^2$的图</p>
<blockquote>
<p>The edge_list class is an adaptor that takes any kind of edge iterator and implements an Edge List Graph.</p>
</blockquote>
<p>edge_list类是一个适配器，它接受任何类型的边迭代器并实现一个<a href="https://www.boost.org/doc/libs/1_71_0/libs/graph/doc/EdgeListGraph.html" target="_blank" rel="noopener">边列表图</a></p>
]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>代码库</category>
        <category>数据结构</category>
        <category>翻译</category>
        <category>图</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>stl</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins]Tomcat托管</title>
    <url>/posts/bc77c204.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="http://www.mamicode.com/info-detail-2535358.html" target="_blank" rel="noopener">ubuntu16.04使用tomcat安装jenkins</a></p><p><a href="https://zj-linux-guide.readthedocs.io/zh_CN/latest/tools/[Ubuntu%2016.02]Tomcat9%E5%AE%89%E8%A3%85.html" target="_blank" rel="noopener">[Ubuntu 16.02]Tomcat9安装</a></p><a id="more"></a>


<p>通过<code>Tomcat</code>托管<code>Jenkins</code>，具体<code>Tomcat</code>操作参考</p>
<ul>
<li><a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/tomcat/[Ubuntu%2016.02]Tomcat9安装.html" target="_blank" rel="noopener">[Ubuntu 16.02]Tomcat9安装</a></li>
<li><a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/tomcat/[Ubuntu%2016.02]非root用户运行.html" target="_blank" rel="noopener">非root用户运行</a></li>
</ul>
<p><em>当前<code>Tomcat</code>以普通用户<code>tomcat</code>身份运行</em></p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>将<code>Jenkins.war</code>文件放置于<code>Tomcat webapps</code>目录下（<em>注意：设置<code>.war</code>文件的属主为<code>tomcat</code></em>）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/opt/apache-tomcat-9.0.27/webapps</span><br></pre></td></tr></table></figure>
<p>登录地址<code>localhost:8080/jenkins</code>，即可启动<code>Jenkins</code></p>
<p><em><code>Tomcat</code>会在<code>webapps</code>目录下自动解压<code>Jenkins.war</code>，生成一个<code>jenkins</code>文件夹</em></p>
<p>进入<code>Jenkins</code>页面后，修改<code>Manage Jenkins -&gt; Configure System -&gt; Jenkins Location</code>，修改<code>Jenkins URL</code>为相应的地址（<em>登录地址</em>），同时修改<code>GitLab</code>中<code>WebHook</code>地址</p>
<h2 id="Jenkins升级"><a href="#Jenkins升级" class="headerlink" title="Jenkins升级"></a>Jenkins升级</h2><p>下载新版本的<code>Jenkins.war</code>文件后，放置于<code>webapps</code>目录下，并删除<code>webapps/jenkins</code>文件夹，重新浏览器登录即可</p>
<h2 id="修改主目录"><a href="#修改主目录" class="headerlink" title="修改主目录"></a>修改主目录</h2><p>如果<code>tomcat</code>以<code>root</code>用户运行，那么其相应的配置文件在<code>/root/.jenkins</code>目录下。修改<code>Jenkins</code>主目录在当前用户下 - <code>/home/zj/.jenkins</code></p>
<h3 id="Tomcat配置"><a href="#Tomcat配置" class="headerlink" title="Tomcat配置"></a>Tomcat配置</h3><p>进入<code>apache tomcat</code>安装地址，新建<code>/bin/setenv.sh</code>，设置环境变量<code>JENKINS_HOME</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat setenv.sh </span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">export JENKINS_HOME=/home/zj/.jenkins</span><br></pre></td></tr></table></figure>
<p><strong>注意<code>setenv.sh</code>的文件属性</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ chown tomcat:tomcat setenv.sh</span><br></pre></td></tr></table></figure>
<p>删除<code>Tomcat webapps</code>目录下的<code>jenkins</code>文件夹，重启<code>Tomcat</code></p>
<h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><p>重新进行浏览器登录，在<code>Manage Jenkins -&gt; Configure System</code>中查找<code>Home directory</code></p>
<p><img src="/imgs/jenkins-tomcat/jenkins-home-dir.png" alt></p>
<h2 id="环境变量设置"><a href="#环境变量设置" class="headerlink" title="环境变量设置"></a>环境变量设置</h2><p>由于<code>Tomcat</code>运行在其他普通用户下，所以还需要进一步将当前用户环境变量添加到<code>Jenkins</code>中，保证程序的执行（比如<code>node</code>）</p>
<p>参考：<a href="https://blog.csdn.net/u011296165/article/details/96110294" target="_blank" rel="noopener">jenkins执行脚本npm: command not found解决</a></p>
<p>进入<code>Manage Jenkins -&gt; Configure System</code>，在<code>Global properties</code>中选中<code>Environment variables</code></p>
<p><img src="/imgs/jenkins-tomcat/global-properties.png" alt></p>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins][GitLab][Hexo]新建Pipeline工程实现CI功能</title>
    <url>/posts/f80ec296.html</url>
    <content><![CDATA[<p>之前通过<code>Jenkins Freesstyle</code>工程实现了<code>Hexo</code>网站的<code>CI</code>部署，<code>Jenkins</code>还提供了<code>Pipeline</code>方式，能够更好的模块化构建过程</p><a id="more"></a>
<ol>
<li><code>Jenkins Pipeline</code>工程配置</li>
<li><code>GitLab WebHook</code>配置</li>
<li><code>Jenkinsfile</code>脚本编辑</li>
</ol>
<h2 id="Jenkins-Pipeline工程配置"><a href="#Jenkins-Pipeline工程配置" class="headerlink" title="Jenkins Pipeline工程配置"></a>Jenkins Pipeline工程配置</h2><p>新建工程<code>Hexo_Pipeline</code>，选择<code>Pipeline</code>类型</p>
<p><img src="/imgs/jenkins-gitlab-hexo-pipeline/project-pipeline.png" alt></p>
<p>在配置页面，类别<code>Build Triggers</code>中选择构建<code>GitLab</code></p>
<p><img src="/imgs/jenkins-gitlab-hexo-pipeline/build-trigger.png" alt></p>
<p>在类别<code>Pipeline</code>中定义<code>Jenkinsfile</code>脚本来自于<code>git</code>工程，并输入<code>GitLab</code>项目地址</p>
<p><img src="/imgs/jenkins-gitlab-hexo-pipeline/pipeline.png" alt></p>
<h2 id="GitLab-WebHook配置"><a href="#GitLab-WebHook配置" class="headerlink" title="GitLab WebHook配置"></a>GitLab WebHook配置</h2><p>在<code>GitLab</code>项目中选择<code>Settings -&gt; Integrations</code>，输入<code>WebHook URL</code></p>
<h2 id="Jenkinsfile脚本编辑"><a href="#Jenkinsfile脚本编辑" class="headerlink" title="Jenkinsfile脚本编辑"></a>Jenkinsfile脚本编辑</h2><p>在工程根目录新建文件<code>Jenkinsfile</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line"></span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(&apos;Install&apos;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                echo &apos;Installing..&apos;</span><br><span class="line">                sh &apos;scripts/install.sh&apos;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&apos;Build&apos;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                echo &apos;Building..&apos;</span><br><span class="line">                sh &apos;scripts/build.sh&apos;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&apos;Deploy&apos;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                echo &apos;Deploying....&apos;</span><br><span class="line">                sh &apos;scripts/deploy.sh&apos;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>分<code>3</code>个阶段实现<code>CI</code>，脚本放置在<code>scripts</code>目录下</p>
<p><strong>注意：每个阶段的起始地址均是根目录</strong></p>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins][GitLab][Hexo]新建Freestyle工程实现CI功能</title>
    <url>/posts/446d640.html</url>
    <content><![CDATA[<p>之前通过<code>Travis CI</code>实现持续部署<code>Hexo</code>项目到腾讯云服务器，参考<a href="https://hexo-guide.readthedocs.io/zh_CN/latest/third-service/[腾讯云][Travis%20CI]持续部署到云服务器.html" target="_blank" rel="noopener">[腾讯云][Travis CI]持续部署到云服务器</a></p><a id="more"></a>
<p>经过一段时间的使用，发现<code>Travis CI</code>传输文件到腾讯云服务器经常失败，所以打算在本地自建<code>Jenkins</code>，同时利用<code>GitLab</code>进行持续部署</p>
<p>实现步骤如下：</p>
<ol>
<li>关闭<code>Travis CI</code>触发器</li>
<li>导入<code>Hexo</code>相关项目到<code>GitLab</code></li>
<li>新建<code>Jenkins Freestyle</code>工程</li>
</ol>
<h2 id="关闭Travis-CI触发器"><a href="#关闭Travis-CI触发器" class="headerlink" title="关闭Travis CI触发器"></a>关闭Travis CI触发器</h2><p>在<code>Travis CI</code>项目页面的<code>Settings</code>中关闭构建命令即可</p>
<p><img src="/imgs/jenkins-gitlab-hexo-freestyle/travis-ci-settings.png" alt></p>
<h2 id="导入Hexo相关工程到GitLab"><a href="#导入Hexo相关工程到GitLab" class="headerlink" title="导入Hexo相关工程到GitLab"></a>导入Hexo相关工程到GitLab</h2><p>本地<code>GitLab</code>的安装和配置参考<a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/gitlab.html" target="_blank" rel="noopener">gitlab相关</a></p>
<p>将<code>Hexo</code>相关工程导入到本地<code>GitLab</code>，有助于加速<code>Jenkins</code>构建</p>
<h2 id="新建Jenkins-Freestyle工程"><a href="#新建Jenkins-Freestyle工程" class="headerlink" title="新建Jenkins Freestyle工程"></a>新建Jenkins Freestyle工程</h2><p><code>Jenkins</code>安装和配置参考<a href="https://container-automation.readthedocs.io/zh_CN/latest/jenkins/index.html" target="_blank" rel="noopener">Jenkins使用指南</a></p>
<p><code>Jenkins</code>中<code>GitLab</code>插件的配置以及<code>GitLab Webhook</code>的连接参考<a href="https://www.zhujian.tech/posts/6ff96ec3.html">[Jenkins][Gitlab]webhook连接</a></p>
<p>新建<code>Jenkins Freestyle</code>工程<code>hexo</code>，进入配置页面，构建脚本如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 安装</span><br><span class="line">cd ./blogs/</span><br><span class="line">git clone http://localhost:8800/zjzstu/hexo-theme-next.git themes/next</span><br><span class="line">git clone http://localhost:8800/zjzstu/theme-next-canvas-nest.git themes/next/source/lib/canvas-nest</span><br><span class="line">git clone http://localhost:8800/zjzstu/theme-next-algolia-instant-search.git themes/next/source/lib/algolia-instant-search</span><br><span class="line">git clone http://localhost:8800/zjzstu/theme-next-fancybox3.git themes/next/source/lib/fancybox</span><br><span class="line">npm install</span><br><span class="line"># 编译</span><br><span class="line">rm node_modules/kramed/lib/rules/inline.js</span><br><span class="line">cp inline.js node_modules/kramed/lib/rules/</span><br><span class="line">npm run gs</span><br><span class="line">hexo algolia</span><br><span class="line">## 集成</span><br><span class="line">mkdir upload_git</span><br><span class="line">cd upload_git</span><br><span class="line">git init</span><br><span class="line">cp -r ../public/* ./</span><br><span class="line">git add .</span><br><span class="line">git commit -m &quot;Update blogs&quot;</span><br><span class="line">git push --force git@148.70.xx.xx:/data/repositories/blogs.git master</span><br><span class="line">git push --force git@github.com:zjZSTU/zjzstu.github.io.git master</span><br><span class="line">git push --force git@git.dev.tencent.com:zjZSTU/zjZSTU.coding.me.git master</span><br></pre></td></tr></table></figure>
<ul>
<li>首先下载<code>GitLab</code>中的项目</li>
<li>然后编译生成<code>html</code>文件</li>
<li>最后上传到腾讯云服务器、<code>Gitlab和Coding</code></li>
</ul>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins][Freestyle]环境变量设置</title>
    <url>/posts/f2f14bee.html</url>
    <content><![CDATA[<p>想要在<code>Freestyle</code>工程中设置加密的环境变量，使用插件<code>Environment Injector</code>完成</p><a id="more"></a>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>首先下载/安装插件，进入<code>Manage Jenkins -&gt; Manage Plugins -&gt; Avaiable</code>，搜索插件<code>Environment Injector Plugin</code>并安装</p>
<p><img src="/imgs/jenkins-env/env-injector-plugin.png" alt></p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>新建<code>Freestyle</code>工程，在<code>Build Environment</code>类别中</p>
<h3 id="普通环境变量"><a href="#普通环境变量" class="headerlink" title="普通环境变量"></a>普通环境变量</h3><p>选中<code>Inject environment variables to the build process</code></p>
<p><img src="/imgs/jenkins-env/inject-env.png" alt></p>
<p>在<code>Properties Content</code>输入键值对，就是构建过程可使用的环境变量</p>
<p><img src="/imgs/jenkins-env/properties_content.png" alt></p>
<h3 id="加密环境变量"><a href="#加密环境变量" class="headerlink" title="加密环境变量"></a>加密环境变量</h3><p>选中<code>Inject passwords to the build as environment variables</code></p>
<p><img src="/imgs/jenkins-env/inject-passwd.png" alt></p>
<p>点击<code>Add</code>，输入<code>Name</code>和<code>Password</code>，就是构建过程中可使用的环境变量（已加密）</p>
<p><img src="/imgs/jenkins-env/job-passwd.png" alt></p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>在脚本中打印环境变量</p>
<p><img src="/imgs/jenkins-env/build-shell.png" alt></p>
<p><img src="/imgs/jenkins-env/console-output.png" alt></p>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins]Url is blocked: Requests to localhost are not allowed</title>
    <url>/posts/5d46d7f9.html</url>
    <content><![CDATA[<p><code>GitLab</code>默认不允许本机<code>URL</code>进行<code>WebHook</code>连接</p><p><img src="/imgs/jenkins-localhost/jenkins-localhost.png" alt></p><p>参考文章<a href="https://docs.gitlab.com/ee/security/webhooks.html" target="_blank" rel="noopener">Webhooks and insecure internal web services</a>，发现<code>GitLab</code>默认关闭了本机连接</p><a id="more"></a>


<p>参考文章<a href="https://www.cnblogs.com/zhongyuanzhao000/p/11379098.html" target="_blank" rel="noopener">解决 Url is blocked: Requests to the local network are not allowed</a></p>
<ol>
<li>登录管理员账户</li>
<li>进入<code>Configure GitLab -&gt; Settings -&gt; Network</code>，允许<code>local network</code>进行<code>web hooks and services</code>请求</li>
<li>保存修改</li>
</ol>
<p><img src="/imgs/jenkins-localhost/outbound-request.png" alt></p>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins]手动下载插件</title>
    <url>/posts/373e88b0.html</url>
    <content><![CDATA[<p>参考：<a href="https://www.jianshu.com/p/3b5ebe85c034" target="_blank" rel="noopener">jenkins安装插件的两种方式</a></p><p>使用<code>Jenkins</code>的插件页面进行下载太慢了，所以打算手动下载插件</p><a id="more"></a>

<h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><p>通过官网查找需要的插件：<a href="https://plugins.jenkins.io" target="_blank" rel="noopener">Plugins Index</a>。比如<a href="https://plugins.jenkins.io/gitlab-plugin" target="_blank" rel="noopener">Gitlab</a></p>
<p><img src="/imgs/jenkins-plugin/jenkins-plugin-gitlab.png" alt></p>
<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>进入下载页面</p>
<p><img src="/imgs/jenkins-plugin/gitlab-archives.png" alt></p>
<p>得到最新的插件文件<code>gitlab-plugin.hpi</code></p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>进入<code>Manage Jenkins -&gt; Manage Plugins -&gt; Advanced</code>，在<code>Upload Plugin</code>中上传插件</p>
<p><img src="/imgs/jenkins-plugin/upload-plugin.png" alt></p>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins][Gitlab]webhook连接</title>
    <url>/posts/6ff96ec3.html</url>
    <content><![CDATA[<p>完成<code>Jenkins+GitLab</code>的连接。步骤如下：</p><ol>
<li>申请<code>gitlab</code>私有<code>token</code></li>
<li>安装<code>jenkins for gitlab</code>插件</li>
<li>在<code>jenkins</code>工程中配置<code>gitlab</code></li>
<li>在<code>gitlab</code>工程中配置<code>jenkins</code></li>
</ol><a id="more"></a>

<h2 id="申请gitlab私有token"><a href="#申请gitlab私有token" class="headerlink" title="申请gitlab私有token"></a>申请gitlab私有token</h2><p>进入<code>Gitlab Settings -&gt; Access Tokens</code>，输入<code>Name</code>，选择<code>api scopes</code>，生成私有访问<code>token</code></p>
<h2 id="安装jenkins-for-gitlab插件"><a href="#安装jenkins-for-gitlab插件" class="headerlink" title="安装jenkins for gitlab插件"></a>安装jenkins for gitlab插件</h2><p>进入<code>Manage Jenkins -&gt; Manage Plugins -&gt; Available</code>，选择<code>Gitlab</code>进行安装</p>
<p><img src="/imgs/jenkins-gitlab/gitlab-plugin.png" alt></p>
<h2 id="在jenkins工程中配置gitlab"><a href="#在jenkins工程中配置gitlab" class="headerlink" title="在jenkins工程中配置gitlab"></a>在jenkins工程中配置gitlab</h2><p>首先进行全局配置，进入<code>Manage Jenkins -&gt; Configure System</code>，输入<code>gitlab</code>主机<code>URL</code>和添加<code>GitLab</code>私有访问<code>token</code></p>
<p><img src="/imgs/jenkins-gitlab/jenkins-system-gitlab.png" alt></p>
<p>然后新建<code>Freestyle</code>工程，配置<code>gitlab</code>工程地址和触发器</p>
<p><img src="/imgs/jenkins-gitlab/jenkins-scm.png" alt></p>
<p><img src="/imgs/jenkins-gitlab/jenkins-trigger.png" alt></p>
<h2 id="在gitlab工程中配置jenkins"><a href="#在gitlab工程中配置jenkins" class="headerlink" title="在gitlab工程中配置jenkins"></a>在gitlab工程中配置jenkins</h2><p>在配置触发器时获取<code>WebHook URL</code>，在<code>gitlab</code>工程中进入<code>Settings -&gt; Integrations</code>，输入<code>URL</code>进行配置</p>
<p><img src="/imgs/jenkins-gitlab/gitlab-integrations.png" alt></p>
<p>完成配置后会在页面下方增加一个配置条目</p>
<p><img src="/imgs/jenkins-gitlab/gitlab-webhook.png" alt></p>
<p>点击<code>Test -&gt; Push events</code>，测试是否能够推送成功</p>
<h2 id="Hook-executed-successfully-but-returned-HTTP-404"><a href="#Hook-executed-successfully-but-returned-HTTP-404" class="headerlink" title="Hook executed successfully but returned HTTP 404"></a>Hook executed successfully but returned HTTP 404</h2><p>使用<code>localhost</code>进行登录，导致出现<code>404</code>错误，修改成局域网或者公网登录即可</p>
<h2 id="Hook-executed-successfully-but-returned-HTTP-403"><a href="#Hook-executed-successfully-but-returned-HTTP-403" class="headerlink" title="Hook executed successfully but returned HTTP 403"></a>Hook executed successfully but returned HTTP 403</h2><p>参考：<a href="https://www.cnblogs.com/chenglc/p/11174530.html" target="_blank" rel="noopener">Hook executed successfully but returned HTTP 403</a></p>
<p>在Jenkins进入<code>Manage Jenkins -&gt; Configure Global Security</code></p>
<ul>
<li>在<code>Access Control</code>类别下选中<code>Allow anonymous read access</code></li>
<li>取消<code>CSRF Protection</code>类别下的<code>Prevent Cross Site Request Forgery exploits</code></li>
</ul>
<p><img src="/imgs/jenkins-gitlab/access-control.png" alt></p>
<p><img src="/imgs/jenkins-gitlab/csrf-protection.png" alt></p>
<p>进入<code>Manage Jenkins -&gt; Gloabl System</code>，取消<code>Gitlab</code>类别下的<code>Enable authentication for &#39;/project&#39; end-point</code></p>
<p><img src="/imgs/jenkins-gitlab/gitlab-authentiation.png" alt></p>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins 更换镜像源</title>
    <url>/posts/9ff7f63d.html</url>
    <content><![CDATA[<p>更新<code>Jenkins</code>国内镜像源，加速插件下载。参考<a href="http://mirrors.jenkins-ci.org/status.html" target="_blank" rel="noopener">the status of Jenkins mirrors</a>，目前国内有<a href="https://mirrors.tuna.tsinghua.edu.cn/jenkins/" target="_blank" rel="noopener">清华镜像源</a></p><a id="more"></a>
<p>有两种配置方式</p>
<ol>
<li>文件配置</li>
<li>页面配置</li>
</ol>
<h2 id="文件配置"><a href="#文件配置" class="headerlink" title="文件配置"></a>文件配置</h2><p>修改文件<code>~/.jenkins/hudson.model.UpdateCenter.xml</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=&apos;1.1&apos; encoding=&apos;UTF-8&apos;?&gt;</span><br><span class="line">&lt;sites&gt;</span><br><span class="line">  &lt;site&gt;</span><br><span class="line">    &lt;id&gt;default&lt;/id&gt;</span><br><span class="line">    &lt;url&gt;https://updates.jenkins.io/update-center.json&lt;/url&gt;</span><br><span class="line">  &lt;/site&gt;</span><br><span class="line">&lt;/sites&gt;</span><br></pre></td></tr></table></figure>
<p>添加国内地址</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json</span><br></pre></td></tr></table></figure>
<p>重启应用即可</p>
<h2 id="界面配置"><a href="#界面配置" class="headerlink" title="界面配置"></a>界面配置</h2><p>参考<a href="https://blog.csdn.net/you227/article/details/81076032" target="_blank" rel="noopener">jenkins插件下载镜像加速</a>，进入<code>Manage Jenkins -&gt; Manage Plugins -&gt; Advanced</code>，修改<code>Update Site</code></p>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>This Jenkins instance appears to be offline</title>
    <url>/posts/6af1c833.html</url>
    <content><![CDATA[<h2 id="错误复现"><a href="#错误复现" class="headerlink" title="错误复现"></a>错误复现</h2><p>重新安装<code>jenkins</code>，输入安装命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ java -jar jenkins.war --httpPort=8080</span><br></pre></td></tr></table></figure><a id="more"></a>

<p>在浏览器输入<code>localhost:8080</code>打开界面，输入密码后页面显示如下错误</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">This Jenkins instance appears to be offline</span><br><span class="line">。。。</span><br></pre></td></tr></table></figure>
<p>查看运行日志</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-10-18 06:31:30.849+0000 [id=55]	INFO	hudson.util.Retrier#start: Calling the listener of the allowed exception &apos;connect timed out&apos; at the attempt #1 to do the action check updates server</span><br><span class="line">2019-10-18 06:31:30.851+0000 [id=55]	INFO	hudson.util.Retrier#start: Attempted the action check updates server for 1 time(s) with no success</span><br><span class="line">2019-10-18 06:31:30.851+0000 [id=55]	SEVERE	hudson.PluginManager#doCheckUpdatesServer: Error checking update sites for 1 attempt(s). Last exception was: SocketTimeoutException: connect timed out</span><br><span class="line">2019-10-18 06:31:30.853+0000 [id=55]	INFO	hudson.model.AsyncPeriodicWork$1#run: Finished Download metadata. 20,156 ms</span><br><span class="line">2019-10-18 06:31:31.539+0000 [id=28]	WARNING	hudson.model.UpdateCenter#updateDefaultSite: Upgrading Jenkins. Failed to update the default Update Site &apos;default&apos;. Plugin upgrades may fail.</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>问题在于<code>jenkins</code>无法正常升级</p>
<h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><p>参考：<a href="https://stackoverflow.com/questions/48726513/jenkins-2-89-3-this-jenkins-instance-appears-to-be-offline" target="_blank" rel="noopener">Jenkins 2.89.3 “This Jenkins instance appears to be offline”</a></p>
<p>修改文件<code>~/.jenkins/hudson.model.UpdateCenter.xml</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">&lt;url&gt;http://updates.jenkins.io/update-center.json&lt;/url&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>将<code>https</code>修改为<code>http</code>。重新启动后恢复正常，进入插件下载页面</p>
<p><img src="/imgs/jenkins-error/customize-jenkins.png" alt></p>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>今天你docker了吗?</title>
    <url>/posts/5c6c610b.html</url>
    <content><![CDATA[<p><img src="/imgs/docker/docker2.jpeg" alt></p><p><code>Docker</code>是近<code>10</code>年来最火的工具之一，从一接触<code>Docker</code>开始就被它的概念所吸引，小结<code>Docker</code>概念、使用以及相关工具</p><a id="more"></a>

<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>参考：<a href="https://containerization-automation.readthedocs.io/zh_CN/latest/docker/basic/[%E8%AF%91]docker%E6%A6%82%E8%BF%B0/" target="_blank" rel="noopener">[译]docker概述</a></p>
<blockquote>
<p><code>Docker</code>是一个开发、发布和运行应用程序的开放平台，提供了在松散隔离的环境（称为容器）中打包和运行应用程序的能力。利用<code>Docker</code>可以将应用程序与基础架构分离，能够统一应用程序运行环境，保证快速的发布、测试和部署</p>
</blockquote>
<p>相比于<code>VMWare</code>独立运行完整的操作系统，<code>Docker</code>容器共享主机内核，其实现占用更少的内存，不过因此在<code>Linux</code>系统上的<code>Docker</code>容器无法运行<code>Windows</code>系统</p>
<h2 id="用途"><a href="#用途" class="headerlink" title="用途"></a>用途</h2><p><code>Docker</code>提供了在多平台（<code>Linux/Windows/IOS</code>）下的运行程序，但是最主要的还是基于<code>Linux</code>系统的操作。我在<code>Ubuntu</code>系统上面主要利用<code>Docker</code>进行两个方面的使用</p>
<ol>
<li>运行<code>GUI</code>应用</li>
<li>统一开发环境</li>
</ol>
<h3 id="运行GUI应用"><a href="#运行GUI应用" class="headerlink" title="运行GUI应用"></a>运行GUI应用</h3><p>通过<code>Docker</code>安装<code>GUI</code>应用，能够隔离各个运行环境，避免依赖冲突和依赖爆炸，并且有利于快速移植和部署</p>
<p>当前已实现的<code>Docker GUI</code>应用，包括<code>wechat/qq/wps/thunder</code>等等</p>
<ul>
<li><a href="https://containerization-automation.readthedocs.io/zh_CN/latest/docker/gui/[Docker]GUI%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/" target="_blank" rel="noopener">可视化运行</a></li>
<li><a href="https://github.com/zjZSTU/Containerization-Automation/tree/master/dockerfiles" target="_blank" rel="noopener">Containerization-Automation/dockerfiles/</a></li>
</ul>
<h3 id="统一开发环境"><a href="#统一开发环境" class="headerlink" title="统一开发环境"></a>统一开发环境</h3><p>通过<code>Docker</code>配置开发环境，能够保证开发、测试和发布的一致性，并且能够加速产品的移植和部署</p>
<h2 id="管理"><a href="#管理" class="headerlink" title="管理"></a>管理</h2><p>越来越多的容器运行在系统上，除了通过<code>docker-cli</code>进行直接管理外，还有一些工具可以进行容器编排</p>
<ul>
<li><code>Docker Compose</code>：定义和运行多容器的<code>Docker</code>工具</li>
<li><code>Docker Swarm</code>：<code>Docker</code>官方提供的容器集群管理工具，其主要作用是把若干台<code>Docker</code>主机抽象为一个整体，并且通过一个入口统一管理这些<code>Docker</code>主机上的各种<code>Docker</code>资源</li>
<li><code>K8S</code>：基于容器的集群管理平台，全称是<code>kubernetes</code></li>
</ul>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>使用<code>Docker</code>快<code>1</code>个半月了，花费了不少时间学习<code>Docker</code>容器的制作，后续还需要继续了解容器编排工具的使用</p>
<p>随着对<code>Docker</code>学习的深入，更加坚信这项工具对于软件开发的用处。未来的<code>Docker</code>会成为基础工具，类似<code>Linux</code>系统一样，加速信息服务在各个领域的应用</p>
<ul>
<li><a href="https://containerization-automation.readthedocs.io/zh_CN/latest/docker/basic/[%E8%AF%91]docker%E6%A6%82%E8%BF%B0/" target="_blank" rel="noopener">docker使用指南</a></li>
<li><a href="https://github.com/zjZSTU/Containerization-Automation" target="_blank" rel="noopener">zjZSTU/Containerization-Automation</a></li>
</ul>
]]></content>
      <categories>
        <category>随笔</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>如何编写好的README</title>
    <url>/posts/79f69ebe.html</url>
    <content><![CDATA[<p>在<code>github</code>上了上传了许多仓库，如何更好的管理、使用这些仓库，其中关键的一点在于<code>README</code>的编写。<code>README</code>的目的是向使用者展示仓库的使用方法、来历以及未来的进展。越来越重视写好一个<code>REAMDE</code>，<em>优秀的工程不一定有一个好的<code>README</code>，但是不好的<code>REAMDE</code>一定不是一个优秀的工程</em></p><a id="more"></a>
<p>关于这个问题在网上也有许多讨论：<a href="https://www.zhihu.com/question/29100816" target="_blank" rel="noopener">如何写好Github中的readme？</a>。当前主要参考了一个关于如何编写标准<code>README</code>的<code>github</code>仓库：<a href="https://github.com/RichardLitt/standard-readme" target="_blank" rel="noopener">RichardLitt/standard-readme</a></p>
<h2 id="内容列表"><a href="#内容列表" class="headerlink" title="内容列表"></a>内容列表</h2><p>下面首先讲解<code>standard-readme</code>提供了<code>README</code>文件编写规范，并结合网上讨论进行相应的调整，然后使用<code>README</code>生成器<code>yo</code>，最后编写一些适应不同场景的<code>README</code>模板</p>
<ul>
<li><a href="#规范">规范</a></li>
<li><a href="#自定义">自定义</a><ul>
<li><a href="#中英文">中英文</a></li>
<li><a href="#徽章">徽章</a></li>
<li><a href="#版本更新日志">版本更新日志</a></li>
<li><a href="#待办事项">待办事项</a></li>
<li><a href="#参与贡献方式">参与贡献方式</a></li>
<li><a href="#完整内容列表">完整内容列表</a></li>
</ul>
</li>
<li><a href="#生成器">生成器</a></li>
<li><a href="#模板">模板</a></li>
</ul>
<h2 id="规范"><a href="#规范" class="headerlink" title="规范"></a>规范</h2><p><code>standard-readme</code>提供了一个编写规范，原文和翻译如下</p>
<ul>
<li>原文：<a href="https://github.com/RichardLitt/standard-readme/blob/master/spec.md" target="_blank" rel="noopener">Specification</a></li>
<li>翻译：<a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/readme/[%E8%AF%91]%E8%A7%84%E8%8C%83/" target="_blank" rel="noopener">[译]规范</a></li>
</ul>
<p>里面提出了<code>README</code>的章节列表：</p>
<ul>
<li>标题（<code>Title</code>，必须）</li>
<li>横幅（<code>Banner</code>，可选）</li>
<li>徽章（<code>Badges</code>，可选）</li>
<li>简短说明（<code>Short Description</code>，必须）</li>
<li>详细描述（<code>Long Description</code>，可选）</li>
<li>内容列表（<code>Table of Contents</code>，必须）</li>
<li>安全（<code>Security</code>，可选）</li>
<li>背景（<code>Background</code>，可选）</li>
<li>安装（<code>Install</code>，默认必须，对文档仓库而言可选）</li>
<li>用法（<code>Usage</code>，默认是必须的，对于文档仓库而言是可选的）</li>
<li>附加内容（<code>Extra Sections</code>，可选）</li>
<li>应用编程接口（<code>API</code>，可选）</li>
<li>主要维护人员（<code>Maintainers</code>，可选）</li>
<li>致谢（<code>Thanks</code>，可选）</li>
<li>参与贡献方式（<code>Contributing</code>，必须）</li>
<li>许可证（<code>License</code>，必须）</li>
</ul>
<p>从上到下按需实现相应章节内容，其中横幅指的是仓库<code>logo</code>，内容列表指的是后续章节标题，而不是工程架构</p>
<h3 id="横幅"><a href="#横幅" class="headerlink" title="横幅"></a>横幅</h3><p>网上有很多在线设计<code>logo</code>的网站，不过下载是要收费的</p>
<p>找了一个免费的<code>logo</code>设计网站：<a href="https://www.logoly.pro/" target="_blank" rel="noopener">logoly</a></p>
<h3 id="协议"><a href="#协议" class="headerlink" title="协议"></a>协议</h3><p>参考<a href="https://help.github.com/en/articles/adding-a-license-to-a-repository" target="_blank" rel="noopener">Adding a license to a repository</a></p>
<p>可以在线添加新文件，输入文件名为<code>LICENSE</code>或<code>LICENSE.md</code>，选择一个<code>license</code>模板，预览后提交即可</p>
<p>如果要更换协议，直接删除新建一个即可</p>
<h2 id="自定义"><a href="#自定义" class="headerlink" title="自定义"></a>自定义</h2><p><code>standard-readme</code>提供了相对完整的<code>README</code>章节架构，结合网上讨论和实际使用经验，再增加以下<code>4</code>个章节：</p>
<ul>
<li>中英文</li>
<li>徽章</li>
<li>版本更新日志</li>
<li>待办事项</li>
</ul>
<p>并更新章节参与贡献方式（<code>Contributing</code>）</p>
<h3 id="中英文"><a href="#中英文" class="headerlink" title="中英文"></a>中英文</h3><ul>
<li>状态：默认是必须的，对于文档仓库而言是可选的</li>
<li>必要条件：<ul>
<li><code>None</code></li>
</ul>
</li>
<li>建议：<ul>
<li>准备中英文两份<code>README</code>，相互之间可跳转</li>
<li><code>README.md</code>为英文内容，<code>README.zh-CN.md</code>为中文内容</li>
<li>放置在徽章之后，简短说明之前</li>
</ul>
</li>
</ul>
<h3 id="徽章"><a href="#徽章" class="headerlink" title="徽章"></a>徽章</h3><ul>
<li>状态：可选</li>
<li>必要条件：<ul>
<li>标题为徽章</li>
</ul>
</li>
<li>建议：<ul>
<li>使用<a href="http://shields.io/" target="_blank" rel="noopener">http://shields.io</a>或类似服务创建和托管图像</li>
</ul>
</li>
</ul>
<p>规范中已经提到了一个徽章章节，里面添加的是仓库编写、部署过程中使用的工具、规范等相应的徽章，而本章节在于给出自己仓库的专属徽章</p>
<p>徽章生成参考<a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/readme/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BE%BD%E7%AB%A0/" target="_blank" rel="noopener">自定义徽章</a>；章节内容参考<a href="https://github.com/RichardLitt/standard-readme#badge" target="_blank" rel="noopener">RichardLitt/standard-readme
</a></p>
<h3 id="版本更新日志"><a href="#版本更新日志" class="headerlink" title="版本更新日志"></a>版本更新日志</h3><ul>
<li>状态：可选</li>
<li>必要条件：<ul>
<li>使用<code>git</code>进行版本管理</li>
</ul>
</li>
<li>建议：<ul>
<li>基于<a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/message/Conventional%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/" target="_blank" rel="noopener">Conventional提交规范</a>和<a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/version/[SEMVER]%E8%AF%AD%E4%B9%89%E7%89%88%E6%9C%AC%E8%A7%84%E8%8C%83/" target="_blank" rel="noopener">[SEMVER]语义版本规范</a>进行版本提交</li>
<li>使用<a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/version/[standard-version]%E7%89%88%E6%9C%AC%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8F%8ACHANGELOG%E7%94%9F%E6%88%90/" target="_blank" rel="noopener">standard-version</a>进行<code>CHANGELOG</code>生成</li>
<li>链接到本地仓库的<code>CHANGELOG</code>文件</li>
</ul>
</li>
</ul>
<h3 id="待办事项"><a href="#待办事项" class="headerlink" title="待办事项"></a>待办事项</h3><ul>
<li>状态：可选</li>
<li>必要条件：<ul>
<li><code>None</code></li>
</ul>
</li>
<li>建议：<ul>
<li>列出后续待完成的事项</li>
<li>按实现顺序从上到下排列</li>
</ul>
</li>
</ul>
<h3 id="参与贡献方式"><a href="#参与贡献方式" class="headerlink" title="参与贡献方式"></a>参与贡献方式</h3><p>在参与贡献方式章节中应该明确是否允许合并请求，并给出进行版本管理的相应规范，比如</p>
<ul>
<li><a href="https://www.conventionalcommits.org/en/v1.0.0-beta.4/" target="_blank" rel="noopener">GIT提交规范</a></li>
<li><a href="https://semver.org/lang/zh-CN/" target="_blank" rel="noopener">语义版本规范</a></li>
<li><a href="https://github.com/RichardLitt/standard-readme" target="_blank" rel="noopener">README编辑规范</a></li>
</ul>
<h3 id="完整内容列表"><a href="#完整内容列表" class="headerlink" title="完整内容列表"></a>完整内容列表</h3><p>综上所述，完整的内容列表如下：</p>
<ul>
<li>标题（<code>Title</code>，必须）</li>
<li>横幅（<code>Banner</code>，可选）</li>
<li>徽章（<code>Badges</code>，可选）</li>
<li>中英文(<code>Chinese and English</code>，默认是必须的，对于文档仓库而言是可选的)</li>
<li>简短说明（<code>Short Description</code>，必须）</li>
<li>详细描述（<code>Long Description</code>，可选）</li>
<li>内容列表（<code>Table of Contents</code>，必须）</li>
<li>安全（<code>Security</code>，可选）</li>
<li>背景（<code>Background</code>，可选）</li>
<li>徽章（<code>Badge</code>，可选）</li>
<li>安装（<code>Install</code>，默认必须，对文档仓库而言可选）</li>
<li>用法（<code>Usage</code>，默认是必须的，对于文档仓库而言是可选的）</li>
<li>附加内容（<code>Extra Sections</code>，可选）</li>
<li>应用编程接口（<code>API</code>，可选）</li>
<li>版本更新日志（<code>CHANGELOG</code>，可选）</li>
<li>待办事项（<code>TODO</code>，可选）</li>
<li>主要维护人员（<code>Maintainers</code>，可选）</li>
<li>致谢（<code>Thanks</code>，可选）</li>
<li>参与贡献方式（<code>Contributing</code>，必须）</li>
<li>许可证（<code>License</code>，必须）</li>
</ul>
<h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h2><p>参考：<a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/readme/readme%E7%94%9F%E6%88%90%E5%99%A8/" target="_blank" rel="noopener">README生成器</a></p>
<h2 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h2><p>参考：</p>
<p><a href="https://github.com/kylelobo/The-Documentation-Compendium/tree/master/en/README_TEMPLATES" target="_blank" rel="noopener">README_TEMPLATES/</a></p>
<p><a href="https://github.com/RichardLitt/standard-readme/tree/master/example-readmes" target="_blank" rel="noopener">example-readmes</a></p>
<p>以仓库<a href="https://github.com/zjZSTU/PyNet" target="_blank" rel="noopener">zjZSTU/PyNet</a>为例，生成不同适用范围的自定义模板。<code>README</code>模板地址：<a href="https://github.com/zjZSTU/git-guide/tree/master/docs/source/readme/templates" target="_blank" rel="noopener">templates</a></p>
<h3 id="最小README"><a href="#最小README" class="headerlink" title="最小README"></a>最小README</h3><p>建立一个最简单基本的<code>README</code>，仅包含必须的章节内容，参考<a href="https://github.com/zjZSTU/git-guide/blob/master/docs/source/readme/templates/MINIMAL_README.md" target="_blank" rel="noopener">MINIMAL_README.md</a></p>
<ul>
<li>标题（<code>Title</code>，必须）</li>
<li>中英文(<code>Chinese and English</code>，默认是必须的，对于文档仓库而言是可选的)</li>
<li>简短说明（<code>Short Description</code>，必须）</li>
<li>内容列表（<code>Table of Contents</code>，必须）</li>
<li>安装（<code>Install</code>，默认必须，对文档仓库而言可选）</li>
<li>用法（<code>Usage</code>，默认是必须的，对于文档仓库而言是可选的）</li>
<li>参与贡献方式（<code>Contributing</code>，必须）</li>
<li>许可证（<code>License</code>，必须）</li>
</ul>
<h3 id="标准README"><a href="#标准README" class="headerlink" title="标准README"></a>标准README</h3><p>完整的实现所有章节内容，参考<a href="https://github.com/zjZSTU/git-guide/blob/master/docs/source/readme/templates/STANDARD_README.md" target="_blank" rel="noopener">STANDARD_README.md</a></p>
]]></content>
      <categories>
        <category>随笔</category>
        <category>版本控制</category>
        <category>规范</category>
      </categories>
      <tags>
        <tag>readme</tag>
      </tags>
  </entry>
  <entry>
    <title>github+gitee</title>
    <url>/posts/ee6c5a93.html</url>
    <content><![CDATA[<p>今年以来一直把代码、文档和工程上传到<code>github</code>进行版本管理，效果很好，通过<code>github</code>可以完成很多自动化任务，比如<code>Travis-CI、Readthedocs</code>等工具的使用</p><a id="more"></a>
<p>不过最近一段时间<code>vpn</code>时不时的失效，这时候经常上不了<code>github</code>以及<code>readthedocs</code>，所以还是想着找一个国内仓库进行备份</p>
<p>国内的<code>git</code>仓库用过腾讯的<code>coding</code>和<code>oschina</code>的<code>gitee</code>，感觉<code>gitee</code>的布局更加<code>github</code>一些，所以打算在<a href="https://github.com" target="_blank" rel="noopener">github</a>和<a href="https://gitee.com" target="_blank" rel="noopener">gitee</a>上进行双重备份</p>
<p>如何进行双重备份的关键在于本地<code>git</code>仓库的<code>CONFIG</code>文件配置，参考<a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/advanced/%E6%8E%A8%E9%80%81%E5%88%B0%E5%A4%9A%E4%B8%AA%E8%BF%9C%E7%A8%8B%E6%89%98%E7%AE%A1%E6%9C%8D%E5%8A%A1%E5%99%A8/" target="_blank" rel="noopener">推送到多个远程托管服务器</a>和<a href="https://www.liaoxuefeng.com/wiki/896043488029600/1163625339727712" target="_blank" rel="noopener">使用码云</a></p>
<p>个人主页：</p>
<ul>
<li><a href="https://gitee.com/zjZSTU" target="_blank" rel="noopener">https://gitee.com/zjZSTU</a></li>
<li><a href="https://github.com/zjZSTU" target="_blank" rel="noopener">https://github.com/zjZSTU</a></li>
</ul>
]]></content>
      <categories>
        <category>随笔</category>
        <category>版本控制</category>
        <category>托管平台</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>coding</tag>
        <tag>gitee</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]欢迎回到C++(现代C++)</title>
    <url>/posts/be56146c.html</url>
    <content><![CDATA[<p>之前写的C++代码一直都是C语言风格，而C++标准经过多次的迭代后，已经拥有了一套自己的风格和实现。微软的这篇文档很好的反映了现代C++的精髓，原文地址：<a href="https://docs.microsoft.com/en-us/cpp/cpp/welcome-back-to-cpp-modern-cpp?view=vs-2019" target="_blank" rel="noopener">Welcome Back to C++ (Modern C++)</a></p><a id="more"></a>
<h2 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h2><blockquote>
<p>C++ is one of the most widely used programming languages in the world. Well-written C++ programs are fast and efficient. The language is more flexible than other languages because you can use it to create a wide range of apps—from fun and exciting games, to high-performance scientific software, to device drivers, embedded programs, and Windows client apps. For more than 20 years, C++ has been used to solve problems like these and many others. What you might not know is that an increasing number of C++ programmers have folded up the dowdy C-style programming of yesterday and have donned modern C++ instead.</p>
</blockquote>
<p>C++是世界上应用最广泛的编程语言之一。写得好的C++程序是快速和高效的。该语言比其他语言更灵活，因为您可以使用它创建各种各样的应用程序，从有趣和刺激的游戏，到高性能的科学软件，再到设备驱动程序、嵌入式程序和Windows客户端应用程序。20多年来，C++已经被用来解决这些问题以及许多其他问题。你可能不知道的是，越来越多的C++程序员已经折叠了昨天过时的C风格编程，并使用了现代C++取代</p>
<blockquote>
<p>One of the original requirements for C++ was backward compatibility with the C language. Since then, C++ has evolved through several iterations—C with Classes, then the original C++ language specification, and then the many subsequent enhancements. Because of this heritage, C++ is often referred to as a multi-paradigm programming language. In C++, you can do purely procedural C-style programming that involves raw pointers, arrays, null-terminated character strings, custom data structures, and other features that may enable great performance but can also spawn bugs and complexity. Because C-style programming is fraught with perils like these, one of the founding goals for C++ was to make programs both type-safe and easier to write, extend, and maintain. Early on, C++ embraced programming paradigms such as object-oriented programming. Over the years, features have been added to the language, together with highly-tested standard libraries of data structures and algorithms. It’s these additions that have made the modern C++ style possible.</p>
</blockquote>
<p>对C++的最初要求之一是与C语言的向后兼容性。从那时起，C++已经经过几次迭代 — 最开始的C++可以称为C与类，然后是最初的C++语言规范，以及后续许多增强。由于这个传统，C++经常被称为多范式编程语言。在C++中，您可以进行纯程序化的C风格编程，包括原始指针、数组、空终止字符串、自定义数据结构和其他可以使性能良好的特征，但也可能导致错误和复杂性。因为C风格的编程充满了这样的危险，C++的一个创始目标是使程序既安全又容易编写、扩展和维护。早期，C++采用了面向对象编程等编程范例。多年来，该语言增加了一些特性，以及经过高度测试的数据结构和算法标准库。正是这些添加物使现代C++风格成为可能</p>
<blockquote>
<p>Modern C++ emphasizes:</p>
<ul>
<li>Stack-based scope instead of heap or static global scope.</li>
<li>Auto type inference instead of explicit type names.</li>
<li>Smart pointers instead of raw pointers.</li>
<li><code>std::string</code> and <code>std::wstring</code> types (see <a href="https://docs.microsoft.com/en-us/cpp/standard-library/string?view=vs-2019" target="_blank" rel="noopener">\<string\></string\></a>) instead of raw <code>char[]</code> arrays.</li>
<li><a href="https://docs.microsoft.com/en-us/cpp/standard-library/cpp-standard-library-header-files?view=vs-2019" target="_blank" rel="noopener">C++ Standard Library</a> containers like <code>vector</code>, <code>list</code>, and <code>map</code> instead of raw arrays or custom containers. See <a href="https://docs.microsoft.com/en-us/cpp/standard-library/vector?view=vs-2019" target="_blank" rel="noopener">\<vector\></vector\></a>, <a href="https://docs.microsoft.com/en-us/cpp/standard-library/list?view=vs-2019" target="_blank" rel="noopener">\<list\></list\></a>, and <a href="https://docs.microsoft.com/en-us/cpp/standard-library/map?view=vs-2019" target="_blank" rel="noopener">\<map\></map\></a>.</li>
<li>C++ Standard Library <a href="https://docs.microsoft.com/en-us/cpp/standard-library/algorithm?view=vs-2019" target="_blank" rel="noopener">algorithms</a> instead of manually coded ones.</li>
<li>Exceptions, to report and handle error conditions.</li>
<li>Lock-free inter-thread communication using C++ Standard Library <code>std::atomic&lt;&gt;</code> (see <a href="https://docs.microsoft.com/en-us/cpp/standard-library/atomic?view=vs-2019" target="_blank" rel="noopener">\<atomic\></atomic\></a>) instead of other inter-thread communication mechanisms.</li>
<li>Inline <a href="https://docs.microsoft.com/en-us/cpp/cpp/lambda-expressions-in-cpp?view=vs-2019" target="_blank" rel="noopener">lambda functions</a> instead of small functions implemented separately.</li>
<li>Range-based for loops to write more robust loops that work with arrays, C++ Standard Library containers, and Windows Runtime collections in the form <code>for ( for-range-declaration : expression )</code>. This is part of the Core Language support. For more information, see <a href="https://docs.microsoft.com/en-us/cpp/cpp/range-based-for-statement-cpp?view=vs-2019" target="_blank" rel="noopener">Range-based for Statement (C++)</a>.</li>
</ul>
</blockquote>
<p>现代C++强调：</p>
<ul>
<li>基于栈的作用域，而不是堆或静态全局作用域</li>
<li>自动类型推断而不是显式类型名</li>
<li>智能指针而不是原始指针</li>
<li><code>std::string</code>和<code>std::wstring</code>类型（参见<code>&lt;string&gt;</code>）而不是原始<code>char[]</code>数组</li>
<li>C++标准库容器，如<code>vector</code>、<code>list</code>和<code>map</code>，而不是原始数组或自定义容器。请参见<code>&lt;vector&gt;</code>、<code>&lt;list&gt;</code>和<code>&lt;map&gt;</code></li>
<li>C++标准库算法，而不是手工编写的算法</li>
<li>通过异常报告和处理错误情况</li>
<li>使用C++标准库<code>std::atomic&lt;&gt;</code>进行无锁线程间通信（参见<code>&lt;atomic&gt;</code>）而不是其他线程间通信机制</li>
<li>内联lambda函数而不是单独实现的小函数</li>
<li>使用基于范围的循环编写更健壮的循环代码，这些循环使用数组、C++标准库容器和Windows运行时集合<code>for ( for-range-declaration : expression )</code>。这是核心语言支持的一部分。有关更多信息，请参见基于范围的语句（C++）</li>
</ul>
<blockquote>
<p>The C++ language itself has also evolved. Compare the following code snippets. This one shows how things used to be in C++:</p>
</blockquote>
<p>C++语言本身也有了发展。比较以下代码段。这个例子显示了C++中的事物是如何使用的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;vector&gt;</span><br><span class="line"></span><br><span class="line">void f()</span><br><span class="line">&#123;</span><br><span class="line">    // Assume circle and shape are user-defined types</span><br><span class="line">    circle* p = new circle( 42 );</span><br><span class="line">    vector&lt;shape*&gt; v = load_shapes();</span><br><span class="line"></span><br><span class="line">    for( vector&lt;circle*&gt;::iterator i = v.begin(); i != v.end(); ++i ) &#123;</span><br><span class="line">        if( *i &amp;&amp; **i == *p )</span><br><span class="line">            cout &lt;&lt; **i &lt;&lt; &quot; is a match\n&quot;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // CAUTION: If v&apos;s pointers own the objects, then you</span><br><span class="line">    // must delete them all before v goes out of scope.</span><br><span class="line">    // If v&apos;s pointers do not own the objects, and you delete</span><br><span class="line">    // them here, any code that tries to dereference copies</span><br><span class="line">    // of the pointers will cause null pointer exceptions.</span><br><span class="line">    for( vector&lt;circle*&gt;::iterator i = v.begin();</span><br><span class="line">            i != v.end(); ++i ) &#123;</span><br><span class="line">        delete *i; // not exception safe</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // Don&apos;t forget to delete this, too.</span><br><span class="line">    delete p;</span><br><span class="line">&#125; // end f()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Here’s how the same thing is accomplished in modern C++:</p>
</blockquote>
<p>下面是如何在现代C++中实现同样的事情：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;memory&gt;</span><br><span class="line">#include &lt;vector&gt;</span><br><span class="line"></span><br><span class="line">void f()</span><br><span class="line">&#123;</span><br><span class="line">    // ...</span><br><span class="line">    auto p = make_shared&lt;circle&gt;( 42 );</span><br><span class="line">    vector&lt;shared_ptr&lt;shape&gt;&gt; v = load_shapes();</span><br><span class="line"></span><br><span class="line">    for( auto&amp; s : v )</span><br><span class="line">    &#123;</span><br><span class="line">        if( s &amp;&amp; *s == *p )</span><br><span class="line">        &#123;</span><br><span class="line">            cout &lt;&lt; *s &lt;&lt; &quot; is a match\n&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>In modern C++, you don’t have to use new/delete or explicit exception handling because you can use smart pointers instead. When you use the <strong>auto</strong> type deduction and <a href="https://docs.microsoft.com/en-us/cpp/cpp/lambda-expressions-in-cpp?view=vs-2019" target="_blank" rel="noopener">lambda function</a>, you can write code quicker, tighten it, and understand it better. And a range-based <strong>for</strong> loop is cleaner, easier to use, and less prone to unintended errors than a C-style <strong>for</strong> loop. You can use boilerplate together with minimal lines of code to write your app. And you can make that code exception-safe and memory-safe, and have no allocation/deallocation or error codes to deal with.</p>
</blockquote>
<p>在现代C++中，你不必使用<code>new/delete</code>或显式的异常处理，因为你可以使用智能指针来代替。当您使用<strong>auto</strong>类型推导和lambda函数时，您可以更快地编写代码，更加精简，并更好地理解它。与C样式的<strong>for</strong>循环相比，基于范围的<strong>for</strong>循环更干净、更容易使用，并且不容易出现意外错误。您可以使用样板文件和最少的代码行来编写应用程序。并且您可以使代码异常安全和内存安全，并且没有要处理的分配/释放或错误代码</p>
<blockquote>
<p>Modern C++ incorporates two kinds of polymorphism: compile-time, through templates, and run-time, through inheritance and virtualization. You can mix the two kinds of polymorphism to great effect. The C++ Standard Library template <code>shared_ptr</code> uses internal virtual methods to accomplish its apparently effortless type erasure. But don’t over-use virtualization for polymorphism when a template is the better choice. Templates can be very powerful.</p>
</blockquote>
<p>现代C++将两种多态性结合在一起：编译时间通过继承，以及运行时间通过虚拟化。您可以将这两种多态性混合到一起，以获得巨大的效果。C++标准库模板<code>shared_ptr</code>使用内部虚拟方法来完成其显然毫不费力的类型擦除。但是当模板是更好的选择时，不要过度使用虚拟化来实现多态性。模板可能非常强大</p>
<blockquote>
<p>If you’re coming to C++ from another language, especially from a managed language in which most of the types are reference types and very few are value types, know that C++ classes are value types by default. But you can specify them as reference types to enable polymorphic behavior that supports object-oriented programming. A helpful perspective: value types are more about memory and layout control, reference types are more about base classes and virtual functions to support polymorphism. By default, value types are copyable—they each have a copy constructor and a copy assignment operator. When you specify a reference type, make the class non-copyable—disable the copy constructor and copy assignment operator—and use a virtual destructor, which supports the polymorphism. Value types are also about the contents, which, when they are copied, give you two independent values that you can modify separately. But reference types are about identity—what kind of object it is—and for this reason are sometimes referred to as polymorphic types.</p>
</blockquote>
<p>如果您从另一种语言进入C++，特别是从大多数类型是引用类型且很少有值类型的托管语言中，需要知道默认情况下C++类是值类型的。但您可以将它们指定为引用类型，以启用支持面向对象编程的多态行为。一个有用的视角：值类型更多地是关于内存和布局控制，引用类型更多地是关于基类和支持多态性的虚拟函数。默认情况下，值类型是可复制的，它们都有一个复制构造函数和一个复制分配运算符。指定引用类型时，请使类不可复制 — 禁用复制构造函数和复制分配运算符，并使用支持多态性的虚拟析构函数。值类型也与内容有关，复制内容时，会为您提供两个独立的值，您可以分别修改这些值。但是引用类型是关于标识 — 它是什么类型的对象，因此有时被称为多态类型</p>
<blockquote>
<p>C++ is experiencing a renaissance because power is king again. Languages like Java and C# are good when programmer productivity is important, but they show their limitations when power and performance are paramount. For high efficiency and power, especially on devices that have limited hardware, nothing beats modern C++.</p>
</blockquote>
<p>C++正在经历复兴，因为能力再次成为国王。像Java和C#这样的语言在程序员的生产力很重要的时候是很好的，但是它们在功率和性能是最重要的时候显示出它们的局限性。对于高效率和功率，特别是在硬件有限的设备上，没有什么比现代C++更出色</p>
<blockquote>
<p>Not only the language is modern, the development tools are, too. Visual Studio makes all parts of the development cycle robust and efficient. It includes Application Lifecycle Management (ALM) tools, IDE enhancements like IntelliSense, tool-friendly mechanisms like XAML, and building, debugging, and many other tools.</p>
</blockquote>
<p>不仅语言是现代的，开发工具也是。Visual Studio使开发周期的所有部分都具有健壮性和高效性。它包括应用程序生命周期管理（ALM）工具、诸如IntelliSense之类的IDE增强、诸如XAML之类的工具友好机制以及构建、调试和许多其他工具</p>
<blockquote>
<p>The articles in this part of the documentation provide high-level guidelines and best practices for the most important features and techniques for writing modern C++ programs.</p>
</blockquote>
<p>文档的这一部分为编写现代C++程序最重要的特征和技术提供了高层次的指导和最佳实践。</p>
<blockquote>
<ul>
<li><a href="https://docs.microsoft.com/en-us/cpp/cpp/cpp-type-system-modern-cpp?view=vs-2019" target="_blank" rel="noopener">C++ Type System</a></li>
<li><a href="https://docs.microsoft.com/en-us/cpp/cpp/uniform-initialization-and-delegating-constructors?view=vs-2019" target="_blank" rel="noopener">Uniform Initialization and Delegating Constructors</a></li>
<li><a href="https://docs.microsoft.com/en-us/cpp/cpp/object-lifetime-and-resource-management-modern-cpp?view=vs-2019" target="_blank" rel="noopener">Object Lifetime And Resource Management</a></li>
<li><a href="https://docs.microsoft.com/en-us/cpp/cpp/objects-own-resources-raii?view=vs-2019" target="_blank" rel="noopener">Objects Own Resources (RAII)</a></li>
<li><a href="https://docs.microsoft.com/en-us/cpp/cpp/smart-pointers-modern-cpp?view=vs-2019" target="_blank" rel="noopener">Smart Pointers</a></li>
<li><a href="https://docs.microsoft.com/en-us/cpp/cpp/pimpl-for-compile-time-encapsulation-modern-cpp?view=vs-2019" target="_blank" rel="noopener">Pimpl For Compile-Time Encapsulation</a></li>
<li><a href="https://docs.microsoft.com/en-us/cpp/cpp/containers-modern-cpp?view=vs-2019" target="_blank" rel="noopener">Containers</a></li>
<li><a href="https://docs.microsoft.com/en-us/cpp/cpp/algorithms-modern-cpp?view=vs-2019" target="_blank" rel="noopener">Algorithms</a></li>
<li><a href="https://docs.microsoft.com/en-us/cpp/cpp/string-and-i-o-formatting-modern-cpp?view=vs-2019" target="_blank" rel="noopener">String and I/O Formatting (Modern C++)</a></li>
<li><a href="https://docs.microsoft.com/en-us/cpp/cpp/errors-and-exception-handling-modern-cpp?view=vs-2019" target="_blank" rel="noopener">Errors and Exception Handling</a></li>
<li><a href="https://docs.microsoft.com/en-us/cpp/cpp/portability-at-abi-boundaries-modern-cpp?view=vs-2019" target="_blank" rel="noopener">Portability At ABI Boundaries</a></li>
</ul>
</blockquote>
<ul>
<li>C++类型系统</li>
<li>统一初始化和委托构造器</li>
<li>对象生命周期和资源管理</li>
<li>对象拥有资源（RAII）</li>
<li>智能指针</li>
<li>用于编译时封装的Pimpl</li>
<li>容器</li>
<li>算法</li>
<li>字符串和I/O格式（现代C++）</li>
<li>错误和异常处理</li>
<li>ABI边界的可移植性</li>
</ul>
<blockquote>
<p>For more information, see the Stack Overflow article <a href="https://stackoverflow.com/questions/9299101/which-c-idioms-are-deprecated-in-c11" target="_blank" rel="noopener">Which C++ idioms are deprecated in C++11</a>.</p>
</blockquote>
<p>有关更多信息，请参见文章<code>Which C++ idioms are deprecated in C++11</code></p>
]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构-图5</title>
    <url>/posts/95d609b4.html</url>
    <content><![CDATA[<p>参考：《大话数据结构》第7章 图</p><p>学习路径如下：</p><ol>
<li><a href="https://github.com/zjZSTU/graph_algorithm" target="_blank" rel="noopener">图的基本定义</a></li>
<li><a href="https://www.zhujian.tech/posts/a1a1ab33.html">顶点/边/图的关系</a></li>
<li><a href="https://www.zhujian.tech/posts/7cb5ac81.html">图的存储结构</a></li>
<li><a href="https://www.zhujian.tech/posts/e2d13922.html">深度/广度优先遍历</a></li>
<li><a href="https://www.zhujian.tech/posts/95d609b4.html">最小生成树</a>（<em>本文学习内容</em>）</li>
</ol><a id="more"></a>


<p>完整工程：<a href="https://github.com/zjZSTU/GraphLib" target="_blank" rel="noopener">zjZSTU/GraphLib</a></p>
<h2 id="最小生成树"><a href="#最小生成树" class="headerlink" title="最小生成树"></a>最小生成树</h2><p>参考：<a href="https://www.zhujian.tech/posts/a1a1ab33.html#more">数据结构-图2</a></p>
<ul>
<li>最小生成树</li>
</ul>
<blockquote>
<p>给定无向图$G=(V,E)$，$(u,v)$代表连接顶点$u$和$v$的边，$w(u,v)$代表此边的权重，如果存在生成树$T$使得$w(T)$最小（<em>权值之和最小</em>），那么称$T$为最小生成树(<code>MST, Minimum Spanning Tree</code>)   </p>
</blockquote>
<p>有两种方式常用于最小生成树的创建，一是普里姆（<code>prim</code>）算法，二是克鲁斯卡尔（<code>kruscal</code>）算法</p>
<p><img src="/imgs/数据结构-图5/test_graph.png" alt></p>
<h2 id="普里姆算法"><a href="#普里姆算法" class="headerlink" title="普里姆算法"></a>普里姆算法</h2><blockquote>
<p>假设$N=(V,E)$是连通网，$TE$是$N$上最小生成树中边的集合。算法从$T=(U, TE), U={u_{0}}(u_{0}\in V), TE=\{\}$开始。重复执行下述操作：在所有$u\in U, v\in (V-U)$的边$(u,v)\in E$中找一条代价最小的边$(u_{0},v_{0})$并入集合$TE$，同时$v_{0}$并入$U$，直至$U=V$为止。此时$TE$中必有$n-1$条边，则$T=(V,TE)$为$N$的最小生成树</p>
</blockquote>
<ul>
<li>因为最小生成树包含连通网所有的顶点，所以从哪个顶点开始都可以</li>
<li>创建一维数组<code>lowcost</code>，表示边集<code>TE</code>的最小权值数组。数组下标表示顶点<ul>
<li>如果该顶点未加入最小生成树，则成员值表示该顶点的边权值，符合条件：所连接的另一个顶点在最小生成树中</li>
<li>如果已加入最小生成树，设置为<code>-1</code></li>
</ul>
</li>
<li>创建一维数组<code>adjvex</code>，表示最小生成树<code>T</code>的边集<code>TE</code><ul>
<li>数组下标表示顶点，成员值表示另一个顶点</li>
<li>两个顶点之间的边权值保存在<code>lowcost</code>对应下标中</li>
</ul>
</li>
</ul>
<p><code>Prim</code>算法对顶点进行展开，每次添加一个顶点到<code>MST</code>，难点在于如何找到符合条件的顶点：</p>
<ul>
<li>初始化时可以随机选择一个顶点加入<code>MST</code>（通常选<code>顶点0</code>）。遍历其他顶点<ul>
<li>如果其他顶点与顶点<code>0</code>存在边，则权值加入<code>lowcost</code>，<code>adjvex</code>对应下标值设置为<code>0</code>（表示顶点<code>0</code>）</li>
<li>如果其他顶点与顶点<code>0</code>不存在边，则<code>lowcost</code>对应下标设置为最大值，<code>adjvex</code>对应下标也设置为<code>0</code></li>
</ul>
</li>
<li>遍历<code>n-1</code>轮（<code>n</code>表示顶点数）<ul>
<li>每一轮都从<code>lowcost</code>中选择一条最小权值边（不包含值为<code>-1</code>的下标），将指定下标加入<code>MST</code>（<code>lowcost</code>对应下标值设置为<code>-1</code>）</li>
<li>遍历每次新加入最小生成树<code>T</code>的顶点所连接的边，如果符合条件（另一个顶点不再<code>T</code>中，通过判断<code>lowcost</code>对应下标值是否为<code>-1</code>），与<code>lowcost</code>相应位置权值进行比较，邻接顶点及其权值加入<code>adjvex</code>和<code>lowcost</code>中</li>
</ul>
</li>
</ul>
<h3 id="c-实现"><a href="#c-实现" class="headerlink" title="c++实现"></a>c++实现</h3><p>分别使用邻接矩阵和邻接表实现普里姆算法</p>
<h4 id="邻接矩阵"><a href="#邻接矩阵" class="headerlink" title="邻接矩阵"></a>邻接矩阵</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void AdjacencyMatrixUndirectedGraph::MiniSpanTree_Prim(MGraph G) &#123;</span><br><span class="line">    int min, i, j, k;</span><br><span class="line">    std::array&lt;int, MAXVEX&gt; adjvex = &#123;&#125;;</span><br><span class="line">    std::array&lt;int, MAXVEX&gt; lowcost = &#123;&#125;;</span><br><span class="line"></span><br><span class="line">    // 最先添加顶点0到MST中</span><br><span class="line">    // adjvex赋值为边的另一个顶点值， 如果顶点已在MST中，指定下标赋值为-1</span><br><span class="line">    int begin_vex = 0;</span><br><span class="line">    adjvex[begin_vex] = 0;</span><br><span class="line">    lowcost[begin_vex] = -1;</span><br><span class="line">    for (i = 1; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        lowcost[i] = G.arcs[0][i];</span><br><span class="line">        adjvex[i] = 0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    int weight = 0;</span><br><span class="line">    // 遍历n-1轮，得到另外的顶点</span><br><span class="line">    for (i = 1; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        min = GINFINITY;</span><br><span class="line">        // 遍历n-1次，搜索最小权值边</span><br><span class="line">        j = 1, k = 0;</span><br><span class="line">        while (j &lt; G.numVertexes) &#123;</span><br><span class="line">            if (lowcost[j] != -1 and lowcost[j] &lt; min) &#123;</span><br><span class="line">                min = lowcost[j];</span><br><span class="line">                k = j;</span><br><span class="line">            &#125;</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 输出最小权值边</span><br><span class="line">        printf(&quot;(%d, %d) %d\n&quot;, adjvex[k], k, lowcost[k]);</span><br><span class="line">        weight += lowcost[k];</span><br><span class="line">        // 顶点k已加入MST，lowcost赋值为-1</span><br><span class="line">        lowcost[k] = -1;</span><br><span class="line"></span><br><span class="line">        // 比较顶点k的边集和MST的最小权值边集，进行替换</span><br><span class="line">        for (j = 1; j &lt; G.numVertexes; j++) &#123;</span><br><span class="line">            if (k != j and lowcost[j] != -1 and G.arcs[k][j] &lt; lowcost[j]) &#123;</span><br><span class="line">                lowcost[j] = G.arcs[k][j];</span><br><span class="line">                adjvex[j] = k;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; &quot;最小权值为：&quot; &lt;&lt; weight &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="邻接表"><a href="#邻接表" class="headerlink" title="邻接表"></a>邻接表</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void AdjacencyTableUndirectedGraph::MiniSpanTree_Prim(GraphAdjList G) &#123;</span><br><span class="line">    int min, i, j, k;</span><br><span class="line">    EdgeNode *e;</span><br><span class="line">    std::array&lt;int, MAXVEX&gt; adjvex = &#123;&#125;;</span><br><span class="line">    std::array&lt;int, MAXVEX&gt; lowcost = &#123;&#125;;</span><br><span class="line"></span><br><span class="line">    // 初始化</span><br><span class="line">    for (i = 0; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        lowcost[i] = GINFINITY;</span><br><span class="line">        adjvex[i] = 0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 默认添加顶点0到MST</span><br><span class="line">    // adjvex赋值为边的另一个顶点值， 如果顶点已在MST中，指定下标赋值为-1</span><br><span class="line">    int begin_index = 0;</span><br><span class="line">    adjvex[begin_index] = 0;</span><br><span class="line">    lowcost[begin_index] = -1;</span><br><span class="line">    e = G.adjList[begin_index].firstEdge;</span><br><span class="line">    while (e != nullptr) &#123;</span><br><span class="line">        lowcost[e-&gt;adjvex] = e-&gt;weight;</span><br><span class="line">        adjvex[e-&gt;adjvex] = 0;</span><br><span class="line"></span><br><span class="line">        e = e-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    int weight = 0;</span><br><span class="line">    // 遍历n-1轮，得到另外的顶点</span><br><span class="line">    for (i = 1; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        min = GINFINITY;</span><br><span class="line">        // 遍历n-1次，搜索最小权值边</span><br><span class="line">        j = 1, k = 0;</span><br><span class="line">        while (j &lt; G.numVertexes) &#123;</span><br><span class="line">            if (lowcost[j] != -1 and lowcost[j] &lt; min) &#123;</span><br><span class="line">                min = lowcost[j];</span><br><span class="line">                k = j;</span><br><span class="line">            &#125;</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 输出最小权值边</span><br><span class="line">        printf(&quot;(%d, %d) %d\n&quot;, adjvex[k], k, lowcost[k]);</span><br><span class="line">        // 顶点k已加入MST，lowcost赋值为-1</span><br><span class="line">        weight += lowcost[k];</span><br><span class="line">        lowcost[k] = -1;</span><br><span class="line"></span><br><span class="line">        // 比较顶点k的边集和MST的最小权值边集</span><br><span class="line">        e = G.adjList[k].firstEdge;</span><br><span class="line">        while (e != nullptr) &#123;</span><br><span class="line">            if (lowcost[e-&gt;adjvex] != -1 and e-&gt;weight &lt; lowcost[e-&gt;adjvex]) &#123;</span><br><span class="line">                lowcost[e-&gt;adjvex] = e-&gt;weight;</span><br><span class="line">                adjvex[e-&gt;adjvex] = k;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            e = e-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; &quot;MST权值和为：&quot; &lt;&lt; weight &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="克鲁斯卡尔算法"><a href="#克鲁斯卡尔算法" class="headerlink" title="克鲁斯卡尔算法"></a>克鲁斯卡尔算法</h2><blockquote>
<p>假设$N=(V,E)$是连通网，则令最小生成树的初始状态为只有$n$个顶点而无边的非连通图$T=(V,\{\})$，图中每个顶点自成一个连通分量。在$E$中选择代价最小的边，若该边依附的顶点在$T$中的不同分量上，则将此边加入到$T$中，否则舍去此边而选择下一条代价最小的边。依次类推，直至$T$中所有顶点都在同一个连通分量上为止</p>
</blockquote>
<ul>
<li>对边集按权重值进行排序，升序搜索，保证得到符合条件的边以及顶点</li>
<li>判断边连接的顶点是否位于不同分量</li>
</ul>
<p><code>Prim</code>算法对边进行展开，每次添加一个边到<code>MST</code>，难点在于如何找到符合条件的边（如何判断两个顶点位于不同分量）：</p>
<ul>
<li>定义结构体<code>Edge</code>，保存边权值和两个顶点（区分边起点和边终点）</li>
<li>定义一维数组<code>edges</code>，类型为<code>Edge</code>，保存每条边信息，并按权值进行升序排序</li>
<li>定义一维数组<code>parent</code>，表示最小生成树的边集，数组下标表示一个顶点，成员值表示另一个顶点</li>
<li>遍历所有边<ul>
<li>初始时所有成员值均为<code>0</code>，表示每个顶点属于一个单独分量</li>
<li>假定第一条边的起始顶点为<code>2</code>，终止顶点为<code>8</code>，那么设置<code>parent[2]=8</code>，表示连接边<code>2-&gt;8</code></li>
<li>假定第二条边的起始顶点为<code>4</code>，终止顶点为<code>8</code>，那么设置<code>parent[4]=8</code>，表示连接边<code>4-&gt;8</code></li>
<li>假定第三条边的起始顶点为<code>2</code>，终止顶点为<code>4</code>，由上面两条边的设置可知，顶点<code>2</code>和<code>4</code>在同一个分量中</li>
<li>设置函数<code>Find</code>，输入起始下标<code>f</code>和数组<code>parent</code>，如果该下标成员值大于<code>0</code>（表明有边相连），将该成员值设为起始下标<code>f</code>，继续遍历，返回最后的<code>f</code></li>
<li>通过<code>Find</code>遍历边的两个顶点所在的分量，得到返回值<code>n</code>和<code>m</code><ul>
<li>如果返回下标值一致，那么属于同一个分量，舍弃该边</li>
<li>如果返回下标值不同，那么两个顶点属于不同的分量。设置<code>parent[n]=m</code>，连接两个分量，并保证下次遍历时得到的最后顶点均为<code>m</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="c-实现-1"><a href="#c-实现-1" class="headerlink" title="c++实现"></a>c++实现</h3><p>分别使用邻接矩阵和邻接表实现克鲁斯卡尔算法</p>
<h4 id="邻接矩阵-1"><a href="#邻接矩阵-1" class="headerlink" title="邻接矩阵"></a>邻接矩阵</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 权值边存储结构</span><br><span class="line">typedef struct &#123;</span><br><span class="line">    int begin;</span><br><span class="line">    int end;</span><br><span class="line">    int weight;</span><br><span class="line">&#125; Edge;</span><br><span class="line"></span><br><span class="line">void AdjacencyMatrixUndirectedGraph::MiniSpanTree_Kruskal(MGraph G) &#123;</span><br><span class="line">    int i, j, k, n, m;</span><br><span class="line">    std::array&lt;Edge, MAXEDGE&gt; edges = &#123;&#125;;</span><br><span class="line">    // 保存最小生成树，数组下标表示一个顶点，赋值表示另一个顶点</span><br><span class="line">    std::array&lt;int, MAXEDGE&gt; parent = &#123;&#125;;</span><br><span class="line"></span><br><span class="line">    // 将边集赋值给edges</span><br><span class="line">    k = 0;</span><br><span class="line">    for (i = 0; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        for (j = i + 1; j &lt; G.numVertexes; j++) &#123;</span><br><span class="line">            if (G.arcs[i][j] != GINFINITY) &#123;</span><br><span class="line">                Edge edge;</span><br><span class="line">                edge.begin = i;</span><br><span class="line">                edge.end = j;</span><br><span class="line">                edge.weight = G.arcs[i][j];</span><br><span class="line"></span><br><span class="line">                edges[k] = edge;</span><br><span class="line">                k++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // 按权值升序排序</span><br><span class="line">    std::sort(edges.begin(), edges.begin() + G.numEdges, less_second);</span><br><span class="line"></span><br><span class="line">    int weight = 0;</span><br><span class="line">    // 遍历所有边，</span><br><span class="line">    for (i = 0; i &lt; G.numEdges; i++) &#123;</span><br><span class="line">        n = Find(parent, edges[i].begin);</span><br><span class="line">        m = Find(parent, edges[i].end);</span><br><span class="line">        // 判断两个分量是否同属一个</span><br><span class="line">        if (n != m) &#123;</span><br><span class="line">            parent[n] = m;</span><br><span class="line">            printf(&quot;(%d, %d) %d\n&quot;, edges[i].begin, edges[i].end, edges[i].weight);</span><br><span class="line">            weight += edges[i].weight;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; &quot;MST权值和为：&quot; &lt;&lt; weight &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">bool AdjacencyMatrixUndirectedGraph::less_second(Edge x, Edge y) &#123;</span><br><span class="line">    return x.weight &lt; y.weight;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int AdjacencyMatrixUndirectedGraph::Find(std::array&lt;int, MAXEDGE&gt; &amp;parent, int f) &#123;</span><br><span class="line">    // 遍历分量</span><br><span class="line">    while (parent[f] &gt; 0) &#123;</span><br><span class="line">        f = parent[f];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return f;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="邻接表-1"><a href="#邻接表-1" class="headerlink" title="邻接表"></a>邻接表</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void AdjacencyTableUndirectedGraph::MiniSpanTree_Kruskal(GraphAdjList G) &#123;</span><br><span class="line">    int i, j, k, n, m;</span><br><span class="line">    EdgeNode *e;</span><br><span class="line">    std::array&lt;Edge, MAXEDGE&gt; edges = &#123;&#125;;</span><br><span class="line">    // 保存最小生成树，数组下标表示一个顶点，赋值表示另一个顶点</span><br><span class="line">    int parent[MAXVEX] = &#123;&#125;;</span><br><span class="line"></span><br><span class="line">    // 将边集赋值给edges</span><br><span class="line">    k = 0;</span><br><span class="line">    for (i = 0; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        e = G.adjList[i].firstEdge;</span><br><span class="line"></span><br><span class="line">        while (e != nullptr) &#123;</span><br><span class="line">            if (e-&gt;adjvex &gt; i) &#123;</span><br><span class="line">                Edge edge;</span><br><span class="line">                edge.begin = i;</span><br><span class="line">                edge.end = e-&gt;adjvex;</span><br><span class="line">                edge.weight = e-&gt;weight;</span><br><span class="line"></span><br><span class="line">                edges[k] = edge;</span><br><span class="line">                k++;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            e = e-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // 按权值升序排序</span><br><span class="line">    std::sort(edges.begin(), edges.begin() + G.numEdges, less_second);</span><br><span class="line"></span><br><span class="line">    int weight = 0;</span><br><span class="line">    // 升序遍历</span><br><span class="line">    for (i = 0; i &lt; G.numEdges; i++) &#123;</span><br><span class="line">        n = Find(parent, edges[i].begin);</span><br><span class="line">        m = Find(parent, edges[i].end);</span><br><span class="line">        // 判断两个分量是否同属一个</span><br><span class="line">        if (n != m) &#123;</span><br><span class="line">            parent[n] = m;</span><br><span class="line">            printf(&quot;(%d, %d) %d\n&quot;, edges[i].begin, edges[i].end, edges[i].weight);</span><br><span class="line">            weight += edges[i].weight;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; &quot;MST权值和为：&quot; &lt;&lt; weight &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">bool AdjacencyTableUndirectedGraph::less_second(Edge x, Edge y) &#123;</span><br><span class="line">    return x.weight &lt; y.weight;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int AdjacencyTableUndirectedGraph::Find(int *parent, int f) &#123;</span><br><span class="line">    // 遍历分量</span><br><span class="line">    while (parent[f] &gt; 0) &#123;</span><br><span class="line">        f = parent[f];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return f;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul>
<li>普里姆算法针对顶点进行展开，每次选择一个顶点进入最小生成树，对于稠密图而言效率更高</li>
<li>克鲁斯卡尔算法针对边进行展开，每次选择一条边连接两个不同分量，对于稀疏图而言效率更高</li>
</ul>
]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据结构</category>
        <category>图</category>
        <category>最小生成树</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>kruskal</tag>
        <tag>邻接矩阵</tag>
        <tag>邻接表</tag>
        <tag>prim</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构-图4</title>
    <url>/posts/e2d13922.html</url>
    <content><![CDATA[<p>参考：《大话数据结构》第7章 图</p><p>学习路径如下：</p><ol>
<li><a href="https://github.com/zjZSTU/graph_algorithm" target="_blank" rel="noopener">图的基本定义</a></li>
<li><a href="https://www.zhujian.tech/posts/a1a1ab33.html">顶点/边/图的关系</a></li>
<li><a href="https://www.zhujian.tech/posts/7cb5ac81.html">图的存储结构</a></li>
<li><a href="https://www.zhujian.tech/posts/e2d13922.html">深度/广度优先遍历</a>（<em>本文学习内容</em>）</li>
<li><a href="https://www.zhujian.tech/posts/95d609b4.html">最小生成树</a></li>
</ol><a id="more"></a>


<p>完整工程：<a href="https://github.com/zjZSTU/graph_algorithm" target="_blank" rel="noopener">zjZSTU/graph_algorithm</a></p>
<h2 id="图的遍历"><a href="#图的遍历" class="headerlink" title="图的遍历"></a>图的遍历</h2><blockquote>
<p>从图中某一顶点出发访遍图中其余顶点，且使每一个顶点仅被访问一次，这一过程称为图的遍历（<code>traversing graph</code>）</p>
</blockquote>
<h2 id="深度优先遍历"><a href="#深度优先遍历" class="headerlink" title="深度优先遍历"></a>深度优先遍历</h2><p>深度优先遍历（<code>depth first search，DFS</code>）:</p>
<blockquote>
<p>从图中某个顶点$v$出发，访问此顶点，然后从$v$的未被访问的邻接点出发深度优先遍历图，直至图中所有和$v$有路径相通的顶点都被访问。<br>若图中尚有顶点未被访问，则另选图中一个未曾被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到为止。</p>
</blockquote>
<ul>
<li><strong>深度优先</strong>指的是每次选择当前访问顶点的邻接点集中未被访问过的点作为下一个访问的点</li>
<li>创建一维数组<code>visited</code>保存已访问顶点</li>
<li>创建一维数组<code>ordered</code>保存访问次序</li>
<li>可使用递归方式进行深度优先遍历的实现</li>
</ul>
<h3 id="c-实现"><a href="#c-实现" class="headerlink" title="c++实现"></a>c++实现</h3><p>分别实现邻接矩阵和邻接表的深度优先遍历，使用递归方式实现</p>
<h4 id="邻接矩阵"><a href="#邻接矩阵" class="headerlink" title="邻接矩阵"></a>邻接矩阵</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bool visited[MAXVEX];</span><br><span class="line">int ordered[MAXVEX];</span><br><span class="line"></span><br><span class="line">int *Undigraph::DFSTraverse(MGraph G) &#123;</span><br><span class="line">    int i;</span><br><span class="line">    for (i = 0; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        visited[i] = false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    int index = 0;</span><br><span class="line">    for (i = 0; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        if (!visited[i]) &#123;</span><br><span class="line">            DFS(G, i, &amp;index);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return ordered;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void Undigraph::DFS(MGraph G, int up, int *index) &#123;</span><br><span class="line">    int j;</span><br><span class="line">    // 访问顶点up</span><br><span class="line">    visited[up] = true;</span><br><span class="line">    ordered[*index] = up;</span><br><span class="line">    *index += 1;</span><br><span class="line"></span><br><span class="line">    for (j = 0; j &lt; G.numVertexes; j++) &#123;</span><br><span class="line">        if (up != j and G.arcs[up][j] != GINFINITY and !visited[j]) &#123;</span><br><span class="line">            DFS(G, j, index);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="邻接表"><a href="#邻接表" class="headerlink" title="邻接表"></a>邻接表</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int *Undigraph::DFSTraverse(GraphAdjList G) &#123;</span><br><span class="line">    int i;</span><br><span class="line">    for (i = 0; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        visited[i] = false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    int index = 0;</span><br><span class="line">    for (i = 0; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        if (!visited[i]) &#123;</span><br><span class="line">            DFS(G, i, &amp;index);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return ordered;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void Undigraph::DFS(GraphAdjList G, int up, int *index) &#123;</span><br><span class="line">    // 访问顶点up</span><br><span class="line">    visited[up] = true;</span><br><span class="line">    ordered[*index] = up;</span><br><span class="line">    *index += 1;</span><br><span class="line"></span><br><span class="line">    EdgeNode *e = G.adjList[up].firstEdge;</span><br><span class="line">    while (e != nullptr) &#123;</span><br><span class="line">        if (!visited[e-&gt;adjvex]) &#123;</span><br><span class="line">            DFS(G, e-&gt;adjvex, index);</span><br><span class="line">        &#125;</span><br><span class="line">        e = e-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="广度优先遍历"><a href="#广度优先遍历" class="headerlink" title="广度优先遍历"></a>广度优先遍历</h2><p>广度优先遍历（<code>breadth first search，BFS</code>）:</p>
<blockquote>
<p>从图中某个顶点$v$出发，访问此顶点，然后依次访问$v$的邻接点集，再依次遍历这些邻接点集进行广度优先遍历，直至图中所有和$v$有路径相通的顶点都被访问。<br>若图中尚有顶点未被访问，则另选图中一个未曾被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到为止。</p>
</blockquote>
<ul>
<li><strong>广度优先</strong>指的是每次选择和当前访问顶点同属一层的未被访问过的点作为下一个访问点</li>
<li>创建一维数组<code>visited</code>保存已访问顶点</li>
<li>创建一维数组<code>ordered</code>保存访问次序</li>
<li>可使用队列结构进行广度优先遍历的实现</li>
</ul>
<p><img src="/imgs/数据结构-图4/bfs.png" alt></p>
<h3 id="c-实现-1"><a href="#c-实现-1" class="headerlink" title="c++实现"></a>c++实现</h3><p>分别使用邻接矩阵和邻接表实现广度优先遍历，采用队列方式</p>
<h4 id="邻接矩阵-1"><a href="#邻接矩阵-1" class="headerlink" title="邻接矩阵"></a>邻接矩阵</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bool visited[MAXVEX];</span><br><span class="line">int ordered[MAXVEX];</span><br><span class="line"></span><br><span class="line">int *Undigraph::BFSTraverse(MGraph G) &#123;</span><br><span class="line">    int i, j, k;</span><br><span class="line">    int index = 0;</span><br><span class="line">    std::queue&lt;int&gt; q;</span><br><span class="line">    for (i = 0; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        visited[i] = false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for (i = 0; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        if (!visited[i]) &#123;</span><br><span class="line">            // 访问顶点i</span><br><span class="line">            visited[i] = true;</span><br><span class="line">            ordered[index] = i;</span><br><span class="line">//            cout &lt;&lt; &quot; &quot; &lt;&lt; G.vexs[i];</span><br><span class="line">            index++;</span><br><span class="line"></span><br><span class="line">            q.push(i);</span><br><span class="line">            while (!q.empty()) &#123;</span><br><span class="line">                // 出队</span><br><span class="line">                k = q.front();</span><br><span class="line">                q.pop();</span><br><span class="line"></span><br><span class="line">                // 遍历邻接矩阵</span><br><span class="line">                for (j = 0; j &lt; G.numVertexes; j++) &#123;</span><br><span class="line">                    if (k != j and G.arcs[k][j] != GINFINITY and !visited[j]) &#123;</span><br><span class="line">                        // 访问顶点k</span><br><span class="line">                        visited[j] = true;</span><br><span class="line">                        ordered[index] = j;</span><br><span class="line">//                        cout &lt;&lt; &quot; &quot; &lt;&lt; G.vexs[j];</span><br><span class="line">                        index++;</span><br><span class="line"></span><br><span class="line">                        q.push(j);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return ordered;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="邻接表-1"><a href="#邻接表-1" class="headerlink" title="邻接表"></a>邻接表</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int *Undigraph::BFSTraverse(GraphAdjList G) &#123;</span><br><span class="line">    int i, k;</span><br><span class="line">    EdgeNode *e;</span><br><span class="line">    int index = 0;</span><br><span class="line">    std::queue&lt;int&gt; q;</span><br><span class="line">    for (i = 0; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        visited[i] = false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for (i = 0; i &lt; G.numVertexes; i++) &#123;</span><br><span class="line">        if (!visited[i]) &#123;</span><br><span class="line">            // 访问顶点i</span><br><span class="line">            visited[i] = true;</span><br><span class="line">            ordered[index] = i;</span><br><span class="line">            index++;</span><br><span class="line"></span><br><span class="line">            q.push(i);</span><br><span class="line">            while (!q.empty()) &#123;</span><br><span class="line">                // 出队</span><br><span class="line">                k = q.front();</span><br><span class="line">                q.pop();</span><br><span class="line"></span><br><span class="line">                e = G.adjList[k].firstEdge;</span><br><span class="line">                while (e != nullptr) &#123;</span><br><span class="line">                    if (!visited[e-&gt;adjvex]) &#123;</span><br><span class="line">                        // 访问顶点adjvex</span><br><span class="line">                        visited[e-&gt;adjvex] = true;</span><br><span class="line">                        ordered[index] = e-&gt;adjvex;</span><br><span class="line">                        index++;</span><br><span class="line"></span><br><span class="line">                        q.push(e-&gt;adjvex);</span><br><span class="line">                    &#125;</span><br><span class="line">                    e = e-&gt;next;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return ordered;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>对于$n$个顶点，$e$条边的无向图而言</p>
<ol>
<li>如果使用邻接矩阵作为存储结构，需要遍历顶点集，每次遍历单个顶点的边集时同样需要遍历二维邻接矩阵的每行（或每列），所以时间复杂度为$O(n^{2})$</li>
<li>如果使用邻接表作为存储结构，同样需要遍历顶点集，每次遍历单个顶点的边集时仅取决于边集的大小，极端情况下，仅需一个顶点就能遍历所有边集，所以时间复杂度为$O(n+e)$</li>
</ol>
<p>所以对于稀疏图而言，使用邻接表的效率远远大于邻接矩阵</p>
<p>深度优先遍历和广度优先遍历的时间复杂度相同，使用过程中依据具体情况分析</p>
<ul>
<li>深度优先更适合目标比较明确，以找到目标为主要目的的情况。有点像学习/开发过程后期，如果有明确研究目标，那就不断细分到想要的方向进行学习/研究</li>
<li>广度优先更适合在不断扩大遍历范围时找到相对最优解的情况。有点像学习/开发过程初期，先广泛的收集资料和数据，力图发现最好的学习/研究目标</li>
</ul>
]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据结构</category>
        <category>图</category>
        <category>遍历</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>邻接矩阵</tag>
        <tag>邻接表</tag>
        <tag>深度优先搜索</tag>
        <tag>广度优先搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构-图3</title>
    <url>/posts/7cb5ac81.html</url>
    <content><![CDATA[<p>参考：《大话数据结构》第7章 图</p><p>学习路径如下：</p><ol>
<li><a href="https://github.com/zjZSTU/graph_algorithm" target="_blank" rel="noopener">图的基本定义</a></li>
<li><a href="https://www.zhujian.tech/posts/a1a1ab33.html">顶点/边/图的关系</a></li>
<li><a href="https://www.zhujian.tech/posts/7cb5ac81.html">图的存储结构</a>（<em>本文学习内容</em>）</li>
<li><a href="https://www.zhujian.tech/posts/e2d13922.html">深度/广度优先遍历</a></li>
<li><a href="https://www.zhujian.tech/posts/95d609b4.html">最小生成树</a></li>
</ol><a id="more"></a>


<p>完整工程：<a href="https://github.com/zjZSTU/GraphLib" target="_blank" rel="noopener">zjZSTU/GraphLib</a></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>有<code>5</code>种图的存储结构：</p>
<ol>
<li>邻接矩阵</li>
<li>邻接表</li>
<li>十字链表</li>
<li>邻接多重表</li>
<li>边集数组</li>
</ol>
<p>其中常用的存储结构是邻接矩阵和邻接表</p>
<h2 id="邻接矩阵"><a href="#邻接矩阵" class="headerlink" title="邻接矩阵"></a>邻接矩阵</h2><p>图由两部分组成：顶点集+边集，分别存储这两部分有利于后续的操作</p>
<blockquote>
<p>图的邻接矩阵（<code>adjacency matrix</code>）存储方式是用两个数组来表示图。一个一维数组存储图中顶点信息，一个二维数组（称为邻接矩阵）存储图中的边或弧信息</p>
</blockquote>
<p><img src="/imgs/数据结构-图3/adjacent_matrix.png" alt></p>
<p>设图$G$中有两个顶点，则邻接矩阵是一个$n\times n$的方阵，定义为：</p>
<script type="math/tex; mode=display">
arc[i][j] = \left\{\begin{matrix}
1 & 若(v_{i}, v_{j})\subseteq E或<v_{i}, v_{j}>\subseteq E\\ 
0 & 反之
\end{matrix}\right.</script><p>对于有权图，修改邻接矩阵指定位置的值即可，如下所示：</p>
<script type="math/tex; mode=display">
arc[i][j] = \left\{\begin{matrix}
1 & 若(v_{i}, v_{j})\subseteq E或<v_{i}, v_{j}>\subseteq E\\ 
0 & 若i==j\\
\infty & 反之
\end{matrix}\right.</script><p>使用$\infty$表示两顶点之间没有连接</p>
<h3 id="C-实现"><a href="#C-实现" class="headerlink" title="C++实现"></a>C++实现</h3><p><img src="/imgs/数据结构-图3/mgraph.png" alt></p>
<p>定义邻接矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;array&gt;</span><br><span class="line"></span><br><span class="line">// 假定最大顶点个数</span><br><span class="line">#define MAXVEX 100</span><br><span class="line">// 假定最大边集个数</span><br><span class="line">#define MAXEDGE 100</span><br><span class="line">// 模拟无穷大</span><br><span class="line">#define GINFINITY 63335</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 顶点数据类型</span><br><span class="line">typedef std::string VertexType;</span><br><span class="line">// 边权值类型</span><br><span class="line">typedef int EdgeType;</span><br><span class="line"></span><br><span class="line">// 邻接矩阵存储结构</span><br><span class="line">typedef struct &#123;</span><br><span class="line">    // 顶点表</span><br><span class="line">    std::array&lt;VertexType, MAXVEX&gt; vexs;</span><br><span class="line">    // 边表</span><br><span class="line">    std::array&lt;std::array&lt;EdgeType, MAXVEX&gt;, MAXVEX&gt; arcs;</span><br><span class="line">    int numVertexes, numEdges;</span><br><span class="line">&#125; MGraph;</span><br></pre></td></tr></table></figure>
<p>创建邻接矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void Undigraph::CreateMGraph(MGraph *G) &#123;</span><br><span class="line">    int i, j, k, w;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; &quot;输入顶点数: &quot;;</span><br><span class="line">    cin &gt;&gt; G-&gt;numVertexes;</span><br><span class="line">    cout &lt;&lt; &quot;输入边集数: &quot;;</span><br><span class="line">    cin &gt;&gt; G-&gt;numEdges;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; &quot;输入顶点信息：&quot; &lt;&lt; endl;</span><br><span class="line">    for (i = 0; i &lt; G-&gt;numVertexes; i++) &#123;</span><br><span class="line">        cin &gt;&gt; G-&gt;vexs[i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 初始化边集二维数组</span><br><span class="line">    for (i = 0; i &lt; G-&gt;numVertexes; i++) &#123;</span><br><span class="line">        for (j = 0; j &lt; G-&gt;numVertexes; j++) &#123;</span><br><span class="line">            if (i == j)</span><br><span class="line">                G-&gt;arcs[i][j] = 0;</span><br><span class="line">            else</span><br><span class="line">                G-&gt;arcs[i][j] = GINFINITY;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; &quot;输入边信息&quot; &lt;&lt; endl;</span><br><span class="line">    for (k = 0; k &lt; G-&gt;numEdges; k++) &#123;</span><br><span class="line">        cout &lt;&lt; &quot;输入第&quot; &lt;&lt; k &lt;&lt; &quot;条边的上标、下标和权值: &quot;;</span><br><span class="line">        cin &gt;&gt; i &gt;&gt; j &gt;&gt; w;</span><br><span class="line">        G-&gt;arcs[i][j] = w;</span><br><span class="line">        G-&gt;arcs[j][i] = w;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="邻接表"><a href="#邻接表" class="headerlink" title="邻接表"></a>邻接表</h2><p>邻接表（<code>adjacency list</code>）同样实现了顶点集和边集的分离，如下所示：</p>
<ol>
<li>顶点集用一个一维数组存储（也可使用单链表存储），每个数据元素对象包含指向第一个邻接点的指针</li>
<li>每个顶点使用单链表存储邻接点信息，同时包含指向下一个邻接点的指针</li>
</ol>
<p><img src="/imgs/数据结构-图3/adjacent_list.png" alt></p>
<h3 id="c-实现"><a href="#c-实现" class="headerlink" title="c++实现"></a>c++实现</h3><p>顶点对象有两个域：<code>data</code>和<code>firstedge</code>。<code>data</code>存储顶点信息，<code>firstedge</code>指向第一个临界点</p>
<p>边对象有两个域：<code>adjvex</code>和<code>next</code>。<code>adjvex</code>存储该邻接点在顶点表中的下标，<code>next</code>指向下一个邻接点</p>
<p><img src="/imgs/数据结构-图3/graphadjlist.png" alt></p>
<p>定义邻接表：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 边表结点</span><br><span class="line">typedef struct EdgeNode &#123;</span><br><span class="line">    // 邻接点域，存储该顶点对应的坐标</span><br><span class="line">    int adjvex;</span><br><span class="line">    // 存储权值</span><br><span class="line">    EdgeType weight;</span><br><span class="line">    struct EdgeNode *next;</span><br><span class="line">&#125; EdgeNode;</span><br><span class="line"></span><br><span class="line">// 顶点表结点</span><br><span class="line">typedef struct VertexNode &#123;</span><br><span class="line">    VertexType data;</span><br><span class="line">    EdgeNode *firstEdge;</span><br><span class="line">&#125; VertextNode;</span><br><span class="line"></span><br><span class="line">// 邻接表</span><br><span class="line">typedef struct &#123;</span><br><span class="line">    // 顶点集数组</span><br><span class="line">    std::array&lt;VertextNode, MAXVEX&gt; adjList;</span><br><span class="line">    // 顶点集和边集大小</span><br><span class="line">    int numVertexes, numEdges;</span><br><span class="line">&#125; GraphAdjList;</span><br></pre></td></tr></table></figure>
<p>创建邻接表：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void Undigraph::CreateGraphAdjList(GraphAdjList *G) &#123;</span><br><span class="line">    int i, j, k, w;</span><br><span class="line">    EdgeNode *e;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; &quot;输入顶点数: &quot;;</span><br><span class="line">    cin &gt;&gt; G-&gt;numVertexes;</span><br><span class="line">    cout &lt;&lt; &quot;输入边集数: &quot;;</span><br><span class="line">    cin &gt;&gt; G-&gt;numEdges;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; &quot;输入顶点信息：&quot; &lt;&lt; endl;</span><br><span class="line">    for (i = 0; i &lt; G-&gt;numVertexes; i++) &#123;</span><br><span class="line">        cin &gt;&gt; G-&gt;adjList[i].data;</span><br><span class="line">        G-&gt;adjList[i].firstEdge = nullptr;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; &quot;输入边信息&quot; &lt;&lt; endl;</span><br><span class="line">    for (k = 0; k &lt; G-&gt;numEdges; k++) &#123;</span><br><span class="line">        cout &lt;&lt; &quot;输入第&quot; &lt;&lt; k &lt;&lt; &quot;条边的上标、下标和权值: &quot;;</span><br><span class="line">        cin &gt;&gt; i &gt;&gt; j &gt;&gt; w;</span><br><span class="line">        // 申请内存空间</span><br><span class="line">        e = (EdgeNode *) malloc(sizeof(EdgeNode));</span><br><span class="line">        e-&gt;adjvex = j;</span><br><span class="line">        e-&gt;weight = w;</span><br><span class="line">        // 头插法</span><br><span class="line">        e-&gt;next = G-&gt;adjList[i].firstEdge;</span><br><span class="line">        G-&gt;adjList[i].firstEdge = e;</span><br><span class="line"></span><br><span class="line">        // 无向图的边表对称</span><br><span class="line">        e = (EdgeNode *) malloc(sizeof(EdgeNode));</span><br><span class="line">        e-&gt;adjvex = i;</span><br><span class="line">        e-&gt;weight = w;</span><br><span class="line">        // 头插法</span><br><span class="line">        e-&gt;next = G-&gt;adjList[j].firstEdge;</span><br><span class="line">        G-&gt;adjList[j].firstEdge = e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>假定图有$n$个顶点和$e$条边，那么</p>
<ul>
<li>创建邻接矩阵的时间复杂度为$O(n^{2}+e)$，创建邻接表的时间复杂度为$O(n+e)$</li>
<li>邻接矩阵的使用极大的浪费存储空间，但有利于数据查询、修改、增添和删除操作</li>
<li>邻接表的使用有利于避免浪费存储空间，但是提高了数据查询、修改、增添和删除操作的复杂度</li>
</ul>
]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据结构</category>
        <category>图</category>
        <category>存储结构</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>邻接矩阵</tag>
        <tag>邻接表</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构-图2</title>
    <url>/posts/a1a1ab33.html</url>
    <content><![CDATA[<p>参考：《大话数据结构》第7章 图</p><p>学习路径如下：</p><ol>
<li><a href="https://github.com/zjZSTU/graph_algorithm" target="_blank" rel="noopener">图的基本定义</a></li>
<li><a href="https://www.zhujian.tech/posts/a1a1ab33.html">顶点/边/图的关系</a>（<em>本文学习内容</em>）</li>
<li><a href="https://www.zhujian.tech/posts/7cb5ac81.html">图的存储结构</a></li>
<li><a href="https://www.zhujian.tech/posts/e2d13922.html">深度/广度优先遍历</a></li>
<li><a href="https://www.zhujian.tech/posts/95d609b4.html">最小生成树</a></li>
</ol><a id="more"></a>


<p>完整工程：<a href="https://github.com/zjZSTU/graph_algorithm" target="_blank" rel="noopener">zjZSTU/graph_algorithm</a></p>
<h2 id="度-入度-出度"><a href="#度-入度-出度" class="headerlink" title="度/入度/出度"></a>度/入度/出度</h2><p>对于无向图$G=(V,E)$，如果边$(u,v)\in E$，则称顶点$u$和$v$互为邻接点（adjacent），即$u$和$v$相邻接</p>
<p>对于有向图$G=(V,E)$，如果弧<code>&lt;u,v&gt;</code>$\in E$，则称顶点$u$邻接<strong>到</strong>顶点$v$，顶点$v$邻接<strong>自</strong>顶点$u$</p>
<ul>
<li>度</li>
</ul>
<blockquote>
<p>顶点$v$的度（<code>degree</code>）是和$v$相关联的边的数目，记为$TD(v)$</p>
</blockquote>
<ul>
<li>入度</li>
</ul>
<blockquote>
<p>以顶点$v$为头的弧的数目称为$v$的入度（<code>InDegree</code>），记为$ID(v)$</p>
</blockquote>
<ul>
<li>出度</li>
</ul>
<blockquote>
<p>以顶点$v$为尾的弧的数目称为$v$的出度（<code>OutDegree</code>），记为$OD(v)$</p>
</blockquote>
<p>对于有向边<code>&lt;u,v&gt;</code>而言，顶点$u$是弧尾，顶点$v$是弧头，所以$ID(v)=1$, $OD(u)=1$</p>
<p>对无向图而言，仅存在度的概念；对于有向图而言，同时还存在入度和出度的概念，入度和出度之和就是该顶点的度：$ TD(v) = ID(v) + OD(v)$</p>
<h2 id="路径"><a href="#路径" class="headerlink" title="路径"></a>路径</h2><ul>
<li>路径</li>
</ul>
<blockquote>
<p>图$G(V,E)$中从顶点$u$到顶点$v$的路径（<code>path</code>）是一个顶点序列$(V=v_{0},v_{1},…,v_{m})$，其中$v_{0}=u, v_{m}=v, (v_{i-1}, v_{i})\subseteq E,1\leq  i\leq m$</p>
</blockquote>
<ul>
<li>回路或环（cycle）</li>
</ul>
<blockquote>
<p>第一个顶点和最后一个顶点相同的路径</p>
</blockquote>
<ul>
<li>简单路径</li>
</ul>
<blockquote>
<p>序列中顶点不重复出现的路径</p>
</blockquote>
<ul>
<li>简单回路或简单环</li>
</ul>
<blockquote>
<p>除了第一个顶点和最后一个顶点相同外，其余顶点不重复出现的回路</p>
</blockquote>
<h2 id="连通图-连通分量"><a href="#连通图-连通分量" class="headerlink" title="连通图/连通分量"></a>连通图/连通分量</h2><p>参考：</p>
<p><a href="https://zh.wikipedia.org/wiki/%E8%BF%9E%E9%80%9A%E5%9B%BE" target="_blank" rel="noopener">连通图</a></p>
<p><a href="https://baike.baidu.com/item/%E8%BF%9E%E9%80%9A%E5%88%86%E9%87%8F" target="_blank" rel="noopener">连通分量</a></p>
<ul>
<li>连通图</li>
</ul>
<blockquote>
<p>在一个无向图$G$中，若从顶点$v_{i}$到顶点$v_{j}$有路径相连，则称$v_{i}$和$v_{j}$是连通的。如果图中任意两点都是连通的，那么图被称作是连通图</p>
</blockquote>
<ul>
<li>强连通图</li>
</ul>
<blockquote>
<p>在图$G$中，如果对于每一对$u,v\subseteq V, u\neq v$，从$u$到$v$和从$v$到$u$都存在路径，则称$G$是强连通图</p>
</blockquote>
<p><em>连通图是相对于无向图而言的，强连通图是相对于有向图而言的</em></p>
<ul>
<li>连通分量</li>
</ul>
<blockquote>
<p>无向图$G$的极大连通子图称为$G$的连通分量（<code>connected component</code>）。任何连通图（<code>connected graph</code>）的连通分量仅有一个，即是其自身，非连通的无向图有多个连通分量</p>
</blockquote>
<ul>
<li>强连通分量</li>
</ul>
<blockquote>
<p>有向图中的极大强连通子图称做有向图的强连通分量</p>
</blockquote>
<h2 id="生成树"><a href="#生成树" class="headerlink" title="生成树"></a>生成树</h2><p>参考：</p>
<p><a href="https://baike.baidu.com/item/%E7%94%9F%E6%88%90%E6%A0%91%E7%AE%97%E6%B3%95/21511961" target="_blank" rel="noopener">生成树算法</a></p>
<p><a href="https://baike.baidu.com/item/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91" target="_blank" rel="noopener">最小生成树</a></p>
<p><a href="https://blog.csdn.net/luomingjun12315/article/details/47700237" target="_blank" rel="noopener">最小生成树之Kruskal算法</a></p>
<ul>
<li>生成树</li>
</ul>
<blockquote>
<p>如果连通图$G$的一个子图是一颗包含$G$的所有顶点的树，则该子图称为$G$的生成树（<code>spanning tree</code>）</p>
</blockquote>
<p><em>连通图的生成树是一个极小的连通子图，包含全部$n$个顶点，但只有足以构成一棵树的$n-1$条边</em></p>
<p><strong>对于生成树而言，前提是它是连通图，也就是顶点之间有连接</strong></p>
<ul>
<li>最小生成树</li>
</ul>
<blockquote>
<p>给定无向图$G=(V,E)$，$(u,v)$代表连接顶点$u$和$v$的边，$w(u,v)$代表此边的权重，如果存在生成树$T$使得$w(T)$最小（<em>权值之和最小</em>），那么称$T$为最小生成树(<code>MST, Minimum Spanning Tree</code>)</p>
</blockquote>
]]></content>
      <categories>
        <category>数据结构</category>
        <category>图</category>
      </categories>
  </entry>
  <entry>
    <title>数据结构-图</title>
    <url>/posts/662946db.html</url>
    <content><![CDATA[<p>参考：《大话数据结构》第7章 图</p><p>学习路径如下：</p><ol>
<li><a href="https://github.com/zjZSTU/graph_algorithm" target="_blank" rel="noopener">图的基本定义</a>（<em>本文学习内容</em>）</li>
<li><a href="https://www.zhujian.tech/posts/a1a1ab33.html">顶点/边/图的关系</a></li>
<li><a href="https://www.zhujian.tech/posts/7cb5ac81.html">图的存储结构</a></li>
<li><a href="https://www.zhujian.tech/posts/e2d13922.html">深度/广度优先遍历</a></li>
<li><a href="https://www.zhujian.tech/posts/95d609b4.html">最小生成树</a></li>
</ol><a id="more"></a>


<p>完整工程：<a href="https://github.com/zjZSTU/graph_algorithm" target="_blank" rel="noopener">zjZSTU/graph_algorithm</a></p>
<h2 id="什么是图"><a href="#什么是图" class="headerlink" title="什么是图"></a>什么是图</h2><ul>
<li>图</li>
</ul>
<blockquote>
<p>图（<code>Graph</code>）是由顶点的有穷非空集合和顶点之间边的集合组成，通常表示为：$G(V，E)$，其中，$G$表示一个图，$V$是图$G$中顶点（<code>vertex</code>）的集合，$E$是图$G$中边（<code>edge</code>）的集合</p>
</blockquote>
<p><strong>注意：图可以没有边，不能没有顶点</strong></p>
<ul>
<li>子图</li>
</ul>
<blockquote>
<p>假设有两个图$G(V,E)$和${G}’({V}’,{E}’)$，如果${V}’\subseteq V$且${E}’\subseteq E$， 则称${G}’$为$G$的子图（<code>subgraph</code>）</p>
</blockquote>
<h3 id="简单图"><a href="#简单图" class="headerlink" title="简单图"></a>简单图</h3><blockquote>
<p>图中不存在顶点到自身的边，且同一条边不重复出现，称这样的图为简单图</p>
</blockquote>
<p><em>之后的讨论都是基于简单图进行的</em></p>
<h3 id="权重-网"><a href="#权重-网" class="headerlink" title="权重/网"></a>权重/网</h3><ul>
<li>权重（<code>weight</code>）</li>
</ul>
<blockquote>
<p>与边相关的数称为权重（<code>weight</code>）</p>
</blockquote>
<ul>
<li>网</li>
</ul>
<blockquote>
<p>带权重的图通常称为网（<code>network</code>）</p>
</blockquote>
<h2 id="有向图-无向图"><a href="#有向图-无向图" class="headerlink" title="有向图/无向图"></a>有向图/无向图</h2><p>参考：</p>
<p><a href="https://www.itcodemonkey.com/article/13876.html" target="_blank" rel="noopener">数据结构与算法——图论基础与图存储结构</a></p>
<p><a href="https://baike.baidu.com/item/%E6%97%A0%E5%90%91%E5%9B%BE" target="_blank" rel="noopener">无向图</a></p>
<ul>
<li>无向边（<code>undirected edge</code>）</li>
</ul>
<blockquote>
<p>若顶点$x$和$y$之间的边没有方向，则称该边为无向边，用无序偶对$(x,y)$表示。$(x,y)$与$(y,x)$意义相同，仅表示$x$和$y$之间有连接</p>
</blockquote>
<ul>
<li>有向边（<code>directed edge</code>）</li>
</ul>
<blockquote>
<p>若顶点$u$和$v$之间的边有方向，则称该边为有向边（也称为弧$Arc$），用有序偶对<code>&lt;u,v&gt;</code>表示，表示从$u$指向$v$。称$u$为该边的起点（<code>origin</code>）或尾顶点/弧尾（<code>tail</code>），称$v$为该边的终点（<code>destination</code>）或头顶点/弧头（<code>head</code>）</p>
</blockquote>
<ul>
<li>无向图</li>
</ul>
<blockquote>
<p>图中任意两个顶点之间的边都是无向边，称该图为无向图（<code>undirected graph</code>）</p>
</blockquote>
<ul>
<li>有向图</li>
</ul>
<blockquote>
<p>图中任意两个顶点之间的边都是有向边的图称为有向图（<code>directed graph</code>）</p>
</blockquote>
<ul>
<li>混合图</li>
</ul>
<blockquote>
<p>包含无向边和有向边的图称为混合图（<code>mixed graph</code>）</p>
</blockquote>
<p><strong>注意：无向边用小括号$()$表示，有向边用尖括号$&lt;&gt;$表示</strong></p>
<h2 id="稀疏图-稠密图-完全图"><a href="#稀疏图-稠密图-完全图" class="headerlink" title="稀疏图/稠密图/完全图"></a>稀疏图/稠密图/完全图</h2><ul>
<li>稀疏图（<code>sparse graph</code>）</li>
</ul>
<blockquote>
<p>顶点很少互相连接的图</p>
</blockquote>
<ul>
<li>稠密图（<code>dense graph</code>）</li>
</ul>
<blockquote>
<p>顶点几乎都能两两连接的图</p>
</blockquote>
<ul>
<li>完全图（<code>complete graph</code>）</li>
</ul>
<blockquote>
<p>每个顶点均与除自身之外的其他顶点连接的图</p>
</blockquote>
<ul>
<li>无向完全图</li>
</ul>
<blockquote>
<p>在无向图中，如果任意两个顶点之间都存在边，则称该图为无向完全图</p>
</blockquote>
<p>含有$n$个顶点的无向完全图有$\frac {n\times (n-1)}{2}$条边</p>
<ul>
<li>有向完全图</li>
</ul>
<blockquote>
<p>在有向图中，如果任意两个顶点之间都存在方向互为相反的两条弧，则称该图为有向完全图</p>
</blockquote>
<p>含有$n$个顶点的有向完全图有$n\times (n-1)$条边</p>
]]></content>
      <categories>
        <category>数据结构</category>
        <category>图</category>
      </categories>
  </entry>
  <entry>
    <title>高斯滤波</title>
    <url>/posts/80b530f2.html</url>
    <content><![CDATA[<p>在进行图像分割之前通常会使用滤波器进行平滑操作，其目的是消除高斯噪声的影响。学习高斯噪声/高斯滤波的相关概念并实现高斯滤波器</p><a id="more"></a>
<h2 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h2><p>参考：</p>
<p><a href="https://www.zhihu.com/question/54918332" target="_blank" rel="noopener">高斯模糊的原理是什么，怎样在界面中实现？</a></p>
<p><a href="https://www.zhujian.tech/posts/6824c6e3.html">正态分布</a></p>
<p><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/matplotlib/3d%E7%BB%98%E5%9B%BE.html" target="_blank" rel="noopener">3d绘图</a></p>
<p>一维高斯分布</p>
<script type="math/tex; mode=display">
G(x) = \frac {1}{\sqrt {2 \pi} \sigma} e^{-\frac {x^{2}}{2\sigma^{2}}}</script><p>二维高斯分布</p>
<script type="math/tex; mode=display">
G(x, y) = \frac {1}{2 \pi \sigma^{2}} e^{-\frac {x^{2} + y^{2}}{2\sigma^{2}}}</script><p>每次计算均以当前像素点为中心，所以均值$\mu$为$0$</p>
<p>标准差$\sigma$控制离散程度，$\sigma$越大，曲线越扁平，数据分布越离散，滤波效果越明显；$\sigma$越小，曲线越廋高，数据分布越集中，滤波效果不明显</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-8-12 下午7:19</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from mpl_toolkits.mplot3d import Axes3D</span><br><span class="line">import numpy as np</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def gauss_filter_1d(x, sigma=1.):</span><br><span class="line">    w = 1 / (np.sqrt(2 * math.pi) * sigma)</span><br><span class="line">    return np.exp(-1 * x ** 2 / (sigma ** 2 * 2)) * w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def gauss_filter_2d(x, y, sigma=1.):</span><br><span class="line">    w = 1 / (2 * math.pi * sigma ** 2)</span><br><span class="line">    return np.exp(-1 * (x ** 2 + y ** 2) / (sigma ** 2 * 2)) * w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    x = np.linspace(-3, 3, num=50)</span><br><span class="line">    y = np.linspace(-3, 3, num=50)</span><br><span class="line"></span><br><span class="line">    X, Y = np.meshgrid(x, y)</span><br><span class="line">    Z = gauss_filter_2d(X, Y, sigma=0.8)</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(1)</span><br><span class="line">    ax = fig.add_subplot(111, projection=&apos;3d&apos;)</span><br><span class="line">    surf = ax.plot_surface(X, Y, Z, cmap=plt.cm.coolwarm)</span><br><span class="line">    fig.colorbar(surf, shrink=0.5, aspect=5)</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(2)</span><br><span class="line">    res = gauss_filter_1d(x, sigma=1)</span><br><span class="line">    plt.scatter(x, res, label=&apos;sigma=1&apos;)</span><br><span class="line">    res = gauss_filter_1d(x, sigma=0.8)</span><br><span class="line">    plt.scatter(x, res, label=&apos;sigma=0.8&apos;)</span><br><span class="line">    res = gauss_filter_1d(x, sigma=0.5)</span><br><span class="line">    plt.scatter(x, res, label=&apos;sigma=0.5&apos;)</span><br><span class="line">    plt.legend()</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/高斯滤波/gauss_1d.png" alt></p>
<p><img src="/imgs/高斯滤波/gauss-2d.png" alt></p>
<h2 id="高斯噪声"><a href="#高斯噪声" class="headerlink" title="高斯噪声"></a>高斯噪声</h2><p>参考：<a href="https://baike.baidu.com/item/%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0" target="_blank" rel="noopener">高斯噪声</a></p>
<p>高斯噪声是指它的概率密度函数服从高斯分布（即正态分布）的一类噪声</p>
<p>数字图像中的高斯噪声的主要来源出现在采集期间，由于不良照明/高温引起的<strong>传感器噪声</strong></p>
<h2 id="高斯滤波"><a href="#高斯滤波" class="headerlink" title="高斯滤波"></a>高斯滤波</h2><p>高斯滤波（<code>gaussian filter</code>）是一种<strong>线性平滑滤波</strong>，就是对整幅图像进行<strong>加权平均</strong>的过程，对每个像素点的值，结合邻域内其他像素值进行加权平均</p>
<p>具体操作如下：用一个模板（或称卷积、掩模）扫描图像中的每一个像素，用模板确定的邻域像素的加权平均灰度值去替代模板中心像素点的值</p>
<p>高斯滤波的优点在于消除高斯噪声，其副作用是消除图像细节，所以又称为高斯模糊（<code>gaussian blur</code>）</p>
<h3 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h3><p>参考：<a href="https://blog.csdn.net/lz0499/article/details/54015150" target="_blank" rel="noopener">关于高斯滤波的一些理解</a></p>
<p>有两个常用的高斯模板，分别是$3\times 3$和$5\times 5$大小</p>
<p><img src="/imgs/高斯滤波/gauss-common.png" alt></p>
<p>滤波过程中的模板是通过高斯公式计算得到的，以$3\times 3$大小模板为例，其原始值是</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[[2 1 2]</span><br><span class="line"> [1 0 1]</span><br><span class="line"> [2 1 2]]</span><br></pre></td></tr></table></figure>
<p>假定$\sigma=0.85$，输入到二维高斯函数计算得到</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[[0.11759572 0.23493154 0.11759572]</span><br><span class="line"> [0.23493154 0.46934386 0.23493154]</span><br><span class="line"> [0.11759572 0.23493154 0.11759572]]</span><br></pre></td></tr></table></figure>
<p>进行归一化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[[0.06256912 0.12499996 0.06256912]</span><br><span class="line"> [0.12499996 0.24972366 0.12499996]</span><br><span class="line"> [0.06256912 0.12499996 0.06256912]]</span><br></pre></td></tr></table></figure>
<p>除以最小值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[[1 2 1]</span><br><span class="line"> [2 4 2]</span><br><span class="line"> [1 2 1]]</span><br></pre></td></tr></table></figure>
<p>$5\times 5$大小模板同理，不过其$\sigma$约为$1.04$</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    x = 5</span><br><span class="line">    y = 5</span><br><span class="line">    sigma = 1.04</span><br><span class="line"></span><br><span class="line">    xx = np.abs(np.arange(-1 * (x // 2), x // 2 + 1))</span><br><span class="line">    yy = np.abs(np.arange(-1 * (y // 2), y // 2 + 1))</span><br><span class="line"></span><br><span class="line">    xx, yy = np.meshgrid(xx, yy)</span><br><span class="line">    print(xx ** 2 + yy ** 2)</span><br><span class="line">    zz = gauss_filter_2d(xx, yy, sigma=sigma)</span><br><span class="line"></span><br><span class="line">    print(zz)</span><br><span class="line">    print(zz / np.sum(zz))</span><br><span class="line">    print((zz / np.min(zz) + 0.5).astype(np.int))</span><br></pre></td></tr></table></figure>
<h3 id="彩色图像"><a href="#彩色图像" class="headerlink" title="彩色图像"></a>彩色图像</h3><p>高斯滤波默认对单个通道图像进行，所以对于彩色图像，需要先分离为<code>3</code>个单通道图像，分别进行滤波处理后再合并为<code>3</code>通道图像</p>
<h2 id="opencv实现"><a href="#opencv实现" class="headerlink" title="opencv实现"></a>opencv实现</h2><p>参考：</p>
<p><a href="https://docs.opencv.org/3.4.2/d4/dbd/Smoothing_8cpp-example.html#a10" target="_blank" rel="noopener">Smoothing.cpp</a></p>
<p><a href="https://docs.opencv.org/3.4.2/d4/d13/tutorial_py_filtering.html" target="_blank" rel="noopener">Gaussian Blurring</a></p>
<p><code>opencv</code>提供了高斯滤波以及高斯模板的实现</p>
<p>源码位于：<code>path/to/modules/imgproc/src/smooth.cpp</code></p>
<h3 id="getGaussianKernel"><a href="#getGaussianKernel" class="headerlink" title="getGaussianKernel"></a>getGaussianKernel</h3><p>函数<a href="https://docs.opencv.org/3.4.2/d4/d86/group__imgproc__filter.html#gac05a120c1ae92a6060dd0db190a61afa" target="_blank" rel="noopener">getGaussianKernel()</a>计算并返回高斯滤波系数的$ksize×1$大小矩阵：</p>
<script type="math/tex; mode=display">
G_{i} = \alpha * e^{-(i-(ksize-1)/2)^{2}/(2*sigma^{2})}</script><ul>
<li>参数$ksize$应该是正奇数（<code>1/3/5/...</code>），如果输入为<code>0</code>（即<code>Size(0,0)</code>），则根据<code>sigma</code>值进行计算</li>
<li>参数$\sigma$是高斯标准差，如果输入不为正，根据<code>ksize</code>计算$sigma = 0.3*((ksize-1)\cdot 0.5 - 1)+0.8$，当<code>ksize=3, sigma=0.8</code>，当<code>ksize=5, sigma=1.1</code></li>
<li>参数$i$遍历$0,…,ksize-1$</li>
<li>参数$\alpha$是缩放因子，其目的是使矩阵归一化：$\sum_{i}G_{i} = 1$</li>
</ul>
<p><code>getGaussianKernel</code>源码位于<code>/path/to/modules/imgproc/src/smooth.cpp</code></p>
<p>当<code>ksize=Size(0,0)</code>时，计算如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// automatic detection of kernel size from sigma</span><br><span class="line">if( ksize.width &lt;= 0 &amp;&amp; sigma1 &gt; 0 )</span><br><span class="line">    ksize.width = cvRound(sigma1*(depth == CV_8U ? 3 : 4)*2 + 1)|1;</span><br><span class="line">if( ksize.height &lt;= 0 &amp;&amp; sigma2 &gt; 0 )</span><br><span class="line">    ksize.height = cvRound(sigma2*(depth == CV_8U ? 3 : 4)*2 + 1)|1;</span><br></pre></td></tr></table></figure>
<ul>
<li>当<code>sigma=1.0</code>时，<code>ksize.width = cvRound(7)|1 = 0111|1 = 0111 = 7</code></li>
<li>当<code>sigma=0.8</code>时，<code>ksize.width = cvRound(5.8)|1 = 6|1 = 0110|1 = 0111 = 7</code></li>
<li>当<code>sigma=0.5</code>时，<code>ksize.width = cvRound(4)|1 = 0100|1 = 0101 = 5</code></li>
</ul>
<h3 id="GaussianBlur"><a href="#GaussianBlur" class="headerlink" title="GaussianBlur"></a>GaussianBlur</h3><p>函数<a href="https://docs.opencv.org/3.4.2/d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1" target="_blank" rel="noopener">GaussianBlur()</a>将源图像与高斯核进行卷积操作</p>
<p>使用$(5,5)$大小，$sigma=1$的高斯核进行卷积操作</p>
<p>python语言</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(&apos;lena.jpg&apos;)</span><br><span class="line">blur = cv2.GaussianBlur(img, (5, 5), 1)</span><br><span class="line">cv2.imshow(&apos;img&apos;, img)</span><br><span class="line">cv2.imshow(&apos;blur&apos;, blur)</span><br><span class="line">cv2.waitKey(0)</span><br></pre></td></tr></table></figure>
<p>C++语言</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;opencv2/opencv.hpp&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line">using namespace cv;</span><br><span class="line"></span><br><span class="line">int main() &#123;</span><br><span class="line">    std::cout &lt;&lt; &quot;Hello, World!&quot; &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    Mat img = imread(&quot;lena.jpg&quot;);</span><br><span class="line">    if (img.empty()) &#123;</span><br><span class="line">        std::cout &lt;&lt; &quot;error&quot; &lt;&lt; std::endl;</span><br><span class="line">        exit(0);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Mat dst = img.clone();</span><br><span class="line">    GaussianBlur(img, dst, Size(5, 5), 1, 1);</span><br><span class="line"></span><br><span class="line">    imshow(&quot;img&quot;, img);</span><br><span class="line">    imshow(&quot;gauss&quot;, dst);</span><br><span class="line">    waitKey(0);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="自定义实现（c-）"><a href="#自定义实现（c-）" class="headerlink" title="自定义实现（c++）"></a>自定义实现（c++）</h2><p>创建类<code>GaussianFilter</code>，实现获取高斯滤波功能</p>
<ol>
<li>使用<code>gaussFilter2d</code>实现高斯分布计算（去掉<code>weight</code>计算，其在归一化过程中不需要）</li>
<li>使用<code>Conv2d</code>实现卷积核与图像计算</li>
<li>使用<code>getGaussianKernel</code>计算高斯模板</li>
<li>使用<code>GaussianBlur</code>进行高斯滤波</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//</span><br><span class="line">// Created by zj on 19-8-13.</span><br><span class="line">//</span><br><span class="line"></span><br><span class="line">#ifndef OPENCV_PROJECT_GAUSSIANFILTER_H</span><br><span class="line">#define OPENCV_PROJECT_GAUSSIANFILTER_H</span><br><span class="line"></span><br><span class="line">#include &lt;cmath&gt;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;opencv2/opencv.hpp&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line">using namespace cv;</span><br><span class="line"></span><br><span class="line">class GaussianFilter &#123;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">    /**</span><br><span class="line">     * 高斯滤波操作</span><br><span class="line">     */</span><br><span class="line">    void GaussianBlur(Mat &amp;src, Mat &amp;dst, int ksize = 3, double sigma = 1.0);</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 生成二维高斯滤波内核</span><br><span class="line">     */</span><br><span class="line">    Mat getGaussianKernel(int ksize, double sigma);</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">    /**</span><br><span class="line">     * 二维卷积操作</span><br><span class="line">     */</span><br><span class="line">    void Conv2d(Mat &amp;src, Mat &amp;dst, Mat filter);</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 二维高斯滤波</span><br><span class="line">     */</span><br><span class="line">    double gaussFilter2d(double x, double y, double sigma = 1.0);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#endif //OPENCV_PROJECT_GAUSSIANFILTER_H</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//</span><br><span class="line">// Created by zj on 19-8-13.</span><br><span class="line">//</span><br><span class="line"></span><br><span class="line">#include &quot;GaussianFilter.h&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">void GaussianFilter::GaussianBlur(Mat &amp;src, Mat &amp;dst, int ksize, double sigma) &#123;</span><br><span class="line">    int channels = src.channels();</span><br><span class="line">    Mat filter = getGaussianKernel(ksize, sigma);</span><br><span class="line"></span><br><span class="line">    if (channels == 1) &#123;</span><br><span class="line">        Conv2d(src, dst, filter);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        vector&lt;Mat&gt; mats;</span><br><span class="line">        vector&lt;Mat&gt; dstMats;</span><br><span class="line">        split(src, mats);</span><br><span class="line">        for (auto srcImg: mats) &#123;</span><br><span class="line">            Mat dstImg = srcImg.clone();</span><br><span class="line"></span><br><span class="line">            Conv2d(srcImg, dstImg, filter);</span><br><span class="line">            dstMats.push_back(dstImg);</span><br><span class="line">        &#125;</span><br><span class="line">        merge(dstMats, dst);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Mat GaussianFilter::getGaussianKernel(int ksize, double sigma) &#123;</span><br><span class="line">    // ksize=3, sigma=0.85</span><br><span class="line">    // kszie=5, sigma=1.04</span><br><span class="line">    static const double gaussian_kernel_3[][3] = &#123;&#123;0.06256912, 0.12499996, 0.06256912&#125;,</span><br><span class="line">                                                  &#123;0.12499996, 0.24972366, 0.12499996&#125;,</span><br><span class="line">                                                  &#123;0.06256912, 0.12499996, 0.06256912&#125;&#125;;</span><br><span class="line">    static const double gaussian_kernel_5[][5] = &#123;</span><br><span class="line">            &#123;0.00373691, 0.0149557, 0.023745,  0.0149557, 0.00373691&#125;,</span><br><span class="line">            &#123;0.0149557,  0.0598552, 0.0950314, 0.0598552, 0.0149557&#125;,</span><br><span class="line">            &#123;0.023745,   0.0950314, 0.15088,   0.0950314, 0.023745&#125;,</span><br><span class="line">            &#123;0.0149557,  0.0598552, 0.0950314, 0.0598552, 0.0149557&#125;,</span><br><span class="line">            &#123;0.00373691, 0.0149557, 0.023745,  0.0149557, 0.00373691&#125;,</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    Mat res;</span><br><span class="line">    if (ksize == 3) &#123;</span><br><span class="line">        res = Mat(ksize, ksize, CV_64FC1);</span><br><span class="line">        std::memcpy(res.data, gaussian_kernel_3, ksize * ksize * sizeof(double));</span><br><span class="line">    &#125; else if (ksize == 5) &#123;</span><br><span class="line">        res = Mat(ksize, ksize, CV_64FC1);</span><br><span class="line">        std::memcpy(res.data, gaussian_kernel_5, ksize * ksize * sizeof(double));</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        double kernel[ksize][ksize];</span><br><span class="line">        int radius = ksize / 2;</span><br><span class="line">        double sum = 0;</span><br><span class="line"></span><br><span class="line">        for (int i = 0; i &lt; ksize; i++) &#123;</span><br><span class="line">            for (int j = 0; j &lt; ksize; j++) &#123;</span><br><span class="line">                kernel[i][j] = gaussFilter2d(abs(i - radius), abs(j - radius), sigma);</span><br><span class="line">                sum += kernel[i][j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        for (int i = 0; i &lt; ksize; i++) &#123;</span><br><span class="line">            for (int j = 0; j &lt; ksize; j++) &#123;</span><br><span class="line">                kernel[i][j] = kernel[i][j] / sum;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        res = Mat(ksize, ksize, CV_64FC1);</span><br><span class="line">        std::memcpy(res.data, kernel, ksize * ksize * sizeof(double));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void GaussianFilter::Conv2d(Mat &amp;src, Mat &amp;dst, Mat filter) &#123;</span><br><span class="line">    int filter_h = filter.rows;</span><br><span class="line">    int filter_w = filter.cols;</span><br><span class="line"></span><br><span class="line">    int radius_y = filter_h / 2;</span><br><span class="line">    int radius_x = filter_w / 2;</span><br><span class="line"></span><br><span class="line">    int h = src.rows;</span><br><span class="line">    int w = src.cols;</span><br><span class="line"></span><br><span class="line">    double temp;</span><br><span class="line">    int target_x;</span><br><span class="line">    int target_y;</span><br><span class="line">    bool flag;</span><br><span class="line">    for (int i = 0; i &lt; h; i++) &#123;</span><br><span class="line">        auto *data = dst.ptr&lt;uchar&gt;(i);</span><br><span class="line">        for (int j = 0; j &lt; w; j++) &#123;</span><br><span class="line">            temp = 0;</span><br><span class="line">            for (int k = 0; k &lt; filter_h; k++) &#123;</span><br><span class="line">                for (int l = 0; l &lt; filter_w; l++) &#123;</span><br><span class="line">                    target_x = j - radius_x + l;</span><br><span class="line">                    target_y = i - radius_y + k;</span><br><span class="line"></span><br><span class="line">                    flag = target_x &gt;= 0 and target_x &lt; h and target_y &gt;= 0 and target_y &lt; w;</span><br><span class="line">                    if (flag) &#123;</span><br><span class="line">                        auto *src_data = src.ptr&lt;uchar&gt;(target_y);</span><br><span class="line">                        auto *filter_data = filter.ptr&lt;double&gt;(k);</span><br><span class="line">                        temp += (int) src_data[target_x] * filter_data[l];</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            data[j] = (uchar) round(temp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">double GaussianFilter::gaussFilter2d(double x, double y, double sigma) &#123;</span><br><span class="line">//    double weight = 1 / (sqrt(2 * M_PI) * sigma);</span><br><span class="line">//    double temp = -1 * (x * x + y * y) / (2 * sigma * sigma);</span><br><span class="line">//    return weight * exp(temp);</span><br><span class="line">    return exp(-1 * (x * x + y * y) / (2 * sigma * sigma));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>参考：</p>
<p><a href="https://blog.csdn.net/lwx309025167/article/details/82761474" target="_blank" rel="noopener">算法优化学习：（二）二维高斯滤波的引入</a></p>
<p><a href="https://blog.csdn.net/zxpddfg/article/details/45912561" target="_blank" rel="noopener">二维高斯模糊和可分离核形式的快速实现</a></p>
<p>二维高斯分布公式可由两个一维高斯分布公式组成：</p>
<script type="math/tex; mode=display">
G(x,y) = G(x)\cdot G(y)</script><p>利用二维高斯模板对图像进行滤波：</p>
<script type="math/tex; mode=display">
f(x,y) = \frac {1}{\sum^{r}_{u=-r}\sum^{r}_{v=-r}G(u,v)}
\cdot \sum^{r}_{u=-r}\sum^{r}_{v=-r}G(u,v)\cdot I(x+u,y+v)</script><p>其中$I()$表示图像像素值，$r$表示模板半径，模板长宽为$2\cdot r+1$</p>
<p>利用一维高斯分布公式进行优化如下：</p>
<script type="math/tex; mode=display">
f(x,y) = \frac {1}{\sum^{r}_{u=-r}\sum^{r}_{v=-r}G(u,v)}
\cdot \sum^{r}_{u=-r}\sum^{r}_{v=-r}G(u,v)\cdot I(x+u,y+v)\\
=\frac {1}{\sum^{r}_{u=-r}\sum^{r}_{v=-r}G(u)\cdot G(v)}
\cdot \sum^{r}_{u=-r}\sum^{r}_{v=-r}G(u)\cdot G(v)\cdot I(x+u,y+v)\\
=\frac {1}{\sum^{r}_{u=-r}G(u)\cdot \sum^{r}_{v=-r} G(v)}
\cdot \sum^{r}_{u=-r}G(u)\cdot \sum^{r}_{v=-r} G(v)\cdot I(x+u,y+v)\\
=\frac {1}{\sum^{r}_{v=-r} G(v)}\cdot \sum^{r}_{u=-r}G(u) [
\frac {1}{\sum^{r}_{u=-r}G(u)}\cdot \sum^{r}_{v=-r} G(v)\cdot I(x+u,y+v)]</script><p>可以先在垂直方向对图像进行一维高斯变换，再在水平方向对图像进行一维高斯变换</p>
<p>按照原先的二维模板计算方式，对单个图像像素进行计算需要$(2\cdot r+1)^{2}$次乘法以及$(2\cdot r+1)^{2}-1$次加法，时间复杂度为$O(n^{2})$</p>
<p>如果转换成一维模板计算，先进行垂直方向计算，需要$(2\cdot r+1)$次乘法，$(2\cdot r+1)-1$次加法。对于水平方向计算类似，总共需要$2\cdot(2\cdot r+1)$次乘法，$2\cdot(2\cdot r+1)-2$次加法，时间复杂度为$O(n)$</p>
<p><em>单单对单个图像像素进行计算不太好理解，好像使用一维模板计算的只是沿该像素点水平和垂直的领域像素，没有涉及到对角领域像素；如果扩大到整副图像就好理解了</em></p>
<p>修改后的<code>GaussianFilter</code>实现如下：</p>
<ol>
<li><code>getGaussianKernel</code>生成一维高斯算子，参考<code>OpenCV</code>实现使用固定模板</li>
<li><code>GaussianBlur</code>先对水平方向进行高斯滤波，再对垂直方向进行高斯滤波</li>
</ol>
<p>完整类定义如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//</span><br><span class="line">// Created by zj on 19-8-13.</span><br><span class="line">//</span><br><span class="line"></span><br><span class="line">#ifndef OPENCV_PROJECT_GAUSSIANFILTER_H</span><br><span class="line">#define OPENCV_PROJECT_GAUSSIANFILTER_H</span><br><span class="line"></span><br><span class="line">#include &lt;cmath&gt;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;opencv2/opencv.hpp&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line">using namespace cv;</span><br><span class="line"></span><br><span class="line">class GaussianFilter &#123;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">    /**</span><br><span class="line">     * 高斯滤波操作</span><br><span class="line">     */</span><br><span class="line">    void GaussianBlur(Mat src, Mat &amp;dst, Size ksize, double sigmaX, double sigmaY = 0);</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 生成一维高斯滤波内核</span><br><span class="line">     */</span><br><span class="line">    Mat getGaussianKernel(int ksize, double sigma, int ktype = CV_64F);</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">    /**</span><br><span class="line">     * 二维卷积操作</span><br><span class="line">     * 边界使用0填充</span><br><span class="line">     */</span><br><span class="line">    void Conv2d(Mat src, Mat &amp;dst, Mat filter);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#endif //OPENCV_PROJECT_GAUSSIANFILTER_H</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//</span><br><span class="line">// Created by zj on 19-8-13.</span><br><span class="line">//</span><br><span class="line"></span><br><span class="line">#include &quot;GaussianFilter.h&quot;</span><br><span class="line"></span><br><span class="line">void GaussianFilter::GaussianBlur(Mat src, Mat &amp;dst, Size ksize, double sigmaX, double sigmaY) &#123;</span><br><span class="line">    sigmaY = sigmaY == 0 ? sigmaX : sigmaY;</span><br><span class="line"></span><br><span class="line">    int channels = src.channels();</span><br><span class="line">    Mat kernel_x = getGaussianKernel(ksize.width, sigmaX).reshape(1, 1);</span><br><span class="line">    Mat kernel_y = getGaussianKernel(ksize.height, sigmaY);</span><br><span class="line"></span><br><span class="line">    Mat tempImg = src.clone();</span><br><span class="line">    if (channels == 1) &#123;</span><br><span class="line">        Conv2d(src, tempImg, kernel_x);</span><br><span class="line">        Conv2d(tempImg, dst, kernel_y);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        vector&lt;Mat&gt; mats;</span><br><span class="line">        vector&lt;Mat&gt; dstMats;</span><br><span class="line">        split(src, mats);</span><br><span class="line">        for (auto srcImg: mats) &#123;</span><br><span class="line">            Mat dstImg = srcImg.clone();</span><br><span class="line">            Conv2d(srcImg, tempImg, kernel_x);</span><br><span class="line">            Conv2d(tempImg, dstImg, kernel_y);</span><br><span class="line"></span><br><span class="line">            dstMats.push_back(dstImg.clone());</span><br><span class="line">        &#125;</span><br><span class="line">        merge(dstMats, dst);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Mat GaussianFilter::getGaussianKernel(int ksize, double sigma, int ktype) &#123;</span><br><span class="line">    const int SMALL_GAUSSIAN_SIZE = 7;</span><br><span class="line">    static const float small_gaussian_tab[][SMALL_GAUSSIAN_SIZE] =</span><br><span class="line">            &#123;</span><br><span class="line">                    &#123;1.f&#125;,</span><br><span class="line">                    &#123;0.25f,    0.5f,      0.25f&#125;,</span><br><span class="line">                    &#123;0.0625f,  0.25f,     0.375f,   0.25f,    0.0625f&#125;,</span><br><span class="line">                    &#123;0.03125f, 0.109375f, 0.21875f, 0.28125f, 0.21875f, 0.109375f, 0.03125f&#125;</span><br><span class="line">            &#125;;</span><br><span class="line"></span><br><span class="line">    const float *fixed_kernel = ksize % 2 == 1 &amp;&amp; ksize &lt;= SMALL_GAUSSIAN_SIZE &amp;&amp; sigma &lt;= 0 ?</span><br><span class="line">                                small_gaussian_tab[ksize &gt;&gt; 1] : nullptr;</span><br><span class="line"></span><br><span class="line">    Mat kernel = Mat(ksize, 1, ktype);</span><br><span class="line">    auto *cd = kernel.ptr&lt;double&gt;();</span><br><span class="line"></span><br><span class="line">    double sigmaX = sigma &gt; 0 ? sigma : ((ksize - 1) * 0.5 - 1) * 0.3 + 0.8;</span><br><span class="line">    double scale2X = -0.5 / (sigmaX * sigmaX);</span><br><span class="line">    double sum = 0;</span><br><span class="line"></span><br><span class="line">    int radius = ksize / 2;</span><br><span class="line">    int i;</span><br><span class="line">    for (i = 0; i &lt; ksize; i++) &#123;</span><br><span class="line">        double x = i - radius;</span><br><span class="line">        double t = fixed_kernel ? (double) fixed_kernel[i] : std::exp(scale2X * x * x);</span><br><span class="line"></span><br><span class="line">        cd[i] = t;</span><br><span class="line">        sum += cd[i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sum = 1. / sum;</span><br><span class="line">    for (i = 0; i &lt; ksize; i++) &#123;</span><br><span class="line">        cd[i] *= sum;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return kernel;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void GaussianFilter::Conv2d(Mat src, Mat &amp;dst, Mat filter) &#123;</span><br><span class="line">    int filter_h = filter.rows;</span><br><span class="line">    int filter_w = filter.cols;</span><br><span class="line"></span><br><span class="line">    int radius_y = filter_h / 2;</span><br><span class="line">    int radius_x = filter_w / 2;</span><br><span class="line"></span><br><span class="line">    int h = src.rows;</span><br><span class="line">    int w = src.cols;</span><br><span class="line"></span><br><span class="line">    double temp;</span><br><span class="line">    int target_x;</span><br><span class="line">    int target_y;</span><br><span class="line">    bool flag;</span><br><span class="line">    for (int i = 0; i &lt; h; i++) &#123;</span><br><span class="line">        auto *data = dst.ptr&lt;uchar&gt;(i);</span><br><span class="line">        for (int j = 0; j &lt; w; j++) &#123;</span><br><span class="line">            temp = 0;</span><br><span class="line">            for (int k = 0; k &lt; filter_h; k++) &#123;</span><br><span class="line">                for (int l = 0; l &lt; filter_w; l++) &#123;</span><br><span class="line">                    target_x = j - radius_x + l;</span><br><span class="line">                    target_y = i - radius_y + k;</span><br><span class="line"></span><br><span class="line">                    flag = target_x &gt;= 0 and target_x &lt; h and target_y &gt;= 0 and target_y &lt; w;</span><br><span class="line">                    if (flag) &#123;</span><br><span class="line">                        auto *src_data = src.ptr&lt;uchar&gt;(target_y);</span><br><span class="line">                        auto *filter_data = filter.ptr&lt;double&gt;(k);</span><br><span class="line">                        temp += (int) src_data[target_x] * filter_data[l];</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            data[j] = (uchar) round(temp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;sys/time.h&gt;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;opencv2/opencv.hpp&gt;</span><br><span class="line">#include &quot;GaussianFilter.h&quot;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line">using namespace cv;</span><br><span class="line"></span><br><span class="line">string getMillisecond() &#123;</span><br><span class="line">    struct timeval tv;</span><br><span class="line">    gettimeofday(&amp;tv, NULL);</span><br><span class="line"></span><br><span class="line">    long int ms = tv.tv_sec * 1000 + tv.tv_usec / 1000;</span><br><span class="line">    return to_string(ms);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void opencv_gauss() &#123;</span><br><span class="line">    Mat img = imread(&quot;lena.jpg&quot;);</span><br><span class="line">    if (img.empty()) &#123;</span><br><span class="line">        std::cout &lt;&lt; &quot;error&quot; &lt;&lt; std::endl;</span><br><span class="line">        exit(0);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Mat dst = img.clone();</span><br><span class="line">    GaussianBlur(img, dst, Size(5, 5), 1, 1);</span><br><span class="line"></span><br><span class="line">    imshow(&quot;img&quot;, img);</span><br><span class="line">    imshow(&quot;gauss&quot;, dst);</span><br><span class="line">    waitKey(0);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">void custom_gauss(int ksize = 3, double sigma = 1.0) &#123;</span><br><span class="line">    Mat img = imread(&quot;lena.jpg&quot;);</span><br><span class="line"></span><br><span class="line">    GaussianFilter gaussianFilter;</span><br><span class="line"></span><br><span class="line">    Mat dst1 = img.clone();</span><br><span class="line">    long int start = stol(getMillisecond());</span><br><span class="line">    gaussianFilter.GaussianBlur(img, dst1, Size(ksize, ksize), sigma);</span><br><span class="line">    long int end = stol(getMillisecond());</span><br><span class="line">    cout &lt;&lt; end - start &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    Mat dst2 = img.clone();</span><br><span class="line">    start = stol(getMillisecond());</span><br><span class="line">    GaussianBlur(img, dst2, Size(ksize, ksize), sigma);</span><br><span class="line">    end = stol(getMillisecond());</span><br><span class="line">    cout &lt;&lt; end - start &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    imshow(&quot;img&quot;, img);</span><br><span class="line">    imshow(&quot;dst1&quot;, dst1);</span><br><span class="line">    imshow(&quot;dst2&quot;, dst2);</span><br><span class="line">    waitKey(0);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main() &#123;</span><br><span class="line">    custom_gauss(3, 0.85);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br></pre></td></tr></table></figure>
<p><code>CMakeLists.txt</code>内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cmake_minimum_required(VERSION 3.13)</span><br><span class="line">project(opencv_project)</span><br><span class="line"></span><br><span class="line">set(CMAKE_CXX_STANDARD 11)</span><br><span class="line"></span><br><span class="line">#set(CMAKE_PREFIX_PATH /home/zj/opencv/opencv-4.0.1/install)</span><br><span class="line">find_package( OpenCV REQUIRED )</span><br><span class="line">MESSAGE(&quot;OpenCV version: $&#123;OpenCV_VERSION&#125;&quot;)</span><br><span class="line">include_directories( $&#123;OpenCV_INCLUDE_DIRS&#125; )</span><br><span class="line"></span><br><span class="line">add_executable(opencv_project main.cpp GaussianFilter.cpp GaussianFilter.h)</span><br><span class="line"></span><br><span class="line">target_link_libraries( opencv_project $&#123;OpenCV_LIBS&#125; )</span><br></pre></td></tr></table></figure>
<p>测试结果如下（单位：<code>ms</code>）：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">OpenCV</th>
<th style="text-align:center">自定义</th>
<th style="text-align:center">优化</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">3x3</td>
<td style="text-align:center">4</td>
<td style="text-align:center">67</td>
<td style="text-align:center">64</td>
</tr>
<tr>
<td style="text-align:center">5x5</td>
<td style="text-align:center">6</td>
<td style="text-align:center">182</td>
<td style="text-align:center">94</td>
</tr>
</tbody>
</table>
</div>
<p><em>进一步优化方向是多线程、编译优化、模板查表等</em></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>图像处理</category>
        <category>编程语言</category>
        <category>图像滤波</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>python</tag>
        <tag>opencv</tag>
        <tag>卷积</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>高斯滤波</tag>
      </tags>
  </entry>
  <entry>
    <title>[译]高效的基于图的图像分割</title>
    <url>/posts/44a20d07.html</url>
    <content><![CDATA[<p>论文及C++实现下载地址：<a href="http://cs.brown.edu/people/pfelzens/segment/" target="_blank" rel="noopener">Efficient Graph-Based Image Segmentation
</a></p><a id="more"></a>
<p>摘要</p>
<blockquote>
<p>This paper addresses the problem of segmenting an image into regions. We define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. We then develop an efficient segmentation algorithm based on this predicate, and show that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties. We apply the algorithm to image segmentation using two different kinds of local neighborhoods in constructing the graph, and illustrate the results with both real and synthetic images. The algorithm runs in time nearly linear in the number of graph edges and is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability image regions while ignoring detail in high-variability regions.</p>
</blockquote>
<p>本文讨论了将图像分割成区域的问题。我们定义了一个谓词，用于使用基于图的图像表示来测量两个区域之间边界的证据。然后，我们开发了一种基于该谓词的高效分割算法，并证明了尽管该算法做出贪婪决策，但它产生满足全局属性的分割。将该算法应用于图像分割中，利用两种不同的局部邻域构造图像，并用真实图像和合成图像对结果进行了说明。算法运行时间与图像边缘数呈线性关系，而且在实际应用中也很快。该方法的一个重要特点是在低变率图像区域（<em>低频区域</em>）保留细节，而在高变率区域（<em>高频区域</em>）忽略细节</p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><blockquote>
<p>The problems of image segmentation and grouping remain great challenges for computer vision. Since the time of the Gestalt movement in psychology (e.g., [17]), it has been known that perceptual grouping plays a powerful role in human visual perception. A wide range of computational vision problems could in principle make good use of segmented images, were such segmentations reliably and efficiently computable. For instance intermediate-level vision problems such as stereo and motion estimation require an appropriate region of support for correspondence operations. Spatially non-uniform regions of support can be identified using segmentation techniques. Higher-level problems such as recognition and image indexing can also make use of segmentation results in matching, to address problems such as figure-ground separation and recognition by parts.</p>
</blockquote>
<p>图像分割和分组问题一直是计算机视觉面临的巨大挑战。从心理学的格式塔运动（如[17]）开始，人们就知道知觉组织在人类视觉感知中起着重要作用。如果这种分割是可靠和有效的计算,那么原则上可以在广泛的计算视觉问题中很好地利用分割图像。例如，中级视觉问题，如立体和运动估计，需要一个适当的区域来支持对应操作。空间上不均匀的支持区域可以用分割技术来识别。更高层次的问题，如识别和图像索引，也可以利用分割结果进行匹配，以解决图形-背景分离和部分识别等问题</p>
<blockquote>
<p>Our goal is to develop computational approaches to image segmentation that are broadly useful, much in the way that other low-level techniques such as edge detection are used in a wide range of computer vision tasks. In order to achieve such broad utility, we believe it is important that a segmentation method have the following properties:</p>
</blockquote>
<p>我们的目标是开发出广泛有用的图像分割的计算方法，这与其他低级技术（如边缘检测）在广泛的计算机视觉任务中的使用方式非常相似。为了实现如此广泛的实用性，我们认为分割方法应该具有以下重要特性：</p>
<blockquote>
<ol>
<li><p>Capture perceptually important groupings or regions, which often reflect global aspects of the image. Two central issues are to provide precise characterizations of what is perceptually important, and to be able to specify what a given segmentation technique does. We believe that there should be precise definitions of the properties of a resulting segmentation, in order to better understand the method as well as to facilitate the comparison of different approaches.</p>
</li>
<li><p>Be highly efficient, running in time nearly linear in the number of image pixels. In order to be of practical use, we believe that segmentation methods should run at speeds similar to edge detection or other low-level visual processing techniques, meaning nearly linear time and with low constant factors. For example, a segmentation technique that runs at several frames per second can be used in video processing applications.</p>
</li>
</ol>
</blockquote>
<ol>
<li><p><em>捕捉感知上重要的组织或区域，这些组织或区域通常反映图像的全局内容</em>。有两个核心问题，一是提供对感知重要的东西的精确描述，二是能够指定给定的分割技术所做的工作。我们认为，为了更好地理解该方法，并便于比较不同方法，应该对结果分割的属性有精确的定义</p>
</li>
<li><p><em>高效率运行，即图像像素数与运行时间呈线性关系</em>。为了实际应用，我们认为分割方法应该以类似于边缘检测或其他低级视觉处理技术的速度运行，这意味着几乎是线性时间，具有较低的常数因子。例如，视频处理应用程序中可以使用每秒几帧的分割技术。</p>
</li>
</ol>
<blockquote>
<p>While the past few years have seen considerable progress in eigenvector-based methods of image segmentation (e.g., [14, 16]), these methods are too slow to be practical for many applications. In contrast, the method described in this paper has been used in large-scale image database applications as described in [13]. While there are other approaches to image segmentation that are highly efficient, these methods generally fail to capture perceptually important non-local properties of an image as discussed below. The segmentation technique developed here both captures certain perceptually important non-local image characteristics and is computationally efficient – running in O(n log n) time for n image pixels and with low constant factors, and can run in practice at video rates.</p>
</blockquote>
<p>虽然在过去的几年里，基于特征向量的图像分割方法（如[14，16]）取得了相当大的进展，但这些方法的速度太慢，不适合许多应用。相比之下，本文所述的方法已用于大型图像数据库应用，如[13]所述。虽然有其他方法可以高效地进行图像分割，但这些方法通常无法捕获如下文所述图像中感知重要的非局部特性。本文实现的分割技术不仅捕获了某些重要的感知非局部图像特征，而且计算效率高 - 在O(nlogn)时间内运行n个图像像素，且常数因子较低，可以在实际中以视频速率运行</p>
<blockquote>
<p>As with certain classical clustering methods [15, 19], our method is based on selecting edges from a graph, where each pixel corresponds to a node in the graph, and certain neighboring pixels are connected by undirected edges. Weights on each edge measure the dissimilarity between pixels. However, unlike the classical methods, our technique adaptively adjusts the segmentation criterion based on the degree of variability in neighboring regions of the image. This results in a method that, while making greedy decisions, can be shown to obey certain non-obvious global properties. We also show that other adaptive criteria, closely related to the one developed here, result in problems that are computationally difficult (NP hard).</p>
</blockquote>
<p>与某些经典的聚类方法[15，19]一样，我们的方法基于从图中选择边，其中每个像素对应于图中的一个节点，并且某些相邻像素由无向边连接。每个边上的权重测量像素之间的差异。但是，与传统方法不同，我们的技术根据图像相邻区域的变化程度自适应调整分割标准。这就产生了一种方法，在做出贪婪决定时，可以证明它服从某些不明显的全局属性。我们还表明，与这里开发的自适应标准密切相关的其他自适应标准会导致计算困难（NP困难）的问题</p>
<blockquote>
<p>We now turn to a simple synthetic example illustrating some of the non-local image characteristics captured by our segmentation method. Consider the image shown in the top left of Figure 1. Most people will say that this image has three distinct regions: a rectangular-shaped intensity ramp in the left half, a constant intensity region with a hole on the right half, and a high-variability rectangular region inside the constant region. This example illustrates some perceptually important properties that we believe should be captured by a segmentation algorithm. First, widely varying intensities should not alone be judged as evidence for multiple regions. Such wide variation in intensities occurs both in the ramp on the left and in the high variability region on the right. Thus it is not adequate to assume that regions have nearly constant or slowly varying intensities.</p>
</blockquote>
<p>现在我们来看一个简单的合成例子，说明我们的分割方法捕获的一些非局部图像特征。考虑图1左上角所示的图像。大多数人会说，这幅图像有三个不同的区域：左半部分有一个矩形的强度渐变，右半部分有一个孔的恒定强度区域，以及恒定区域内的高变率矩形区域。这个例子说明了一些我们认为应该由分割算法捕获的重要感知属性。首先，广泛变化的强度不应单独作为多个区域的证据。这种强度的巨大变化既发生在左侧的斜坡上，也发生在右侧的高变率区域。因此，不足以假设区域具有几乎恒定或缓慢变化的强度</p>
<blockquote>
<p>A second perceptually important aspect of the example in Figure 1 is that the three meaningful regions cannot be obtained using purely local decision criteria. This is because the intensity difference across the boundary between the ramp and the constant region is actually smaller than many of the intensity differences within the high variability region. Thus, in order to segment such an image, some kind of adaptive or non-local criterion must be used.</p>
</blockquote>
<p>图1中示例的第二个重要方面是，不能使用纯粹的本地决策标准获得三个有意义的区域。这是因为斜坡和恒定区域之间边界上的强度差实际上小于高变率区域内的许多强度差。因此，为了分割这类图像，必须使用某种自适应或非局部准则</p>
<blockquote>
<p>The method that we introduce in Section 3.1 measures the evidence for a boundary between two regions by comparing two quantities: one based on intensity differences across the boundary, and the other based on intensity differences between neighboring pixels within each region. Intuitively, the intensity differences across the boundary of two regions are perceptually important if they are large relative to the intensity differences inside at least one of the regions. We develop a simple algorithm which computes segmentations using this idea. The remaining parts of Figure 1 show the three largest regions found by our algorithm. Although this method makes greedy decisions, it produces results that capture certain global properties which are derived below and whose consequences are illustrated by the example in Figure 1. The method also runs in a small fraction of a second for the 320 × 240 image in the example.</p>
</blockquote>
<p>我们在第3.1节中介绍的方法通过比较两个数量来测量两个区域之间边界的证据：一个基于边界上的强度差，另一个基于每个区域内相邻像素之间的强度差。直观地说，如果两个区域之间的强度差异相对于其中至少一个区域内的强度差异较大，则两个区域之间的强度差异在感知上是重要的。我们开发了一个简单的算法，使用这个想法来计算分段。图1的其余部分显示了我们的算法找到的三个最大的区域。尽管该方法做出贪婪决定，但它产生的结果捕获了下面派生的某些全局属性，其结果如图1中的示例所示。对于示例中的320×240图像，该方法在不到一秒时间内运行完成</p>
<p><img src="/imgs/基于图的图像分割/figure-1.png" alt></p>
<blockquote>
<p>Figure 1: A synthetic image with three perceptually distinct regions, and the three largest regions found by our segmentation method (image 320 × 240 pixels; algorithm parameters σ = 0.8, k = 300, see Section 5 for an explanation of the parameters).</p>
</blockquote>
<p>图 1：一幅具有三个明显感知区域的合成图像以及我们的分割方法发现的三个最大区域（图像320×240像素；算法参数σ=0.8，k=300，参数解释见第5节）</p>
<blockquote>
<p>The organization of this paper is as follows. In the next Section we discuss some related work, including both classical formulations of segmentation and recent graph-based methods. In Section 3 we consider a particular graph-based formulation of the segmentation problem and define a pairwise region comparison predicate. Then in Section 4 we present an algorithm for efficiently segmenting an image using this predicate, and derive some global properties that it obeys even though it is a greedy algorithm. In Section 5 we show results for a number of images using the image grid to construct a graph-based representation of the image data. Then in Section 6 we illustrate the method using more general graphs, but where the number of edges is still linear in the number of pixels. Using this latter approach yields results that capture high-level scene properties such as extracting a flower bed as a single region, while still preserving fine detail in other portions of the image. In the Appendix we show that a straightforward generalization of the region comparison predicate presented in Section 3 makes the problem of finding a good segmentation NP-hard.</p>
</blockquote>
<p>本文的组织结构如下。在下一节中，我们将讨论一些相关的工作，包括经典的分割公式和最新的基于图的方法。在第3节中，我们考虑了一个特殊的基于图的分割问题公式，并定义了一个成对区域比较谓词。然后，在第4节中，我们提出了一种使用该谓词有效分割图像的算法，并推导出它所遵循的一些全局属性，即使它是贪婪算法。在第5节中，我们展示了使用图像网格构建基于图的图像数据表示的多个图像的结果。然后在第6节中，我们用更一般的图来说明这个方法，但是在图中，边的数量仍然是像素数量的线性。使用后一种方法可以生成捕获高级场景属性的结果，例如将花坛提取为单个区域，同时在图像的其他部分保留精细细节。在附录中，我们证明了第3节中提出的区域比较谓词的一个简单概括使得找到一个好的分割变得NP-困难</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><blockquote>
<p>There is a large literature on segmentation and clustering, dating back over 30 years, with applications in many areas other than computer vision (cf. [9]). In this section we briefly consider some of the related work that is most relevant to our approach: early graph-based methods (e.g., [15, 19]), region merging techniques (e.g., [5, 11]), techniques based on mapping image pixels to some feature space (e.g., [3, 4]) and more recent formulations in terms of graph cuts (e.g., [14, 18]) and spectral methods (e.g., [16]).</p>
</blockquote>
<p>关于分割和聚类的大量文献可以追溯到30多年前，在计算机视觉以外的许多领域都有应用（参见[9]）。在本节中，我们简要地考虑了与我们的方法最相关的一些相关工作：早期基于图的方法（例如[15，19]）、区域合并技术（例如[5，11]）、基于将图像像素映射到某些特征空间的技术（例如[3，4]）以及关于图形切割的更新公式（例如[14，18]）和光谱方法（例如[16]）</p>
<blockquote>
<p>Graph-based image segmentation techniques generally represent the problem in terms of a graph $G = (V, E)$ where each node $v_i ∈ V$ corresponds to a pixel in the image, and the edges in $E$ connect certain pairs of neighboring pixels. A weight is associated with each edge based on some property of the pixels that it connects, such as their image intensities. Depending on the method, there may or may not be an edge connecting each pair of vertices. The earliest graph-based methods use fixed thresholds and local measures in computing a segmentation. The work of Zahn[19] presents a segmentation method based on the minimum spanning tree (MST) of the graph. This method has been applied both to point clustering and to image segmentation. For image segmentation the edge weights in the graph are based on the differences between pixel intensities, whereas for point clustering the weights are based on distances between points.</p>
</blockquote>
<p>基于图的图像分割技术通常用图$G=(V，E)$来表示问题，其中每个节点$v_{i}∈V$对应于图像中的一个像素，$E$中的边缘连接包含某些相邻像素对。与每条边关联的权重是基于边所连接像素的某些属性（例如图像强度）的。根据方法的不同，连接每对顶点的边可能存在，也可能不存在。最早的基于图的方法在计算分割时使用固定阈值和局部度量。Zahn[19]的工作提出了一种基于图的最小生成树（MST）的分割方法。该方法既适用于点聚类，也适用于图像分割。对于图像分割，图中的边缘权重基于像素强度之间的差异，而对于点聚类，权重基于点之间的距离</p>
<blockquote>
<p>The segmentation criterion in Zahn’s method is to break MST edges with large weights. The inadequacy of simply breaking large edges, however, is illustrated by the example in Figure 1. As mentioned in the introduction, differences between pixels within the high variability region can be larger than those between the ramp and the constant region. Thus, depending on the threshold, simply breaking large weight edges would either result in the high variability region being split into multiple regions, or would merge the ramp and the constant region together. The algorithm proposed by Urquhart [15] attempts to address this shortcoming by normalizing the weight of an edge using the smallest weight incident on the vertices touching that edge. When applied to image segmentation problems, however, this is not enough to provide a reasonable adaptive segmentation criterion. For example, many pixels in the high variability region of Figure 1 have some neighbor that is highly similar.</p>
</blockquote>
<p>Zahn方法中的分割标准是用较大的权重分割MST边缘。然而，图1中的示例说明了简单地破坏大边缘的不足。正如在引言中提到的，高变率区域内像素之间的差异可能大于渐变和恒定区域之间的差异。因此，根据阈值的不同，简单地打破较大的权重边缘将导致高变率区域分割为多个区域，或者将斜坡和常量区域合并在一起。Urquhart[15]提出的算法试图通过使用与边缘接触的顶点上的最小权重来规范化边缘的权重来解决这一缺点。然而，当应用于图像分割问题时，这不足以提供一个合理的自适应分割标准。例如，图1的高可变性区域中的许多像素具有高度相似的邻居</p>
<blockquote>
<p>Another early approach to image segmentation is that of splitting and merging regions according to how well each region fits some uniformity criterion (e.g., [5,11]). Generally these uniformity criteria obey a subset property, such that when a uniformity predicate $U (A)$ is true for some region $A$ then $U (B)$ is also true for any $B ⊂ A$. Usually such criteria are aimed at finding either uniform intensity or uniform gradient regions. No region uniformity criterion that has been proposed to date could be used to correctly segment the example in Figure 1, due to the high variation region. Either this region would be split into pieces, or it would be merged with the surrounding area.</p>
</blockquote>
<p>另一种早期的图像分割方法是根据每个区域符合某种均匀性标准的程度来分割和合并区域（例如[5,11]）。一般来说，这些一致性标准服从一个子集属性，当某个区域$A$的一致性谓词$U(A)$为真时，则任何$B ⊂ A$的一致性谓词$U(b)$也为真。通常，这些标准旨在寻找均匀强度或均匀梯度区域。由于存在较大的变化区域，目前还没有一个区域均匀性标准可用于正确分割图1中的示例。要么将这个区域分割成若干块，要么将其与周围区域合并</p>
<blockquote>
<p>A number of approaches to segmentation are based on finding compact clusters in some feature space (cf. [3, 9]). These approaches generally assume that the image is piecewise constant, because searching for pixels that are all close together in some feature space implicitly requires that the pixels be alike (e.g., similar color). A recent technique using feature space clustering [4] first transforms the data by smoothing it in a way that preserves boundaries between regions. This smoothing operation has the overall effect of bringing points in a cluster closer together. The method then finds clusters by dilating each point with a hypersphere of some fixed radius, and finding connected components of the dilated points. This technique for finding clusters does not require all the points in a cluster to lie within any fixed distance. The technique is actually closely related to the region comparison predicate that we introduce in Section 3.1, which can be viewed as an adaptive way of selecting an appropriate dilation radius. We return to this issue in Section 6.</p>
</blockquote>
<p>许多分割方法都是基于在某些特征空间中找到紧密的聚类（参见[3，9]）。这些方法通常假定图像是分段不变的，因为在某些特征空间中搜索所有相邻的像素隐含地要求像素相同（例如，相似的颜色）。最近的一种使用特征空间聚类的技术[4]首先通过平滑操作来转换数据以保留区域之间的边界。这种平滑操作的总体效果是使同一聚类中的点更靠近。然后，该方法通过用一个固定半径的超球体来扩张每个点，并找到扩张点的连接组件来找到聚类。这种寻找聚类的技术不需要聚类中位于固定距离内的所有点。该技术实际上与我们在第3.1节中介绍的区域比较谓词密切相关，它可以被视为选择适当扩张半径的一种自适应方法。我们将在第6节中讨论这个问题</p>
<blockquote>
<p>Finally we briefly consider a class of segmentation methods based on finding minimum cuts in a graph, where the cut criterion is designed in order to minimize the similarity between pixels that are being split. Work by Wu and Leahy [18] introduced such a cut criterion, but it was biased toward finding small components. This bias was addressed with the normalized cut criterion developed by Shi and Malik [14], which takes into account self-similarity of regions. These cut-based approaches to segmentation capture non-local properties of the image, in contrast with the early graph-based methods. However, they provide only a characterization of each cut rather than of the final segmentation.</p>
</blockquote>
<p>最后，我们简单地考虑了一类基于在图中找到最小分割集的分割方法，分割准则是最小化被分割像素之间的相似性。Wu和Leahy[18]的工作引入了这样一个切割标准，但它倾向于寻找小部件。利用Shi和Malik[14]提出的标准化切割标准解决了这种偏差，该标准考虑了区域的自相似性。与早期的基于图的分割方法相比，这些基于切割的分割方法捕获了图像的非局部特性。但是，它们只提供每个切割的特征，而不是最终分割的特征</p>
<blockquote>
<p>The normalized cut criterion provides a significant advance over the previous work in [18], both from a theoretical and practical point of view (the resulting segmentations capture intuitively salient parts of an image). However, the normalized cut criterion also yields an NP-hard computational problem. While Shi and Malik develop approximation methods for computing the minimum normalized cut, the error in these approximations is not well understood. In practice these approximations are still fairly hard to compute, limiting the method to relatively small images or requiring computation times of several minutes. Recently Weiss [16] has shown how the eigenvector-based approximations developed by Shi and Malik relate to more standard spectral partitioning methods on graphs. However, all such methods are too slow for many practical applications.</p>
</blockquote>
<p>从理论和实践的角度来看，归一化切割标准比[18]中之前的工作有了显著的进步（由此产生的分割可以直观地捕获图像的显著部分）。然而，归一化割准则也产生了一个NP-困难的计算问题。尽管Shi和Malik开发了计算最小归一化割集的近似方法，但这些近似中的误差还不太清楚。实际上，这些近似值仍然很难计算，将该方法限制在相对较小的图像上，或者需要几分钟的计算时间。最近，Weiss[16]已经展示了Shi和Malik开发的基于特征向量的近似与更标准的图上光谱划分方法的关系。然而，对于许多实际应用来说，所有这些方法都太慢了</p>
<blockquote>
<p>An alternative to the graph cut approach is to look for cycles in a graph embedded in the image plane. For example in [10] the quality of each cycle is normalized in a way that is closely related to the normalized cuts approach.</p>
</blockquote>
<p>另一种图切割方法是在嵌入图像平面的图中查找循环。例如，在[10]中每个循环的质量都以与标准化切割方法密切相关的方式进行标准化</p>
<h2 id="基于图的分割"><a href="#基于图的分割" class="headerlink" title="基于图的分割"></a>基于图的分割</h2><blockquote>
<p>Graph-Based Segmentation</p>
<p>We take a graph-based approach to segmentation. Let $G = (V, E)$ be an undirected graph with vertices $v_{i} ∈ V$ , the set of elements to be segmented, and edges $(v_i , v_j ) ∈ E$ corresponding to pairs of neighboring vertices. Each edge $(v_i , v_j ) ∈ E$ has a corresponding weight $w((v_i , v_j ))$, which is a non-negative measure of the dissimilarity between neighboring elements $v_i$ and $v_j$ . In the case of image segmentation, the elements in $V$ are pixels and the weight of an edge is some measure of the dissimilarity between the two pixels connected by that edge (e.g., the difference in intensity, color, motion, location or some other local attribute). In Sections 5 and 6 we consider particular edge sets and weight functions for image segmentation. However, the formulation here is independent of these definitions.</p>
</blockquote>
<p>我们采用了一种基于图的分割方法。 设$G=(V，E)$为顶点为$v_i∈V$的无向图，即要分割的元素集，且边$(v_i，v_j)$对应于相邻顶点对。每个边$(v_i，v_j)∈E$有一个对应的权重$w((v_i，v_j))$，这是相邻元素$v_i$和$v_j$之间差异的非负度量。在图像分割的情况下，$V$中的元素是像素，边的权重是衡量由该边连接的两个像素之间差异性的某种度量（例如，强度、颜色、运动、位置或其他局部属性的差异）。在第5和第6节中，我们考虑了用于图像分割的特定边集和权重函数。然而，这里的公式独立于这些定义</p>
<blockquote>
<p>In the graph-based approach, a segmentation $S$ is a partition of $V$ into components such that each component (or region) $C ∈ S$ corresponds to a connected component in a graph ${G}’ = (V, {E}’)$, where ${E}’ ⊆ E$. In other words, any segmentation is induced by a subset of the edges in $E$. There are different ways to measure the quality of a segmentation but in general we want the elements in a component to be similar, and elements in different components to be dissimilar. This means that edges between two vertices in the same component should have relatively low weights, and edges between vertices in different components should have higher weights.</p>
</blockquote>
<p>在基于图的方法中，分割$S$将$V$分割成若干个分量，使得每个分量（或区域）$C∈S$对应于图中的一个连通分量$G’=（V，E’）$，其中$E’ \in E$。换句话说，任何分割都是$E$的一个子集。有不同的方法来衡量分割的质量，但一般来说，我们希望一个分量中的元素相似，而不同分量中的元素有差异。这意味着同一分量中两个顶点之间的边应该具有相对较低的权重，而不同分量中顶点之间的边应该具有较高的权重</p>
<h3 id="成对区域比较渭词"><a href="#成对区域比较渭词" class="headerlink" title="成对区域比较渭词"></a>成对区域比较渭词</h3><blockquote>
<p>Pairwise Region Comparison Predicate</p>
<p>In this section we define a predicate, $D$, for evaluating whether or not there is evidence for a boundary between two components in a segmentation (two regions of an image). This predicate is based on measuring the dissimilarity between elements along the boundary of the two components relative to a measure of the dissimilarity among neighboring elements within each of the two components. The resulting predicate compares the inter-component differences to the within component differences and is thereby adaptive with respect to the local characteristics of the data.</p>
</blockquote>
<p>在本节中，我们定义一个谓词$D$，用于评估分割中两个分量（图像的两个区域）之间是否存在边界的证据。相对于测量两个分量中每个分量内相邻元素之间的差异性，这个谓词是基于测量沿两个分量边界的元素之间的差异性。结果谓词将分量间差异与分量内差异进行比较，从而对数据的局部特征进行自适应</p>
<blockquote>
<p>We define the <em>internal difference</em> of a component $C ⊆ V$ to be the largest weight in the minimum spanning tree of the component, $MST(C, E)$. That is,</p>
</blockquote>
<p>我们将分量$C ⊆ V$的<em>内部差异</em>定义为分量的最小生成树$MST(C, E)$中的最大权重。也就是说，</p>
<script type="math/tex; mode=display">
Int(C) = \max_{e\in MST(C,E)} w(e)</script><blockquote>
<p>One intuition underlying this measure is that a given component C only remains connected when edges of weight at least Int(C) are considered.</p>
</blockquote>
<p>这个度量的一个直觉是，给定的分量$C$只有在边的最大权重值至少为$Int(C)$时才保持连接</p>
<blockquote>
<p>We define the difference between two components $C_1, C_2 ⊆ V$ to be the minimum weight edge connecting the two components. That is,</p>
</blockquote>
<p>我们将两个分量$C_1，C_2\in V$之间的差异定义为连接两个分量的边的最小权重。也就是说，</p>
<script type="math/tex; mode=display">
Dif(C_{1}, C_{2}) = \min_{v_{i}\in C_{1}, v_{j}\in C_{2},(v_{i},v_{j})\in E} w((v_{i}, v_{j}))</script><blockquote>
<p>If there is no edge connecting $C_1$ and $C_2$ we let $Dif(C_1, C_2)=∞$. This measure of difference could in principle be problematic, because it reflects only the smallest edge weight between two components. In practice we have found that the measure works quite well in spite of this apparent limitation. Moreover, changing the definition to use the median weight, or some other quantile, in order to make it more robust to outliers, makes the problem of finding a good segmentation NP-hard, as discussed in the Appendix. Thus a small change to the segmentation criterion vastly changes the difficulty of the problem.</p>
</blockquote>
<p>如果$C_{1}$和$C_{2}$之间没有边连接在一起，那么设置$Dif(C_1, C_2)=∞$。原则上，这种差异度量可能存在问题，因为它只反映连接两个分量的边的最小权重。在实践中，我们发现，尽管存在这一明显的局限性，但这一措施仍非常有效。此外，使用中间权重或其他分位数来更改定义以使其对异常值更为健壮，这些操作都会使得找到一个好的分割变得NP-困难，如附录中所述。因此，对分割标准的微小改变都会极大地改变问题的难度</p>
<blockquote>
<p>The region comparison predicate evaluates if there is evidence for a boundary between a pair or components by checking if the difference between the components, $Dif(C_1, C_2)$, is large relative to the internal difference within at least one of the components, $Int(C_1)$ and $Int(C_2)$. A threshold function is used to control the degree to which the difference between components must be larger than minimum internal difference. We define the pairwise comparison predicate as,</p>
</blockquote>
<p>区域比较谓词通过检查分量间差异$Dif(C_1, C_2)$是否比至少一个分量($Int(C_1)$, $Int(C_2)$)的内部差异大来评估是否存在一对或多个分量之间边界的证据。阈值函数用于控制分量间差异必须大于最小内部差异的程度。我们将成对比较谓词定义为（<em>$D$为$true$表示分量间存在边界</em>），</p>
<script type="math/tex; mode=display">
D(C_{1}, C_{2}) =
\left\{\begin{matrix}
true & if Dif(C_{1}, C_{2}) >M Int(C_{1}, C_{2})\\
false & otherwise
\end{matrix}\right.</script><blockquote>
<p>where the minimum internal difference, $M Int$, is defined as,</p>
</blockquote>
<p>其中最小内部差异$M Int$定义如下,</p>
<script type="math/tex; mode=display">
M Int(C_1, C_2) = min(Int(C_1) + τ(C_1), Int(C_2) + τ(C_2)).</script><blockquote>
<p>The threshold function $τ$ controls the degree to which the difference between two components must be greater than their internal differences in order for there to be evidence of a boundary between them (D to be true). For small components, $Int(C)$ is not a good estimate of the local characteristics of the data. In the extreme case, when $|C| = 1$, $Int(C) = 0$. Therefore, we use a threshold function based on the size of the component,</p>
</blockquote>
<p>阈值函数$τ$控制两个分量之间的差异必须大于其内部差异的程度，以便有证据表明它们之间存在边界（$D$为真）。 对于小分量，$int(C)$不是对数据本地特性的良好估计。在极端情况下，当$|C| = 1$时，$int(C)=0$。因此，我们使用基于分量大小的阈值函数,</p>
<script type="math/tex; mode=display">
τ(C) = k / |C|</script><blockquote>
<p>where $|C|$ denotes the size of $C$, and $k$ is some constant parameter. That is, for small components we require stronger evidence for a boundary. In practice $k$ sets a scale of observation, in that a larger $k$ causes a preference for larger components. Note, however, that $k$ is not a minimum component size. Smaller components are allowed when there is a sufficiently large difference between neighboring components.</p>
</blockquote>
<p>其中$|C|$表示$C$的大小（<em>像素个数</em>），$k$是常数参数。也就是说，对于小分量，我们需要更有力的边界证据。在实践中，$k$设置了一个观察尺度，因为较大的$k$会导致对较大分量的偏好。但是，请注意，$k$不是最小分量大小（<em>像素个数</em>）。当相邻分量之间存在足够大的差异时，允许使用较小的分量</p>
<blockquote>
<p>Any non-negative function of a single component can be used for $τ$ without changing the algorithmic results in Section 4. For instance, it is possible to have the segmentation method prefer components of certain shapes, by defining a $τ$ which is large for components that do not fit some desired shape and small for ones that do. This would cause the segmentation algorithm to aggressively merge components that are not of the desired shape. Such a shape preference could be as weak as preferring components that are not long and thin (e.g., using a ratio of perimeter to area) or as strong as preferring components that match a particular shape model. Note that the result of this would not solely be components of the desired shape, however for any two neighboring components one of them would be of the desired shape.</p>
</blockquote>
<p>在不改变第4节中算法结果的情况下，可以将单个分量的任何非负函数用于$τ$。例如，通过定义一个$τ$，可以使分割方法更喜欢某些形状的分量，该$τ$对于不适合某个所需形状的分量大，对于适合某个形状的分量小。这将导致分割算法积极地合并不符合所需形状的分量。这种形状偏好可能弱于不长和薄的首选分量（例如，使用周长与面积的比率），或强于匹配特定形状模型的首选分量。请注意，这样做的结果不仅仅是所需形状的分量，但是对于任何两个相邻的分量，其中一个将是所需形状</p>
<h2 id="算法及其性质"><a href="#算法及其性质" class="headerlink" title="算法及其性质"></a>算法及其性质</h2><blockquote>
<p>The Algorithm and Its Properties</p>
<p>In this section we describe and analyze an algorithm for producing a segmentation using the decision criterion $D$ introduced above. We will show that a segmentation produced by this algorithm obeys the properties of being neither <em>too coarse</em> nor <em>too fine</em>, according to the following definitions.</p>
</blockquote>
<p>在本节中，我们描述并分析了一种使用上述决策标准$D$生成分割的算法。我们将证明，根据以下定义，该算法生成的分割遵循既不<em>太粗</em>也不<em>太细</em>的特性</p>
<blockquote>
<p><strong>Definition 1</strong> <em>A segmentation $S$ is too fine if there is some pair of regions $C_1, C_2 ∈ S$ for which there is no evidence for a boundary between them.</em></p>
</blockquote>
<p><strong>定义 1</strong> <em>如果没有证据表明一些区域对$C_1, C_2 ∈ S$中的两个区域之间存在边界，那么分割$S$就太精细了</em></p>
<blockquote>
<p>In order to define the complementary notion of what it means for a segmentation to be too coarse (to have too few components), we first introduce the notion of a <em>refinement</em> of a segmentation. Given two segmentations $S$ and $T$ of the same base set, we say that $T$ is a refinement of $S$ when each component of $T$ is contained in (or equal to) some component of $S$. In addition, we say that $T$ is a <em>proper</em> refinement of $S$ when $T \neq S$.</p>
</blockquote>
<p>为了定义分割过于粗糙（组件太少）意味着什么的互补概念，我们首先引入分割<em>细化</em>的概念。给定两个相同基集的分段$S$和$T$，当$T$的每个分量都包含在$S$的某个分量中（或等于）时，我们说$T$是$S$的细化。另外，当$T \neq S$时，我们认为$T$是$S$的一个适当的细化</p>
<blockquote>
<p><strong>Definition 2</strong> <em>A segmentation $S$ is</em> too coarse <em>when there exists a proper refinement of $S$ that is not too fine.</em></p>
</blockquote>
<p><strong>定义 2</strong> <em>当存在不太精细的适当细化时，分割</em>$S$太粗糙</p>
<blockquote>
<p>This captures the intuitive notion that if regions of a segmentation can be split and yield a segmentation where there is evidence for a boundary between all pairs of neighboring regions, then the initial segmentation has too few regions.</p>
</blockquote>
<p>这捕捉到了一个直观的概念，即如果一次分割后的区域还可以被分割，并且再次分割后有证据表明所有相邻区域对之间存在边界，那么初始分割的区域太少</p>
<blockquote>
<p>Two natural questions arise about segmentations that are neither too coarse nor too fine, namely whether or not one always exists, and if so whether or not it is unique. First we note that in general there can be more than one segmentation that is neither too coarse nor too fine, so such a segmentation is not unique. On the question of existence, there is always some segmentation that is both not too coarse and not too fine, as we now establish.</p>
</blockquote>
<p>对于既不太粗也不太细的分割，会出现两个自然的问题，即是否总是存在一次分割操作，如果存在，是否是唯一一次分割（<em>一次分割操作后就完成了</em>）。首先，我们注意到，一般来说，可以有多次既不太粗也不太细的分割，因此这样的分割不是唯一的。在是否存在的问题上，总是存在一些既不太粗糙也不太精细的分割，正如我们现在所确定的</p>
<blockquote>
<p><strong>Property 1</strong> <em>For any (finite) graph $G = (V, E)$ there exists some segmentation $S$ that is neither too coarse nor too fine.</em></p>
</blockquote>
<p><strong>属性一</strong> <em>对于任何（有限）图$G=(V，E)$，都存在一些既不太粗糙也不太精细的分割$S$</em></p>
<blockquote>
<p>It is easy to see why this property holds. Consider the segmentation where all the elements are in a single component. Clearly this segmentation is not too fine, because there is only one component. If the segmentation is also not too coarse we are done. Otherwise, by the definition of what it means to be too coarse there is a proper refinement that is not too fine. Pick one of those refinements and keep repeating this procedure until we obtain a segmentation that is not too coarse. The procedure can only go on for n−1 steps because whenever we pick a proper refinement we increase the number of components in the segmentation by at least one, and the finest segmentation we can get is the one where every element is in its own component.</p>
</blockquote>
<p>很容易看出这个属性为什么会存在。考虑所有元素都在单个分量中的分割。显然，这种细分并不太精细，因为只有一个分量。如果分割也不太粗糙，我们就完成了。否则，通过太粗糙的定义可知需要有一个适当的细化。选择其中一个分量进行细化，并不断重复这个过程，直到我们得到一个不太粗糙的分割。这个过程最多进行n-1个步骤，因为每当我们选择分量进行适当的细化，我们都会将分割后的分量数量至少增加一个，我们可以得到的最好的分割是每个元素都在其自己的分量中</p>
<blockquote>
<p>We now turn to the segmentation algorithm, which is closely related to Kruskal’s algorithm for constructing a minimum spanning tree of a graph (cf. [6]). It can be implemented to run in $O(m log m)$ time, where $m$ is the number of edges in the graph.</p>
</blockquote>
<p>我们现在讨论的是分割算法，它与构建图的最小生成树的Kruskal算法密切相关（参见[6]）。它可以实现在$O(mlogm)$时间内运行，其中$m$是图的边数</p>
<p><img src="/imgs/基于图的图像分割/alg-1.png" alt></p>
<blockquote>
<p><strong>Algorithm 1</strong> <em>Segmentation algorithm</em></p>
</blockquote>
<p><strong>算法 1</strong> <em>分割算法</em></p>
<blockquote>
<p>The input is a graph $G = (V, E)$, with $n$ vertices and $m$ edges. The output is a segmentation of $V$ into components $S = (C_1 , . . . , C_r)$.</p>
</blockquote>
<p>输入是一个图$G=(V，E)$，有$n$个顶点和$m$条边。输出是将$V$分割成分量$S=(C_1,…,C_r)$</p>
<blockquote>
<ol>
<li>Sort $E$ into $π = (o_1 , . . . , o_m )$, by non-decreasing edge weight.</li>
<li>Start with a segmentation $S_0$ , where each vertex $v_i$ is in its own component.</li>
<li>Repeat step $3$ for $q = 1, . . . , m$.</li>
<li>Construct $S^q$ given $S^{q−1}$ as follows. Let $v_i$ and $v_j$ denote the vertices connected by the $q$-th edge in the ordering, i.e., $o_q = (v_i , v_j)$. If $v_i$ and $v_j$ are in disjoint components of $S^{q−1}$ and $w(o_q)$ is small compared to the internal difference of both those components, then merge the two components otherwise do nothing. More formally, let $C_{i}^{q−1}$ be the component of $S^{q−1}$ containing $v_i$ and $C_{j}^{q−1}$ the component containing $v_j$ . If $C_{i}^{q−1}\neq C_{j}^{q−1}$ and $w(o_q) ≤ M Int(C_{i}^{q−1} , C_{j}^{q−1})$ then $S^{q}$ is obtained from $S^{q−1}$ by merging $C_{i}^{q−1}$ and $C_{j}^{q−1}$ . Otherwise $S^{q}=S^{q−1}$.</li>
<li>Return $S=S^{m}$</li>
</ol>
</blockquote>
<ol>
<li>按边权重递增排序边集$E$到$π = (o_1 , . . . , o_m )$</li>
<li>从分割$S_{0}$开始，此时每个顶点$v_i$都表示一个分量</li>
<li>对于$q=1,…,m$，重复第$3$步</li>
<li>给定$S^{q-1}$，按如下方式构造$S^{q}$。$v_{i}$和$v_{j}$表示按序第$q$个条边的顶点，比如$o_{q}=(v_{i}, v_{j})$。如果$v_{i}$和$v_{j}$在$S^{q-1}$的不同分量中，并且$w(o_q)$比这两个分量各自的内部差异还小，那么合并这两个组件，否则不做任何事。更正式地说，$C_{i}^{q-1}$是$S^{q-1}$中包含$v_{i}$的分量，$C_{j}^{q-1}$是包含$v_{j}$的分量。如果$C_{i}^{q-1} \neq C_{j}^{q-1}$并且$w(o_{q}) ≤ M Int(C_{i}^{q−1} , C_{j}^{q−1})$，那么通过合并$C_{i}^{q-1}$和$C_{j}^{q-1}$，从$S^{q-1}$中得到$S^{q}$。否则$S^{q} = S^{q-1}$</li>
<li>返回$S=S^{m}$</li>
</ol>
<blockquote>
<p>We now establish that a segmentation $S$ produced by Algorithm 1 obeys the global properties of being neither too fine nor too coarse when using the region comparison predicate $D$ defined in (3). That is, although the algorithm makes only greedy decisions it produces a segmentation that satisfies these global properties. Moreover, we show that any of the possible non-decreasing weight edge orderings that could be picked in Step 0 of the algorithm produce the same segmentation.</p>
</blockquote>
<p>我们现在证明，当使用（3）中定义的区域比较渭词$D$时，由算法1生成的分割$S$遵循既不太精细也不太粗糙的全局属性。也就是说，虽然算法只做出贪婪决定，但它会产生满足这些全局属性的分割。此外，我们还证明了可以在算法的第0步选择任何可能的递增权重边排序方法最后都会产生相同的分割集</p>
<blockquote>
<p><strong>Lemma 1</strong> <em>In Step $3$ of the algorithm, when considering edge $o_q$ , if two distinct components are considered and not merged then one of these two components will be in the final segmentation. Let $C_{i}^{q−1}$ and $C_{j}^{q−1}$ denote the two components connected by edge $o_{q} = (v_i , v_j)$ when this edge is considered by the algorithm. Then either $C_i = C_{i}^{q−1}$ or $C_{j} = C_{j}^{q−1}$ , where $C_{i}$ is the component containing $v_i$ and $C_j$ is the component containing $v_j$ in the final segmentation $S$.</em></p>
</blockquote>
<p><strong>引理 1</strong> <em>在算法的第$3$步中，对边$o_q$及其连接的两个不同分量进行判断后不执行合并操作，那么其中一个分量必将进入最终分割。假定$C_{i}^{q-1}$和$C_{j}^{q-1}$是由边$o_{q}=(v_{i}, v_{j})$连接的两个分量。那么或者$C_{i}=C_{i}^{q-1}$，或者$C_{j}=C_{j}^{q-1}$会出现在最后的分割集$S$中，其中$C_{i}$是包含$v_{i}$的组件，$C_{j}$是包含$v_{j}$的组件</em></p>
<blockquote>
<p><em>Proof.</em> There are two cases that would result in a merge not happening. Say that it is due to $w(o_q) &gt; Int(C_{i}^{q−1}) + τ(C_{i}^{q−1})$. Since edges are considered in non-decreasing weight order, $w(o_{k}) ≥ w(o_{q})$, for all $k ≥ q + 1$. Thus no additional merges will happen to this component, i.e., $C_i = C_{i}^{q−1}$. The case for $w(o_q) &gt; Int(C_{j}^{q−1}) + τ(C_{j}^{q−1})$ is analogous.</p>
</blockquote>
<p><em>证明</em> 只有两种情况会导致合并不发生。一是因为$w(o_q) &gt; Int(C_{i}^{q−1}) + τ(C_{i}^{q−1})$。因为边是按递增权重进行排序，所以对于所有$k ≥ q + 1$都有$w(o_{k}) ≥ w(o_{q})$。因此，此分量之后也不会发生其他合并，即$C_i = C_{i}^{q−1}$。另一种情况$w(o_q) &gt; Int(C_{j}^{q−1}) + τ(C_{j}^{q−1})$是类似的</p>
<blockquote>
<p>Note that Lemma 1 implies that the edge causing the merge of two components is exactly the minimum weight edge between the components. Thus the edges causing merges are exactly the edges that would be selected by Kruskal’s algorithm for constructing the minimum spanning tree (MST) of each component.</p>
</blockquote>
<p>注意，引理1说明导致两个分量合并的边恰好是分量之间的最小权重边。因此，导致分量合并的边也是Kruskal算法选择用于构造每个分量的最小生成树（MST）的边</p>
<blockquote>
<p><strong>Theorem 1</strong> <em>The segmentation $S$ produced by Algorithm 1 is not too fine according to Definition 1, using the region comparison predicate $D$ defined in (3).</em></p>
</blockquote>
<p><strong>定理1</strong> <em>根据定义1，使用（3）中定义的区域比较谓词$D$，由算法$1$生成的分割$S$没有过于精细</em></p>
<blockquote>
<p><em>Proof.</em> By definition, in order for $S$ to be too fine there is some pair of components for which $D$ does not hold. There must be at least one edge between such a pair of components that was considered in Step 3 and did not cause a merge. Let $o_q = (v_i , v_j)$ be the first such edge in the ordering. In this case the algorithm decided not to merge $C_{i}^{q−1}$ with $C_{j}^{q−1}$ which implies $w(o_q) &gt; M Int(C_{i}^{q−1}, C_{j}^{q−1})$. By Lemma 1 we know that either $C_i = C_{i}^{q−1}$ or $C_{j} = C_{j}^{q−1}$. Either way we see that $w(o_q) &gt; M Int(C_i , C_j)$ implying $D$ holds for $C_i$ and $C_j$, which is a contradiction.</p>
</blockquote>
<p><em>证明</em> 假设$S$过于精细，必定有一些不符合$D$定义的分量对。在步骤3操作过程中必定会出现不会导致这些分量对合并的边。假定$o_q = (v_i , v_j)$是排序中第一个这样的边。如果算法确定不合并$C_{i}^{q-1}$和$C_{j}^{q-1}$，表明$w(o_q) &gt; M Int(C_{i}^{q−1}, C_{j}^{q−1})$。通过引理1可知在最终分割$S$中或者$C_i = C_{i}^{q−1}$，或者$C_{j} = C_{j}^{q−1}$。每种结果都意味着$w(o_q) &gt; M Int(C_i , C_j)$，即表明$D$符合$C_i$和$C_j$设置，这与假设是矛盾的，所以使用（3）中定义的区域比较谓词$D$，由算法$1$生成的分割$S$不会过于精细</p>
<blockquote>
<p><strong>Theorem 2</strong> <em>The segmentation $S$ produced by Algorithm 1 is not too coarse according to Definition 2, using the region comparison predicate $D$ defined in (3).</em></p>
</blockquote>
<p><strong>定理 2</strong> <em>根据定义2，使用（3）中定义的区域比较谓词$D$，通过算法1产生的分段$S$不会太粗糙</em></p>
<blockquote>
<p><em>Proof.</em> In order for $S$ to be too coarse there must be some proper refinement, $T$ , that is not too fine. Consider the minimum weight edge $e$ that is internal to a component $C ∈ S$ but connects distinct components $A, B ∈ T$ . Note that by the definition of refinement $A ⊂ C$ and $B ⊂ C$.</p>
</blockquote>
<p><em>证明</em> 为了使$S$太粗糙，必须有一些适当的不太精细的细化$T$，考虑分量内部$C \in S$的最小权重边$e$，其连接不同分量$A, B ∈ T$。注意，根据精细化定义$A ⊂ C$以及$B ⊂ C$</p>
<blockquote>
<p>Since $T$ is not too fine, either $w(e) &gt; Int(A) + τ (A)$ or $w(e) &gt; Int(B) + τ (B)$. Without loss of generality, say the former is true. By construction any edge connecting $A$ to another sub-component of $C$ has weight at least as large as $w(e)$, which is in turn larger than the maximum weight edge in $MST(A, E)$ because $w(e) &gt; Int(A)$. Thus the algorithm, which considers edges in non-decreasing weight order, must consider all the edges in $MST(A, E)$ before considering any edge from $A$ to other parts of $C$. So the algorithm must have formed $A$ before forming $C$, and in forming $C$ it must have merged $A$ with some other sub-component of $C$. The weight of the edge that caused this merge must be least as large as $w(e)$. However, the algorithm would not have merged $A$ in this case because $w(e) &gt; Int(A) + τ(A)$, which is a contradiction.</p>
</blockquote>
<p>因为$T$不是太精细，所以要么$w(e) &gt; Int(A) + τ (A)$，要么$w(e) &gt; Int(B) + τ (B)$。为了不失一般性，通常说前者是正确的。根据分量间差异$Dif$定义，分量$A$连接$C$的子分量的任一条边的权重都比$w(e)$大，同时因为$w(e)&gt;Int(A)$，比$MST(A, E)$中的最大权重还大。因此，该算法在考虑$A$到$C$的其他子分量之间的任何边之前，必须考虑$MST(A，E)$中的所有边。因此算法在计算$C$之前必须已经计算$A$，在计算$C$的过程中将$A$合并到$C$的子分量中。造成合并发生的边的权重至少和$w(e)$一样大。然而，算法不会合并$A$，因为$w(e) &gt; Int(A) + τ(A)$，这与开头的假定不符。所以使用（3）中定义的区域比较谓词$D$，由算法$1$生成的分割$S$不会过于粗糙</p>
<blockquote>
<p><strong>Theorem 3</strong> <em>The segmentation produced by Algorithm 1 does not depend on which non-decreasing weight order of the edges is used.</em></p>
</blockquote>
<p><strong>定理 3</strong> <em>由算法1产生的分割集不依赖于边的权重递增顺序（应该指的是同一权重的不同边的顺序）</em></p>
<blockquote>
<p><em>Proof.</em> Any ordering can be changed into another one by only swapping adjacent elements. Thus it is sufficient to show that swapping the order of two adjacent edges of the same weight in the non-decreasing weight ordering does not change the result produced by Algorithm 1.</p>
</blockquote>
<p><em>证明</em> 任何顺序都可以通过交换相邻元素而更改为另一个顺序。因此，在非递减权重排序中交换同一权重的两个相邻边的顺序并不改变算法1产生的结果</p>
<blockquote>
<p>Let $e_1$ and $e_2$ be two edges of the same weight that are adjacent in some non-decreasing weight ordering. Clearly if when the algorithm considers the first of these two edges they connect disjoint pairs of components or exactly the same pair of components, then the order in which the two are considered does not matter. The only case we need to check is when $e_1$ is between two components $A$ and $B$ and $e_2$ is between one of these components, say $B$, and some other component $C$.</p>
</blockquote>
<p>假定$e_1$和$e_2$是同一权重的边。显然，如果算法考虑到这两条边中的第一条边时，它们连接不相交的分量对或完全相同的分量对，则考虑这两条边的顺序无关紧要。惟一需要考虑的情况是当边$e_1$连接的是分量$A$和$B$，而$e_2$连接的是其中一个分量，假定为$B$，与另一个分量$C$</p>
<blockquote>
<p>Now we show that $e_1$ causes a merge when considered after $e_2$ exactly when it would cause a merge if considered before $e_2$. First, suppose that $e_1$ causes a merge when considered before $e_2$. This implies $w(e_1) ≤ MInt(A, B)$. If $e_2$ were instead considered before $e_1$, either $e_2$ would not cause a merge and trivially $e_1$ would still cause a merge, or $e_2$ would cause a merge in which case the new component $B ∪ C$ would have $Int(B ∪ C) = w(e_2) = w(e_1)$. So we know $w(e_1) ≤ MInt(A, B ∪ C)$ which implies $e_1$ will still cause a merge. On the other hand, suppose that $e_1$ does not cause a merge when considered before $e_2$. This implies $w(e_1) &gt; MInt(A, B)$. Then either $w(e_1) &gt; Int(A) + τ(A)$, in which case this would still be true if $e_2$ were considered first (because $e_2$ does not touch $A$), or $w(e_1) &gt; Int(B) + τ(B)$. In this second case, if $e_2$ were considered first it could not cause a merge since $w(e_2) = w(e_1)$ and so $w(e_2) &gt; MInt(B, C)$. Thus when considering $e_1$ after $e_2$ we still have $w(e_1) &gt; MInt(A, B)$ and $e_1$ does not cause a merge.</p>
</blockquote>
<p>假定$e_1$不管排序在$e_2$之前还是之后，它都会导致分量合并。首先，当$e_1$排序在$e_2$之前导致了合并。这意味着$w(e_1) ≤ MInt(A, B)$。如果$e_2$排序在$e_1$之前，或者$e_2$无法导致合并从而仍旧是$e_1$导致了合并，或者$e_2$导致了合并，此时对于新分量$B ∪ C$有$Int(B ∪ C) = w(e_2) = w(e_1)$。根据之前分析$w(e_1) ≤ MInt(A, B ∪ C)$所以$e_1$仍旧会产生一次合并。从另一方面来说，假设$e_1$排序在$e_2$之前不会产生合并。这表明$w(e_1) &gt; MInt(A, B)$。那么或者$w(e_1) &gt; Int(A) + τ(A)$，此时如果$e_2$在前面，因为不连接$A$所以不会考虑合并；或者$w(e_1) &gt; Int(B) + τ(B)$，因为$w(e_2) = w(e_1)$，所以$w(e_2) &gt; MInt(B, C)$不会导致合并。因此当$e_1$在$e_2$之后仍旧有$w(e_1) &gt; MInt(A, B)$，所以$e_1$不会造成合并</p>
<h2 id="实施问题和运行时间"><a href="#实施问题和运行时间" class="headerlink" title="实施问题和运行时间"></a>实施问题和运行时间</h2><blockquote>
<p>Implementation Issues and Running Time</p>
<p>Our implementation maintains the segmentation $S$ using a disjoint-set forest with union by rank and path compression (cf. [6]). The running time of the algorithm can be factored into two parts. First in Step 0, it is necessary to sort the weights into non-decreasing order. For integer weights this can be done in linear time using counting sort, and in general it can be done in $O(m log m)$ time using any one of several sorting methods.</p>
</blockquote>
<p>我们的实现使用一个按秩和路径压缩联合的不相交森林来维护分割$S$（参见[6]）。算法的运行时间可分为两部分。首先，在步骤0中，需要将权重排序为非递减顺序。对于整数权重，可以使用计数排序在线性时间内完成，一般来说，可以使用任何一种$O(mlogm)$时间内完成的排序方法</p>
<blockquote>
<p>Steps 1-3 of the algorithm take $O(mα(m))$ time, where $α$ is the very slow-growing inverse Ackerman’s function. In order to check whether two vertices are in the same component we use set-find on each vertex, and in order to merge two components we use use set-union. Thus there are at most three disjoint-set operations per edge. The computation of $MInt$ can be done in constant time per edge if we know $Int$ and the size of each component. Maintaining $Int$ for a component can be done in constant time for each merge, as the maximum weight edge in the $MST$ of a component is simply the edge causing the merge. This is because Lemma 1 implies that the edge causing the merge is the minimum weight edge between the two components being merged. The size of a component after a merge is simply the sum of the sizes of the two components being merged.</p>
</blockquote>
<p>算法步骤1-3的时间复杂度为$O(mα(m))$，其中$α$是非常缓慢增长的逆Ackerman函数。为了检查两个顶点是否在同一分量中，我们在每个顶点上使用set-find，为了合并两个组件，我们使用set-union。如果我们知道$Int$和每个分量的大小，那么每条边的$MInt$的计算可以在常数时间内完成。在每次合并中维持分量的$Int$可以在常数时间内完成，因为分量$MST$中的最大权重边就是导致合并的边。而引理1表明了导致合并的边是被合并的两个分量之间的最小权重边。合并后分量的（<em>数量</em>）大小就是被合并的两个分量大小的总和</p>
<h2 id="网格图的结果"><a href="#网格图的结果" class="headerlink" title="网格图的结果"></a>网格图的结果</h2><blockquote>
<p>Results for Grid Graphs</p>
<p>First we consider the case of monochrome (intensity) images. Color images are handled as three separate monochrome images, as discussed below. As in other graph-based approaches to image segmentation (e.g., [14, 18, 19]) we define an undirected graph $G = (V, E)$, where each image pixel $p_i$ has a corresponding vertex $v_i ∈ V$. The edge set $E$ is constructed by connecting pairs of pixels that are neighbors in an 8-connected sense (any other local neighborhood could be used). This yields a graph where $m = O(n)$, so the running time of the segmentation algorithm is $O(nlogn)$ for $n$ image pixels. We use an edge weight function based on the absolute intensity difference between the pixels connected by an edge,</p>
</blockquote>
<p>首先，我们考虑单色（强度）图像的情况。彩色图像被处理为三个单独的单色图像，如下所述。 与其他基于图的图像分割方法（例如[14，18，19]）一样，我们定义了一个无向图$G=(V，E)$，其中每个图像像素$p_i$都有一个对应的顶点$v_i∈V$。边集$E$是通过连接8连通意义上的相邻像素对来构造的（任何其他的局部邻域都可以使用）。这将生成一个$m=O(n)$的图，因此对于$n$个图像像素，分割算法的运行时间为$O(nlogn)$。我们使用基于边连接像素之间的绝对强度差作为边权重函数，</p>
<script type="math/tex; mode=display">
w((v_{i}, v_{j})) = |I(p_{i}) - I(p_{j})|</script><blockquote>
<p>where $I(p_i)$ is the intensity of the pixel $p_i$. In general we use a Gaussian filter to smooth the image slightly before computing the edge weights, in order to compensate for digitization artifacts. We always use a Gaussian with $σ = 0.8$, which does not produce any visible change to the image but helps remove artifacts.</p>
</blockquote>
<p>其中$I(p_i)$表示像素$p_i$的强度。通常在计算边权重之前使用高斯滤波器平滑图像，以便补偿数字化伪影。我们总是使用$σ=0.8$的高斯滤波，它不会对图像产生任何可见的变化，但有助于消除伪影</p>
<blockquote>
<p>For color images we run the algorithm three times, once for each of the red, green and blue color planes, and then intersect these three sets of components. Specifically, we put two neighboring pixels in the same component when they appear in the same component in all three of the color plane segmentations. Alternatively one could run the algorithm just once on a graph where the edge weights measure the distance between pixels in some color space, however experimentally we obtained better results by intersecting the segmentations for each color plane in the manner just described.</p>
</blockquote>
<p>对于彩色图像，我们分别为红色、绿色和蓝色的颜色平面运行算法，然后交叉这三组分量。具体地说，当两个相邻像素在所有三个颜色平面分割中都属于同一分量时，我们将其最终放置在同一个分量中。或者，可以在一个图上运行该算法一次，其中边权重测量某些颜色空间中像素之间的距离，但是在实验上，我们通过按刚才描述的方式相交每个颜色平面的分割获得了更好的结果</p>
<blockquote>
<p>There is one runtime parameter for the algorithm, which is the value of $k$ that is used to compute the threshold function $τ$. Recall we use the function $τ(C) = k/|C|$ where $|C|$ is the number of elements in $C$. Thus $k$ effectively sets a scale of observation, in that a larger $k$ causes a preference for larger components. We use two different parameter settings for the examples in this section (and throughout the paper), depending on the resolution of the image and the degree to which fine detail is important in the scene. For instance, in the $128 × 128$ images of the COIL database of objects we use $k = 150$. In the $320 × 240$ or larger images, such as the street scene and the baseball player, we use $k = 300$.</p>
</blockquote>
<p>算法有一个运行时参数，即用于计算阈值函数$τ$的$k$值。回想一下，我们使用函数$τ(C) = k/|C|$，其中$|C|$是$C$的元素数。因此$k$有效地设置了一个观察尺度，$k$越大，就越倾向于使用更大的分量。根据图像的分辨率和精细细节在场景中的重要性，我们使用两种不同的参数设置作为本节（以及整个论文）中的示例。例如，对于$128×128$大小的COIL对象数据库图像，我们使用$k=150$。而对于$320 × 240$甚至更大的图像，比如街景和棒球运动员，使用$k=300$（<em>就是小图像的$k$值小，大图像的$k$值大；$k$值就越小越精细</em>）</p>
<blockquote>
<p>The first image in Figure 2 shows a street scene. Note that there is considerable variation in the grassy slope leading up to the fence. It is this kind of variability that our algorithm is designed to handle (recall the high variability region in the synthetic example in Figure 1). The second image shows the segmentation, where each region is assigned a random color. The six largest components found by the algorithm are: three of the grassy areas behind the fence, the grassy slope, the van, and the roadway. The missing part of the roadway at the lower left is a visibly distinct region in the color image from which this segmentation was computed (a spot due to an imaging artifact). Note that the van is also not uniform in color, due to specular reflections, but these are diffuse enough that they are treated as internal variation and incorporated into a single region.</p>
</blockquote>
<p>图2中的第一个图像显示了一个街道场景。请注意，通往围栏的草坡有相当大的变化。我们的算法正是被设计来处理这种可变性（回想一下图1中合成示例中的高可变性区域）。第二幅图像显示了分割，每个区域被分配一个随机颜色。算法发现的六个最大的分量是：栅栏后面的三个草地区域、草地斜坡、货车和道路。左下角的道路缺失部分是彩色图像中一个明显不同的区域，从中可以计算出该分割（图像伪影造成的斑点）。请注意，由于镜面反射，面包车的颜色也不均匀，但这些面包车的漫反射程度足以将其视为内部变化并合并到单个区域中</p>
<blockquote>
<p>The first image in Figure 3 shows two baseball players (from [14]). As in the previous example, there is a grassy region with considerable variation. The uniforms of the players also have substantial variation due to folds in the cloth. The second image shows the segmentation. The six largest components found by the algorithm are: the back wall, the Mets emblem, a large grassy region (including part of the wall under the top player), each of the two players’ uniforms, and a small grassy patch under the second player. The large grassy region includes part of the wall due to the relatively high variation in the region, and the fact that there is a long slow change in intensity (not strong evidence for a boundary) between the grass and the wall. This “boundary” is similar in magnitude to those within the player uniforms due to folds in the cloth.</p>
</blockquote>
<p>图3中的第一张图片显示了两名棒球运动员（来自[14]）。和前面的例子一样，有一个有相当大变化的长满草的区域。由于布料的褶皱，运动员的制服也有很大的变化。第二幅图像显示了分割。算法发现的六个最大的分量是：后墙、大都会会徽、一个大的草区（包括顶部球员下方的部分墙）、两名球员的制服，以及第二名球员下方的一个小草区。由于该区域的变化相对较大，且草与墙之间的强度变化缓慢（没有强有力的边界证据），因此大型草地区域包括墙的一部分。这个“边界”在数量上与球员制服内的边界相似，因为布料上有褶皱</p>
<blockquote>
<p>Figure 4 shows the results of the algorithm for an image of an indoor scene, where both fine detail and larger structures are perceptually important. Note that the segmentation preserves small regions such as the name tags the people are wearing and things behind the windows, while creating single larger regions for high variability areas such as the air conditioning duct near the top of the image, the clothing and the furniture. This image also shows that sometimes small “boundary regions” are found, for example at the edge of the jacket or shirt. Such narrow regions occur because there is a one or two pixel wide area that is halfway between the two neighboring regions in color and intensity. This is common in any segmentation method based on grid graphs. Such regions can be eliminated if desired, by removing long thin regions whose color or intensity is close to the average of neighboring regions.</p>
</blockquote>
<p>图4显示了一个室内场景图像的算法结果，在这个场景中，精细的细节和较大的结构在感知上都很重要。请注意，分割保留了小区域，如人们所戴的姓名标签和窗户后面的东西，同时为高变化区域创建了单个较大的区域，如靠近图像顶部的空调管道、衣服和家具。这张图片还显示了有时会发现一些小的“边界区域”，例如在夹克或衬衫的边缘。这种狭窄区域的出现是因为在颜色和强度上，两个相邻区域之间有一个或两个像素宽的区域。这在任何基于网格图的分割方法中都很常见。如果需要，可以通过去除颜色或强度接近相邻区域平均值的细长区域来消除这些区域</p>
<blockquote>
<p>Figure 5 shows three simple objects from the Columbia COIL image database. Shown for each is the largest region found by our algorithm that is not part of the black background. Note that each of these objects has a substantial intensity gradient across the face of the object, yet the regions are correctly segmented. This illustrates another situation that the algorithm was designed to handle, slow changes in intensity due to lighting.</p>
</blockquote>
<p>图5显示了哥伦比亚COIL图像数据库中的三个简单对象。显示的每个区域都是我们的算法发现的最大区域，不是黑色背景的一部分。请注意，这些对象的每个面都有一个很大的强度梯度，但是区域是正确分割的。这说明了另一种该算法设计处理的情况，即照明导致的亮度变化缓慢</p>
<p><img src="/imgs/基于图的图像分割/fig-2.png" alt></p>
<blockquote>
<p>Figure 2: A street scene ($320 × 240$ color image), and the segmentation results produced by our algorithm ($σ = 0.8, k = 300$).</p>
</blockquote>
<p>图 2：街景($320 × 240$大小彩色图像)，以及算法分割结果（$σ = 0.8, k = 300$）</p>
<p><img src="/imgs/基于图的图像分割/fig-3.png" alt></p>
<blockquote>
<p>Figure 3: A baseball scene ($432 × 294$ grey image), and the segmentation results produced by our algorithm ($σ = 0.8, k = 300$).</p>
</blockquote>
<p>图 3：棒球场景（$432 × 294$大小灰度图像），以及算法分割结果（$σ = 0.8, k = 300$）</p>
<p><img src="/imgs/基于图的图像分割/fig-4.png" alt></p>
<blockquote>
<p>Figure 4: An indoor scene (image $320 × 240$, color), and the segmentation results produced by our algorithm ($σ = 0.8, k = 300$).</p>
</blockquote>
<p>图 4：室内场景（$320 × 240$大小彩色图像），以及算法分割结果（$σ = 0.8, k = 300$）</p>
<p><img src="/imgs/基于图的图像分割/fig-5.png" alt></p>
<blockquote>
<p>Figure 5: Three images from the COIL database, , and the largest non-background component found in each image ($128×128$ color images; algorithm parameters $σ = 0.8, k = 150$).</p>
</blockquote>
<p>图 5：COIL数据集的3张图片，以及每张图片最大的非背景分量（$128×128$大小彩色图像，算法参数为$σ = 0.8, k = 150$）</p>
<h2 id="最近邻图的结果"><a href="#最近邻图的结果" class="headerlink" title="最近邻图的结果"></a>最近邻图的结果</h2><blockquote>
<p>Results for Nearest Neighbor Graphs</p>
<p>One common approach to image segmentation is based on mapping each pixel to a point in some feature space, and then finding clusters of similar points (e.g., [3, 4, 9]). In this section we investigate using the graph-based segmentation algorithm from Section 4 in order to find such clusters of similar points. In this case, the graph $G = (V, E)$ has a vertex corresponding to each feature point (each pixel) and there is an edge $(v_i , v_j)$ connecting pairs of feature points $v_i$ and $v_j$ that are nearby in the feature space, rather than using neighboring pixels in the image grid. There are several possible ways of determining which feature points to connect by edges. We connect each point to a fixed number of nearest neighbors. Another possibility is to use all the neighbors within some fixed distance $d$. In any event, it is desirable to avoid considering all $O(n^2)$ pairs of feature points.</p>
</blockquote>
<p>一种常见的图像分割方法是将每个像素映射到某些特征空间中的一个点，然后找到相似点的簇（例如[3，4，9]）。 在本节中，我们使用第4节中基于图的分割算法，希望找到类似的点群。在这种情况下，图$G=(V，E)$的顶点对应于每个特征点（每个像素），并且边$(v_i，v_j)$连接特征空间中相邻的一对特征点$v_i$和$v_j$，而不是使用图像网格中的相邻像素。有几种方法来确定要通过边连接的特征点。我们选择每个点有固定数量的最近邻。另一种方法是连接固定距离内$d$的所有相邻点。在任一中情况下，都要考虑避免所有$O(n^2)$对特征点</p>
<blockquote>
<p>The weight $w((v_i , v_j))$ of an edge is the distance between the two corresponding points in feature space. For the experiments shown here we map each pixel to the feature point $(x, y, r, g, b)$, where $(x, y)$ is the location of the pixel in the image and $(r, g, b)$ is the color value of the pixel. We use the $L_2$ (Euclidean) distance between points as the edge weights, although other distance functions are possible.</p>
</blockquote>
<p>边权重$w((v_i , v_j))$指的是一对点在特征空间中的距离。本实验中将每个像素映射到特征点$(x, y, r, g, b)$，其中$(x,y)$表示像素位置，$(r,g,b)$表示颜色值。我们使用点之间的$L_2$（欧几里得）距离作为边权重，其他距离函数也是可以的</p>
<blockquote>
<p>The internal difference measure, $Int(C)$, has a relatively simple underlying intuition for points in feature space. It specifies the minimum radius of dilation necessary to connect the set of feature points contained in $C$ together into a single volume in feature space. Consider replacing each feature point by a ball with radius $r$. From the definition of the $MST$ it can be seen that the union of these balls will form one single connected volume only when $r ≥ Int(C)/2$. The difference between components, $Dif(C_1, C_2)$, also has a simple underlying intuition. It specifies the minimum radius of dilation necessary to connect at least one point of $C_1$ to a point of $C_2$. Our segmentation technique is thus closely related to the work of [4], which similarly takes an approach to clustering based on dilating points in a parameter space (however they first use a novel transformation of the data that we do not perform, and then use a fixed dilation radius rather than the variable one that we use).</p>
</blockquote>
<p>内部差异测量$Int(C)$对于特征空间中的点具有相对简单的潜在直觉。它指定了将$C$中包含的一组特征点连接到特征空间中的单个体积（<em>分量</em>）所需的最小扩张半径。考虑用半径为$r$的球替换每个特征点。从$MST$的定义可以看出，只有当$R≥Int(C)/2$时，这些球的联合才会形成一个单连通体。分量之间的差异$Dif(C_1，C_2)$也具有简单的基本直觉。它指定了将$C_1$的至少一个点连接到$C_2$点所需的最小膨胀半径。因此，我们的分割技术与[4]的工作密切相关，后者同样采用基于参数空间中的扩张点的聚类方法（然而，它们首先使用我们不执行的数据转换，然后使用固定的扩张半径而不是我们使用的变量）</p>
<blockquote>
<p>Rather than constructing the complete graph, where all points are neighbors of one another, we find a small fixed number of neighbors for each point. This results in a graph with $O(n)$ edges for $n$ image pixels, and an overall running time of the segmentation method of $O(nlogn)$ time. There are many possible ways of picking a small fixed number of neighbors for each point. We use the ANN algorithm [1] to find the nearest neighbors for each point. This algorithm is quite fast in practice, given a 5-dimensional feature space with several hundred thousand points. The ANN method can also find approximate nearest neighbors, which runs more quickly than finding the actual nearest neighbors. For the examples reported here we use ten nearest neighbors of each pixel to generate the edges of the graph.</p>
</blockquote>
<p>我们没有构建一个完整的图，其中所有点都是彼此的邻居，而是为每个点找到一个固定数量的邻居。结果得到了一个具有$n$个图像像素的$O(n)$条边的图，以及$O(nlogn)$时间的分割方法的总体运行时间。有许多可能的方法可以为每个点选择少量固定数量的邻居。我们使用ANN(Approximate Nearest Neighbor)算法[1]为每个点找到最近的邻居。在给定具有数十万个点的5维特征空间中，该算法在实际应用中速度很快。ANN方法也可以找到近似最近邻点，并且比实际的最近邻方法运行得更快。对于这里的示例，我们使用每个像素的十个最近邻来生成图的边</p>
<blockquote>
<p>One of the key differences from the previous section, where the image grid was used to define the graph, is that the nearest neighbors in feature space capture more spatially non-local properties of the image. In the grid-graph case, all of the neighbors in the graph are neighbors in the image. Here, points can be far apart in the image and still be among a handful of nearest neighbors (if their color is highly similar and intervening image pixels are of dissimilar color). For instance, this can result segmentations with regions that are disconnected in the image, which did not happen in the grid-graph case.</p>
</blockquote>
<p>与上一节（使用图像网格定义图）的主要区别之一是，特征空间中最近邻捕获的图像具有更大的空间非局部属性。在网格图的情况下，图中的所有邻居都是图像中的邻居。在这里，点可以在图像中相距很远，并且仍然是特征空间中最近的邻居之一（如果它们的颜色非常相似，并且中间的图像像素的颜色不同）。例如，这可能会导致图像中断开的同一区域分割，而网格图中没有发生这种情况</p>
<blockquote>
<p>Figure 6 shows a synthetic image from [12] and [8] and its segmentation, using $k = 150$ and with no smoothing ($σ = 0$). In this example the spatially disconnected regions do not reflect interesting scene structures, but we will see examples below which do.</p>
</blockquote>
<p>图6显示了来自[12]和[8]的合成图像及其分割，使用$k=150$且没有平滑操作（$σ=0$）。在本例中，空间断开区域并不反映有趣的场景结构，但我们将看到下面的示例</p>
<blockquote>
<p>For the remaining examples in this section, we use $k = 300$ and $σ = 0.8$, as in the previous section. First, we note that the nearest neighbor graph produces similar results to the grid graph for images in which the perceptually salient regions are spatially connected. For instance, the street scene and baseball player scene considered in the previous section yield very similar segmentations using either the nearest neighbor graph or the grid graph, as can be seen by comparing the results in Figure 7 with those in Figure 2 and Figure 3.</p>
</blockquote>
<p>对于本节中的其余示例，我们使用$k=300$和$σ=0.8$，如前一节所述。首先，我们注意到最近邻图产生的结果与感知显著区域在空间上连接的图像的网格图相似。例如，上一节中考虑的街道场景和棒球运动员场景使用最近邻图或网格图生成非常相似的分割，如图7中的结果与图2和图3中的结果进行比较所示</p>
<blockquote>
<p>Figure 8 shows two additional examples using the nearest neighbor graph. These results are not possible to achieve with the grid graph approach because certain interesting regions are not spatially connected. The first example shows a flower garden, where the red flowers are spatially disjoint in the foreground of the image, and then merge together in the background. Most of these flowers are merged into a single region, which would not be possible with the grid-graph method. The second example in Figure 8 shows the Eiffel tower at night. The bright yellow light forms a spatially disconnected region. These examples show that the segmentation method, coupled with the use of a nearest neighbor graph, can capture very high level properties of images, while preserving perceptually important region boundaries.</p>
</blockquote>
<p>图8显示了使用最近邻图的另外两个示例。这些结果不可能使用网格图的方法实现，因为某些有趣的区域没有空间连接。 第一个例子显示了一个花园，在图像的前景中，红色的花在空间上是不相交的，但是在背景中合并在一起。这些花中的大多数被合并到一个单一的区域，这是使用网格图方法不可能实现的。图8中的第二个例子显示了晚上的埃菲尔铁塔。明亮的黄光形成一个空间上不相连的区域。这些实例表明，该分割方法结合最近邻图的使用，可以捕捉图像的高层次属性，同时保留感知上重要的区域边界</p>
<p><img src="/imgs/基于图的图像分割/fig-6.png" alt></p>
<blockquote>
<p>Figure 6: A synthetic image ($40 × 32$ grey image) and the segmentation using the nearest neighbor graph ($σ = 0, k = 150$).</p>
</blockquote>
<p>图 6：合成图像（$40 × 32$灰度图像）以及使用最近邻图的分割结果（$σ = 0, k = 150$）</p>
<p><img src="/imgs/基于图的图像分割/fig-7.png" alt></p>
<blockquote>
<p>Figure 7: Segmentation of the street and baseball player scenes from the previous section, using the nearest neighbor graph rather than the grid graph ($σ = 0.8, k = 300$).</p>
</blockquote>
<p>图 7：使用最近邻图分割上一节使用的街景和棒球场景（$σ = 0.8, k = 300$）</p>
<p><img src="/imgs/基于图的图像分割/fig-8.png" alt></p>
<blockquote>
<p>Figure 8: Segmentation using the nearest neighbor graph can capture spatially non-local regions ($σ = 0.8, k = 300$).</p>
</blockquote>
<p>图 8：使用最近邻图的分割（$σ = 0.8, k = 300$），捕获了空间非局部区域（<em>不相连的同一区域</em>）</p>
<h2 id="总结和结论"><a href="#总结和结论" class="headerlink" title="总结和结论"></a>总结和结论</h2><blockquote>
<p>Summary and Conclusions</p>
<p>In this paper we have introduced a new method for image segmentation based on pairwise region comparison. We have shown that the notions of a segmentation being too coarse or too fine can be defined in terms of a function which measures the evidence for a boundary between a pair of regions. Our segmentation algorithm makes simple greedy decisions, and yet produces segmentations that obey the global properties of being not too coarse and not too fine according to a particular region comparison function. The method runs in $O(mlogm)$ time for $m$ graph edges and is also fast in practice, generally running in a fraction of a second.</p>
</blockquote>
<p>本文介绍了一种基于成对区域比较的图像分割方法。我们已经证明，分割过粗或过细的概念可以用一个函数来定义，该函数测量一对区域之间边界的证据。我们的分割算法可以做出简单的贪婪决策，但根据特定的区域比较函数，可以产生符合不太粗糙和不太精细的全局属性的分割。该方法对$m$个边在$O(mlogm)$时间内运行，并且在实践中也很快，通常只在一秒钟内运行</p>
<blockquote>
<p>The pairwise region comparison predicate we use considers the minimum weight edge between two regions in measuring the difference between them. Thus our algorithm will merge two regions even if there is a single low weight edge between them. This is not as much of a problem as it might first appear, in part because this edge weight is compared only to the minimum spanning tree edges of each component. For instance, the examples considered in Sections 5 and 6 illustrate that the method finds segmentations that capture many perceptually important aspects of complex imagery. Nonetheless, one can envision measures that require more than a single cheap connection before deciding that there is no evidence for a boundary between two regions. One natural way of addressing this issue is to use a quantile rather than the minimum edge weight. However, in this case finding a segmentation that is neither too coarse nor too fine is an NP-hard problem (as shown in the Appendix). Our algorithm is unique, in that it is both highly efficient and yet captures non-local properties of images.</p>
</blockquote>
<p>我们使用的成对区域比较谓词在测量两个区域之间的差异时考虑了两个区域之间的最小权重边。因此，我们的算法将合并两个区域，即使它们之间有一个单独的低权重边。这并不是第一次出现的问题，部分原因是边权重只与每个分量的最小生成树的边进行比较。例如，第5节和第6节中考虑的示例说明，该方法发现了捕捉复杂图像许多重要方面的分割。尽管如此，在决定两个区域之间没有边界的证据之前，我们可以设想需要一个以上连接的措施。解决这个问题的一种自然方法是使用分位数，而不是最小边权重。然而，在这种情况下，找到既不太粗糙也不太精细的分割是一个NP难题（如附录所示）。我们的算法是独一无二的，因为它既高效又能捕捉图像的非局部特性</p>
<blockquote>
<p>We have illustrated our image segmentation algorithm with two different kinds of graphs. The first of these uses the image grid to define a local neighborhood between image pixels, and measures the difference in intensity (or color) between each pair of neighbors. The second of these maps the image pixels to points in a feature space that combines the $(x, y)$ location and $(r, g, b)$ color value. Edges in the graph connect points that are close together in this feature space. The algorithm yields good results using both kinds of graphs, but the latter type of graph captures more perceptually global aspects of the image.</p>
</blockquote>
<p>我们用两种不同的图说明了我们的图像分割算法。第一种方法使用图像网格定义图像像素之间的局部邻域，并测量每对邻域之间的强度（或颜色）差异。第二个将图像像素映射到特征空间中的点，该特征空间组合了$(x，y)$位置和$(r，g，b)$颜色值。图中的边连接在此特征空间中相邻的点。该算法使用这两种图都能得到很好的结果，但是后一种图能捕捉到图像更感性的全局方面</p>
<blockquote>
<p>Image segmentation remains a challenging problem, however we are beginning to make substantial progress through the introduction of graph-based algorithms that both help refine our understanding of the problem and provide useful computational tools. The work reported here and the normalized cuts approach [14] are just a few illustrations of these recent advances.</p>
</blockquote>
<p>图像分割仍然是一个具有挑战性的问题，但是我们开始通过引入基于图的算法取得实质性进展，这两种算法都有助于改进我们对问题的理解，并提供有用的计算工具。这里报告的工作和标准化切割方法[14]只是这些最新进展的几个例子</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>图像处理</category>
        <category>机器学习</category>
        <category>目标分割</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>基于图的图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>PPM文件解析</title>
    <url>/posts/6cbcc636.html</url>
    <content><![CDATA[<p>最近进行图像处理时遇到<a href="http://netpbm.sourceforge.net/doc/ppm.html" target="_blank" rel="noopener">PPM</a>文件，其格式与<code>PGM</code>文件类似，参考<a href="https://blog.csdn.net/u012005313/article/details/83685584" target="_blank" rel="noopener">Python pgm解析和格式转换</a>进行<code>PPM</code>文件格式解析以及图像格式转换</p><a id="more"></a>
<h2 id="PPM"><a href="#PPM" class="headerlink" title="PPM"></a>PPM</h2><p><code>PPM</code>(<code>Portable Pixel Map</code>，便携式像素地图)文件是<code>Netpbm</code>开源工程设计的一种图像格式，除了<code>ppm</code>外，还有<code>pbm，pgm</code>。<code>PPM</code>文件由一个或多个<code>PPM</code>图像序列组成。在图像之前、之后或之间没有数据、分隔符或填充</p>
<p>每个<code>PPM</code>文件按序包含如下信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. A &quot;magic number&quot; for identifying the file type. A ppm image&apos;s magic number is the two characters &quot;P6&quot;.</span><br><span class="line">2. Whitespace (blanks, TABs, CRs, LFs).</span><br><span class="line">3. A width, formatted as ASCII characters in decimal.</span><br><span class="line">4. Whitespace.</span><br><span class="line">5. A height, again in ASCII decimal.</span><br><span class="line">6. Whitespace.</span><br><span class="line">7. The maximum color value (Maxval), again in ASCII decimal. Must be less than 65536 and more than zero.</span><br><span class="line">8. A single whitespace character (usually a newline).</span><br><span class="line">9. A raster of Height rows, in order from top to bottom. Each row consists of Width pixels, in order from left to right. Each pixel is a triplet of red, green, and blue samples, in that order. Each sample is represented in pure binary by either 1 or 2 bytes. If the Maxval is less than 256, it is 1 byte. Otherwise, it is 2 bytes. The most significant byte is first.</span><br><span class="line"></span><br><span class="line">1. 用于识别文件类型的“幻数”。PPM图像的幻数是两个字符“P6”。</span><br><span class="line">2. 空格（blanks, TABs, CRs, LFs）。</span><br><span class="line">3. 宽度，格式为ASCII十进制数字。</span><br><span class="line">4. 空格。</span><br><span class="line">5. 高度，同样为ASCII十进制数字。</span><br><span class="line">6. 空格。</span><br><span class="line">7. 最大灰度值（Maxval），同时是ASCII十进制。范围为[0，6536]。</span><br><span class="line">8. 单个空白字符（通常是换行符）。</span><br><span class="line">9. 按从上到下的顺序排列的高度行光栅。每行由宽度大小像素组成，从左到右依次排列。每一个像素都是红、绿、蓝三色样本的三重组合。每个样本用纯二进制表示，用1或2个字节表示。如果maxval小于256，则为1字节。否则，它是2个字节。最重要的字节是第一个。</span><br></pre></td></tr></table></figure>
<p><em>注意 1：以<code>#</code>开头的字符串可能是注释，与<a href="http://netpbm.sourceforge.net/doc/pbm.html" target="_blank" rel="noopener">PBM</a>相同</em></p>
<p><em>注意 2：图像数据集是连续存放的</em></p>
<p>使用<code>vim</code>打开<code>PPM</code>文件，初始文件信息如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">P6</span><br><span class="line">1440 1080</span><br><span class="line">255</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h3 id="Plain-PPM"><a href="#Plain-PPM" class="headerlink" title="Plain PPM"></a>Plain PPM</h3><p>还存在另一种格式的<code>PPM</code>文件，其差别如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. There is exactly one image in a file.</span><br><span class="line">2. The magic number is P3 instead of P6.</span><br><span class="line">3. Each sample in the raster is represented as an ASCII decimal number (of arbitrary size).</span><br><span class="line">4. Each sample in the raster has white space before and after it. There must be at least one character of white space between any two samples, but there is no maximum. There is no particular separation of one pixel from another -- just the required separation between the blue sample of one pixel from the red sample of the next pixel.</span><br><span class="line">5. No line should be longer than 70 characters.</span><br><span class="line"></span><br><span class="line">1. 文件中仅有单个图像。</span><br><span class="line">2. 幻数是P3。</span><br><span class="line">3. 栅格中的每个像素表示为ASCII十进制数（任意大小）。</span><br><span class="line">4. 光栅中的每个样本前后都有空白。任何两个样本之间必须至少有一个空白字符，没有最多空白限制。一个像素与另一个像素之间没有特殊的分离——只是一个像素的蓝色样本与下一个像素的红色样本之间需要的分离。</span><br><span class="line">5. 没有一行应该长于70个字符。</span><br></pre></td></tr></table></figure>
<p>样本图像如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">P3</span><br><span class="line"># feep.ppm</span><br><span class="line">4 4</span><br><span class="line">15</span><br><span class="line"> 0  0  0    0  0  0    0  0  0   15  0 15</span><br><span class="line"> 0  0  0    0 15  7    0  0  0    0  0  0</span><br><span class="line"> 0  0  0    0  0  0    0 15  7    0  0  0</span><br><span class="line">15  0 15    0  0  0    0  0  0    0  0  0</span><br></pre></td></tr></table></figure>
<p><em>注意：每行末尾都有一个换行符</em></p>
<h3 id="文件命名"><a href="#文件命名" class="headerlink" title="文件命名"></a>文件命名</h3><p>通常以<code>.PPM</code>或者<code>.ppm</code>文件结尾</p>
<h3 id="PPM-vs-PGM"><a href="#PPM-vs-PGM" class="headerlink" title="PPM vs. PGM"></a>PPM vs. PGM</h3><p><code>PPM</code>文件是<code>3</code>通道彩色图像文件，<code>PGM</code>是灰度图像文件</p>
<h2 id="格式转换"><a href="#格式转换" class="headerlink" title="格式转换"></a>格式转换</h2><p>可以使用库<code>Image</code>进行<code>PPM</code>格式与<code>PNG/JPEG</code>等其他格式转换</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from PIL import Image</span><br><span class="line"></span><br><span class="line">img = Image.open(&apos;test.PPM&apos;)</span><br><span class="line">img.save(&apos;test2.png&apos;)</span><br><span class="line">img.show()</span><br></pre></td></tr></table></figure>
<p>也可依据图像格式读取文件信息后在转换成图像，完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-8-10 下午2:21</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">from __future__ import print_function</span><br><span class="line"></span><br><span class="line">import cv2</span><br><span class="line">import time</span><br><span class="line">import os</span><br><span class="line">import operator</span><br><span class="line">import numpy as np</span><br><span class="line">import argparse</span><br><span class="line">from PIL import Image</span><br><span class="line"></span><br><span class="line">__author__ = &apos;zj&apos;</span><br><span class="line"></span><br><span class="line">image_formats = [&apos;jpg&apos;, &apos;JPG&apos;, &apos;jpeg&apos;, &apos;JPEG&apos;, &apos;png&apos;, &apos;PNG&apos;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def is_ppm_file(in_path):</span><br><span class="line">    if not os.path.isfile(in_path):</span><br><span class="line">        return False</span><br><span class="line">    if in_path is not str and not in_path.lower().endswith(&apos;.ppm&apos;):</span><br><span class="line">        return False</span><br><span class="line">    return True</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def convert_ppm_by_PIL(in_path, out_path):</span><br><span class="line">    if not is_ppm_file(in_path):</span><br><span class="line">        raise Exception(&quot;%s 不是一个PPM文件&quot; % in_path)</span><br><span class="line">    # 读取文件</span><br><span class="line">    im = Image.open(in_path)</span><br><span class="line">    im.save(out_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def convert_ppm_P6(in_path, out_path):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    将ppm文件转换成其它图像格式</span><br><span class="line">    读取二进制文件，先读取幻数，再读取宽和高，以及最大值</span><br><span class="line">    :param in_path: 输入ppm文件路径</span><br><span class="line">    :param out_path: 输出文件路径</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if not is_ppm_file(in_path):</span><br><span class="line">        raise Exception(&quot;%s 不是一个PPM文件&quot; % in_path)</span><br><span class="line">    with open(in_path, &apos;rb&apos;) as f:</span><br><span class="line">        # 读取两个字节 - 幻数，并解码成字符串</span><br><span class="line">        magic_number = f.readline().strip().decode(&apos;utf-8&apos;)</span><br><span class="line">        if not operator.eq(magic_number, &quot;P6&quot;):</span><br><span class="line">            raise Exception(&quot;该图像有误&quot;)</span><br><span class="line">        # 读取高和宽</span><br><span class="line">        width, height = f.readline().strip().decode(&apos;utf-8&apos;).split(&apos; &apos;)</span><br><span class="line">        width = int(width)</span><br><span class="line">        height = int(height)</span><br><span class="line">        # 读取最大值</span><br><span class="line">        maxval = f.readline().strip()</span><br><span class="line">        byte_array = np.array(list(f.readline()))</span><br><span class="line">        img = byte_array.reshape((height, width, 3)).astype(np.uint8)</span><br><span class="line">        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)</span><br><span class="line">        cv2.imwrite(out_path, img)</span><br><span class="line">        print(&apos;%s save ok&apos; % out_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def convert_ppm_P6_batch(in_dir, out_dir, res_format):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    批量转换PPM文件</span><br><span class="line">    :param in_dir: ppm文件夹路径</span><br><span class="line">    :param out_dir: 输出文件夹路径</span><br><span class="line">    :param res_format: 结果图像格式</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if not os.path.isdir(in_dir):</span><br><span class="line">        raise Exception(&apos;%s 不是路径&apos; % in_dir)</span><br><span class="line">    if not os.path.isdir(out_dir):</span><br><span class="line">        raise Exception(&apos;%s 不是路径&apos; % out_dir)</span><br><span class="line">    if not res_format in image_formats:</span><br><span class="line">        raise Exception(&apos;%s 暂不支持&apos; % res_format)</span><br><span class="line">    file_list = os.listdir(in_dir)</span><br><span class="line">    for file_name in file_list:</span><br><span class="line">        file_path = os.path.join(in_dir, file_name)</span><br><span class="line">        # 若为ppm文件路径，那么将其进行格式转换</span><br><span class="line">        if is_ppm_file(file_path):</span><br><span class="line">            file_out_path = os.path.join(out_dir, os.path.splitext(file_name)[0] + &apos;.&apos; + res_format)</span><br><span class="line">            convert_ppm_P6(file_path, file_out_path)</span><br><span class="line">        # 若为目录，则新建结果文件目录，递归处理</span><br><span class="line">        elif os.path.isdir(file_path):</span><br><span class="line">            file_out_dir = os.path.join(out_dir, file_name)</span><br><span class="line">            if not os.path.exists(file_out_dir):</span><br><span class="line">                os.mkdir(file_out_dir)</span><br><span class="line">            convert_ppm_P6_batch(file_path, file_out_dir, res_format)</span><br><span class="line">        else:</span><br><span class="line">            pass</span><br><span class="line">    print(&apos;batch operation over&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    script_start_time = time.time()</span><br><span class="line"></span><br><span class="line">    parser = argparse.ArgumentParser(description=&apos;Format Converter - PPM&apos;)</span><br><span class="line"></span><br><span class="line">    ### Positional arguments</span><br><span class="line"></span><br><span class="line">    ### Optional arguments</span><br><span class="line"></span><br><span class="line">    parser.add_argument(&apos;-i&apos;, &apos;--input&apos;, type=str, help=&apos;Path to the ppm file&apos;)</span><br><span class="line">    parser.add_argument(&apos;-o&apos;, &apos;--output&apos;, type=str, help=&apos;Path to the result file&apos;)</span><br><span class="line">    parser.add_argument(&apos;--input_dir&apos;, type=str, help=&apos;Dir to the ppm files&apos;)</span><br><span class="line">    parser.add_argument(&apos;--output_dir&apos;, type=str, help=&apos;Dir to the result files&apos;)</span><br><span class="line">    parser.add_argument(&apos;-f&apos;, &apos;--format&apos;, default=&apos;png&apos;, type=str, help=&apos;result image format&apos;)</span><br><span class="line">    parser.add_argument(&apos;-b&apos;, &apos;--batch&apos;, action=&quot;store_true&quot;, default=False, help=&apos;Batch processing&apos;)</span><br><span class="line"></span><br><span class="line">    args = vars(parser.parse_args())</span><br><span class="line">    # print(args)</span><br><span class="line">    in_path = args[&apos;input&apos;]</span><br><span class="line">    out_path = args[&apos;output&apos;]</span><br><span class="line"></span><br><span class="line">    isbatch = args[&apos;batch&apos;]</span><br><span class="line">    in_dir = args[&apos;input_dir&apos;]</span><br><span class="line">    out_dir = args[&apos;output_dir&apos;]</span><br><span class="line">    res_format = args[&apos;format&apos;]</span><br><span class="line"></span><br><span class="line">    if in_path is not None and out_path is not None:</span><br><span class="line">        # 转换单个ppm文件格式</span><br><span class="line">        convert_ppm_P6(in_path, out_path)</span><br><span class="line">        # convert_ppm_by_PIL(in_path, out_path)</span><br><span class="line">    elif isbatch:</span><br><span class="line">        # 批量转换</span><br><span class="line">        convert_ppm_P6_batch(in_dir, out_dir, res_format)</span><br><span class="line">    else:</span><br><span class="line">        print(&apos;请输入相应参数&apos;)</span><br><span class="line"></span><br><span class="line">    print(&apos;Script took %s seconds.&apos; % (time.time() - script_start_time,))</span><br></pre></td></tr></table></figure>
<p>转换单个<code>PPM</code>图像为<code>PNG</code>图像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ python ppm_converter.py -i test.ppm -o test2.png</span><br><span class="line">test2.png save ok</span><br><span class="line">Script took 0.2900853157043457 seconds.</span><br></pre></td></tr></table></figure>
<p>批量转换<code>PPM</code>图像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ python ppm_converter.py --input_dir 输入路径 --output_dir 输出路径 -f PNG -b</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据</category>
        <category>代码库</category>
        <category>数据格式</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
        <tag>numpy</tag>
        <tag>ppm</tag>
        <tag>argparse</tag>
      </tags>
  </entry>
  <entry>
    <title>基于图的图像分割-引言</title>
    <url>/posts/2e594804.html</url>
    <content><![CDATA[<p>参考：<a href="https://blog.csdn.net/guoyunfei20/article/details/78727972" target="_blank" rel="noopener">基于图的图像分割（Graph-Based Image Segmentation）</a></p><p>学习<code>R-CNN</code>过程中发现其前期使用了选择性搜索方法进行区域提取，而在选择性搜索方法中使用了论文<a href="http://cs.brown.edu/people/pfelzens/papers/seg-ijcv.pdf" target="_blank" rel="noopener">Efficient Graph-Based Image Segmentation</a>提出的基于图的图像分割算法</p><a id="more"></a>

<h2 id="内容列表"><a href="#内容列表" class="headerlink" title="内容列表"></a>内容列表</h2><ul>
<li><a href="#先导知识">先导知识</a></li>
<li><a href="#论文下载">论文下载</a></li>
<li><a href="#算法解析">算法解析</a></li>
<li><a href="#算法流程">算法流程</a></li>
<li><a href="#源码解析">源码解析</a></li>
</ul>
<h2 id="先导知识"><a href="#先导知识" class="headerlink" title="先导知识"></a>先导知识</h2><p>基于图的图像分割算法主要运用了数据结构图的概念和最小生成树的实现（<code>kruskal</code>算法），并且在最小生成树的实现中运用了并查集</p>
<p>参考：</p>
<p><a href="https://www.zhujian.tech/posts/662946db.html">数据结构-图</a></p>
<p><a href="https://www.zhujian.tech/posts/95d609b4.html">数据结构-图5</a></p>
<p><a href="https://www.zhujian.tech/posts/3eedae4a.html">[数据结构][图算法]并查集</a></p>
<h2 id="论文下载"><a href="#论文下载" class="headerlink" title="论文下载"></a>论文下载</h2><ul>
<li><p>论文下载：<a href="http://cs.brown.edu/people/pfelzens/segment/" target="_blank" rel="noopener">Graph Based Image Segmentation</a></p>
</li>
<li><p>论文翻译：<a href="https://www.zhujian.tech/posts/44a20d07.html">[译]高效的基于图的图像分割</a></p>
</li>
</ul>
<h2 id="算法解析"><a href="#算法解析" class="headerlink" title="算法解析"></a>算法解析</h2><h3 id="成对区域比较渭词"><a href="#成对区域比较渭词" class="headerlink" title="成对区域比较渭词"></a>成对区域比较渭词</h3><p>基于图的图像分割算法将图像解析成无向图，最开始每个像素表示一个分量，创建相邻像素之间的边集，通过不断合并分量，最终目标是图中各个分量能够表示感知上重要的组织或区域</p>
<p>其中的关键在于<strong>如何划分最终分量的边界</strong>，对此论文提出一个成对区域比较渭词$D$，通过比较分量间差异和分量内差异，判断相邻两个分量之间是否存在边界</p>
<p>分量内部差异定义为分量内的最大边权重</p>
<script type="math/tex; mode=display">
Int(C) = \max_{e\in MST(C,E)} w(e)</script><p>分量间差异定义为连接两个分量的边的最小权重</p>
<script type="math/tex; mode=display">
Dif(C_{1}, C_{2}) = \min_{v_{i}\in C_{1}, v_{j}\in C_{2},(v_{i},v_{j})\in E} w((v_{i}, v_{j}))</script><p>直观上理解，分量内像素差异应该小于分量间像素差异，所以同一分量中两个顶点之间的边应该具有相对较低的权重，而不同分量中顶点之间的边应该具有较高的权重</p>
<p>于此同时，渭词$D$还定义了一个阈值函数$τ(C)$</p>
<script type="math/tex; mode=display">
τ(C) = k / |C|</script><p>参数$|C|$表示分量$C$的像素个数，参数$k$是一个参数，用于控制分量间差异必须大于最小内部差异的程度，以增强算法对于异常值的健壮性，同时能够控制最终分量的大小。$k$越大，最终得到的分量越大，个数越少</p>
<p>渭词$D$的算法定义如下：</p>
<script type="math/tex; mode=display">
M Int(C_1, C_2) = min(Int(C_1) + τ(C_1), Int(C_2) + τ(C_2)).</script><script type="math/tex; mode=display">
D(C_{1}, C_{2}) =
\left\{\begin{matrix}
true & if Dif(C_{1}, C_{2}) >M Int(C_{1}, C_{2})\\
false & otherwise
\end{matrix}\right.</script><p>$MInt$表示两个分量中的最小内部差异，如果连接两个分量的边的最小权重大于最小内部差异，则两个分量存在边界；否则，进行分量合并</p>
<h3 id="算法实现难点"><a href="#算法实现难点" class="headerlink" title="算法实现难点"></a>算法实现难点</h3><p>如何实现成对区域比较渭词，有以下几个难点：</p>
<ol>
<li>如何找到分量内的最大边权重？</li>
<li>如何找到分量间的最小边权重?</li>
</ol>
<p>通过最小生成树的<code>Kruskal</code>算法实现，能够完美解决上述问题</p>
<p><code>Kruskal</code>算法需要对边集按边权重进行升序排序，然后遍历边集进行分量合并。在遍历过程中，每次得到的边权重既是分量间的最小边权重，如果符合条件能够进行分量合并，这条边又变成了分量内的最大边权重</p>
<h3 id="如何计算边权重"><a href="#如何计算边权重" class="headerlink" title="如何计算边权重"></a>如何计算边权重</h3><p>如何计算边权重，是后续算法的关键基础步骤。论文提出两种方式进行边权重的计算</p>
<ol>
<li>网格图</li>
<li>最近邻图</li>
</ol>
<h4 id="网格图"><a href="#网格图" class="headerlink" title="网格图"></a>网格图</h4><p>将彩色图像划分为<code>3</code>个单色图像，分别计算各个图像，将边连接像素的绝对强度差作为边权重</p>
<script type="math/tex; mode=display">
w((v_{i}, v_{j})) = |I(p_{i}) - I(p_{j})|</script><p>分别输入<code>3</code>个单色图像到算法中，只有各个图像中的相邻像素均属于同一分量时，才将其放置在最终分量中</p>
<h4 id="最近邻图"><a href="#最近邻图" class="headerlink" title="最近邻图"></a>最近邻图</h4><p>计算彩色图像的相邻像素点之间的$L2$距离作为边权重</p>
<h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p>结合论文和实际实现算法，整体算法流程如下：</p>
<ol>
<li>高斯滤波，减轻异常值影响，需要设置参数<code>sigma</code></li>
<li>创建无向图和边集</li>
<li>通过并查集合并分量，需要设置参数<code>k</code></li>
<li>去除极小分量，需要设置参数<code>min_size</code></li>
</ol>
<p><img src="/imgs/基于图的图像分割-引言/graph-seg.png" alt></p>
<h2 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h2><p>研究基于图的图像分割方法过程中，作者提供了工程源码，同时<code>OpenCV</code>上也实现了相应功能，通过相互印证能够加快算法理解</p>
<p>源码工程地址：<a href="http://cs.brown.edu/people/pfelzens/segment/" target="_blank" rel="noopener">Graph Based Image Segmentation</a></p>
<p><code>OpenCV</code>实现：</p>
<ul>
<li>头文件<code>segmentation.hpp - /path/to/include/opencv4/opencv2/ximgproc/segmentation.hpp</code></li>
<li>源文件<code>graphsegmentation.cpp - /path/to/opencv_contrib/modules/ximgproc/src/graphsegmentation.cpp</code></li>
<li>实现示例<code>graphsegmentation_demo.cpp - /path/to/opencv_contrib/modules/ximgproc/samples/graphsegmentation_demo.cpp</code></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>图像处理</category>
        <category>机器学习</category>
        <category>目标分割</category>
      </categories>
      <tags>
        <tag>基于图的图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>[数据集]PASCAL-VOC</title>
    <url>/posts/28b6703d.html</url>
    <content><![CDATA[<p><code>PASCAL VOC(visual object classes)</code>提供了图像以及标记数据，可用于目标分类、检测、分割等任务</p><a id="more"></a>
<p>官网地址：<a href="http://host.robots.ox.ac.uk/pascal/VOC/" target="_blank" rel="noopener">The PASCAL Visual Object Classes Homepage</a></p>
<h2 id="数据集与挑战赛"><a href="#数据集与挑战赛" class="headerlink" title="数据集与挑战赛"></a>数据集与挑战赛</h2><p><code>PASCAL VOC</code>每年都会发布一个新的数据集，针对数据集进行不同任务的竞赛，从<code>2005</code>年持续到<code>2012</code>年</p>
<ul>
<li>从<code>2007</code>年开始，数据集类别数固定为<code>20</code>类</li>
<li>从<code>2008</code>年开始，不再公布测试集标注数据</li>
<li>从<code>2009</code>年开始，数据集在前一年数据集的基础上添加新数据</li>
</ul>
<p><code>2012</code>年数据集包含<code>11530</code>张图片，包含<code>27450</code>个<code>ROI</code>标注对象和<code>6929</code>个分割</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>目前常用的是<code>VOC 2007</code>（包含测试集标注信息）和<code>VOC 2012</code>数据集（最新数据集）</p>
<p>可分别去各个竞赛主页下载：</p>
<ul>
<li><a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/index.html" target="_blank" rel="noopener">The PASCAL Visual Object Classes Challenge 2007</a></li>
<li><a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html" target="_blank" rel="noopener">Visual Object Classes Challenge 2012 (VOC2012)</a></li>
</ul>
<h2 id="排行榜"><a href="#排行榜" class="headerlink" title="排行榜"></a>排行榜</h2><p><code>PASCAL VOC</code>提供了一个<a href="http://host.robots.ox.ac.uk:8080/" target="_blank" rel="noopener">评估服务器</a>，可以上传测试结果进行成绩排行，具体标准参考：<a href="http://host.robots.ox.ac.uk/pascal/VOC/#bestpractice" target="_blank" rel="noopener">Best Practice</a>，分两个参与类型，一是仅使用了官方提供的训练/验证数据；二是使用了除测试数据外的综合数据集</p>
<p>看了上面的排行榜，目前仍有不少人员参与其中：<a href="http://host.robots.ox.ac.uk:8080/leaderboard/main_bootstrap.php" target="_blank" rel="noopener">Leaderboards for the Evaluations on PASCAL VOC Data</a></p>
<p>不过要使用评估服务器之前需要先注册，注册要求之一是要提供一个机构邮箱，为的是防止重复上传的刷榜行为，所以独立开发者没办法参与其中了</p>
]]></content>
      <categories>
        <category>数据</category>
        <category>数据集</category>
      </categories>
      <tags>
        <tag>pascal voc</tag>
      </tags>
  </entry>
  <entry>
    <title>模型集成</title>
    <url>/posts/e0761e53.html</url>
    <content><![CDATA[<p>训练多个独立模型，在测试阶段平均其预测结果，是一种有效的提高检测精度的方法，称为模型集成（<code>model ensemble</code>）</p><a id="more"></a>
<h2 id="不同模型集成方式"><a href="#不同模型集成方式" class="headerlink" title="不同模型集成方式"></a>不同模型集成方式</h2><p>检测精度通常与模型数量呈正比关系，不过其效果会逐渐降低。另外，控制不同变量得到的模型具有不一样的性能，<code>cs231n</code>中提出了几种模型集成方式：<a href="http://cs231n.github.io/neural-networks-3/#ensemble" target="_blank" rel="noopener">Model Ensembles</a></p>
<ul>
<li><p>同一套模型结构，不同的初始化</p>
<p>  使用交叉验证确定最好的超参数，然后使用不同随机初始化方式训练多个模型。其缺点在于该方法变量仅依赖于初始化</p>
</li>
<li><p>交叉验证过程中发现的最好一批超参数</p>
<p>  使用交叉验证确定最好的超参数，然后取检测效果最好的前一批（比如前<code>10</code>个）组成模型集成。这种方式提高了模型的多样性，但是有包含次优模型的危险。实际使用过程中，这种方式更容易实现，因为它不需要在交叉验证后再次训练</p>
</li>
<li><p>单个模型的不同检查点</p>
<p>  如果训练过程非常耗时，可以使用单个网络的不同检查点（<code>checkpoint</code>）进行模型集成。虽然这种方式缺乏多样性，取得的进步有限，但是在实际使用过程中仍旧有效，因为其实现方式很简单</p>
</li>
<li><p>在训练过程中运行参数平均值</p>
<p>  在内存中保持一个权重副本，其维持训练过程中权重的指数衰减和，这样能够得到前几次迭代过程中网络的平均状态，这种方式总能保证<code>1%-2%</code>的性能提高。其粗略的理解是损失对象是碗状的（<code>bowl-shaped</code>），训练过程中的网络不断的在其中跳跃，而平均权重方式能够更有机会跳入最低点</p>
</li>
</ul>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>模型集成方式能够进一步提高模型精度，减小误差率；不过在检测过程中需要花费更长时间</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>最优化</category>
      </categories>
      <tags>
        <tag>模型集成</tag>
      </tags>
  </entry>
  <entry>
    <title>超参数优化</title>
    <url>/posts/a042eba2.html</url>
    <content><![CDATA[<p>参考:</p><p><a href="http://cs231n.github.io/neural-networks-3/#hyper" target="_blank" rel="noopener">Hyperparameter optimization</a></p><p><a href="https://zhuanlan.zhihu.com/p/21798784?refer=intelligentunit" target="_blank" rel="noopener">超参数调优</a></p><p>神经网络/卷积神经网络中存在很多的超参数，并且随着优化技术的发展，越来越多的超参数被加入进来，最常见的超参数包括：</p><a id="more"></a>



<ol>
<li>初始学习率</li>
<li>学习率衰减机制（比如衰减常数）</li>
<li>正则化策略（<code>L2</code>惩罚，随机失活强度）</li>
</ol>
<p>大多数超参数在训练过程中相对固定，比如动量大小，衰减常数等，<code>cs231n</code>提出一些学习技巧来帮助搜索最佳的超参数值</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>使用两个程序实现优化过程，<code>worker</code>程序持续采样随机超参数并执行优化。在训练过程中，<code>worker</code>程序持续追踪每一轮的验证集性能（或者其他数据集性能），写入一个模型检查点（包含了各种数据，包括损失值，精度值，权重向量等等）文件，文件名应该直接包含验证集精度值，以便后续的排序。<code>master</code>程序用于加载或杀死<code>worker</code>程序，通常额外包含查看检查点文件以及绘图功能</p>
<h2 id="单验证集文件"><a href="#单验证集文件" class="headerlink" title="单验证集文件"></a>单验证集文件</h2><p>通常情况在交叉验证（<code>crosss-validation</code>）某个参数时使用单个验证集即可，这样可以简化代码库实现</p>
<h2 id="超参数范围"><a href="#超参数范围" class="headerlink" title="超参数范围"></a>超参数范围</h2><p>在对数尺度上搜索超参数。以学习率搜索为例，采样公式为<code>learning_rate = 10 ** uniform(-6, 1)</code>，在均匀分布中采样随机数作为<code>10</code>的阶数，这种策略同样可用于正则化强度</p>
<p>如果学习率为<code>0.001</code>，那么固定增减<code>0.01</code>会发生很大影响；但是如果学习率是<code>10</code>，几乎没有影响。应该考虑对学习率乘以或者除以某个值，而不是在一定范围内增加或者减去某个值</p>
<p>对于某些超参数（比如随机失活）而言，还是应该使用正常尺度进行搜索（<code>dropout = uniform(0,1)</code>）</p>
<h2 id="使用随机搜索而不是网格搜索"><a href="#使用随机搜索而不是网格搜索" class="headerlink" title="使用随机搜索而不是网格搜索"></a>使用随机搜索而不是网格搜索</h2><p>文章<a href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf" target="_blank" rel="noopener">Random Search for Hyper-Parameter Optimization</a>提出使用随机搜索更有利于超参数优化，同时更容易实现</p>
<p><img src="/imgs/超参数优化/gridsearchbad.jpeg" alt></p>
<h2 id="注意边界上的最佳值"><a href="#注意边界上的最佳值" class="headerlink" title="注意边界上的最佳值"></a>注意边界上的最佳值</h2><p>有些时候不一定能在指定范围内得到最佳的超参数，所以搜索得到超参数后应该再次检查该超参数值是否出现在边界，如果是，重设取值范围进行搜索</p>
<h2 id="从粗到细进行搜索"><a href="#从粗到细进行搜索" class="headerlink" title="从粗到细进行搜索"></a>从粗到细进行搜索</h2><p>可以划分不同阶段，先粗粒度搜索，再进行细粒度搜索。粗细阶段的划分有两个方面：</p>
<p>一个方面是在粗范围搜索过程中设置更大的取值，在细范围搜索过程中设置更小的取值</p>
<p>另一方面是在粗范围搜索过程中训练一次完整迭代（<code>one epoch</code>）甚至更少，然后随着阶段的深入逐渐提高训练迭代次数（<code>1 -&gt; 5 -&gt; 50 -&gt; ...</code>）</p>
<h2 id="贝叶斯超参数优化"><a href="#贝叶斯超参数优化" class="headerlink" title="贝叶斯超参数优化"></a>贝叶斯超参数优化</h2><p>贝叶斯（<code>bayesian</code>）超参数优化是一个研究领域，致力于提出更有效地导航超参数空间的算法。核心思想是在查询不同超参数下的性能时，适当平衡勘探开发权衡。当前有很多的模型库实现，不过在实际应用中其效果并不如随机搜索优化策略</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><code>cs231n</code>中更推荐使用随机搜索方式（配合粗细阶段设置）进行超参数优化</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>最优化</category>
      </categories>
      <tags>
        <tag>超参数优化</tag>
      </tags>
  </entry>
  <entry>
    <title>权重初始化</title>
    <url>/posts/cfd35552.html</url>
    <content><![CDATA[<p>合理的权重初始化操作有助于实现更快的训练和得到更好的结果，<code>cs231n</code>中讨论了不同的初始化权重方式：<a href="http://cs231n.github.io/neural-networks-2/#init" target="_blank" rel="noopener">Weight Initialization</a></p><a id="more"></a>
<h2 id="全零初始化"><a href="#全零初始化" class="headerlink" title="全零初始化"></a>全零初始化</h2><p>有一个合理性假设是保持初始化后的权重值一半为正一半为负，即权重均值为零。虽然直接设置权重为零符合这一假设，但因为全零权重导致神经元输出一致，在反向传播中计算得到相同梯度并进行同样的权重更新，无法训练得到好的模型</p>
<p>这也给出一个方向在于初始化后的权重虽然基于均值为零的前提，但应该打破正负两边的对称性</p>
<h2 id="小随机数初始化"><a href="#小随机数初始化" class="headerlink" title="小随机数初始化"></a>小随机数初始化</h2><p>通常用小随机数赋值权重，同时保证对称打破（<code>symmetry breaking</code>），实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">W = 0.01 * np.random.randn(D, H)</span><br></pre></td></tr></table></figure>
<p>这样得到的权重符合均值为零，方差为<code>0.01</code>的正态分布</p>
<p><strong>注意：不一定是权重越小越好，因为计算得到的梯度跟权重值呈正相关，对于深度网络而言，梯度在反向传播过程中会随着层的递增而越来越小，出现梯度弥散现象</strong></p>
<h2 id="方差校准"><a href="#方差校准" class="headerlink" title="方差校准"></a>方差校准</h2><p>使用小随机数初始化方式得到的权重会导致神经元输出分布的方差会随着输入神经元个数的增长而增长。推导如下，假设点积操作为$s = \sum_{i}^{n} w_{i}x_{i}$，输出结果$s$的方差计算如下：</p>
<script type="math/tex; mode=display">
Var(s) = Var(\sum_{i}^{n}w_{i}x_{i})=\sum_{i}^{n}Var(w_{i}x_{i})\\
=\sum_{i}^{n}([E(w_{i})]^{2}Var(x_{i}) + [E(x_{i})]^{2}Var(w_{i})) + Var(x_{i})Var(w_{i})\\
=\sum_{i}^{n}Var(x_{i})Var(w_{i})
=nVar(w)Var(x)
=Var(\frac {1}{n}w)Var(x)</script><p>上述推导基于如下定义，参考：<a href="https://en.wikipedia.org/wiki/Variance#Product_of_independent_variables" target="_blank" rel="noopener">Product of independent variables</a></p>
<script type="math/tex; mode=display">
Var(XY) = [E(X)]^{2}Var(Y) + [E(Y)]^{2}Var(X) + Var(X)Var(Y)\\
Var(aX) = a^{2}Var(X)</script><p>基于输入数据和权重的均值为零：$E(w)=0$、$E(x)=0$</p>
<p>为保持输入输出具有同样分布，所以需要对权重除以$\frac {1}{\sqrt n}$。修改权重初始化方式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">W = weight_scale * np.random.rand(n) / sqrt(n)</span><br></pre></td></tr></table></figure>
<p>其中$n$是每层输入神经元的个数</p>
<p>文章<a href="http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf" target="_blank" rel="noopener">Understanding the difficulty of training deep feedforward neural networks</a>基于对反向传播梯度的折衷和等效分析（<code>compromise and an equivalent analysis</code>），提出的权重分布为$Var(w) = 2/(n_{in}+n_{out})$，其中$n_{in}$和$n_{out}$是上一层和下一层的神经元数量，初始化方式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">W = weight_scale * np.random.randn(n) * 2 / (n_in + n_out)</span><br></pre></td></tr></table></figure>
<p>文章<a href="http://arxiv-web3.library.cornell.edu/abs/1502.01852" target="_blank" rel="noopener">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a>是最新的一个研究，其初始化方式为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">W = weight_scale * np.random.randn(n) * sqrt(2.0/n)</span><br></pre></td></tr></table></figure>
<p>是目前推荐的使用<code>ReLU</code>的网络的权重初始化方法</p>
<p><em>另一种解决方差校正的方式是使用稀疏初始化</em></p>
<h2 id="偏置值校正"><a href="#偏置值校正" class="headerlink" title="偏置值校正"></a>偏置值校正</h2><p>打破对称影响以通过权重初始化实现，简单设置偏置向量为<code>0</code>即可</p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>选择小随机数初始化方式以及<code>2</code>种方差校正方式进行测试</p>
<p>参考：<a href="https://github.com/zjZSTU/cs231n/blob/master/coding/classifier/weight_initialize.py" target="_blank" rel="noopener">weight_initialize.py</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def weight_initialize_v1(D, H, weight_scale=1e-2):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    小随机数初始化权重</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return weight_scale * np.random.randn(D, H)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def weight_initialize_v2(D, H, weight_scale=1e-2):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    方差校正方式一</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return weight_scale * np.random.randn(D, H) / np.sqrt(D)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def weight_initialize_v3(D, H, weight_scale=1e-2):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    方差校正方式二</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return weight_scale * np.random.randn(D, H) * np.sqrt(2.0 / D)</span><br></pre></td></tr></table></figure>
<ul>
<li>数据集设置：使用<code>CIFAR10</code>数据集，从中取<code>5000</code>张作为小测试集进行训练</li>
<li>超参数设置：初始学习率<code>1e-3</code>，迭代<code>100</code>轮，批量大小为<code>200</code></li>
<li>使用<code>Adam</code>实现权重更新</li>
<li>使用<code>3</code>层网络，大小为<code>32*32*3 -&gt; 400 -&gt; 200 -&gt; 10</code></li>
</ul>
<p>完整实现参考：<a href="https://github.com/zjZSTU/cs231n/blob/master/coding/train/weight_initialize.py" target="_blank" rel="noopener">weight_initialize.py</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-8-3 下午8:51</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">from datas.cifar import get_CIFAR10_data</span><br><span class="line">from classifier.nn_classifier import NN</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">cifar_path = &apos;/home/zj/data/cifar-10-batches-py&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(results):</span><br><span class="line">    for k, v in results.items():</span><br><span class="line">        plt.plot(v, label=k)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    data_dict = get_CIFAR10_data(cifar_path, val_size=0.1)</span><br><span class="line"></span><br><span class="line">    x_val = data_dict[&apos;X_val&apos;]</span><br><span class="line">    y_val = data_dict[&apos;y_val&apos;]</span><br><span class="line"></span><br><span class="line">    x_val_flatten = x_val.reshape(x_val.shape[0], -1)</span><br><span class="line"></span><br><span class="line">    D = 32 * 32 * 3</span><br><span class="line">    H1 = 400</span><br><span class="line">    H2 = 200</span><br><span class="line">    O = 10</span><br><span class="line"></span><br><span class="line">    weight_init_list = [&apos;v1&apos;, &apos;v2&apos;, &apos;v3&apos;]</span><br><span class="line">    loss_dict = &#123;&#125;</span><br><span class="line">    for item in weight_init_list:</span><br><span class="line">        classifier = NN([H1, H2], input_dim=D, num_classes=O, learning_rate=1e-3, weight_init=item)</span><br><span class="line">        loss_history = classifier.train(x_val_flatten, y_val, num_iters=50, verbose=True)</span><br><span class="line">        loss_dict[item] = loss_history</span><br><span class="line">    plot(loss_dict)</span><br></pre></td></tr></table></figure>
<p>训练<code>100</code>轮后的损失值变化如下：</p>
<p><img src="/imgs/权重初始化/loss_weight_init.png" alt></p>
<p>从上图可知，使用小随机数初始化以及方差矫正方法的结果类似，不过使用推荐方式进行初始化的权重收敛曲线更平稳</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>对于使用<code>ReLU</code>的网络，权重和偏置向量初始化方式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">W = weight_scale * np.random.randn(D, H) * sqrt(2.0/D)</span><br><span class="line">b = np.zeros((1, H))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>最优化</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>权重初始化</tag>
      </tags>
  </entry>
  <entry>
    <title>合理性检查</title>
    <url>/posts/869619ac.html</url>
    <content><![CDATA[<p>创建模型，进行数据集训练之前可以进行合理性检查（<code>sanity check</code>），参考<a href="http://cs231n.github.io/neural-networks-3/#sanitycheck" target="_blank" rel="noopener">Before learning: sanity checks Tips/Tricks</a>，有助于更好的判断模型有效性</p><a id="more"></a>
<p><code>cs231n</code>中给出了<code>3</code>个技巧：</p>
<ol>
<li>寻找正确损失值</li>
<li>判断正则化强度有效性</li>
<li>过拟合小数据集</li>
</ol>
<h2 id="寻找正确损失值"><a href="#寻找正确损失值" class="headerlink" title="寻找正确损失值"></a>寻找正确损失值</h2><p>确保初始化模型完成后能够得到期待的损失值，这次检查仅关注于数据损失（<code>data loss</code>），所以先设置正则化强度为零</p>
<p>以<code>Softmax</code>分类器为例，在<code>CIFAR-10</code>数据集上的初始损失值应该是$2.302$，因为期望每个类的扩散概率（<code>diffuse probability</code>）为<code>0.1</code>（共<code>10</code>个类），<code>Softmax</code>损失是计算正确类的负对数概率（<code>the negative log probability of the correct class</code>），所以计算结果是：$-\ln(0.1)=2.302$</p>
<p>对于<code>SVM</code>分类器而言，期待正确类对错误类的分离边界为$1$，所以损失值为$9$</p>
<h2 id="判断正则化强度有效性"><a href="#判断正则化强度有效性" class="headerlink" title="判断正则化强度有效性"></a>判断正则化强度有效性</h2><p>提高正则化强度会导致损失值变大</p>
<h2 id="过拟合小数据集"><a href="#过拟合小数据集" class="headerlink" title="过拟合小数据集"></a>过拟合小数据集</h2><p>在训练完整数据集之前，先设置正则化强度为零，尝试训练一个小数据集（比如<code>20</code>个样本），看是否能够实现损失值为$0$</p>
<p>这一步是<strong>最重要的</strong>合理性检查技巧，如果没法过拟合小数据集，那么没有必要再训练完整的数据集</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>最优化</category>
      </categories>
      <tags>
        <tag>合理性检查</tag>
      </tags>
  </entry>
  <entry>
    <title>梯度检查</title>
    <url>/posts/d91a1c6f.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit" target="_blank" rel="noopener">CS231n课程笔记翻译：神经网络笔记3（上）</a></p><p><a href="https://zhuanlan.zhihu.com/p/21387326" target="_blank" rel="noopener">CS231n课程笔记翻译：最优化笔记（下）</a></p><p>通过数值梯度（<code>numerical gradient</code>）和解析梯度（<code>analytic gradient</code>）的比较进行梯度检查，这个过程有助于得到更准确的网络</p><a id="more"></a>



<p>学习<a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">Gradient checks</a>中提到的技巧和注意事项</p>
<h2 id="中心差分"><a href="#中心差分" class="headerlink" title="中心差分"></a>中心差分</h2><p>使用中心差分公式（<code>the centered difference formula</code>）能够更好的计算数值梯度</p>
<script type="math/tex; mode=display">
\frac {df(x)}{dx}
=\frac {f(x+h) - f(x-h)}{2h}</script><p>步长$h$是一个极小值，当前取值为$1e^{-5}$</p>
<h2 id="相对误差比较"><a href="#相对误差比较" class="headerlink" title="相对误差比较"></a>相对误差比较</h2><p>计算数值梯度$f_{n}’$和解析梯度$f_{a}’$的相对误差，同时除以其中最大值以消除量纲，最后得到的值能够有一个统一的评判标准</p>
<script type="math/tex; mode=display">
\frac {|f_{n}' - f_{a}'|}{\max (|f_{n}'|, |f_{a}'|, 1e^{-8})}</script><p>使用$max$以及$1e^{-8}$是为了避免最大值为$0$以及两个值均为$0$的情况</p>
<h2 id="评判标准"><a href="#评判标准" class="headerlink" title="评判标准"></a>评判标准</h2><ul>
<li>相对误差大于$1e^{-2}$通常意味着梯度可能是错误的</li>
<li>相对误差在$[1e^{-2}, 1e^{-4}]$之间同样不太准确</li>
<li>相对误差小于$1e^{-4}$，如果目标存在扭结（<code>kinks</code>），比如<code>tanh</code>非线性或者<code>softmax</code>，那么这个结果是可以接受的；否则，$1e^{-4}$仍然太高</li>
<li>相对误差小于$1e^{-7}$是最好的结果</li>
</ul>
<p>深度网络的相对误差变得更大，所以对于<code>10</code>层网络而言，其相对误差小于$1e^{-2}$可能就很好了，因为误差在传递过程中累积；相反，对于单个可微函数而言，$1e^{-2}$表明梯度不正确</p>
<h2 id="使用双精度"><a href="#使用双精度" class="headerlink" title="使用双精度"></a>使用双精度</h2><p>使用双精度（<code>double precision</code>）数据进行梯度检查能够得到更准确的相对误差</p>
<h2 id="保持浮点数有效范围"><a href="#保持浮点数有效范围" class="headerlink" title="保持浮点数有效范围"></a>保持浮点数有效范围</h2><p>参考：<a href="http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html" target="_blank" rel="noopener">What Every Computer Scientist Should Know About Floating-Point Arithmetic</a></p>
<p>在梯度计算过程中，如果梯度的有效范围（<em>大部分梯度的取值</em>）太小，会造成更多的数值问题（<code>numerical issues</code>）</p>
<p>可以通过打印原始数值/解析梯度的方式查看，也可以通过<code>IDE</code>调试工具进行查看。如果数值梯度过小，比如取值在$1e^{-10}$左右甚至更小，可以通过放大损失函数值进行调整，理想情况下在$1.0$的数量级，即浮点数的指数为$0$</p>
<h2 id="目标中的扭结"><a href="#目标中的扭结" class="headerlink" title="目标中的扭结"></a>目标中的扭结</h2><p>相对误差过大的一个原因在于扭结（<code>kink</code>）的问题，扭结是指目标函数的不可微部分（<code>non-differentiable parts</code>），比如<code>ReLU</code>函数在$x=0$点</p>
<p>假定输入数据$x=-1e^{-6}$，因为<code>x</code>小于<code>0</code>，所以该点的解析梯度为<code>0</code>，然而如果$h&gt;1e^{-6}$，那么$f(x+h)&gt;0$，数值梯度大于<code>0</code>，会得到一个较大的相对误差</p>
<p>查找是否出现扭结需要追踪所有激活函数$\max(x,y)$中<code>winner</code>的身份，比如在前向计算中$x$或者$y$的值更大，但是在$f(x+h)$或$f(x-h)$的计算中<code>winner</code>身份发生了改变，那么表明出现了扭结现象</p>
<p>一种解决技巧是使用少量的数据点进行测试，降低发生扭结的可能性</p>
<h2 id="谨慎设置步长h"><a href="#谨慎设置步长h" class="headerlink" title="谨慎设置步长h"></a>谨慎设置步长h</h2><p>参考：<a href="https://en.wikipedia.org/wiki/Numerical_differentiation" target="_blank" rel="noopener">Numerical differentiation</a></p>
<p>步长$h$不一定是越小越好，因为过小的步长有可能会产生数值精度问题。当梯度无法检查时，可以尝试改变步长为$1e^{-4}$或$1e^{-6}$</p>
<h2 id="Gradcheck-during-a-“characteristic”-mode-of-operation"><a href="#Gradcheck-during-a-“characteristic”-mode-of-operation" class="headerlink" title="Gradcheck during a “characteristic” mode of operation"></a>Gradcheck during a “characteristic” mode of operation</h2><p>使用随机参数对网络进行梯度检查可能会引入病理边缘病例，并掩盖梯度的错误实现，也就是梯度看起来正确实现了，但实际上并没有</p>
<p>最好先训练一段时间，在损失值开始下降后再进行梯度检查，更能够保证网络的准确性</p>
<h2 id="不要让正则化项影响数据"><a href="#不要让正则化项影响数据" class="headerlink" title="不要让正则化项影响数据"></a>不要让正则化项影响数据</h2><p>损失函数包括数据损失以及正则化损失，如果正则化损失比数据损失大，那么主要的梯度将来自于正则化项，这会掩盖数据丢失梯度的错误实现</p>
<p>所以梯度检查时可以先单独检查数据损失，再检查正则化损失。检查正则化损失的方式一方面可以去除数据损失相关代码，另一方面可以提高正则化强度，使正则化梯度无法被忽略</p>
<h2 id="关闭随机失活-数据扩充"><a href="#关闭随机失活-数据扩充" class="headerlink" title="关闭随机失活/数据扩充"></a>关闭随机失活/数据扩充</h2><p>执行梯度检查的过程中，应该关闭网络中任何非确定性（<code>non-deterministic</code>）的影响，比如随机失活（<code>dropout</code>）、随机数据扩充（<code>random data augmentation</code>），因为在计算数值梯度时，这些参数会明显的带来巨大的误差</p>
<p>关闭操作会导致无法梯度检查这些参数，一种更好的解决方案是在计算$f(x+h)$和$f(x-h)$过程中设置特定的随机数种子</p>
<h2 id="检查少量维度"><a href="#检查少量维度" class="headerlink" title="检查少量维度"></a>检查少量维度</h2><p>实际操作中网络存在上百万的参数，这种情况下只能假设大部分参数是正确的，仅检查少数参数，<strong>特别注意的是</strong>确保在不同参数的某些维度进行梯度检查</p>
<h2 id="python实现"><a href="#python实现" class="headerlink" title="python实现"></a>python实现</h2><p>在<code>cs231n</code>课程的课后作业<code>assignment</code>中已实现了数值梯度计算 - <a href="https://github.com/zjZSTU/cs231n/blob/master/assignment1/cs231n/gradient_check.py" target="_blank" rel="noopener">gradient_check.py</a>，主要操作的是前两个函数：</p>
<blockquote>
<p>def eval_numerical_gradient(f, x, verbose=True, h=0.00001):<br>def eval_numerical_gradient_array(f, x, df, h=1e-5):</p>
</blockquote>
<ul>
<li>参数$f$表示待检查的方法/类/网络</li>
<li>参数$x$表示输入数据</li>
<li>参数$df$表示反向传播中回传的梯度</li>
</ul>
<p>两者均采用中心差分公式计算数值梯度，区别在于前一个函数的$f$输出值是单个数值，而后者$f$的输出值可以是数组</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-8-1 下午7:40</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def eval_numerical_gradient(f, x, verbose=True, h=0.00001):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    a naive implementation of numerical gradient of f at x</span><br><span class="line">    - f should be a function that takes a single argument</span><br><span class="line">    - x is the point (numpy array) to evaluate the gradient at</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    fx = f(x)  # evaluate function value at original point</span><br><span class="line">    grad = np.zeros_like(x)</span><br><span class="line">    # iterate over all indexes in x</span><br><span class="line">    it = np.nditer(x, flags=[&apos;multi_index&apos;], op_flags=[&apos;readwrite&apos;])</span><br><span class="line">    while not it.finished:</span><br><span class="line"></span><br><span class="line">        # evaluate function at x+h</span><br><span class="line">        ix = it.multi_index</span><br><span class="line">        oldval = x[ix]</span><br><span class="line">        x[ix] = oldval + h  # increment by h</span><br><span class="line">        fxph = f(x)  # evalute f(x + h)</span><br><span class="line">        x[ix] = oldval - h</span><br><span class="line">        fxmh = f(x)  # evaluate f(x - h)</span><br><span class="line">        x[ix] = oldval  # restore</span><br><span class="line"></span><br><span class="line">        # compute the partial derivative with centered formula</span><br><span class="line">        grad[ix] = (fxph - fxmh) / (2 * h)  # the slope</span><br><span class="line">        if verbose:</span><br><span class="line">            print(ix, grad[ix])</span><br><span class="line">        it.iternext()  # step to next dimension</span><br><span class="line"></span><br><span class="line">    return grad</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def eval_numerical_gradient_array(f, x, df, h=1e-5):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Evaluate a numeric gradient for a function that accepts a numpy</span><br><span class="line">    array and returns a numpy array.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    grad = np.zeros_like(x)</span><br><span class="line">    it = np.nditer(x, flags=[&apos;multi_index&apos;], op_flags=[&apos;readwrite&apos;])</span><br><span class="line">    while not it.finished:</span><br><span class="line">        ix = it.multi_index</span><br><span class="line"></span><br><span class="line">        oldval = x[ix]</span><br><span class="line">        x[ix] = oldval + h</span><br><span class="line">        pos = f(x).copy()</span><br><span class="line">        x[ix] = oldval - h</span><br><span class="line">        neg = f(x).copy()</span><br><span class="line">        x[ix] = oldval</span><br><span class="line"></span><br><span class="line">        grad[ix] = np.sum((pos - neg) * df) / (2 * h)</span><br><span class="line">        it.iternext()</span><br><span class="line">    return grad</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_value(x):</span><br><span class="line">    return np.sum(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_value_array(x):</span><br><span class="line">    return x + x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    x = np.arange(9., dtype=np.double).reshape(3, 3)</span><br><span class="line"></span><br><span class="line">    grad = eval_numerical_gradient(compute_value, x, verbose=False)</span><br><span class="line">    print(grad)</span><br><span class="line"></span><br><span class="line">    grad = eval_numerical_gradient_array(compute_value_array, x, 1)</span><br><span class="line">    print(grad)</span><br></pre></td></tr></table></figure>
<p>参考<code>cs231n</code>实现了全连接神经网络：<a href="https://github.com/zjZSTU/cs231n/blob/master/coding/classifier/nn_classifier.py" target="_blank" rel="noopener">nn_classifier.py</a>，包含了全连接以及<code>ReLU</code>层的前后向运算，神经网络配置、训练及预测功能</p>
<p>同时实现了全连接神经网络的测试文件：<a href="https://github.com/zjZSTU/cs231n/blob/master/coding/tests/test_nn_classifier.py" target="_blank" rel="noopener">test_nn_classifier.py</a>，里面包含了对全连接操作、<code>ReLU</code>操作、<code>softmax</code>损失操作以及<code>2</code>层和<code>3</code>层网络的测试</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>最优化</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>梯度检查</tag>
      </tags>
  </entry>
  <entry>
    <title>单元测试</title>
    <url>/posts/cef93ee3.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://en.wikipedia.org/wiki/Unit_testing" target="_blank" rel="noopener">Unit testing</a></p><p><a href="https://zh.wikipedia.org/wiki/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95" target="_blank" rel="noopener">单元测试</a></p><p><a href="https://baike.baidu.com/item/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95" target="_blank" rel="noopener">单元测试</a></p><p>单元测试（<code>unit testing</code>，简称<code>UT</code>）是用于测试源代码不同单元的软件测试方法， 能够有效提高代码质量和可维护性</p><a id="more"></a>




<h2 id="什么是单元测试"><a href="#什么是单元测试" class="headerlink" title="什么是单元测试"></a>什么是单元测试</h2><p>单元测试是由开发人员编写的用于测试程序单元正确性的方法，<strong>在面向对象过程中，一个单元通常指一个完整的接口，比如一个类，也可以是一个单独方法</strong></p>
<p>之前实现一个类的时候，总会实现<code>main</code>函数来测试该类是否能够正确运行，这就是最简单的单元测试，而利用单元测试框架 + 持续集成工具能够有效管理测试用例，加速软件开发</p>
<p>为了能够分离错误，测试用例应该独立运行，不相互依赖；每个测试用例仅用于测试单个程序单元</p>
<h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>单元测试的目的就是为了提高代码质量和可维护性。通过编写<code>UT</code>将程序分离成单元进行测试，一方面易于调试，在开发初期就能够发现潜在错误，另一方面保证基础单元的正确性能够自下而上（<code>bottom-up</code>）的提高代码质量；同时编写<code>UT</code>的过程也有利于明确需求，保持程序简洁，提高可维护性</p>
<h2 id="测试用例"><a href="#测试用例" class="headerlink" title="测试用例"></a>测试用例</h2><p>参考：</p>
<p><a href="https://zhuanlan.zhihu.com/p/29968920" target="_blank" rel="noopener">Python 单元测试</a></p>
<p><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/python/pytest.html" target="_blank" rel="noopener">pytest</a></p>
<p>编写类<code>Password</code>，输入密码满足<code>6-16</code>位</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-31 下午7:44</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Password(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.password = None</span><br><span class="line"></span><br><span class="line">    def set_password(self, inputs):</span><br><span class="line">        assert isinstance(inputs, str) or isinstance(inputs, int)</span><br><span class="line">        length = len(str(inputs))</span><br><span class="line">        if 6 &lt;= length &lt;= 16:</span><br><span class="line">            self.password = str(inputs)</span><br><span class="line">        else:</span><br><span class="line">            raise ValueError(&apos;password length is between 6 and 16&apos;)</span><br></pre></td></tr></table></figure>
<p>编写类<code>TestPassword</code>，测试异常情况</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-31 下午7:52</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import pytest</span><br><span class="line"></span><br><span class="line">from test.password import Password</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class TestPassword(object):</span><br><span class="line"></span><br><span class="line">    def test_exception(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        测试错误输入是否能够抛出异常</span><br><span class="line">        :return:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        password = Password()</span><br><span class="line">        with pytest.raises(ValueError, match=&apos;password length is between 6 and 16&apos;):</span><br><span class="line">            password.set_password(2123)</span><br><span class="line">        with pytest.raises(ValueError, match=&apos;password length is between 6 and 16&apos;):</span><br><span class="line">            password.set_password(&apos;123sadfasdfsddddddddddddddddddddddddddddd&apos;)</span><br><span class="line"></span><br><span class="line">    def test_value(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        测试正确输入</span><br><span class="line">        :return:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        password = Password()</span><br><span class="line">        assert password.set_password(&apos;123456&apos;)</span><br><span class="line">        assert password.set_password(1234125)</span><br></pre></td></tr></table></figure>
<p>执行测试</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ pytest </span><br><span class="line">========================================================== test session starts ===========================================================</span><br><span class="line">platform linux -- Python 3.7.1, pytest-4.0.2, py-1.7.0, pluggy-0.8.0</span><br><span class="line">rootdir: /home/zj/deeplearning/cs231n/coding/test, inifile:</span><br><span class="line">plugins: remotedata-0.3.1, openfiles-0.3.1, doctestplus-0.2.0, arraydiff-0.3</span><br><span class="line">collected 2 items                                                                                                                        </span><br><span class="line"></span><br><span class="line">test_password.py ..                                                                                                                [100%]</span><br><span class="line"></span><br><span class="line">======================================================== 2 passed in 0.01 seconds ========================================================</span><br></pre></td></tr></table></figure>
<h2 id="需不需要编写单元测试"><a href="#需不需要编写单元测试" class="headerlink" title="需不需要编写单元测试"></a>需不需要编写单元测试</h2><p>相对于功能实现，编写<code>UT</code>是一份额外工作，自己也会考虑需不需要编写<code>UT</code>，网上有一个讨论 - <a href="https://www.zhihu.com/question/28729261" target="_blank" rel="noopener">单元测试到底是什么？应该怎么做？</a></p>
<p>经历过大大小小多个项目的开发后，渐渐会感觉到测试对于项目质量和维护的重要性，所有对于是否需要编写单元测试持肯定态度。不过具体到某个项目，也要根据实际场景进行分析：如果项目代码量不大（少于<code>1000</code>行）并且功能简单，那么看时间安排是否编写<code>UT</code>；否则，一定要编写<code>UT</code>。当然，如果对<code>UT</code>不熟悉，最好还是先在小项目上多练练手</p>
<p><em>突然想到一个事情：如何判断你在做产品还是做外包？有没有写单元测试！</em></p>
]]></content>
      <categories>
        <category>软件工程</category>
        <category>测试模型</category>
      </categories>
      <tags>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title>测试驱动开发</title>
    <url>/posts/913b0c70.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://en.wikipedia.org/wiki/Test-driven_development#Benefits" target="_blank" rel="noopener">Test-driven development</a></p><p><a href="https://baike.baidu.com/item/TDD/9064369" target="_blank" rel="noopener">测试驱动开发(Test-Driven Development)</a></p><a id="more"></a>


<p>主要内容：</p>
<ol>
<li>什么是TDD</li>
<li>实现流程</li>
<li>开发风格</li>
<li>优点</li>
<li>是否需要TDD</li>
</ol>
<h2 id="什么是TDD"><a href="#什么是TDD" class="headerlink" title="什么是TDD"></a>什么是TDD</h2><p>测试驱动开发（<code>test-driven development, TDD</code>）是一种敏捷开发模型的开发流程，首先编写测试用例来理清开发需求，之后修改代码以通过测试，最后重构代码，不断重复这个开发周期。<code>TDD</code>通过测试用例来具体化开发需求，不仅有利于需求的实现，也有利于软件的鲁棒性</p>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>参考：<a href="https://www.guru99.com/test-driven-development.html" target="_blank" rel="noopener">What is Test Driven Development (TDD)? Tutorial with Example</a></p>
<h2 id="实现流程"><a href="#实现流程" class="headerlink" title="实现流程"></a>实现流程</h2><ol>
<li><p><strong>添加测试（Add a test）</strong></p>
<p> 在<code>TDD</code>中，每次添加新功能都需要先编写测试用例。可以修改原有测试代码或者添加新的测试代码，其目的是让开发者更加理解和明确新功能的要求和规范，同时编写的测试应该覆盖所有的意外情况</p>
</li>
<li><p><strong>运行所有测试，是否新测试失败（Run all tests and see if the new test fails）</strong></p>
<p> 执行这一步骤是为了验证修改后的测试代码是否符合原先的测试要求，同时验证新测试是否因为预期原因而失败，保证测试的可靠性</p>
</li>
<li><p><strong>编写代码（Writing the code）</strong></p>
<p> 修改代码以确保测试通过。这个步骤过程中不关注代码可读性，同时不能编写超出测试检查功能之外的代码</p>
</li>
<li><p><strong>运行测试（Run tests）</strong></p>
<p> 确认所有测试是否通过。这一步骤确保编写的代码符合新测试的要求，并且没有破坏（<code>break</code>）或降低（<code>degrade</code>）已有测试，如果没有成功，重复第三步</p>
</li>
<li><p><strong>重构（Refactor code）</strong></p>
<p> 修改代码已保证代码可读性，确保对象（<code>Object</code>）、类（<code>Class</code>）、模块（<code>Module</code>）、变量（<code>Variable</code>）和方法（<code>Method</code>）名能够清晰的表明其当前目的和作用</p>
</li>
<li><p><strong>重复（Repeat）</strong></p>
<p> 重复上述循环以推动功能实现。每个周期的修改部分应该尽可能小，最好仅有<code>1-10</code>处编辑位置。如果新代码无法快速满足新测试，可以先恢复（<code>revert</code>）修改代码，重新结构化需求和测试</p>
</li>
</ol>
<p>上述实现流程设定了开发节点，配合版本管理工具和持续集成工具能够更好的帮助开发</p>
<h2 id="开发风格"><a href="#开发风格" class="headerlink" title="开发风格"></a>开发风格</h2><p>保持代码尽可能简洁和简单，遵循以下3条原则：</p>
<ul>
<li>Keep it simple, stupid(KISS)</li>
<li>You aren’t gonna need it(YANGI)</li>
<li>Fake it until you make it</li>
</ul>
<h3 id="小单元开发"><a href="#小单元开发" class="headerlink" title="小单元开发"></a>小单元开发</h3><p>每个开发周期尽可能涉及较少的类或者模块，有以下好处：</p>
<ol>
<li>减少调试工作量 - 当检测到测试失败时，较小的单元有助于跟踪错误</li>
<li>自我文档测试 - 小型测试用例更容易阅读和理解</li>
</ol>
<h3 id="测试结构"><a href="#测试结构" class="headerlink" title="测试结构"></a>测试结构</h3><p>保持统一的测试结构有助于提高可读性以及理解执行流程，常用的测试用例结构如下：</p>
<ol>
<li>设置（<code>setup</code>）：将被测单元（<code>the Unit Under Test, UUT</code>）或整个测试系统置于运行测试所需的状态，也就是设置初始状态</li>
<li>执行（<code>execution</code>）：触发或驱动<code>UUT</code>执行目标行为，并捕获所有输出，比如返回值和输出参数</li>
<li>验证（<code>validation</code>）：确保测试结果正确。这些结果可能包括执行期间捕获的显式输出或<code>UUT</code>中的状态更改</li>
<li>清理（<code>cleanup</code>）：将<code>UUT</code>或整个测试系统恢复到预测试状态。此恢复允许在此之后立即执行另一个测试</li>
</ol>
<h3 id="环境分离"><a href="#环境分离" class="headerlink" title="环境分离"></a>环境分离</h3><p>开发过程中保持测试和生产代码分离，确保发布版本中不包含测试代码</p>
<h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>测试优先能够保证接下来的编写代码环节专注于可检验性（<code>testability</code>），同时确保每次添加新功能都会实现测试用例，有助于更深和更快的理解产品需求，保持对产品质量的关注。如果在功能完成之后再编写测试用例，经常会专注于下一个新功能而忘记测试（<strong><em>有道理</em></strong>）</p>
<h2 id="是否需要TDD"><a href="#是否需要TDD" class="headerlink" title="是否需要TDD"></a>是否需要TDD</h2><p>网上有一些讨论：<a href="https://www.zhihu.com/question/37623307" target="_blank" rel="noopener">TDD（测试驱动开发）是否已死？</a>，关于是否需要<code>TDD</code>编程</p>
<p>就我个人而言，虽然只是刚开始接触，但是之前的<code>coding</code>经历让我明确了测试实现的必要性，学习<code>TDD</code>流程会有一种豁然开朗的感觉，不管咋样，先尝试一段时间看看再说</p>
<p>相关文章：</p>
<p><a href="https://zhuanlan.zhihu.com/p/29074678" target="_blank" rel="noopener">TDD看起来什么都不能干，但我为什么还要坚持TDD</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/25571122" target="_blank" rel="noopener">TDD 伤害了软件架构吗？</a></p>
]]></content>
      <categories>
        <category>软件工程</category>
        <category>开发流程</category>
      </categories>
      <tags>
        <tag>测试驱动开发</tag>
      </tags>
  </entry>
  <entry>
    <title>决策边界</title>
    <url>/posts/c37e79f3.html</url>
    <content><![CDATA[<p>在分类问题上经常会遇到一个名词 - 决策边界。对它有一些了解但是没有很多的认识，同时很难直观去理解高维数据分类问题的决策边界</p><a id="more"></a>
<p>理清决策边界的概念，同时可视化决策边界</p>
<h2 id="什么是决策边界"><a href="#什么是决策边界" class="headerlink" title="什么是决策边界"></a>什么是决策边界</h2><p>参考：<a href="https://en.wikipedia.org/wiki/Decision_boundary" target="_blank" rel="noopener">Decision boundary</a></p>
<p>对于二分类问题，如果在向量空间中存在一个能够分类数据集的超曲面（<code>hypersurface</code>），使得同一类的数据点在超曲面的同一边，称该超曲面为决策边界（<code>decision boundary</code>）或决策曲面（<code>decision surface</code>）</p>
<h2 id="什么是超平面"><a href="#什么是超平面" class="headerlink" title="什么是超平面"></a>什么是超平面</h2><p>参考：</p>
<p><a href="https://baike.baidu.com/item/%E8%B6%85%E5%B9%B3%E9%9D%A2" target="_blank" rel="noopener">超平面</a></p>
<p><a href="https://blog.csdn.net/dengheCSDN/article/details/77313758" target="_blank" rel="noopener">超平面是什么？——理解超平面（SVM开篇之超平面详解）</a></p>
<p><a href="https://www.zhihu.com/question/24954154" target="_blank" rel="noopener">关于超平面的疑问?</a></p>
<p>超平面是维度比向量空间维度小<code>1</code>的线性子空间，比如<code>3</code>维向量空间的超平面是<code>2</code>维，<code>2</code>维向量空间的超平面是<code>1</code>维</p>
<p>超平面的另一种解释是它的自由度比向量空间维度小<code>1</code>，比如在<code>3</code>维向量空间的<code>2</code>维超平面上，给定<code>（x,y,z）</code>中的任意两点就能确定剩余一点的值</p>
<p>超平面的数学形式如下：</p>
<p>对于二维空间，超平面就是一条直线：$ax + by + c=0$</p>
<p>对于三维空间，超平面就是一个平面：$ax + by + cz + d = 0$</p>
<p>推广到$n$维空间：$ax + by + cz + … + x = 0$</p>
<p>简写成：$wX + b = 0$</p>
<h2 id="线性-vs-非线性"><a href="#线性-vs-非线性" class="headerlink" title="线性 vs. 非线性"></a>线性 vs. 非线性</h2><p>参考：<a href="https://www.zhihu.com/question/30633734" target="_blank" rel="noopener">线性分类器与非线性分类器的区别？</a></p>
<p>如果决策边界是一个超平面（<code>hyperplane</code>），那么称该分类问题为线性可分的，分类器是线性分类器（<code>linear classifier</code>），反之称之为非线性分类器（<code>nonlinear classifier</code>）</p>
<h3 id="常用线性和非线性分类器"><a href="#常用线性和非线性分类器" class="headerlink" title="常用线性和非线性分类器"></a>常用线性和非线性分类器</h3><p>线性分类器</p>
<ul>
<li>对于<strong>线性SVM分类器</strong>而言，其前向操作就是一个线性映射，所以它是线性分类器</li>
<li>对于<strong>逻辑回归分类器</strong>而言，其前向操作是线性映射+<code>sigmoid</code>函数，其是否线性判定比较复杂，参考<a href="https://www.zhihu.com/question/30726036" target="_blank" rel="noopener">logistic回归属于线性模型还是非线性模型？</a>，<strong>就我个人观察，虽然<code>sigmoid</code>操作增加了非线性因素，但通常以$p=0.5$作为分类面进行分类，也就是说，线性映射结果就决定了分类结果，那么可以看成是线性分类器</strong></li>
<li>对于<strong>softmax分类器</strong>而言，其是逻辑回归对于多分类问题的推广，参考<a href="http://cs231n.github.io/linear-classify/#softmax" target="_blank" rel="noopener">Softmax classifier</a>，同样可看成是线性分类器</li>
</ul>
<p>非线性分类器</p>
<ul>
<li>对于<strong>神经网络</strong>而言，如果没有隐藏层，那么就是一个线性分类器；如果有多个隐藏层就是非线性分类器</li>
<li>对于<strong>KNN分类器</strong>而言，其分类标准基于训练数据和测试数据的像素差异，不存在分类超平面，所以是非线性分类器</li>
</ul>
<h2 id="决策边界可视化"><a href="#决策边界可视化" class="headerlink" title="决策边界可视化"></a>决策边界可视化</h2><p>参考：</p>
<p><a href="https://www.devtalking.com/articles/machine-learning-11/" target="_blank" rel="noopener">机器学习笔记十一之决策边界</a></p>
<p><a href="http://blog.itpub.net/31545819/viewspace-2564384/" target="_blank" rel="noopener">决策边界可视化，让你的分类合理有序</a></p>
<p>可视化决策边界能够有助于算法的理解和改进，实现方式可分为两类：</p>
<ol>
<li><p>单线决策边界：使用一条数据线分隔不同类区域</p>
</li>
<li><p>基于轮廓的决策边界：利用不同颜色的轮廓包围数据点区域</p>
</li>
</ol>
<h3 id="单线决策边界"><a href="#单线决策边界" class="headerlink" title="单线决策边界"></a>单线决策边界</h3><p>这种方式适用于线性分类器，以逻辑回归分类器为例，其类实现地址：<a href="https://github.com/zjZSTU/cs231n/blob/master/coding/classifier/lr_classifier.py" target="_blank" rel="noopener">lr_classifier.py</a></p>
<p>数据集<code>scores.csv</code>包含<code>100</code>名学生在<code>2</code>次考试中获得的分数和标签，下载链接</p>
<ul>
<li><a href="https://github.com/navoneel1092283/logistic_regression.git" target="_blank" rel="noopener">https://github.com/navoneel1092283/logistic_regression.git</a></li>
<li><a href="https://download.csdn.net/download/u012005313/11384178" target="_blank" rel="noopener">https://download.csdn.net/download/u012005313/11384178</a></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-18 下午8:51</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from lr_classifier import LogisticClassifier</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_scores(data_path, shuffle=True, tsize=0.8):</span><br><span class="line">    df = pd.read_csv(data_path, header=None, sep=&apos;,&apos;)</span><br><span class="line">    values = np.array(df.values)</span><br><span class="line">    x = values[:, :2]</span><br><span class="line">    y = values[:, 2]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=shuffle, train_size=tsize)</span><br><span class="line"></span><br><span class="line">    return x_train, x_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    scores_path = &apos;/home/zj/data/scores.csv&apos;</span><br><span class="line">    x_train, x_test, y_train, y_test = load_scores(scores_path)</span><br><span class="line"></span><br><span class="line">    # 零中心 + 单位方差</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-5</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(var + eps)</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(var + eps)</span><br><span class="line"></span><br><span class="line">    # 训练分类器</span><br><span class="line">    classifier = LogisticClassifier()</span><br><span class="line">    classifier.train(x_train, y_train, num_iters=5000, batch_size=120, verbose=True)</span><br><span class="line"></span><br><span class="line">    # 编辑网络，预测结果</span><br><span class="line">    x_min, x_max = min(x_test[:, 0]) - 0.5, max(x_test[:, 0]) + 0.5</span><br><span class="line">    y_min, y_max = min(x_test[:, 1]) - 0.5, max(x_test[:, 1]) + 0.5</span><br><span class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))</span><br><span class="line">    x_grid = np.vstack((xx.reshape(-1), yy.reshape(-1))).T</span><br><span class="line">    # 预测结果</span><br><span class="line">    y_pred = classifier.predict(x_grid).reshape(xx.shape)</span><br><span class="line">    # 绘制等高轮廓</span><br><span class="line">    plt.contourf(xx, yy, y_pred, cmap=plt.cm.cool_r)</span><br><span class="line">    # 绘制测试点</span><br><span class="line">    indexs_0 = np.argwhere(y_test == 0).squeeze()</span><br><span class="line">    indexs_1 = np.argwhere(y_test == 1).squeeze()</span><br><span class="line">    plt.scatter(x_test[indexs_0, 0], x_test[indexs_0, 1], c=&apos;r&apos;, marker=&apos;&lt;&apos;)</span><br><span class="line">    plt.scatter(x_test[indexs_1, 0], x_test[indexs_1, 1], c=&apos;g&apos;, marker=&apos;8&apos;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>实现步骤如下：</p>
<ol>
<li>加载数据</li>
<li>训练逻辑回归分类器</li>
<li>编辑网格，预测结果</li>
<li>绘制轮廓图以及散点图</li>
</ol>
<p><img src="/imgs/决策边界/lr_decision_boundary.png" alt></p>
<h3 id="基于轮廓的决策边界"><a href="#基于轮廓的决策边界" class="headerlink" title="基于轮廓的决策边界"></a>基于轮廓的决策边界</h3><h4 id="两类数据决策边界"><a href="#两类数据决策边界" class="headerlink" title="两类数据决策边界"></a>两类数据决策边界</h4><p>从上面可知，使用单线决策边界无法实现非线性数据分类，下面使用神经网络分类器实现基于轮廓的决策边界。参考上述实现，替换分类器为神经网络分类器即可</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-18 下午9:22</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from nn_classifier import NN</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_scores(data_path, shuffle=True, tsize=0.8):</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">def draw_decision_boundary(classifier, x, y):</span><br><span class="line">    # 编辑网络，预测结果</span><br><span class="line">    x_min, x_max = min(x[:, 0]) - 0.5, max(x[:, 0]) + 0.5</span><br><span class="line">    y_min, y_max = min(x[:, 1]) - 0.5, max(x[:, 1]) + 0.5</span><br><span class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))</span><br><span class="line">    x_grid = np.vstack((xx.reshape(-1), yy.reshape(-1))).T</span><br><span class="line">    # 预测结果</span><br><span class="line">    y_pred = classifier.predict(x_grid).reshape(xx.shape)</span><br><span class="line">    # 绘制等高轮廓</span><br><span class="line">    plt.contourf(xx, yy, y_pred, cmap=plt.cm.cool_r)</span><br><span class="line">    # 绘制测试点</span><br><span class="line">    indexs_0 = np.argwhere(y == 0).squeeze()</span><br><span class="line">    indexs_1 = np.argwhere(y == 1).squeeze()</span><br><span class="line">    plt.scatter(x[indexs_0, 0], x[indexs_0, 1], c=&apos;r&apos;, marker=&apos;&lt;&apos;)</span><br><span class="line">    plt.scatter(x[indexs_1, 0], x[indexs_1, 1], c=&apos;g&apos;, marker=&apos;8&apos;)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    scores_path = &apos;/home/zj/data/scores.csv&apos;</span><br><span class="line">    x_train, x_test, y_train, y_test = load_scores(scores_path)</span><br><span class="line"></span><br><span class="line">    # 零中心 + 单位方差</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-8</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(var + eps)</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(var + eps)</span><br><span class="line"></span><br><span class="line">    # 训练分类器</span><br><span class="line">    classifier = NN([100], input_dim=2, num_classes=2, learning_rate=5e-2, reg=1e-3)</span><br><span class="line">    classifier.train(x_train, y_train, num_iters=20000, batch_size=256, verbose=True)</span><br><span class="line"></span><br><span class="line">    draw_decision_boundary(classifier, x_test, y_test)</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/决策边界/nn_decision_boundary.png" alt></p>
<h4 id="多类数据决策边界"><a href="#多类数据决策边界" class="headerlink" title="多类数据决策边界"></a>多类数据决策边界</h4><p><code>cs231n</code>中提供了一个神经网络测试：<a href="http://cs231n.github.io/" target="_blank" rel="noopener">Putting it together: Minimal Neural Network Case Study</a>，里面实现了<code>3</code>类数据集的分类，并绘制了决策面</p>
<p>数据集是自定义得到的<code>3</code>类数据，每类个数为<code>100</code>，维度为<code>2</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def load_data():</span><br><span class="line">    N = 100  # number of points per class</span><br><span class="line">    D = 2  # dimensionality</span><br><span class="line">    K = 3  # number of classes</span><br><span class="line">    X = np.zeros((N * K, D))  # data matrix (each row = single example)</span><br><span class="line">    y = np.zeros(N * K, dtype=&apos;uint8&apos;)  # class labels</span><br><span class="line">    for j in range(K):</span><br><span class="line">        ix = range(N * j, N * (j + 1))</span><br><span class="line">        r = np.linspace(0.0, 1, N)  # radius</span><br><span class="line">        t = np.linspace(j * 4, (j + 1) * 4, N) + np.random.randn(N) * 0.2  # theta</span><br><span class="line">        X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]</span><br><span class="line">        y[ix] = j</span><br><span class="line">    # lets visualize the data:</span><br><span class="line">    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    np.random.seed(100)</span><br><span class="line">    np.random.shuffle(X)</span><br><span class="line">    np.random.seed(100)</span><br><span class="line">    np.random.shuffle(y)</span><br><span class="line"></span><br><span class="line">    return X, y</span><br></pre></td></tr></table></figure>
<p>使用<code>softmax</code>分类器实现结果：</p>
<p><img src="/imgs/决策边界/spiral_linear.png" alt></p>
<p>使用<code>2</code>层神经网络（隐藏层神经元个数为<code>100</code>），学习率为<code>1e-0</code>，正则化强度为<code>1e-3</code>，共训练<code>10000</code>轮</p>
<p><img src="/imgs/决策边界/spiral_net.png" alt></p>
<h4 id="多维数据决策边界"><a href="#多维数据决策边界" class="headerlink" title="多维数据决策边界"></a>多维数据决策边界</h4><p>如果数据集维度为多维，需要进一步降维才能进行决策边界可视化。有两种方式进行降维操作：</p>
<blockquote>
<p>1.利用随机森林分类器等给特征进行重要性评分，得到2个最重要的特征，然后在散点图上绘制决策边界。<br>2.主成分分析(PCA)或线性判别分析(LDA)等降维技术可用于将N个特征嵌入到2个特征中，从而将N个特征的信息解释或减少为2个特征(n_components = 2)。然后再基于这两个特征在散点图上绘制决策边界。</p>
</blockquote>
<p>使用<code>Iris</code>数据集进行测试，其包含<code>3</code>类数据，数据维度为<code>4</code>，参考：<a href="https://www.zhujian.tech/posts/ba2ca878.html">iris数据集</a></p>
<p>参考<a href="https://www.zhujian.tech/posts/49729a62.html#more">主成分分析</a>，实现<code>PCA</code>降维操作，完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-16 上午9:52</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn import utils</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import matplotlib as mpl</span><br><span class="line">from nn_classifier import NN</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_iris(iris_path, shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(iris_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        data = utils.shuffle(data)</span><br><span class="line"></span><br><span class="line">    species_dict = &#123;</span><br><span class="line">        &apos;Iris-setosa&apos;: 0,</span><br><span class="line">        &apos;Iris-versicolor&apos;: 1,</span><br><span class="line">        &apos;Iris-virginica&apos;: 2</span><br><span class="line">    &#125;</span><br><span class="line">    data[&apos;Species&apos;] = data[&apos;Species&apos;].map(species_dict)</span><br><span class="line"></span><br><span class="line">    data_x = np.array(</span><br><span class="line">        [data[&apos;SepalLengthCm&apos;], data[&apos;SepalWidthCm&apos;], data[&apos;PetalLengthCm&apos;], data[&apos;PetalWidthCm&apos;]]).T</span><br><span class="line">    data_y = np.array(data[&apos;Species&apos;])</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=False)</span><br><span class="line"></span><br><span class="line">    return x_train, x_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def pca(X, ratio=0.99, **kwargs):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    pca降维</span><br><span class="line">    :param X: 大小为NxM，其中M是个数，N是维度，每个字段已是零均值</span><br><span class="line">    :param ratio: 表示投影均方误差和方差比值，默认为0.99,保持99%的方差</span><br><span class="line">    :param kwargs: 字典参数，如果指定了k值，则直接计算</span><br><span class="line">    :return: 降维后数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    N, M = X.shape[:2]</span><br><span class="line">    C = X.dot(X.T) / M</span><br><span class="line">    u, s, v = np.linalg.svd(C)</span><br><span class="line"></span><br><span class="line">    k = 1</span><br><span class="line">    if &apos;k&apos; in kwargs:</span><br><span class="line">        k = kwargs[&apos;k&apos;]</span><br><span class="line">    else:</span><br><span class="line">        while k &lt; N:</span><br><span class="line">            s_k = np.sum(s[:k])</span><br><span class="line">            s_N = np.sum(s)</span><br><span class="line">            if (s_k * 1.0 / s_N) &gt;= ratio:</span><br><span class="line">                break</span><br><span class="line">            k += 1</span><br><span class="line">    p = u.transpose()[:k]</span><br><span class="line">    y = p.dot(X)</span><br><span class="line"></span><br><span class="line">    return y, p</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw_decision_boundary(classifier, x_test, y_test):</span><br><span class="line">    # PCA降维</span><br><span class="line">    y, p = pca(x_test, k=2)</span><br><span class="line">    # 编辑网络，预测结果</span><br><span class="line">    x_min, x_max = min(p[0]) - 0.05, max(p[0]) + 0.05</span><br><span class="line">    y_min, y_max = p[1].min() - 0.05, p[1].max() + 0.05</span><br><span class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.001), np.arange(y_min, y_max, 0.001))</span><br><span class="line">    x_grid = np.vstack((xx.reshape(-1), yy.reshape(-1))).T.dot(y)</span><br><span class="line">    y_pred = classifier.predict(x_grid).reshape(xx.shape)</span><br><span class="line">    # 绘制等高轮廓</span><br><span class="line">    plt.contourf(xx, yy, y_pred, cmap=mpl.cm.jet)</span><br><span class="line">    # 绘制测试点</span><br><span class="line">    indexs_0 = np.argwhere(y_test == 0).squeeze()</span><br><span class="line">    indexs_1 = np.argwhere(y_test == 1).squeeze()</span><br><span class="line">    indexs_2 = np.argwhere(y_test == 2).squeeze()</span><br><span class="line">    plt.scatter(p[0, indexs_0], p[1, indexs_0], c=&apos;r&apos;, marker=&apos;&lt;&apos;)</span><br><span class="line">    plt.scatter(p[0, indexs_1], p[1, indexs_1], c=&apos;g&apos;, marker=&apos;8&apos;)</span><br><span class="line">    plt.scatter(p[0, indexs_2], p[1, indexs_2], c=&apos;y&apos;, marker=&apos;*&apos;)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    iris_path = &apos;/home/zj/data/iris-species/Iris.csv&apos;</span><br><span class="line">    x_train, x_test, y_train, y_test = load_iris(iris_path)</span><br><span class="line"></span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-8</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(var + eps)</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(var + eps)</span><br><span class="line"></span><br><span class="line">    # 训练分类器</span><br><span class="line">    classifier = NN([100, 60], input_dim=4, num_classes=3, learning_rate=1e-1, reg=1e-3)</span><br><span class="line">    classifier.train(x_train, y_train, num_iters=30000, batch_size=200, verbose=True)</span><br><span class="line"></span><br><span class="line">    draw_decision_boundary(classifier, x_test, y_test)</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/决策边界/nn_iris.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>sklearn</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络分类器</title>
    <url>/posts/81a57a7.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://www.zhujian.tech/posts/1dd3ebad.html">神经网络推导-矩阵计算</a></p><p><a href="https://www.zhujian.tech/posts/ba2ca878.html">神经网络实现-numpy</a></p><p>参考<a href="https://www.zhujian.tech/posts/ebe205e.html">线性SVM分类器</a>实现神经网络分类器</p><p><code>cs231n assignment2</code>中实现了自定义层数和数量的神经网络模型，参考其实现完成单个类的神经网络分类器</p><a id="more"></a>




<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-18 上午10:15</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class NN(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self, hidden_dims, input_dim=32 * 32 * 3, num_classes=10, weight_scale=1e-2, learning_rate=1e-3,</span><br><span class="line">                 reg=0.0, dtype=np.float64):</span><br><span class="line">        self.reg = reg</span><br><span class="line">        self.lr = learning_rate</span><br><span class="line">        self.dtype = dtype</span><br><span class="line">        self.params = &#123;&#125;</span><br><span class="line">        self.num_layers = len(hidden_dims) + 1</span><br><span class="line"></span><br><span class="line">        if hidden_dims is None:</span><br><span class="line">            self.params[&apos;W1&apos;] = weight_scale * np.random.randn(input_dim, num_classes)</span><br><span class="line">            self.params[&apos;b1&apos;] = np.zeros((1, num_classes))</span><br><span class="line">        else:</span><br><span class="line">            for i in range(self.num_layers):</span><br><span class="line">                if i == 0:</span><br><span class="line">                    in_dim = input_dim</span><br><span class="line">                    out_dim = hidden_dims[i]</span><br><span class="line">                elif i == (self.num_layers - 1):</span><br><span class="line">                    in_dim = hidden_dims[i - 1]</span><br><span class="line">                    out_dim = num_classes</span><br><span class="line">                else:</span><br><span class="line">                    in_dim = hidden_dims[i - 1]</span><br><span class="line">                    out_dim = hidden_dims[i]</span><br><span class="line"></span><br><span class="line">                self.params[&apos;W%d&apos; % (i + 1)] = weight_scale * np.random.randn(in_dim, out_dim)</span><br><span class="line">                self.params[&apos;b%d&apos; % (i + 1)] = np.zeros((1, out_dim))</span><br><span class="line"></span><br><span class="line">        self.configs = &#123;&#125;</span><br><span class="line">        config = &#123;&apos;learning_rate&apos;: learning_rate&#125;</span><br><span class="line">        for k in self.params.keys():</span><br><span class="line">            self.configs[k] = config.copy()</span><br><span class="line"></span><br><span class="line">        # Cast all parameters to the correct datatype</span><br><span class="line">        for k, v in self.params.items():</span><br><span class="line">            self.params[k] = v.astype(dtype)</span><br><span class="line"></span><br><span class="line">    def train(self, X, y, num_iters=100, batch_size=200, verbose=False):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Inputs:</span><br><span class="line">        - X: A numpy array of shape (N, D) containing training data; there are N</span><br><span class="line">          training samples each of dimension D.</span><br><span class="line">        - y: A numpy array of shape (N,) containing training labels; y[i] = c</span><br><span class="line">          means that X[i] has label 0 &lt;= c &lt; C for C classes.</span><br><span class="line">        - num_iters: (integer) number of steps to take when optimizing</span><br><span class="line">        - batch_size: (integer) number of training examples to use at each step.</span><br><span class="line">        - verbose: (boolean) If true, print progress during optimization.</span><br><span class="line"></span><br><span class="line">        Outputs:</span><br><span class="line">        A list containing the value of the loss function at each training iteration.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        X = X.astype(self.dtype)</span><br><span class="line">        num_train, dim = X.shape</span><br><span class="line"></span><br><span class="line">        # Run stochastic gradient descent to optimize W</span><br><span class="line">        loss_history = []</span><br><span class="line">        range_list = np.arange(0, num_train, step=batch_size)</span><br><span class="line">        for it in range(num_iters):</span><br><span class="line">            total_loss = 0</span><br><span class="line">            for i in range_list:</span><br><span class="line">                X_batch = X[i:i + batch_size]</span><br><span class="line">                y_batch = y[i:i + batch_size]</span><br><span class="line"></span><br><span class="line">                # evaluate loss and gradient</span><br><span class="line">                loss, grads = self.loss(X_batch, y_batch)</span><br><span class="line">                total_loss += loss</span><br><span class="line"></span><br><span class="line">                for k in self.params.keys():</span><br><span class="line">                    #     config = self.configs[k]</span><br><span class="line">                    w = self.params[k]</span><br><span class="line">                    dw = grads[k]</span><br><span class="line"></span><br><span class="line">                    # next_w, next_config = self.adam(w, dw, config)</span><br><span class="line">                    next_w = w - self.lr * dw</span><br><span class="line"></span><br><span class="line">                    self.params[k] = next_w</span><br><span class="line">                    # self.configs[k] = config</span><br><span class="line"></span><br><span class="line">            avg_loss = total_loss / len(range_list)</span><br><span class="line">            loss_history.append(avg_loss)</span><br><span class="line"></span><br><span class="line">            if verbose and it % 100 == 0:</span><br><span class="line">                print(&apos;iteration %d / %d: loss %f&apos; % (it, num_iters, avg_loss))</span><br><span class="line"></span><br><span class="line">        return loss_history</span><br><span class="line"></span><br><span class="line">    def predict(self, X):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Use the trained weights of this linear classifier to predict labels for</span><br><span class="line">        data points.</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - X: A numpy array of shape (N, D) containing training data; there are N</span><br><span class="line">          training samples each of dimension D.</span><br><span class="line"></span><br><span class="line">        Returns:</span><br><span class="line">        - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional</span><br><span class="line">          array of length N, and each element is an integer giving the predicted</span><br><span class="line">          class.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        scores, caches = self.forward(X)</span><br><span class="line">        scores -= np.atleast_2d(np.max(scores, axis=1)).T</span><br><span class="line">        exp_scores = np.exp(scores)</span><br><span class="line">        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)</span><br><span class="line"></span><br><span class="line">        y_pred = np.argmax(probs, axis=1)</span><br><span class="line">        return y_pred</span><br><span class="line"></span><br><span class="line">    def loss(self, X_batch, y_batch):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Compute the loss function and its derivative.</span><br><span class="line">        Subclasses will override this.</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - X_batch: A numpy array of shape (N, D) containing a minibatch of N</span><br><span class="line">          data points; each point has dimension D.</span><br><span class="line">        - y_batch: A numpy array of shape (N,) containing labels for the minibatch.</span><br><span class="line"></span><br><span class="line">        Returns: A tuple containing:</span><br><span class="line">        - loss as a single float</span><br><span class="line">        - gradient with respect to self.W; an array of the same shape as W</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        scores, caches = self.forward(X_batch)</span><br><span class="line">        data_loss, dout = self.softmax_loss(scores, y_batch)</span><br><span class="line"></span><br><span class="line">        reg_loss = 0</span><br><span class="line">        for i in range(self.num_layers):</span><br><span class="line">            reg_loss += 0.5 * self.reg * np.sum(self.params[&apos;W%d&apos; % (i + 1)] ** 2)</span><br><span class="line">        loss = data_loss + reg_loss</span><br><span class="line"></span><br><span class="line">        grads = &#123;&#125;</span><br><span class="line">        dx = None</span><br><span class="line">        for i in reversed(range(self.num_layers)):</span><br><span class="line">            cache = caches[&apos;cache%d&apos; % (i + 1)]</span><br><span class="line">            if i == (self.num_layers - 1):</span><br><span class="line">                dx, dw, db = self.affine_backward(dout, cache)</span><br><span class="line">            else:</span><br><span class="line">                dx, dw, db = self.affine_relu_backward(dx, cache)</span><br><span class="line">            grads[&apos;W%d&apos; % (i + 1)] = dw + self.reg * self.params[&apos;W%d&apos; % (i + 1)]</span><br><span class="line">            grads[&apos;b%d&apos; % (i + 1)] = db</span><br><span class="line"></span><br><span class="line">        return loss, grads</span><br><span class="line"></span><br><span class="line">    def forward(self, X):</span><br><span class="line">        a = None</span><br><span class="line">        z = None</span><br><span class="line">        caches = &#123;&#125;</span><br><span class="line">        for i in range(self.num_layers):</span><br><span class="line">            if i == 0:</span><br><span class="line">                a = X</span><br><span class="line">            if i == (self.num_layers - 1):</span><br><span class="line">                z, caches[&apos;cache%d&apos; % self.num_layers] = self.affine_forward(a,</span><br><span class="line">                                                                             self.params[&apos;W%d&apos; % (self.num_layers)],</span><br><span class="line">                                                                             self.params[&apos;b%d&apos; % (self.num_layers)])</span><br><span class="line">            else:</span><br><span class="line">                a, caches[&apos;cache%d&apos; % (i + 1)] = self.affine_relu_forward(a,</span><br><span class="line">                                                                          self.params[&apos;W%d&apos; % (i + 1)],</span><br><span class="line">                                                                          self.params[&apos;b%d&apos; % (i + 1)])</span><br><span class="line"></span><br><span class="line">        scores = z</span><br><span class="line">        return scores, caches</span><br><span class="line"></span><br><span class="line">    def affine_relu_forward(self, x, w, b):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Convenience layer that perorms an affine transform followed by a ReLU</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - x: Input to the affine layer</span><br><span class="line">        - w, b: Weights for the affine layer</span><br><span class="line"></span><br><span class="line">        Returns a tuple of:</span><br><span class="line">        - out: Output from the ReLU</span><br><span class="line">        - cache: Object to give to the backward pass</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        a, fc_cache = self.affine_forward(x, w, b)</span><br><span class="line">        out, relu_cache = self.relu_forward(a)</span><br><span class="line">        cache = (fc_cache, relu_cache)</span><br><span class="line">        return out, cache</span><br><span class="line"></span><br><span class="line">    def affine_relu_backward(self, dout, cache):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Backward pass for the affine-relu convenience layer</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        fc_cache, relu_cache = cache</span><br><span class="line">        da = self.relu_backward(dout, relu_cache)</span><br><span class="line">        dx, dw, db = self.affine_backward(da, fc_cache)</span><br><span class="line">        return dx, dw, db</span><br><span class="line"></span><br><span class="line">    def affine_forward(self, x, w, b):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Computes the forward pass for an affine (fully-connected) layer.</span><br><span class="line"></span><br><span class="line">        The input x has shape (N, d_1, ..., d_k) and contains a minibatch of N</span><br><span class="line">        examples, where each example x[i] has shape (d_1, ..., d_k). We will</span><br><span class="line">        reshape each input into a vector of dimension D = d_1 * ... * d_k, and</span><br><span class="line">        then transform it to an output vector of dimension M.</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - x: A numpy array containing input data, of shape (N, d_1, ..., d_k)</span><br><span class="line">        - w: A numpy array of weights, of shape (D, M)</span><br><span class="line">        - b: A numpy array of biases, of shape (M,)</span><br><span class="line"></span><br><span class="line">        Returns a tuple of:</span><br><span class="line">        - out: output, of shape (N, M)</span><br><span class="line">        - cache: (x, w, b)</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        inputs = x.reshape(x.shape[0], -1)</span><br><span class="line">        out = inputs.dot(w) + b.reshape(1, -1)</span><br><span class="line"></span><br><span class="line">        cache = (x, w, b)</span><br><span class="line">        return out, cache</span><br><span class="line"></span><br><span class="line">    def affine_backward(self, dout, cache):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Computes the backward pass for an affine layer.</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - dout: Upstream derivative, of shape (N, M)</span><br><span class="line">        - cache: Tuple of:</span><br><span class="line">          - x: Input data, of shape (N, d_1, ... d_k)</span><br><span class="line">          - w: Weights, of shape (D, M)</span><br><span class="line">          - b: Biases, of shape (M,)</span><br><span class="line"></span><br><span class="line">        Returns a tuple of:</span><br><span class="line">        - dx: Gradient with respect to x, of shape (N, d1, ..., d_k)</span><br><span class="line">        - dw: Gradient with respect to w, of shape (D, M)</span><br><span class="line">        - db: Gradient with respect to b, of shape (M,)</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        x, w, b = cache</span><br><span class="line"></span><br><span class="line">        dx = dout.dot(w.T).reshape(x.shape)</span><br><span class="line">        dw = x.reshape(x.shape[0], -1).T.dot(dout)</span><br><span class="line">        db = np.sum(dout, axis=0)</span><br><span class="line"></span><br><span class="line">        return dx, dw, db</span><br><span class="line"></span><br><span class="line">    def relu_forward(self, x):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Computes the forward pass for a layer of rectified linear units (ReLUs).</span><br><span class="line"></span><br><span class="line">        Input:</span><br><span class="line">        - x: Inputs, of any shape</span><br><span class="line"></span><br><span class="line">        Returns a tuple of:</span><br><span class="line">        - out: Output, of the same shape as x</span><br><span class="line">        - cache: x</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        out = x.copy()</span><br><span class="line">        out[x &lt; 0] = 0</span><br><span class="line"></span><br><span class="line">        cache = x</span><br><span class="line">        return out, cache</span><br><span class="line"></span><br><span class="line">    def relu_backward(self, dout, cache):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Computes the backward pass for a layer of rectified linear units (ReLUs).</span><br><span class="line"></span><br><span class="line">        Input:</span><br><span class="line">        - dout: Upstream derivatives, of any shape</span><br><span class="line">        - cache: Input x, of same shape as dout</span><br><span class="line"></span><br><span class="line">        Returns:</span><br><span class="line">        - dx: Gradient with respect to x</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        dx, x = None, cache</span><br><span class="line"></span><br><span class="line">        dx = dout</span><br><span class="line">        dx[x &lt; 0] = 0</span><br><span class="line"></span><br><span class="line">        return dx</span><br><span class="line"></span><br><span class="line">    def softmax_loss(self, scores, y):</span><br><span class="line">        num = y.shape[0]</span><br><span class="line"></span><br><span class="line">        exp_scores = np.exp(scores)</span><br><span class="line">        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)</span><br><span class="line"></span><br><span class="line">        data_loss = -1.0 / num * np.sum(np.log(probs[range(num), y]))</span><br><span class="line"></span><br><span class="line">        dscores = scores</span><br><span class="line">        dscores[range(num), y] -= 1</span><br><span class="line">        dscores /= num</span><br><span class="line"></span><br><span class="line">        return data_loss, dscores</span><br><span class="line"></span><br><span class="line">    def adam(self, w, dw, config=None):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Uses the Adam update rule, which incorporates moving averages of both the</span><br><span class="line">        gradient and its square and a bias correction term.</span><br><span class="line"></span><br><span class="line">        config format:</span><br><span class="line">        - learning_rate: Scalar learning rate.</span><br><span class="line">        - beta1: Decay rate for moving average of first moment of gradient.</span><br><span class="line">        - beta2: Decay rate for moving average of second moment of gradient.</span><br><span class="line">        - epsilon: Small scalar used for smoothing to avoid dividing by zero.</span><br><span class="line">        - m: Moving average of gradient.</span><br><span class="line">        - v: Moving average of squared gradient.</span><br><span class="line">        - t: Iteration number.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if config is None: config = &#123;&#125;</span><br><span class="line">        config.setdefault(&apos;learning_rate&apos;, 1e-3)</span><br><span class="line">        config.setdefault(&apos;beta1&apos;, 0.9)</span><br><span class="line">        config.setdefault(&apos;beta2&apos;, 0.999)</span><br><span class="line">        config.setdefault(&apos;epsilon&apos;, 1e-8)</span><br><span class="line">        config.setdefault(&apos;m&apos;, np.zeros_like(w))</span><br><span class="line">        config.setdefault(&apos;v&apos;, np.zeros_like(w))</span><br><span class="line">        config.setdefault(&apos;t&apos;, 0)</span><br><span class="line"></span><br><span class="line">        t = config[&apos;t&apos;] + 1</span><br><span class="line">        m = config[&apos;beta1&apos;] * config[&apos;m&apos;] + (1 - config[&apos;beta1&apos;]) * dw</span><br><span class="line">        mt = m / (1 - config[&apos;beta1&apos;] ** t)</span><br><span class="line">        v = config[&apos;beta2&apos;] * config[&apos;v&apos;] + (1 - config[&apos;beta2&apos;]) * (dw ** 2)</span><br><span class="line">        vt = v / (1 - config[&apos;beta2&apos;] ** t)</span><br><span class="line"></span><br><span class="line">        next_w = w - config[&apos;learning_rate&apos;] * mt / (np.sqrt(vt) + config[&apos;epsilon&apos;])</span><br><span class="line"></span><br><span class="line">        config[&apos;t&apos;] = t</span><br><span class="line">        config[&apos;m&apos;] = m</span><br><span class="line">        config[&apos;v&apos;] = v</span><br><span class="line"></span><br><span class="line">        return next_w, config</span><br></pre></td></tr></table></figure>
<h2 id="数值稳定性"><a href="#数值稳定性" class="headerlink" title="数值稳定性"></a>数值稳定性</h2><p>预测计算结果时，有可能出现数值溢出</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scores, caches = self.forward(X)</span><br><span class="line">exp_scores = np.exp(scores)</span><br><span class="line">probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)</span><br></pre></td></tr></table></figure>
<p>出错信息如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">RuntimeWarning: overflow encountered in exp</span><br><span class="line">exp_scores = np.exp(scores)</span><br><span class="line"></span><br><span class="line">RuntimeWarning: invalid value encountered in true_divide</span><br><span class="line">probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)</span><br></pre></td></tr></table></figure>
<p>参考<a href="https://zhujian.tech/posts/2626bec3.html" target="_blank" rel="noopener">指数计算 - 数值稳定性考虑</a>，修改代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scores, caches = self.forward(X)</span><br><span class="line">scores -= np.atleast_2d(np.max(scores, axis=1)).T</span><br><span class="line">exp_scores = np.exp(scores)</span><br><span class="line">probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)</span><br></pre></td></tr></table></figure>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>整体结构仍旧遵循<code>创建-&gt;训练-&gt;预测</code>模型</p>
<p>实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">classifier = Classifier([120, 60], input_dim=dim, num_classes=out_dim, learning_rate=lr, reg=reg)</span><br><span class="line"></span><br><span class="line">classifier.train(x_train, y_train, num_iters=10000, batch_size=100, verbose=True)</span><br><span class="line">y_train_pred = classifier.predict(x_train)</span><br><span class="line">y_val_pred = classifier.predict(x_val)</span><br><span class="line"></span><br><span class="line">train_acc = np.mean(y_train_pred == y_train)</span><br><span class="line">val_acc = np.mean(y_val_pred == y_val</span><br></pre></td></tr></table></figure>
<p>完整训练和实现代码参考：<a href="https://github.com/zjZSTU/cs231n/tree/master/coding" target="_blank" rel="noopener">cs231n/coding/</a></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
        <category>分类器</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>softmax分类器</title>
    <url>/posts/e043b7fb.html</url>
    <content><![CDATA[<p>参考：<a href="https://www.zhujian.tech/posts/2626bec3.html">softmax回归</a></p><p>模仿<a href="https://www.zhujian.tech/posts/ebe205e.html#more">线性SVM分类器</a>实现<code>softmax</code>分类器</p><h2 id="分类器实现"><a href="#分类器实现" class="headerlink" title="分类器实现"></a>分类器实现</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-17 下午7:45</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class SoftmaxClassifier(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.W = None</span><br><span class="line">        self.b = None</span><br><span class="line"></span><br><span class="line">        self.lr = None</span><br><span class="line">        self.reg = None</span><br><span class="line"></span><br><span class="line">    def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100, batch_size=200, verbose=False):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Inputs:</span><br><span class="line">        - X: A numpy array of shape (N, D) containing training data; there are N</span><br><span class="line">          training samples each of dimension D.</span><br><span class="line">        - y: A numpy array of shape (N,) containing training labels; y[i] = c</span><br><span class="line">          means that X[i] has label 0 &lt;= c &lt; C for C classes.</span><br><span class="line">        - learning_rate: (float) learning rate for optimization.</span><br><span class="line">        - reg: (float) regularization strength.</span><br><span class="line">        - num_iters: (integer) number of steps to take when optimizing</span><br><span class="line">        - batch_size: (integer) number of training examples to use at each step.</span><br><span class="line">        - verbose: (boolean) If true, print progress during optimization.</span><br><span class="line"></span><br><span class="line">        Outputs:</span><br><span class="line">        A list containing the value of the loss function at each training iteration.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.lr = learning_rate</span><br><span class="line">        self.reg = reg</span><br><span class="line"></span><br><span class="line">        num_train, dim = X.shape</span><br><span class="line">        num_classes = np.max(y) + 1  # assume y takes values 0...K-1 where K is number of classes</span><br><span class="line">        if self.W is None:</span><br><span class="line">            # lazily initialize W</span><br><span class="line">            self.W = 0.001 * np.random.randn(dim, num_classes)</span><br><span class="line">            self.b = np.zeros((1, num_classes))</span><br><span class="line"></span><br><span class="line">        # Run stochastic gradient descent to optimize W</span><br><span class="line">        loss_history = []</span><br><span class="line">        for it in range(num_iters):</span><br><span class="line">            indices = np.random.choice(num_train, batch_size)</span><br><span class="line">            X_batch = X[indices]</span><br><span class="line">            y_batch = y[indices]</span><br><span class="line"></span><br><span class="line">            # evaluate loss and gradient</span><br><span class="line">            loss, dW, db = self.loss(X_batch, y_batch, reg)</span><br><span class="line">            loss_history.append(loss)</span><br><span class="line"></span><br><span class="line">            self.W -= learning_rate * dW</span><br><span class="line">            self.b -= learning_rate * db</span><br><span class="line"></span><br><span class="line">            if verbose and it % 100 == 0:</span><br><span class="line">                print(&apos;iteration %d / %d: loss %f&apos; % (it, num_iters, loss))</span><br><span class="line"></span><br><span class="line">        return loss_history</span><br><span class="line"></span><br><span class="line">    def predict(self, X):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Use the trained weights of this linear classifier to predict labels for</span><br><span class="line">        data points.</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - X: A numpy array of shape (N, D) containing training data; there are N</span><br><span class="line">          training samples each of dimension D.</span><br><span class="line"></span><br><span class="line">        Returns:</span><br><span class="line">        - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional</span><br><span class="line">          array of length N, and each element is an integer giving the predicted</span><br><span class="line">          class.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        scores = self.softmax(X)</span><br><span class="line">        exp_scores = np.exp(scores)</span><br><span class="line">        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)</span><br><span class="line"></span><br><span class="line">        y_pred = np.argmax(probs, axis=1)</span><br><span class="line">        return y_pred</span><br><span class="line"></span><br><span class="line">    def loss(self, X_batch, y_batch, reg, delta=1):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Compute the loss function and its derivative.</span><br><span class="line">        Subclasses will override this.</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - X_batch: A numpy array of shape (N, D) containing a minibatch of N</span><br><span class="line">          data points; each point has dimension D.</span><br><span class="line">        - y_batch: A numpy array of shape (N,) containing labels for the minibatch.</span><br><span class="line">        - reg: (float) regularization strength.</span><br><span class="line"></span><br><span class="line">        Returns: A tuple containing:</span><br><span class="line">        - loss as a single float</span><br><span class="line">        - gradient with respect to self.W; an array of the same shape as W</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        num_train = X_batch.shape[0]</span><br><span class="line"></span><br><span class="line">        scores = self.softmax(X_batch)</span><br><span class="line">        exp_scores = np.exp(scores)</span><br><span class="line">        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)</span><br><span class="line"></span><br><span class="line">        data_loss = -1.0 / num_train * np.sum(np.log(probs[range(num_train), y_batch]))</span><br><span class="line">        reg_loss = 0.5 * reg * np.sum(self.W ** 2)</span><br><span class="line"></span><br><span class="line">        loss = data_loss + reg_loss</span><br><span class="line"></span><br><span class="line">        dscores = scores</span><br><span class="line">        dscores[range(num_train), y_batch] -= 1</span><br><span class="line">        dscores /= num_train</span><br><span class="line">        dW = X_batch.T.dot(dscores) + reg * self.W</span><br><span class="line">        db = np.sum(dscores)</span><br><span class="line"></span><br><span class="line">        return loss, dW, db</span><br><span class="line"></span><br><span class="line">    def softmax(self, x):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :param x: A numpy array of shape (N, D)</span><br><span class="line">        :param w: A numpy array of shape (D)</span><br><span class="line">        :param b: A numpy array of shape (1)</span><br><span class="line">        :return: A numpy array of shape (N)</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        z = x.dot(self.W) + self.b</span><br><span class="line">        z -= np.max(z, axis=1, keepdims=True)</span><br><span class="line">        return z</span><br></pre></td></tr></table></figure><a id="more"></a>


<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>使用交叉验证方法寻找最优的学习率和正则化强度组合</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-17 下午8:00</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">from builtins import range</span><br><span class="line">from softmax_classifier import SoftmaxClassifier</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import math</span><br><span class="line">from sklearn import utils</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_iris(iris_path, shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(iris_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        data = utils.shuffle(data)</span><br><span class="line"></span><br><span class="line">    species_dict = &#123;</span><br><span class="line">        &apos;Iris-setosa&apos;: 0,</span><br><span class="line">        &apos;Iris-versicolor&apos;: 1,</span><br><span class="line">        &apos;Iris-virginica&apos;: 2</span><br><span class="line">    &#125;</span><br><span class="line">    data[&apos;Species&apos;] = data[&apos;Species&apos;].map(species_dict)</span><br><span class="line"></span><br><span class="line">    data_x = np.array(</span><br><span class="line">        [data[&apos;SepalLengthCm&apos;], data[&apos;SepalWidthCm&apos;], data[&apos;PetalLengthCm&apos;], data[&apos;PetalWidthCm&apos;]]).T</span><br><span class="line">    data_y = np.array(data[&apos;Species&apos;])</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=False)</span><br><span class="line"></span><br><span class="line">    return np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_german_data(data_path, shuffle=True, tsize=0.8):</span><br><span class="line">    data_list = pd.read_csv(data_path, header=None, sep=&apos;\s+&apos;)</span><br><span class="line"></span><br><span class="line">    data_array = data_list.values</span><br><span class="line">    height, width = data_array.shape[:2]</span><br><span class="line">    data_x = data_array[:, :(width - 1)]</span><br><span class="line">    data_y = data_array[:, (width - 1)]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    y_train = np.array(list(map(lambda x: 1 if x == 2 else 0, y_train)))</span><br><span class="line">    y_test = np.array(list(map(lambda x: 1 if x == 2 else 0, y_test)))</span><br><span class="line"></span><br><span class="line">    return x_train, x_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(y, y_pred):</span><br><span class="line">    num = y.shape[0]</span><br><span class="line">    num_correct = np.sum(y_pred == y)</span><br><span class="line">    acc = float(num_correct) / num</span><br><span class="line">    return acc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def cross_validation(x_train, y_train, x_val, y_val, lr_choices, reg_choices, classifier=SoftmaxClassifier):</span><br><span class="line">    results = &#123;&#125;</span><br><span class="line">    best_val = -1  # The highest validation accuracy that we have seen so far.</span><br><span class="line">    best_svm = None  # The LinearSVM object that achieved the highest validation rate.</span><br><span class="line"></span><br><span class="line">    for lr in lr_choices:</span><br><span class="line">        for reg in reg_choices:</span><br><span class="line">            svm = classifier()</span><br><span class="line"></span><br><span class="line">            svm.train(x_train, y_train, learning_rate=lr, reg=reg, num_iters=2000, batch_size=100, verbose=True)</span><br><span class="line">            y_train_pred = svm.predict(x_train)</span><br><span class="line">            y_val_pred = svm.predict(x_val)</span><br><span class="line"></span><br><span class="line">            train_acc = np.mean(y_train_pred == y_train)</span><br><span class="line">            val_acc = np.mean(y_val_pred == y_val)</span><br><span class="line"></span><br><span class="line">            results[(lr, reg)] = (train_acc, val_acc)</span><br><span class="line">            if best_val &lt; val_acc:</span><br><span class="line">                best_val = val_acc</span><br><span class="line">                best_svm = svm</span><br><span class="line"></span><br><span class="line">    return results, best_svm, best_val</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(results):</span><br><span class="line">    # Visualize the cross-validation results</span><br><span class="line">    x_scatter = [math.log10(x[0]) for x in results]</span><br><span class="line">    y_scatter = [math.log10(x[1]) for x in results]</span><br><span class="line"></span><br><span class="line">    # plot training accuracy</span><br><span class="line">    marker_size = 100</span><br><span class="line">    colors = [results[x][0] for x in results]</span><br><span class="line">    plt.subplot(2, 1, 1)</span><br><span class="line">    plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    plt.xlabel(&apos;log learning rate&apos;)</span><br><span class="line">    plt.ylabel(&apos;log regularization strength&apos;)</span><br><span class="line">    plt.title(&apos;training accuracy&apos;)</span><br><span class="line"></span><br><span class="line">    # plot validation accuracy</span><br><span class="line">    colors = [results[x][1] for x in results]  # default size of markers is 20</span><br><span class="line">    plt.subplot(2, 1, 2)</span><br><span class="line">    plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    plt.xlabel(&apos;log learning rate&apos;)</span><br><span class="line">    plt.ylabel(&apos;log regularization strength&apos;)</span><br><span class="line">    plt.title(&apos;validation accuracy&apos;)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    iris_path = &apos;/home/zj/data/iris-species/Iris.csv&apos;</span><br><span class="line">    x_train, x_test, y_train, y_test = load_iris(iris_path, shuffle=True, tsize=0.8)</span><br><span class="line"></span><br><span class="line">    # data_path = &apos;/home/zj/data/german/german.data-numeric&apos;</span><br><span class="line">    # x_train, x_test, y_train, y_test = load_german_data(data_path, shuffle=True, tsize=0.8)</span><br><span class="line"></span><br><span class="line">    x_train = x_train.astype(np.double)</span><br><span class="line">    x_test = x_test.astype(np.double)</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-8</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(var + eps)</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(var + eps)</span><br><span class="line"></span><br><span class="line">    lr_choices = [1e-4, 2.5e-4, 5e-4, 7.5e-4, 1e-3, 2.5e-2]</span><br><span class="line">    reg_choices = [7.5e-6, 1e-5, 2.5e-5, 5e-5, 7.5e-5, 1e-4]</span><br><span class="line">    results, best_svm, best_val = cross_validation(x_train, y_train, x_test, y_test, lr_choices, reg_choices)</span><br><span class="line"></span><br><span class="line">    plot(results)</span><br><span class="line"></span><br><span class="line">    for k in results.keys():</span><br><span class="line">        lr, reg = k</span><br><span class="line">        train_acc, val_acc = results[k]</span><br><span class="line">        print(&apos;lr = %f, reg = %f, train_acc = %f, val_acc = %f&apos; % (lr, reg, train_acc, val_acc))</span><br><span class="line"></span><br><span class="line">    print(&apos;最好的设置是： lr = %f, reg = %f&apos; % (best_svm.lr, best_svm.reg))</span><br><span class="line">    print(&apos;最好的测试精度： %f&apos; % best_val)</span><br></pre></td></tr></table></figure>
<p>批量大小为<code>100</code>，共迭代<code>2000</code>次</p>
<p><code>Iris</code>数据集测试结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">最好的设置是： lr = 0.005000, reg = 0.000008</span><br><span class="line">最好的测试精度： 0.933333</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/softmax分类器/iris_softmax.png" alt></p>
<p>德国信用卡数据集测试结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">最好的设置是： lr = 0.050000, reg = 0.000075</span><br><span class="line">最好的测试精度： 0.765000</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/softmax分类器/iris_softmax.png" alt></p>
<p><code>2000</code>次迭代后的测试结果，与<code>KNN</code>分类器和线性<code>SVM</code>分类器比较结果如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">Iris</th>
<th style="text-align:center">German data</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">KNN</td>
<td style="text-align:center">93.33%</td>
<td style="text-align:center">73.5%</td>
</tr>
<tr>
<td style="text-align:center">SVM</td>
<td style="text-align:center">80%</td>
<td style="text-align:center">75%</td>
</tr>
<tr>
<td style="text-align:center">SVM</td>
<td style="text-align:center">93.33%</td>
<td style="text-align:center">76.5%</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
        <category>分类器</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>sklearn</tag>
        <tag>pandas</tag>
        <tag>softmax</tag>
      </tags>
  </entry>
  <entry>
    <title>逻辑回归分类器</title>
    <url>/posts/96ce93d9.html</url>
    <content><![CDATA[<p>参考：<a href="https://www.zhujian.tech/posts/9f2d3388.html">逻辑回归</a></p><p>参考<a href="https://www.zhujian.tech/posts/ebe205e.html">线性SVM分类器</a>实现逻辑回归分类器，并进行决策边界可视化</p><h2 id="分类器实现"><a href="#分类器实现" class="headerlink" title="分类器实现"></a>分类器实现</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-16 上午10:24</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class LogisticClassifier(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.W = None</span><br><span class="line">        self.b = None</span><br><span class="line"></span><br><span class="line">        self.lr = None</span><br><span class="line">        self.reg = None</span><br><span class="line"></span><br><span class="line">    def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100, batch_size=200, verbose=False):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Inputs:</span><br><span class="line">        - X: A numpy array of shape (N, D) containing training data; there are N</span><br><span class="line">          training samples each of dimension D.</span><br><span class="line">        - y: A numpy array of shape (N,) containing training labels; y[i] = c</span><br><span class="line">          means that X[i] has label 0 &lt;= c &lt; C for C classes.</span><br><span class="line">        - learning_rate: (float) learning rate for optimization.</span><br><span class="line">        - reg: (float) regularization strength.</span><br><span class="line">        - num_iters: (integer) number of steps to take when optimizing</span><br><span class="line">        - batch_size: (integer) number of training examples to use at each step.</span><br><span class="line">        - verbose: (boolean) If true, print progress during optimization.</span><br><span class="line"></span><br><span class="line">        Outputs:</span><br><span class="line">        A list containing the value of the loss function at each training iteration.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.lr = learning_rate</span><br><span class="line">        self.reg = reg</span><br><span class="line"></span><br><span class="line">        num_train, dim = X.shape</span><br><span class="line">        num_classes = np.max(y) + 1  # assume y takes values 0...K-1 where K is number of classes</span><br><span class="line">        if self.W is None:</span><br><span class="line">            # lazily initialize W</span><br><span class="line">            self.W = 0.001 * np.random.randn(dim)</span><br><span class="line">            self.b = np.zeros(1)</span><br><span class="line"></span><br><span class="line">        # Run stochastic gradient descent to optimize W</span><br><span class="line">        loss_history = []</span><br><span class="line">        for it in range(num_iters):</span><br><span class="line">            indices = np.random.choice(num_train, batch_size)</span><br><span class="line">            X_batch = X[indices]</span><br><span class="line">            y_batch = y[indices]</span><br><span class="line"></span><br><span class="line">            # evaluate loss and gradient</span><br><span class="line">            loss, dW, db = self.loss(X_batch, y_batch, reg)</span><br><span class="line">            loss_history.append(loss)</span><br><span class="line"></span><br><span class="line">            self.W -= learning_rate * dW</span><br><span class="line">            self.b -= learning_rate * db</span><br><span class="line"></span><br><span class="line">            if verbose and it % 100 == 0:</span><br><span class="line">                print(&apos;iteration %d / %d: loss %f&apos; % (it, num_iters, loss))</span><br><span class="line"></span><br><span class="line">        return loss_history</span><br><span class="line"></span><br><span class="line">    def predict(self, X):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Use the trained weights of this linear classifier to predict labels for</span><br><span class="line">        data points.</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - X: A numpy array of shape (N, D) containing training data; there are N</span><br><span class="line">          training samples each of dimension D.</span><br><span class="line"></span><br><span class="line">        Returns:</span><br><span class="line">        - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional</span><br><span class="line">          array of length N, and each element is an integer giving the predicted</span><br><span class="line">          class.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        scores = self.logistic_regression(X)</span><br><span class="line">        y_pred = (scores &gt; 0.5).astype(np.uint8)</span><br><span class="line"></span><br><span class="line">        return y_pred</span><br><span class="line"></span><br><span class="line">    def loss(self, X_batch, y_batch, reg, delta=1):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Compute the loss function and its derivative.</span><br><span class="line">        Subclasses will override this.</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - X_batch: A numpy array of shape (N, D) containing a minibatch of N</span><br><span class="line">          data points; each point has dimension D.</span><br><span class="line">        - y_batch: A numpy array of shape (N,) containing labels for the minibatch.</span><br><span class="line">        - reg: (float) regularization strength.</span><br><span class="line"></span><br><span class="line">        Returns: A tuple containing:</span><br><span class="line">        - loss as a single float</span><br><span class="line">        - gradient with respect to self.W; an array of the same shape as W</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        eplison = 1e-5</span><br><span class="line">        num_train = X_batch.shape[0]</span><br><span class="line"></span><br><span class="line">        scores = self.logistic_regression(X_batch)</span><br><span class="line">        data_loss = -1.0 / num_train * \</span><br><span class="line">                    np.sum(y_batch * np.log(np.maximum(scores, eplison)) + (1 - y_batch) * np.log(np.maximum(1 - scores, eplison)))</span><br><span class="line">        reg_loss = 0.5 * reg * np.sum(self.W ** 2)</span><br><span class="line"></span><br><span class="line">        loss = data_loss + reg_loss</span><br><span class="line"></span><br><span class="line">        dscores = scores - y_batch</span><br><span class="line">        dscores /= num_train</span><br><span class="line">        dW = X_batch.T.dot(dscores) + reg * self.W</span><br><span class="line">        db = np.sum(dscores)</span><br><span class="line"></span><br><span class="line">        return loss, dW, db</span><br><span class="line"></span><br><span class="line">    def sigmoid(self, x):</span><br><span class="line">        return 1 / (1 + np.exp(-1 * x))</span><br><span class="line"></span><br><span class="line">    def logistic_regression(self, x):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :param x: A numpy array of shape (N, D)</span><br><span class="line">        :param w: A numpy array of shape (D)</span><br><span class="line">        :param b: A numpy array of shape (1)</span><br><span class="line">        :return: A numpy array of shape (N)</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        z = x.dot(self.W) + self.b</span><br><span class="line">        return self.sigmoid(z)</span><br></pre></td></tr></table></figure><a id="more"></a>


<h2 id="决策边界"><a href="#决策边界" class="headerlink" title="决策边界"></a>决策边界</h2><p>逻辑回归前向操作是线性映射 + <code>sigmoid</code>函数，其决策界面如下：</p>
<script type="math/tex; mode=display">
x_{1}\cdot w_{1} + x_{2}\cdot w_{2} + w_{0} = 0\\
\Rightarrow x_{2} = -1 * \frac {x_{1}\cdot w_{1} + w_{0}}{w_{2}}</script><h2 id="测试数据"><a href="#测试数据" class="headerlink" title="测试数据"></a>测试数据</h2><p>生成一个二维线性数据集，训练集大小为$200\times 2$，测试集大小为$40\times 2$</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def two_cate_linear():</span><br><span class="line">    x1 = np.linspace(20, 40, num=200)[np.random.choice(200, 120)]</span><br><span class="line">    y1 = np.linspace(20, 40, num=200)[np.random.choice(200, 120)]</span><br><span class="line"></span><br><span class="line">    x2 = np.linspace(-10, 10, num=200)[np.random.choice(200, 120)]</span><br><span class="line">    y2 = np.linspace(-10, 10, num=200)[np.random.choice(200, 120)]</span><br><span class="line"></span><br><span class="line">    x = np.vstack((np.concatenate((x1, x2)), np.concatenate((y1, y2)))).T</span><br><span class="line">    y = np.concatenate((np.zeros(120), np.ones(120)))</span><br><span class="line"></span><br><span class="line">    np.random.seed(120)</span><br><span class="line">    np.random.shuffle(x)</span><br><span class="line">    np.random.seed(120)</span><br><span class="line">    np.random.shuffle(y)</span><br><span class="line"></span><br><span class="line">    return x[:200], x[200:], y[:200], y[200:]</span><br></pre></td></tr></table></figure>
<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p>以学习率和正则化强度为参数进行交叉验证，搜索最好的学习率和正则化强度组合</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-16 上午10:38</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">from lr_classifier import LogisticClassifier</span><br><span class="line">import numpy as np</span><br><span class="line">import math</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def two_cate_linear():</span><br><span class="line">    x1 = np.linspace(20, 40, num=200)[np.random.choice(200, 120)]</span><br><span class="line">    y1 = np.linspace(20, 40, num=200)[np.random.choice(200, 120)]</span><br><span class="line"></span><br><span class="line">    x2 = np.linspace(-10, 10, num=200)[np.random.choice(200, 120)]</span><br><span class="line">    y2 = np.linspace(-10, 10, num=200)[np.random.choice(200, 120)]</span><br><span class="line"></span><br><span class="line">    x = np.vstack((np.concatenate((x1, x2)), np.concatenate((y1, y2)))).T</span><br><span class="line">    y = np.concatenate((np.zeros(120), np.ones(120)))</span><br><span class="line"></span><br><span class="line">    np.random.seed(120)</span><br><span class="line">    np.random.shuffle(x)</span><br><span class="line">    np.random.seed(120)</span><br><span class="line">    np.random.shuffle(y)</span><br><span class="line"></span><br><span class="line">    return x[:200], x[200:], y[:200], y[200:]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def cross_validation(x_train, y_train, x_val, y_val, lr_choices, reg_choices, classifier=LogisticClassifier):</span><br><span class="line">    results = &#123;&#125;</span><br><span class="line">    best_val = -1  # The highest validation accuracy that we have seen so far.</span><br><span class="line">    best_svm = None  # The LinearSVM object that achieved the highest validation rate.</span><br><span class="line"></span><br><span class="line">    for lr in lr_choices:</span><br><span class="line">        for reg in reg_choices:</span><br><span class="line">            svm = classifier()</span><br><span class="line"></span><br><span class="line">            svm.train(x_train, y_train, learning_rate=lr, reg=reg, num_iters=2000, batch_size=30, verbose=True)</span><br><span class="line">            y_train_pred = svm.predict(x_train)</span><br><span class="line">            y_val_pred = svm.predict(x_val)</span><br><span class="line"></span><br><span class="line">            train_acc = np.mean(y_train_pred == y_train)</span><br><span class="line">            val_acc = np.mean(y_val_pred == y_val)</span><br><span class="line"></span><br><span class="line">            results[(lr, reg)] = (train_acc, val_acc)</span><br><span class="line">            if best_val &lt; val_acc:</span><br><span class="line">                best_val = val_acc</span><br><span class="line">                best_svm = svm</span><br><span class="line"></span><br><span class="line">    return results, best_svm, best_val</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(y, y_pred):</span><br><span class="line">    num = y.shape[0]</span><br><span class="line">    num_correct = np.sum(y_pred == y)</span><br><span class="line">    acc = float(num_correct) / num</span><br><span class="line">    return acc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(results):</span><br><span class="line">    # Visualize the cross-validation results</span><br><span class="line">    x_scatter = [math.log10(x[0]) for x in results]</span><br><span class="line">    y_scatter = [math.log10(x[1]) for x in results]</span><br><span class="line"></span><br><span class="line">    # plot training accuracy</span><br><span class="line">    marker_size = 100</span><br><span class="line">    colors = [results[x][0] for x in results]</span><br><span class="line">    plt.subplot(2, 1, 1)</span><br><span class="line">    plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    plt.xlabel(&apos;log learning rate&apos;)</span><br><span class="line">    plt.ylabel(&apos;log regularization strength&apos;)</span><br><span class="line">    plt.title(&apos;training accuracy&apos;)</span><br><span class="line"></span><br><span class="line">    # plot validation accuracy</span><br><span class="line">    colors = [results[x][1] for x in results]  # default size of markers is 20</span><br><span class="line">    plt.subplot(2, 1, 2)</span><br><span class="line">    plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    plt.xlabel(&apos;log learning rate&apos;)</span><br><span class="line">    plt.ylabel(&apos;log regularization strength&apos;)</span><br><span class="line">    plt.title(&apos;validation accuracy&apos;)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot_v2(x, w, b):</span><br><span class="line">    plt.scatter(x[:, 0], x[:, 1])</span><br><span class="line"></span><br><span class="line">    x = np.linspace(-10, 40, num=200)</span><br><span class="line">    y = (-x * w[0] - b) / w[1]</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    x_train, x_test, y_train, y_test = two_cate_linear()</span><br><span class="line"></span><br><span class="line">    lr_choices = [1e-3, 2.5e-3, 5e-3, 7.5e-3, 1e-2, 2.5e-2]</span><br><span class="line">    reg_choices = [8e-6, 1e-5, 2.5e-5, 5e-5, 7.5e-5, 1e-4]</span><br><span class="line">    results, best_classifier, best_val = cross_validation(x_train, y_train, x_test, y_test, lr_choices, reg_choices)</span><br><span class="line"></span><br><span class="line">    plot(results)</span><br><span class="line">    plot_v2(x_test, best_classifier.W, best_classifier.b)</span><br><span class="line"></span><br><span class="line">    for k in results.keys():</span><br><span class="line">        lr, reg = k</span><br><span class="line">        train_acc, val_acc = results[k]</span><br><span class="line">        print(&apos;lr = %f, reg = %f, train_acc = %f, val_acc = %f&apos; % (lr, reg, train_acc, val_acc))</span><br><span class="line"></span><br><span class="line">    print(&apos;最好的设置是： lr = %f, reg = %f&apos; % (best_classifier.lr, best_classifier.reg))</span><br><span class="line">    print(&apos;最好的测试精度： %f&apos; % best_val)</span><br></pre></td></tr></table></figure>
<p>训练结果如下，能够100%正确检测测试数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">最好的设置是： lr = 0.005000, reg = 0.000008</span><br><span class="line">最好的测试精度： 1.000000</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/逻辑回归分类器/lr_acc.png" alt></p>
<p><img src="/imgs/逻辑回归分类器/lr_decision_boundary.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
        <category>分类器</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>逻辑回归</tag>
      </tags>
  </entry>
  <entry>
    <title>线性SVM分类器</title>
    <url>/posts/ebe205e.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="http://cs231n.github.io/linear-classify/" target="_blank" rel="noopener">Linear classification: Support Vector Machine, Softmax</a></p><a id="more"></a>

<p>最近重温<code>cs231n</code>课程，完成了课堂作业<a href="http://cs231n.github.io/assignments2019/assignment1/" target="_blank" rel="noopener">assignment1</a>，记录一下线性<code>SVM</code>分类器相关的概念以及实现</p>
<h2 id="什么是SVM分类器"><a href="#什么是SVM分类器" class="headerlink" title="什么是SVM分类器"></a>什么是SVM分类器</h2><p><code>SVM</code>（<code>support vector machine</code>，支持向量机）分类器定义为特征空间上间隔最大的线性分类器模型，其学习策略是使得分类间隔最大化</p>
<h3 id="线性SVM分类器实现"><a href="#线性SVM分类器实现" class="headerlink" title="线性SVM分类器实现"></a>线性SVM分类器实现</h3><p><em><code>cs231n</code>上的线性<code>SVM</code>分类器并没有给出数学推导过程，不过其介绍方式更容易理解</em></p>
<p><code>SVM</code>分类器训练结果是使得正确类别的成绩至少比错误类别成绩高一个间隔$\triangle $</p>
<p>训练过程如下：</p>
<ul>
<li>首先对输入数据进行线性映射，得到分类成绩；</li>
<li>然后，使用折页损失（<code>hinge loss</code>）函数计算损失值</li>
<li>最后根据损失值进行梯度求导，反向传播</li>
</ul>
<h3 id="损失值计算"><a href="#损失值计算" class="headerlink" title="损失值计算"></a>损失值计算</h3><p>完整的损失值包括折页损失+正则化项</p>
<script type="math/tex; mode=display">
L = \frac {1}{N} \sum_{i} L_{i} + \lambda R(W)</script><p>折页损失（<code>hinge loss</code>）计算表达式如下：</p>
<script type="math/tex; mode=display">
L_{i} = \sum_{j\neq y_{i}} \max(0, s_{j} - s_{y_{i}} + \triangle )</script><p>其中$i$表示批量数据中第$i$个样本，$y_{i}$表示第$i$个样本的正确类别，$j$表示不正确类别</p>
<p>正则化项使用<code>L2</code>范数:</p>
<script type="math/tex; mode=display">
R(W) = \sum_{k} \sum_{l} W_{k,l}^{2}</script><h2 id="矩阵推导"><a href="#矩阵推导" class="headerlink" title="矩阵推导"></a>矩阵推导</h2><p>参考：<a href="https://www.zhujian.tech/posts/1dd3ebad.html">神经网络推导-矩阵计算</a></p>
<p>输入参数：</p>
<script type="math/tex; mode=display">
X \in R^{N\times D}</script><script type="math/tex; mode=display">
y \in R^{N}</script><script type="math/tex; mode=display">
W \in R^{D\times C}</script><script type="math/tex; mode=display">
b \in R^{1\times C}</script><script type="math/tex; mode=display">
delta \in R^{1}</script><p>前向计算如下：</p>
<script type="math/tex; mode=display">
scores = X\cdot W + b \in R^{N\times C}</script><script type="math/tex; mode=display">
corrects = scores[y] \in R^{N\times 1}</script><script type="math/tex; mode=display">
margins = \frac {1}{N}\sum_{i=1}^{N}\max (0, scores_{i} - corrects_{i} + delta)</script><script type="math/tex; mode=display">
loss = margins + \lambda R(W)</script><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scores = X_batch.dot(self.W) + self.b</span><br><span class="line">correct_class_scores = np.atleast_2d(scores[range(num_train), y_batch]).T</span><br><span class="line">margins = scores - correct_class_scores + delta</span><br><span class="line"></span><br><span class="line">loss += np.sum(np.maximum(0, margins)) / num_train</span><br><span class="line">loss += reg * np.sum(self.W ** 2)</span><br></pre></td></tr></table></figure>
<p>反向求导如下：</p>
<script type="math/tex; mode=display">
dmargins =
\left\{\begin{matrix}
dscores_{i} - dcorrects_{i} & scores_{i} - corrects_{i} + delta > 0\\
0 & scores_{i} - corrects_{i} + delta <= 0
\end{matrix}\right.</script><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dscores = np.zeros(scores.shape)</span><br><span class="line">dscores[margins &gt; 0] = 1</span><br><span class="line">dscores[range(num_train), y_batch] = -1 * np.sum(dscores, axis=1)</span><br><span class="line">dscores /= num_train</span><br></pre></td></tr></table></figure>
<p>权重更新</p>
<script type="math/tex; mode=display">
dW = X^{T} \cdot dscores + reg \cdot W</script><script type="math/tex; mode=display">
db = \sum_{i=1}^{N}dscores_{i}</script><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dW = X_batch.T.dot(dscores) + reg * self.W</span><br><span class="line">db = np.sum(dscores, axis=0)</span><br></pre></td></tr></table></figure>
<h2 id="SVM分类器实现"><a href="#SVM分类器实现" class="headerlink" title="SVM分类器实现"></a>SVM分类器实现</h2><p>设置超参数$\triangle =1$</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-14 下午2:45</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class LinearSVM(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.W = None</span><br><span class="line">        self.b = None</span><br><span class="line"></span><br><span class="line">    def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100, batch_size=200, verbose=False):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Inputs:</span><br><span class="line">        - X: A numpy array of shape (N, D) containing training data; there are N</span><br><span class="line">          training samples each of dimension D.</span><br><span class="line">        - y: A numpy array of shape (N,) containing training labels; y[i] = c</span><br><span class="line">          means that X[i] has label 0 &lt;= c &lt; C for C classes.</span><br><span class="line">        - learning_rate: (float) learning rate for optimization.</span><br><span class="line">        - reg: (float) regularization strength.</span><br><span class="line">        - num_iters: (integer) number of steps to take when optimizing</span><br><span class="line">        - batch_size: (integer) number of training examples to use at each step.</span><br><span class="line">        - verbose: (boolean) If true, print progress during optimization.</span><br><span class="line"></span><br><span class="line">        Outputs:</span><br><span class="line">        A list containing the value of the loss function at each training iteration.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        num_train, dim = X.shape</span><br><span class="line">        num_classes = np.max(y) + 1  # assume y takes values 0...K-1 where K is number of classes</span><br><span class="line">        if self.W is None:</span><br><span class="line">            # lazily initialize W</span><br><span class="line">            self.W = 0.001 * np.random.randn(dim, num_classes)</span><br><span class="line">            self.b = np.zeros((1, num_classes))</span><br><span class="line"></span><br><span class="line">        # Run stochastic gradient descent to optimize W</span><br><span class="line">        loss_history = []</span><br><span class="line">        for it in range(num_iters):</span><br><span class="line">            indices = np.random.choice(num_train, batch_size)</span><br><span class="line">            X_batch = X[indices]</span><br><span class="line">            y_batch = y[indices]</span><br><span class="line"></span><br><span class="line">            # evaluate loss and gradient</span><br><span class="line">            loss, dW, db = self.loss(X_batch, y_batch, reg)</span><br><span class="line">            loss_history.append(loss)</span><br><span class="line"></span><br><span class="line">            self.W -= learning_rate * dW</span><br><span class="line">            self.b -= learning_rate * db</span><br><span class="line"></span><br><span class="line">            if verbose and it % 100 == 0:</span><br><span class="line">                print(&apos;iteration %d / %d: loss %f&apos; % (it, num_iters, loss))</span><br><span class="line"></span><br><span class="line">        return loss_history</span><br><span class="line"></span><br><span class="line">    def predict(self, X):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Use the trained weights of this linear classifier to predict labels for</span><br><span class="line">        data points.</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - X: A numpy array of shape (N, D) containing training data; there are N</span><br><span class="line">          training samples each of dimension D.</span><br><span class="line"></span><br><span class="line">        Returns:</span><br><span class="line">        - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional</span><br><span class="line">          array of length N, and each element is an integer giving the predicted</span><br><span class="line">          class.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        scores = X.dot(self.W)</span><br><span class="line">        y_pred = np.argmax(scores, axis=1)</span><br><span class="line"></span><br><span class="line">        return y_pred</span><br><span class="line"></span><br><span class="line">    def loss(self, X_batch, y_batch, reg, delta=1):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Compute the loss function and its derivative.</span><br><span class="line">        Subclasses will override this.</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - X_batch: A numpy array of shape (N, D) containing a minibatch of N</span><br><span class="line">          data points; each point has dimension D.</span><br><span class="line">        - y_batch: A numpy array of shape (N,) containing labels for the minibatch.</span><br><span class="line">        - reg: (float) regularization strength.</span><br><span class="line"></span><br><span class="line">        Returns: A tuple containing:</span><br><span class="line">        - loss as a single float</span><br><span class="line">        - gradient with respect to self.W; an array of the same shape as W</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        loss = 0.0</span><br><span class="line">        num_train = X_batch.shape[0]</span><br><span class="line"></span><br><span class="line">        scores = X_batch.dot(self.W) + self.b</span><br><span class="line">        correct_class_scores = np.atleast_2d(scores[range(num_train), y_batch]).T</span><br><span class="line">        margins = scores - correct_class_scores + delta</span><br><span class="line"></span><br><span class="line">        loss += np.sum(np.maximum(0, margins)) / num_train</span><br><span class="line">        loss += reg * np.sum(self.W ** 2)</span><br><span class="line"></span><br><span class="line">        dscores = np.zeros(scores.shape)</span><br><span class="line">        dscores[margins &gt; 0] = 1</span><br><span class="line">        dscores[range(num_train), y_batch] = -1 * np.sum(dscores, axis=1)</span><br><span class="line">        dscores /= num_train</span><br><span class="line"></span><br><span class="line">        dW = X_batch.T.dot(dscores) + reg * self.W</span><br><span class="line">        db = np.sum(dscores, axis=0)</span><br><span class="line"></span><br><span class="line">        return loss, dW, db</span><br></pre></td></tr></table></figure>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>参考：<a href="http://localhost:4000/posts/1ee29eaf.html#more" target="_blank" rel="noopener">实验</a></p>
<p>针对<code>Iris</code>数据集和<code>German data</code>数据集进行<code>SVM</code>分类器训练，完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-15 下午1:50</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">from builtins import range</span><br><span class="line">from classifier.svm_classifier import LinearSVM</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import math</span><br><span class="line">from sklearn import utils</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_iris(iris_path, shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(iris_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        data = utils.shuffle(data)</span><br><span class="line"></span><br><span class="line">    species_dict = &#123;</span><br><span class="line">        &apos;Iris-setosa&apos;: 0,</span><br><span class="line">        &apos;Iris-versicolor&apos;: 1,</span><br><span class="line">        &apos;Iris-virginica&apos;: 2</span><br><span class="line">    &#125;</span><br><span class="line">    data[&apos;Species&apos;] = data[&apos;Species&apos;].map(species_dict)</span><br><span class="line"></span><br><span class="line">    data_x = np.array(</span><br><span class="line">        [data[&apos;SepalLengthCm&apos;], data[&apos;SepalWidthCm&apos;], data[&apos;PetalLengthCm&apos;], data[&apos;PetalWidthCm&apos;]]).T</span><br><span class="line">    data_y = data[&apos;Species&apos;]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=False)</span><br><span class="line"></span><br><span class="line">    return np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_german_data(data_path, shuffle=True, tsize=0.8):</span><br><span class="line">    data_list = pd.read_csv(data_path, header=None, sep=&apos;\s+&apos;)</span><br><span class="line"></span><br><span class="line">    data_array = data_list.values</span><br><span class="line">    height, width = data_array.shape[:2]</span><br><span class="line">    data_x = data_array[:, :(width - 1)]</span><br><span class="line">    data_y = data_array[:, (width - 1)]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    y_train = np.array(list(map(lambda x: 1 if x == 2 else 0, y_train)))</span><br><span class="line">    y_test = np.array(list(map(lambda x: 1 if x == 2 else 0, y_test)))</span><br><span class="line"></span><br><span class="line">    return x_train, x_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(y, y_pred):</span><br><span class="line">    num = y.shape[0]</span><br><span class="line">    num_correct = np.sum(y_pred == y)</span><br><span class="line">    acc = float(num_correct) / num</span><br><span class="line">    return acc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def cross_validation(x_train, y_train, x_val, y_val, lr_choices, reg_choices):</span><br><span class="line">    results = &#123;&#125;</span><br><span class="line">    best_val = -1  # The highest validation accuracy that we have seen so far.</span><br><span class="line">    best_svm = None  # The LinearSVM object that achieved the highest validation rate.</span><br><span class="line"></span><br><span class="line">    for lr in lr_choices:</span><br><span class="line">        for reg in reg_choices:</span><br><span class="line">            svm = LinearSVM()</span><br><span class="line"></span><br><span class="line">            svm.train(x_train, y_train, learning_rate=lr, reg=reg, num_iters=2000, batch_size=100, verbose=True)</span><br><span class="line">            y_train_pred = svm.predict(x_train)</span><br><span class="line">            y_val_pred = svm.predict(x_val)</span><br><span class="line"></span><br><span class="line">            train_acc = np.mean(y_train_pred == y_train)</span><br><span class="line">            val_acc = np.mean(y_val_pred == y_val)</span><br><span class="line"></span><br><span class="line">            results[(lr, reg)] = (train_acc, val_acc)</span><br><span class="line">            if best_val &lt; val_acc:</span><br><span class="line">                best_val = val_acc</span><br><span class="line">                best_svm = svm</span><br><span class="line"></span><br><span class="line">    return results, best_svm, best_val</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(results):</span><br><span class="line">    # Visualize the cross-validation results</span><br><span class="line">    x_scatter = [math.log10(x[0]) for x in results]</span><br><span class="line">    y_scatter = [math.log10(x[1]) for x in results]</span><br><span class="line"></span><br><span class="line">    # plot training accuracy</span><br><span class="line">    marker_size = 100</span><br><span class="line">    colors = [results[x][0] for x in results]</span><br><span class="line">    plt.subplot(2, 1, 1)</span><br><span class="line">    plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    plt.xlabel(&apos;log learning rate&apos;)</span><br><span class="line">    plt.ylabel(&apos;log regularization strength&apos;)</span><br><span class="line">    plt.title(&apos;training accuracy&apos;)</span><br><span class="line"></span><br><span class="line">    # plot validation accuracy</span><br><span class="line">    colors = [results[x][1] for x in results]  # default size of markers is 20</span><br><span class="line">    plt.subplot(2, 1, 2)</span><br><span class="line">    plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    plt.xlabel(&apos;log learning rate&apos;)</span><br><span class="line">    plt.ylabel(&apos;log regularization strength&apos;)</span><br><span class="line">    plt.title(&apos;validation accuracy&apos;)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    iris_path = &apos;/home/zj/data/iris-species/Iris.csv&apos;</span><br><span class="line">    x_train, x_test, y_train, y_test = load_iris(iris_path, shuffle=True, tsize=0.8)</span><br><span class="line"></span><br><span class="line">    # data_path = &apos;/home/zj/data/german/german.data-numeric&apos;</span><br><span class="line">    # x_train, x_test, y_train, y_test = load_german_data(data_path, shuffle=True, tsize=0.8)</span><br><span class="line"></span><br><span class="line">    x_train = x_train.astype(np.double)</span><br><span class="line">    x_test = x_test.astype(np.double)</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-8</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(var + eps)</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(var + eps)</span><br><span class="line"></span><br><span class="line">    lr_choices = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2]</span><br><span class="line">    reg_choices = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2]</span><br><span class="line">    results, best_svm, best_val = cross_validation(x_train, y_train, x_test, y_test, lr_choices, reg_choices)</span><br><span class="line"></span><br><span class="line">    plot(results)</span><br><span class="line"></span><br><span class="line">    for k in results.keys():</span><br><span class="line">        lr, reg = k</span><br><span class="line">        train_acc, val_acc = results[k]</span><br><span class="line">        print(&apos;lr = %f, reg = %f, train_acc = %f, val_acc = %f&apos; % (lr, reg, train_acc, val_acc))</span><br><span class="line"></span><br><span class="line">    print(&apos;最好的设置是： lr = %f, reg = %f&apos; % (best_svm.lr, best_svm.reg))</span><br><span class="line">    print(&apos;最好的测试精度： %f&apos; % best_val)</span><br></pre></td></tr></table></figure>
<p>测试不同学习率和正则化强度下的<code>SVM</code>分类器训练结果，批量大小为<code>100</code>，每组参数训练<code>2000</code>次</p>
<p><code>Iris</code>数据集训练结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">最好的设置是： lr = 0.001000, reg = 0.000100</span><br><span class="line">最好的测试精度： 0.800000</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/SVM/iris_svm.png" alt></p>
<p><code>German data</code>数据集训练结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">最好的设置是： lr = 0.010000, reg = 0.001000</span><br><span class="line">最好的测试精度： 0.750000</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/SVM/german_svm.png" alt></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">Iris</th>
<th style="text-align:center">German data</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">KNN</td>
<td style="text-align:center">93.33%</td>
<td style="text-align:center">73.5%</td>
</tr>
<tr>
<td style="text-align:center">SVM</td>
<td style="text-align:center">80%</td>
<td style="text-align:center">75%</td>
</tr>
</tbody>
</table>
</div>
<p>线性<code>SVM</code>分类器对于非线性数据的分类结果不理想。不过可以通过核技巧，将原始特征投影到高维空间，从而能够实现非线性<code>SVM</code>分类器，进一步提高分类性能</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
        <category>分类器</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>sklearn</tag>
        <tag>pandas</tag>
        <tag>支持向量机</tag>
      </tags>
  </entry>
  <entry>
    <title>KNN分类器</title>
    <url>/posts/1ee29eaf.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="http://cs231n.github.io/classification/" target="_blank" rel="noopener">Image Classification: Data-driven Approach, k-Nearest Neighbor, train/val/test splits</a></p><a id="more"></a>

<p>最近重温<code>cs231n</code>课程，完成了课堂作业<a href="http://cs231n.github.io/assignments2019/assignment1/" target="_blank" rel="noopener">assignment1</a>，记录一下<code>KNN</code>分类器相关的概念以及实现，包括通用的分类器训练及测试过程</p>
<h2 id="什么是KNN分类器"><a href="#什么是KNN分类器" class="headerlink" title="什么是KNN分类器"></a>什么是KNN分类器</h2><p>参考：<a href="https://www.devtalking.com/articles/machine-learning-11/" target="_blank" rel="noopener">机器学习笔记十一之决策边界</a></p>
<p><code>KNN(K-Nearest Neighbor)</code>分类器是最简单的分类器实现之一，其决策边界是非线性的。它通过比较测试图像和样本图像的像素差异，按差异值从低到高排序对应样本图像标签，选择前<code>K</code>个标签中出现次数最多的标签作为分类结果</p>
<p>常用的比较像素差异的方法有<code>L1/L2</code>范数，参考<a href="https://www.zhujian.tech/posts/ce0afb50.html">范数</a></p>
<h3 id="优势和劣势"><a href="#优势和劣势" class="headerlink" title="优势和劣势"></a>优势和劣势</h3><p>主要有<code>2</code>点优势：</p>
<ol>
<li>易于理解和实现</li>
<li>不需要花费时间训练</li>
</ol>
<p>主要有<code>3</code>点缺陷：</p>
<ol>
<li>分类器需要保存所有的训练数据，空间效率低下</li>
<li>测试过程中测试图像需要和所有的训练图像进行比较，时间效率低下</li>
<li>通过像素差异进行分类，对于偏移（<code>shift</code>）、遮挡（<code>messed up</code>）和亮度调节的泛化效果不高</li>
</ol>
<h2 id="KNN分类器实现"><a href="#KNN分类器实现" class="headerlink" title="KNN分类器实现"></a>KNN分类器实现</h2><p>实现<code>KNN</code>分类器，使用<code>L2</code>范数进行像素差异计算，默认执行最近邻分类（<em>K=1</em>）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-11 下午8:02</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">from builtins import range</span><br><span class="line">from builtins import object</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class KNN(object):</span><br><span class="line">    &quot;&quot;&quot; a kNN classifier with L2 distance &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.X_train = None</span><br><span class="line">        self.y_train = None</span><br><span class="line"></span><br><span class="line">    def train(self, X, y):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Train the classifier. For k-nearest neighbors this is just</span><br><span class="line">        memorizing the training data.</span><br><span class="line">        Inputs:</span><br><span class="line">        - X: A numpy array of shape (num_train, D) containing the training data</span><br><span class="line">          consisting of num_train samples each of dimension D.</span><br><span class="line">        - y: A numpy array of shape (N,) containing the training labels, where</span><br><span class="line">             y[i] is the label for X[i].</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.X_train = X</span><br><span class="line">        self.y_train = y</span><br><span class="line"></span><br><span class="line">    def predict(self, X, k=1):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Predict labels for test data using this classifier.</span><br><span class="line">        Inputs:</span><br><span class="line">        - X: A numpy array of shape (num_test, D) containing test data consisting</span><br><span class="line">             of num_test samples each of dimension D.</span><br><span class="line">        - k: The number of nearest neighbors that vote for the predicted labels.</span><br><span class="line">        Returns:</span><br><span class="line">        - y: A numpy array of shape (num_test,) containing predicted labels for the</span><br><span class="line">          test data, where y[i] is the predicted label for the test point X[i].</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        dists = self._compute_distances(X)</span><br><span class="line"></span><br><span class="line">        return self._predict_labels(dists, k=k)</span><br><span class="line"></span><br><span class="line">    def _compute_distances(self, X):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Compute the distance between each test point in X and each training point</span><br><span class="line">        in self.X_train using no explicit loops.</span><br><span class="line">        Input / Output: Same as compute_distances_two_loops</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        num_test = X.shape[0]</span><br><span class="line">        num_train = self.X_train.shape[0]</span><br><span class="line">        dists = np.zeros((num_test, num_train))</span><br><span class="line"></span><br><span class="line">        temp_test = np.atleast_2d(np.sum(X ** 2, axis=1)).T</span><br><span class="line">        temp_train = np.atleast_2d(np.sum(self.X_train ** 2, axis=1))</span><br><span class="line">        temp_test_train = -2 * X.dot(self.X_train.T)</span><br><span class="line"></span><br><span class="line">        dists = np.sqrt(temp_test + temp_train + temp_test_train)</span><br><span class="line">        return dists</span><br><span class="line"></span><br><span class="line">    def _predict_labels(self, dists, k=1):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Given a matrix of distances between test points and training points,</span><br><span class="line">        predict a label for each test point.</span><br><span class="line">        Inputs:</span><br><span class="line">        - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</span><br><span class="line">          gives the distance betwen the ith test point and the jth training point.</span><br><span class="line">        Returns:</span><br><span class="line">        - y: A numpy array of shape (num_test,) containing predicted labels for the</span><br><span class="line">          test data, where y[i] is the predicted label for the test point X[i].</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        num_test = dists.shape[0]</span><br><span class="line">        y_pred = np.zeros(num_test)</span><br><span class="line">        for i in range(num_test):</span><br><span class="line">            idxes = np.argsort(dists[i])</span><br><span class="line">            closest_y = list(self.y_train[idxes][:k])</span><br><span class="line"></span><br><span class="line">            nums = np.array([closest_y.count(m) for m in closest_y])</span><br><span class="line">            y_pred[i] = closest_y[np.argmax(nums)]</span><br><span class="line"></span><br><span class="line">        return y_pred</span><br></pre></td></tr></table></figure>
<h2 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h2><p>交叉验证（<code>cross-validation</code>）是模型训练过程中调试超参数$k$的很有效的手段，训练过程如下：</p>
<ol>
<li>将训练数据等分为$N$份</li>
<li>按序取出其中一份作为验证集，其余数据重新作为训练集</li>
<li>计算超参数$k$为某一值时的预测精度。这样，每个超参数$k$都会得到$N$个精度值</li>
<li>平均$N$个精度值作为当前超参数$k$值的检测结果，比较不同$k$值下的检测精度，选取最好的$k$值</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">num_folds = 5</span><br><span class="line">k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]</span><br><span class="line"></span><br><span class="line">X_train_folds = []</span><br><span class="line">y_train_folds = []</span><br><span class="line"></span><br><span class="line">X_train_folds = np.array_split(X_train, num_folds)</span><br><span class="line">y_train_folds = np.array_split(y_train, num_folds)</span><br><span class="line"></span><br><span class="line"># A dictionary holding the accuracies for different values of k that we find</span><br><span class="line"># when running cross-validation. After running cross-validation,</span><br><span class="line"># k_to_accuracies[k] should be a list of length num_folds giving the different</span><br><span class="line"># accuracy values that we found when using that value of k.</span><br><span class="line">k_to_accuracies = &#123;&#125;</span><br><span class="line"></span><br><span class="line"># 计算预测标签和验证集标签的精度</span><br><span class="line">def compute_accuracy(y_test, y_test_pred):</span><br><span class="line">    num_test = y_test.shape[0]</span><br><span class="line">    num_correct = np.sum(y_test_pred == y_test)</span><br><span class="line">    accuracy = float(num_correct) / num_test</span><br><span class="line">    return accuracy</span><br><span class="line"></span><br><span class="line">for k in k_choices:</span><br><span class="line">    k_accuracies = []</span><br><span class="line">    # 随机选取其中一份为验证集，其余为测试集</span><br><span class="line">    for i in range(num_folds):</span><br><span class="line">        x_folds = X_train_folds.copy()</span><br><span class="line">        y_folds = y_train_folds.copy()</span><br><span class="line">        </span><br><span class="line">        x_vals = x_folds.pop(i)</span><br><span class="line">        x_trains = np.vstack(x_folds)</span><br><span class="line">        </span><br><span class="line">        y_vals = y_folds.pop(i)</span><br><span class="line">        y_trains = np.hstack(y_folds)</span><br><span class="line">        </span><br><span class="line">        classifier = KNearestNeighbor()</span><br><span class="line">#         print(x_trains.shape)</span><br><span class="line">#         print(y_trains.shape)</span><br><span class="line">        classifier.train(x_trains, y_trains)</span><br><span class="line">        </span><br><span class="line">#         print(x_vals.shape)</span><br><span class="line">        y_val_pred = classifier.predict(x_vals, k=k, num_loops=0)</span><br><span class="line">        k_accuracies.append(compute_accuracy(y_vals, y_val_pred))</span><br><span class="line">    k_to_accuracies[k] = k_accuracies</span><br><span class="line"></span><br><span class="line"># print(k_to_accuracies)</span><br><span class="line"># Print out the computed accuracies</span><br><span class="line">for k in sorted(k_to_accuracies):</span><br><span class="line">    for accuracy in k_to_accuracies[k]:</span><br><span class="line">        print(&apos;k = %d, accuracy = %f&apos; % (k, accuracy))</span><br></pre></td></tr></table></figure>
<p><em>通常设置训练集为$5$等分或$10$等分</em></p>
<p>交叉验证方法的优点在于其得到的超参数具有最好的泛化效果，缺点在于训练时间长</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>使用两个数据集分别测试<code>KNN</code>分类器，使用交叉验证方法训练最好的<code>KNN</code>分类器</p>
<p>完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-7-15 上午11:33</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">from builtins import range</span><br><span class="line">from classifier.knn_classifier import KNN</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn import utils</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_iris(iris_path, shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(iris_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        data = utils.shuffle(data)</span><br><span class="line"></span><br><span class="line">    species_dict = &#123;</span><br><span class="line">        &apos;Iris-setosa&apos;: 0,</span><br><span class="line">        &apos;Iris-versicolor&apos;: 1,</span><br><span class="line">        &apos;Iris-virginica&apos;: 2</span><br><span class="line">    &#125;</span><br><span class="line">    data[&apos;Species&apos;] = data[&apos;Species&apos;].map(species_dict)</span><br><span class="line"></span><br><span class="line">    data_x = np.array(</span><br><span class="line">        [data[&apos;SepalLengthCm&apos;], data[&apos;SepalWidthCm&apos;], data[&apos;PetalLengthCm&apos;], data[&apos;PetalWidthCm&apos;]]).T</span><br><span class="line">    data_y = data[&apos;Species&apos;]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=False)</span><br><span class="line"></span><br><span class="line">    return x_train, x_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_german_data(data_path, shuffle=True, tsize=0.8):</span><br><span class="line">    data_list = pd.read_csv(data_path, header=None, sep=&apos;\s+&apos;)</span><br><span class="line"></span><br><span class="line">    data_array = data_list.values</span><br><span class="line">    height, width = data_array.shape[:2]</span><br><span class="line">    data_x = data_array[:, :(width - 1)]</span><br><span class="line">    data_y = data_array[:, (width - 1)]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    y_train = np.array(list(map(lambda x: 1 if x == 2 else 0, y_train)))</span><br><span class="line">    y_test = np.array(list(map(lambda x: 1 if x == 2 else 0, y_test)))</span><br><span class="line"></span><br><span class="line">    return x_train, x_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(y, y_pred):</span><br><span class="line">    num = y.shape[0]</span><br><span class="line">    num_correct = np.sum(y_pred == y)</span><br><span class="line">    acc = float(num_correct) / num</span><br><span class="line">    return acc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def cross_validation(x_train, y_train, k_choices, num_folds=5, Classifier=KNN):</span><br><span class="line">    X_train_folds = np.array_split(x_train, num_folds)</span><br><span class="line">    y_train_folds = np.array_split(y_train, num_folds)</span><br><span class="line"></span><br><span class="line">    # 计算预测标签和验证集标签的精度</span><br><span class="line">    k_to_accuracies = &#123;&#125;</span><br><span class="line">    for k in k_choices:</span><br><span class="line">        k_accuracies = []</span><br><span class="line">        # 随机选取其中一份为验证集，其余为测试集</span><br><span class="line">        for i in range(num_folds):</span><br><span class="line">            x_folds = X_train_folds.copy()</span><br><span class="line">            y_folds = y_train_folds.copy()</span><br><span class="line"></span><br><span class="line">            x_vals = x_folds.pop(i)</span><br><span class="line">            x_trains = np.vstack(x_folds)</span><br><span class="line"></span><br><span class="line">            y_vals = y_folds.pop(i)</span><br><span class="line">            y_trains = np.hstack(y_folds)</span><br><span class="line"></span><br><span class="line">            classifier = Classifier()</span><br><span class="line">            classifier.train(x_trains, y_trains)</span><br><span class="line"></span><br><span class="line">            y_val_pred = classifier.predict(x_vals, k=k)</span><br><span class="line">            k_accuracies.append(compute_accuracy(y_vals, y_val_pred))</span><br><span class="line">        k_to_accuracies[k] = k_accuracies</span><br><span class="line"></span><br><span class="line">    return k_to_accuracies</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(k_choices, k_to_accuracies):</span><br><span class="line">    # plot the raw observations</span><br><span class="line">    for k in k_choices:</span><br><span class="line">        accuracies = k_to_accuracies[k]</span><br><span class="line">        plt.scatter([k] * len(accuracies), accuracies)</span><br><span class="line"></span><br><span class="line">    # plot the trend line with error bars that correspond to standard deviation</span><br><span class="line">    accuracies_mean = np.array([np.mean(v) for k, v in sorted(k_to_accuracies.items())])</span><br><span class="line">    accuracies_std = np.array([np.std(v) for k, v in sorted(k_to_accuracies.items())])</span><br><span class="line">    plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)</span><br><span class="line">    plt.title(&apos;Cross-validation on k&apos;)</span><br><span class="line">    plt.xlabel(&apos;k&apos;)</span><br><span class="line">    plt.ylabel(&apos;Cross-validation accuracy&apos;)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # iris_path = &apos;/home/zj/data/iris-species/Iris.csv&apos;</span><br><span class="line">    # x_train, x_test, y_train, y_test = load_iris(iris_path, shuffle=True, tsize=0.8)</span><br><span class="line"></span><br><span class="line">    data_path = &apos;/home/zj/data/german/german.data-numeric&apos;</span><br><span class="line">    x_train, x_test, y_train, y_test = load_german_data(data_path, shuffle=True, tsize=0.8)</span><br><span class="line"></span><br><span class="line">    x_train = x_train.astype(np.double)</span><br><span class="line">    x_test = x_test.astype(np.double)</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    var = np.var(x_train, axis=0)</span><br><span class="line">    eps = 1e-8</span><br><span class="line">    x_train = (x_train - mu) / np.sqrt(var + eps)</span><br><span class="line">    x_test = (x_test - mu) / np.sqrt(var + eps)</span><br><span class="line"></span><br><span class="line">    k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 30, 50, 100]</span><br><span class="line">    k_to_accuracies = cross_validation(x_train, y_train, k_choices)</span><br><span class="line"></span><br><span class="line">    # print(k_to_accuracies)</span><br><span class="line">    # Print out the computed accuracies</span><br><span class="line">    for k in sorted(k_to_accuracies):</span><br><span class="line">        for accuracy in k_to_accuracies[k]:</span><br><span class="line">            print(&apos;k = %d, accuracy = %f&apos; % (k, accuracy))</span><br><span class="line"></span><br><span class="line">    plot(k_choices, k_to_accuracies)</span><br><span class="line"></span><br><span class="line">    accuracies_mean = np.array([np.mean(v) for k, v in sorted(k_to_accuracies.items())])</span><br><span class="line">    k = k_choices[np.argmax(accuracies_mean)]</span><br><span class="line">    print(&apos;最好的k值是：%d&apos; % k)</span><br><span class="line"></span><br><span class="line">    # 测试集测试</span><br><span class="line">    classifier = KNN()</span><br><span class="line">    classifier.train(x_train, y_train)</span><br><span class="line"></span><br><span class="line">    y_test_pred = classifier.predict(x_test, k=k)</span><br><span class="line">    y_test_acc = compute_accuracy(y_test, y_test_pred)</span><br><span class="line">    print(&apos;测试集精度为：%f&apos; % y_test_acc)</span><br></pre></td></tr></table></figure>
<p>数据集一：<code>Iris</code>数据集，共<code>4</code>个变量，<code>3</code>个类别。参考：<a href="https://www.zhujian.tech/posts/2626bec3.html">鸢尾数据集</a></p>
<p>测试结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">最好的k值是：12</span><br><span class="line">测试集精度为：0.933333</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/KNN/iris.png" alt></p>
<p>数据集二：德国信用卡数据集，共<code>24</code>个变量，<code>2</code>个类别。参考：<a href="https://download.csdn.net/download/u012005313/11351036" target="_blank" rel="noopener">german data</a></p>
<p>测试结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">最好的k值是：20</span><br><span class="line">测试集精度为：0.735000</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/KNN/german_data.png" alt></p>
<p><em>由于数据集过小，进行多次交叉验证才能得到比较好的结果</em></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
        <category>分类器</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>K近邻</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>sklearn</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>AdaGrad、RMSProp和Adam</title>
    <url>/posts/2bdd8f16.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="http://cs231n.github.io/neural-networks-3/#ada" target="_blank" rel="noopener">Per-parameter adaptive learning rate methods</a></p><p><a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" target="_blank" rel="noopener">lecture_slides_lec6.pdf</a></p><a id="more"></a>


<p><code>AdaGrad、RMSProp</code>以及<code>Adam</code>都是逐元素的自适应学习率方法（<code>per-parameter adaptive learning rate methods</code>），根据每个神经元的梯度变化进行权重调整，能够有效的提高模型精度</p>
<h2 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h2><p>数学公式如下：</p>
<script type="math/tex; mode=display">
cache = cache + (dw)^{2}\\
w += -1 * lr / (\sqrt{cache} + eps)</script><p>其中$w$是权重，$dw$是梯度，$lr$是学习率，使用$cache$累加梯度平方和</p>
<p><em>$eps$是常量，通常设为<code>1e-8</code>，用于保证数值稳定性</em></p>
<p>实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cache += dw**2</span><br><span class="line">w += - learning_rate * dw / (np.sqrt(cache) + eps)</span><br></pre></td></tr></table></figure>
<p>与原始$SGD$实现相比，有两点优势：</p>
<ol>
<li>其学习率除以$cache$的平方根，起到了学习率退火的效果</li>
<li>如果得到了高梯度，则有效学习率下降，反之有效学习率提高，这样保证权重向量的变化更加稳定，不易被个别样本影响</li>
</ol>
<p>其缺点在于变量$cache$是单调递增的，这导致学习率的单调递减，最终趋向于$0$，过早的停止学习</p>
<h2 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h2><p>数学公式如下：</p>
<script type="math/tex; mode=display">
cache = decay_{rate} * cache + (1 - decay_{rate}) * (dw)^{2}\\
w += -1 * lr / (\sqrt{cache} + eps)</script><p>其中$w$是权重，$dw$是梯度，$lr$是学习率，$decay_{rate}$表示衰减率，通常设为<code>[0.9, 0.99, 0.999]</code>其中之一，使用$cache$累加梯度平方和</p>
<p><em>$eps$是常量，通常设为<code>1e-8</code>，用于保证数值稳定性</em></p>
<p>实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cache = decay_rate * cache + (1 - decay_rate) * dw**2</span><br><span class="line">w += - learning_rate * dw / (np.sqrt(cache) + eps)</span><br></pre></td></tr></table></figure>
<p>与<code>AdaGrad</code>相比，其$cache$取值进行了弱化调整，通过<a href="https://baike.baidu.com/item/EMA/12646151" target="_blank" rel="noopener">指数移动平均值</a>的方式，避免梯度平方和（二阶动量）的单调累积，根据梯度变化进行自主调整，有效延长学习过程</p>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><p><a href="https://arxiv.org/abs/1412.6980" target="_blank" rel="noopener">Adam</a>方法集成了前两者，数学实现如下：</p>
<script type="math/tex; mode=display">
m_{t} = \beta_{1}\cdot m_{t-1} + (1-\beta_{1})\cdot dw_{t}\\
v_{t} = \beta_{2}\cdot v_{t-1} + (1-\beta_{2})\cdot dw_{t}^{2}\\
\tilde{m_{t}} = m_{t} / (1 - \beta_{1})\\
\tilde{v_{t}} = v_{t} / (1 - \beta_{2})\\
w_{t} = w_{t-1} - lr \cdot \tilde{m_{t}} / (\sqrt{\tilde{v_{t}}} + \xi)</script><p>$t$表示迭代次数</p>
<p>$\beta_{1}$和$\beta_{2}$是常量，取值在<code>[0,1]</code>之间</p>
<p>$lr$是学习率</p>
<p>$\xi$是常量，用于数值稳定，保证不除以$0$，取值在<code>[1e-4, 1e-8]</code>之间</p>
<p>常用的取值组合为$lr=0.001, \beta_{1}=0.9, \beta_{2}=0.999, \xi=10^{-8}$</p>
<p>参考：</p>
<p><img src="/imgs/AdaGrad、RMSProp和Adam/adam_alg1.png" alt></p>
<p>实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">m = beta1*m + (1-beta1)*dw</span><br><span class="line">mt = m / (1-beta1**t)</span><br><span class="line">v = beta2*v + (1-beta2)*(dw**2)</span><br><span class="line">vt = v / (1-beta2**t)</span><br><span class="line">w += - learning_rate * mt / (np.sqrt(vt) + eps)</span><br></pre></td></tr></table></figure>
<p><code>Adam</code>方法计算了梯度的一阶动量（均值，<code>mean</code>）和二阶动量（方差，<code>the uncentered variance</code>），同时为了避免初始动量不趋向于$0$，进行了偏置校正（<code>bias correction</code>）</p>
<p>与<code>RMSProp</code>方法相比，<code>Adam</code>方法进一步平滑了权重更新过程</p>
<h2 id="梯度下降流程"><a href="#梯度下降流程" class="headerlink" title="梯度下降流程"></a>梯度下降流程</h2><p>文章<a href="https://zhuanlan.zhihu.com/p/32626442" target="_blank" rel="noopener">从 SGD 到 Adam —— 深度学习优化算法概览(一)</a>总结了梯度下降方法的更新框架</p>
<ol>
<li>计算梯度$dw$</li>
<li>计算梯度的一阶动量$m_{t}$和二阶动量$v_{t}$</li>
<li>更新权重$w_{t} = w_{t-1} - m_{t} / (\sqrt{v_{t} + \xi})$</li>
</ol>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>逐元素的自适应学习率方法能够更加有效的利用神经元的梯度变化，加速学习过程</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>最优化</category>
        <category>逐元素自适应学习率方法</category>
      </categories>
      <tags>
        <tag>AdaGrad</tag>
        <tag>RMSProp</tag>
        <tag>Adam</tag>
      </tags>
  </entry>
  <entry>
    <title>GoogLeNet-pytorch</title>
    <url>/posts/e2a2caab.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>GoogLeNet-numpy</title>
    <url>/posts/d3f167aa.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>用于大尺度图像分类的极深卷积网络</title>
    <url>/posts/2738b55.html</url>
    <content><![CDATA[<p>文章<a href="https://arxiv.org/abs/1409.1556v6#" target="_blank" rel="noopener">very deep convolutional networks for large-scale image recognition</a>对<strong>卷积网络深度</strong>进行了详细研究，证明了增加模型深度能够有效提高网络性能，其实现的<code>VGGNet</code>在<code>2014</code>年<code>ImageNet</code>的定位（<code>localisation</code>）和分类（<code>classification</code>）比赛中获得第一和第二名</p><a id="more"></a>
<p><code>VGGNet</code>在<a href="https://www.zhujian.tech/posts/ca9994d1.html#more">AlexNet</a>模型配置和学习的基础上，参考<a href="https://zjzstu.github.io/posts/3f18ad9b.html#more" target="_blank" rel="noopener">ZFNet</a>使用更小的感受野和更小的步长，参考<a href="https://arxiv.org/abs/1312.6229" target="_blank" rel="noopener">OverFeat</a>在整个图像和多个尺度上对网络进行密集的训练和测试。最终，<code>VGGNet</code>使用$3\times 3$大小卷积核进行模型深度的研究，在学习过程中使用多尺度图像进行训练和测试</p>
<p>主要内容如下：</p>
<ol>
<li>卷积网络配置</li>
<li>训练和测试细节</li>
<li>分类实验</li>
<li>小结</li>
</ol>
<h2 id="卷积网络配置"><a href="#卷积网络配置" class="headerlink" title="卷积网络配置"></a>卷积网络配置</h2><h3 id="通用架构"><a href="#通用架构" class="headerlink" title="通用架构"></a>通用架构</h3><p><code>VGGNet</code>有多个版本，每个模型均包含以下内容</p>
<ul>
<li>输入数据固定为$224\times 224$大小的<code>RGB</code>图像</li>
<li>图像预处理仅执行均值零中心</li>
<li>使用$3\times 3$大小的卷积核，某些模型会额外配置$1\times 1$大小的卷积核，用于跨通道信息交互</li>
<li>步长固定为<code>1</code>，零填充用于保证卷积操作不改变输入数据体空间尺寸，$3\times 3$大小卷积核对应的零填充是<code>1</code></li>
<li>每个模型共有<code>5</code>个最大池化层，用于空间池化，滤波器大小为$2\times 2$，步长为<code>2</code></li>
<li>每个模型都包含<code>3</code>个全连接层，第一二个全连接层的神经元个数是<code>4096</code>，第三个神经元个数是类别数</li>
<li>模型输出结果使用<code>softmax</code>评分函数</li>
<li>所有隐藏层使用<code>ReLU</code>作为激活函数</li>
</ul>
<h3 id="模型配置"><a href="#模型配置" class="headerlink" title="模型配置"></a>模型配置</h3><p><code>VGGNet</code>共有<code>5</code>个版本，分别命名为<code>A-E</code></p>
<p><img src="/imgs/用于大尺度图像分类的极深卷积网络/vggnet.png" alt></p>
<p>每一列表示一个模型配置，不同列的区别在于增加的卷积层，卷积层命名规则为</p>
<blockquote>
<p>conv&lt;卷积核大小&gt;-&lt;滤波器个数&gt;</p>
</blockquote>
<p>由于参数主要集中在全连接层，所以<code>5</code>个模型的参数大体一致</p>
<p><img src="/imgs/用于大尺度图像分类的极深卷积网络/params.png" alt></p>
<h2 id="小卷积优势"><a href="#小卷积优势" class="headerlink" title="小卷积优势"></a>小卷积优势</h2><p><code>VGGNet</code>使用$3\times 3$大小卷积核进行特征提取，多个小卷积核操作的有效感受野等同于大卷积核一次操作。比如，两次$3\times 3$大小卷积操作（中间没有池化操作）等同于一次$5\times 5$大小卷积操作，三次$3\times 3$大小卷积操作的有效感受野等同于一次$7\times 7$大小卷积操作，参考<a href="https://www.zhujian.tech/posts/3b660279.html#more">感受野尺寸</a></p>
<p>$3\times 3$大小卷积操作还有如下优势：</p>
<ol>
<li>每个卷积层包含激活函数运算，堆叠小卷积网络能够集成更多的非线性函数，增强模型判别能力</li>
<li>假设每个卷积层滤波器个数均为$C$通道，那么3次$3\times 3$大小卷积操作共有$3\cdot 3\cdot 3\cdot C = 27C$个参数，而一次$7\times 7$大小卷积操作共有$49C$个参数。使用小卷积网络能够降低45%的参数（<em>此处和文章数据不太一致</em>）</li>
</ol>
<p>在模型<code>C</code>中还使用了$1\times 1$大小卷积核，参考<a href="https://zjzstu.github.io/posts/359ae103.html#more" target="_blank" rel="noopener">NIN</a>，其作用是进行跨通道的信息交互，同时能够集成激活函数，增加判别能力</p>
<h2 id="训练和测试细节"><a href="#训练和测试细节" class="headerlink" title="训练和测试细节"></a>训练和测试细节</h2><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><ul>
<li>批量大小为$256$</li>
<li>动量因子为$0.9$</li>
<li>权重惩罚因子为$5\cdot 10^{-4}$</li>
<li>第一二个全连接层进行随机失活（失活因子为<code>0.5</code>）</li>
<li>学习率初始化为$10^{-2}$，每当验证集精度停止提高时下降<code>10%</code></li>
</ul>
<p>整个训练过程共进行<code>370K</code>次（<code>74</code>次迭代），由于更小的卷积核滤波器、更深的深度以及某些层的预初始化，所以网络在较少的迭代次数后就能够拟合</p>
<p>首先对模型<code>A</code>进行训练，参数初始化为零均值，<code>0.01</code>方差；训练完成后使用其参数设置其他模型的<code>1-4</code>层卷积层和最后<code>3</code>个全连接层</p>
<h4 id="训练图像"><a href="#训练图像" class="headerlink" title="训练图像"></a>训练图像</h4><p>在每轮迭代中对图像进行随机采样$224\times 224$大小，并且进行随机水平翻转以及随机<code>RGB</code>颜色偏移</p>
<p>文章使用多种方法扩充数据集</p>
<p><strong>单尺度图像采样</strong>：假设最小边长度为$S$，将输入图像最小边缩放到$S=256或384$大小，随机采样$224\times 224$大小进行训练</p>
<p><strong>多尺度图像采样</strong>：将$S$随机缩放到尺度<code>[S_{min}, S_{max}]</code>之间（$S_{min}=256, S_{max}=512$），再随机采样$224\times 224$大小进行训练</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>将模型全连接层转换成卷积层：第一二个全连接层的卷积核大小为$7\times 7$，第三个全连接层的卷积核大小为$1\times 1$，最后输出的通道数就是类别成绩</p>
<p>将测试图像最小边缩放至大小$Q$，直接应用到全卷积网络，对最后输出的激活图求均值得到类别成绩</p>
<p>同时使用水平翻转扩充测试集，使用最大类后验概率平均原始和翻转图像获得最终的成绩</p>
<h2 id="分类实验"><a href="#分类实验" class="headerlink" title="分类实验"></a>分类实验</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>使用<code>ILSVRC-2012</code>数据集，共<code>1000</code>类，分为<code>3</code>组图像：训练集（<code>130</code>万张）、验证集（<code>5</code>万张）和测试集（<code>10</code>万张）</p>
<p>下面的单尺度、多尺度和多裁剪相对于测试阶段</p>
<h3 id="单尺度评估"><a href="#单尺度评估" class="headerlink" title="单尺度评估"></a>单尺度评估</h3><p>对于固定$S$，设置$Q=S$，对于$S\in [S_{min}, S_{max}]$，设置$Q=0.5(S_{min}+S_{max})$</p>
<p><img src="/imgs/用于大尺度图像分类的极深卷积网络/single_scale.png" alt></p>
<ul>
<li><strong>比较模型<code>A</code>和<code>A-LRN</code>，增加<code>LRN</code>层不对实验结果有提高</strong></li>
<li>比较模型<code>A-E</code>，增加模型深度能够提高检测结果</li>
<li>比较模型<code>B、C和D</code>，<code>C</code>比<code>B</code>增加了$1\times 1$大小的卷积层，<code>D</code>比<code>B</code>增加了$3\times 3$大小的卷积层，实验结果表明虽然增加$1\times 1$卷积层能够提高判别能力，但是捕获更多的空间上下文信息更重要</li>
<li>文章用$5\times 5$大小卷积核替换模型<code>B</code>的每一对$3\times 3$大小卷积核，结果发现更浅的网络比模型<code>B</code>的<code>top-1</code>误差率提高了<code>7%</code>，证明小卷积的深网络比大卷积的浅网络更有效</li>
<li>训练阶段多尺度采样图像比单尺度采样图像的结果更好，表明尺度抖动（<code>scale jittering</code>）能够有效捕获多尺度图像信息</li>
</ul>
<h3 id="多尺度评估"><a href="#多尺度评估" class="headerlink" title="多尺度评估"></a>多尺度评估</h3><p>对于训练集固定$S$的情况，测试集采集<code>3</code>张测试图像：${S-32, S, S+32}$，平均其检测结果</p>
<p>对于训练集浮动$S$的情况，测试集采集更大范围的图像：${S_{min}, 0.5(S_{min}+S_{max}), S_{max}}$</p>
<p><img src="/imgs/用于大尺度图像分类的极深卷积网络/multi_scale.png" alt></p>
<p>测试集尺度抖动能够有效提升检测性能</p>
<h3 id="多裁剪评估"><a href="#多裁剪评估" class="headerlink" title="多裁剪评估"></a>多裁剪评估</h3><p>参考：<a href="https://blog.csdn.net/C_chuxin/article/details/82832229" target="_blank" rel="noopener">在VGG网络中dense evaluation 与multi-crop evaluation两种预测方法的区别以及效果</a></p>
<p>比较<code>dense evaluation</code>（密集评估）和<code>multi-crop evaluation</code>（多裁剪评估）</p>
<ul>
<li><p>密集评估指直接将原图输入全卷积网络（<code>FCN</code>），最后对每个特征图求均值得到类别成绩</p>
</li>
<li><p>多裁剪评估指对图像进行多次随机裁剪，最后平均每个类别值</p>
</li>
</ul>
<p>通过实验证明两者存在互补性（<code>complementarity</code>），</p>
<p><img src="/imgs/用于大尺度图像分类的极深卷积网络/multi_crop.png" alt></p>
<h3 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a>模型融合</h3><p>使用模型集成（<code>model ensemble</code>）的方法，组合多个网络进行测试，平均最后的检测结果，能够有效提高检测性能</p>
<p><img src="/imgs/用于大尺度图像分类的极深卷积网络/convnet_fusion.png" alt></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>参考：<a href="http://cs231n.github.io/convolutional-networks/#case" target="_blank" rel="noopener">VGGNet</a></p>
<p>文章对模型深度进行了详尽的评估，提出的共<code>5</code>个<code>VGGNet</code>模型从<code>11</code>层到<code>19</code>层，证明了堆叠深度能够有效提高网络性能</p>
<p>通过尺度抖动增加训练集，通过多裁剪评估和密集评估融合增加测试集，通过模型集成的方式来提高性能</p>
<p>虽然网络深度的增加能够提高网络性能，但是<code>VGGNet</code>的缺点在于参数多，占用内存大，运算时间长。所以后续的方向一方面在于<strong>是否能够减少网络参数，提高运算时间</strong>；另一方面在于<strong>是否能够堆叠更深的网络来得到更好的性能</strong></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>VGGNet</tag>
      </tags>
  </entry>
  <entry>
    <title>NIN-pytorch</title>
    <url>/posts/cab4035.html</url>
    <content><![CDATA[<p><code>numpy</code>实现<a href="https://www.zhujian.tech/posts/359ae103.html#more">NIN</a>模型，利用<code>cifar-10</code>、<code>cifar-100</code>和<code>mnist</code>数据集进行<code>MLPConv</code>和<code>GAP</code>的测试</p><a id="more"></a>
<p>完整实现：<a href="https://github.com/zjZSTU/PyNet" target="_blank" rel="noopener">zjZSTU/PyNet</a></p>
<h2 id="GAP实现"><a href="#GAP实现" class="headerlink" title="GAP实现"></a>GAP实现</h2><p>参考<a href="https://discuss.pytorch.org/t/global-average-pooling-in-pytorch/6721" target="_blank" rel="noopener">Global Average Pooling in Pytorch</a>，使用<a href="https://pytorch.org/docs/stable/nn.html?highlight=avgpool2d#torch.nn.AvgPool2d" target="_blank" rel="noopener">torch.nn.AvgPool2d</a></p>
<blockquote>
<p>class torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)</p>
</blockquote>
<p>输入数据体大小为$N\times C\times H_{in}\times W_{in}$，输出大小为$N\times C\times H_{out}\times W_{out}$，则</p>
<script type="math/tex; mode=display">
H_{out} = \left \lfloor \frac {H_{in}+2\times padding[0] - kernelsize[0]} {stride[0]} \right \rfloor + 1</script><script type="math/tex; mode=display">
W_{out} = \left \lfloor \frac {W_{in}+2\times padding[1] - kernelsize[1]} {stride[1]} \right \rfloor + 1</script><p>设核空间尺寸为输入数据体大小，即为全局平均池化层</p>
<p>测试代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; gap = nn.AvgPool2d(3)</span><br><span class="line">&gt;&gt;&gt; a = torch.arange(36.).reshape(2,2,3,3)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">tensor([[[[ 0.,  1.,  2.],</span><br><span class="line">          [ 3.,  4.,  5.],</span><br><span class="line">          [ 6.,  7.,  8.]],</span><br><span class="line"></span><br><span class="line">         [[ 9., 10., 11.],</span><br><span class="line">          [12., 13., 14.],</span><br><span class="line">          [15., 16., 17.]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[18., 19., 20.],</span><br><span class="line">          [21., 22., 23.],</span><br><span class="line">          [24., 25., 26.]],</span><br><span class="line"></span><br><span class="line">         [[27., 28., 29.],</span><br><span class="line">          [30., 31., 32.],</span><br><span class="line">          [33., 34., 35.]]]])</span><br><span class="line">&gt;&gt;&gt; gap(a)</span><br><span class="line">tensor([[[[ 4.]],</span><br><span class="line"></span><br><span class="line">         [[13.]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[22.]],</span><br><span class="line"></span><br><span class="line">         [[31.]]]])</span><br><span class="line">&gt;&gt;&gt; gap(a).shape</span><br><span class="line">torch.Size([2, 2, 1, 1])</span><br><span class="line">&gt;&gt;&gt; res = gap(a).reshape(2,2)</span><br><span class="line">&gt;&gt;&gt; res</span><br><span class="line">tensor([[ 4., 13.],</span><br><span class="line">        [22., 31.]])</span><br><span class="line">&gt;&gt;&gt; gap(a).view(2,2) # 或使用view函数</span><br><span class="line">tensor([[ 4., 13.],</span><br><span class="line">        [22., 31.]])</span><br></pre></td></tr></table></figure>
<h2 id="NIN定义"><a href="#NIN定义" class="headerlink" title="NIN定义"></a>NIN定义</h2><p>参考：<a href="https://github.com/jiecaoyu/pytorch-nin-cifar10/blob/master/original.py" target="_blank" rel="noopener"> pytorch-nin-cifar10/original.py </a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class NIN(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, in_channels=1, out_channels=10):</span><br><span class="line">        super(NIN, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.features1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, 192, (5, 5), stride=1, padding=2),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(192, 160, (1, 1), stride=1, padding=0),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(160, 96, (1, 1), stride=1, padding=0),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(2, stride=2),</span><br><span class="line">            nn.Dropout2d()</span><br><span class="line">        )</span><br><span class="line">        self.features2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(96, 192, (5, 5), stride=1, padding=2),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(192, 192, (1, 1), stride=1, padding=0),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(192, 192, (1, 1), stride=1, padding=0),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(2, stride=2),</span><br><span class="line">            nn.Dropout2d()</span><br><span class="line">        )</span><br><span class="line">        self.features3 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(192, 192, (3, 3), stride=1, padding=1),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(192, 192, (1, 1), stride=1, padding=0),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(192, out_channels, (1, 1), stride=1, padding=0),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.gap = nn.AvgPool2d(8)</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        x = self.features1(inputs)</span><br><span class="line">        x = self.features2(x)</span><br><span class="line">        x = self.features3(x)</span><br><span class="line">        x = self.gap(x)</span><br><span class="line"></span><br><span class="line">        return x.view(x.shape[0], x.shape[1])</span><br></pre></td></tr></table></figure>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def train():</span><br><span class="line">    train_loader, test_loader = vision.data.load_cifar10_pytorch(data_path, batch_size=batch_size, shuffle=True)</span><br><span class="line"></span><br><span class="line">    # device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">    device = torch.device(&quot;cpu&quot;)</span><br><span class="line"></span><br><span class="line">    net = models.pytorch.nin(in_channels=3).to(device)</span><br><span class="line">    criterion = nn.CrossEntropyLoss().to(device)</span><br><span class="line">    optimer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, nesterov=True)</span><br><span class="line">    # stepLR = StepLR(optimer, 100, 0.5)</span><br><span class="line"></span><br><span class="line">    best_train_accuracy = 0.995</span><br><span class="line">    best_test_accuracy = 0</span><br><span class="line"></span><br><span class="line">    accuracy = vision.Accuracy()</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    train_list = []</span><br><span class="line">    for i in range(epochs):</span><br><span class="line">        num = 0</span><br><span class="line">        total_loss = 0</span><br><span class="line">        start = time.time()</span><br><span class="line">        # 训练阶段</span><br><span class="line">        net.train()</span><br><span class="line">        for j, item in enumerate(train_loader, 0):</span><br><span class="line">            data, labels = item</span><br><span class="line">            data = data.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">            scores = net.forward(data)</span><br><span class="line">            loss = criterion.forward(scores, labels)</span><br><span class="line">            total_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            optimer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimer.step()</span><br><span class="line">            num += 1</span><br><span class="line">        end = time.time()</span><br><span class="line">        # stepLR.step()</span><br><span class="line"></span><br><span class="line">        avg_loss = total_loss / num</span><br><span class="line">        loss_list.append(float(&apos;%.8f&apos; % avg_loss))</span><br><span class="line">        print(&apos;epoch: %d time: %.2f loss: %.8f&apos; % (i + 1, end - start, avg_loss))</span><br><span class="line"></span><br><span class="line">        if i % 20 == 19:</span><br><span class="line">            # 验证阶段</span><br><span class="line">            net.eval()</span><br><span class="line">            train_accuracy = accuracy.compute_pytorch(train_loader, net, device)</span><br><span class="line">            train_list.append(float(&apos;%.4f&apos; % train_accuracy))</span><br><span class="line">            if best_train_accuracy &lt; train_accuracy:</span><br><span class="line">                best_train_accuracy = train_accuracy</span><br><span class="line"></span><br><span class="line">                test_accuracy = accuracy.compute_pytorch(test_loader, net, device)</span><br><span class="line">                if best_test_accuracy &lt; test_accuracy:</span><br><span class="line">                    best_test_accuracy = test_accuracy</span><br><span class="line"></span><br><span class="line">            print(&apos;best train accuracy: %.2f %%   best test accuracy: %.2f %%&apos; % (</span><br><span class="line">                best_train_accuracy * 100, best_test_accuracy * 100))</span><br><span class="line">            print(loss_list)</span><br><span class="line">            print(train_list)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>NIN</tag>
      </tags>
  </entry>
  <entry>
    <title>NIN-numpy</title>
    <url>/posts/55877cae.html</url>
    <content><![CDATA[<p><code>numpy</code>实现<a href="https://www.zhujian.tech/posts/359ae103.html#more">NIN</a>模型，利用<code>cifar-10</code>、<code>cifar-100</code>和<code>mnist</code>数据集进行<code>MLPConv</code>和<code>GAP</code>的测试</p><a id="more"></a>
<p>完整实现：<a href="https://github.com/zjZSTU/PyNet" target="_blank" rel="noopener">zjZSTU/PyNet</a></p>
<h2 id="MLPConv实现"><a href="#MLPConv实现" class="headerlink" title="MLPConv实现"></a>MLPConv实现</h2><p><code>MLPConv</code>对局部连接执行微神经网络操作，在<code>NIN</code>模型中，每个<code>MLPConv</code>包含一个<code>3</code>层<code>MLP</code></p>
<p>首先需要对输入数据体提取局部连接，可使用一个常规卷积操作实现</p>
<p>比如输入数据体大小为$128\times 3\times 32\times 32$</p>
<p>第一层执行$5\times 5$卷积核大小，步长为$1$，零填充为$2$，滤波器个数为192的卷积操作</p>
<p>输出数据体大小为$128\times 192\times 32\times 32$，特征图上的一点即为输入数据体的单个局部连接结果</p>
<p>第二和第三层执行$1\times 1$卷积核大小，步长为$1$，零填充为$0$的卷积操作</p>
<p>输出数据体空间尺寸为$32\times 32$，不改变输入数据体大小，仅执行深度方向的降维重组</p>
<h2 id="GAP实现"><a href="#GAP实现" class="headerlink" title="GAP实现"></a>GAP实现</h2><p>输入张量大小为$N\times C\times H\times W$，对每个特征图进行均值运算，输出大小为$N\times C$，前向运算如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.arange(36).reshape(2,2,3,3)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[[[ 0,  1,  2],</span><br><span class="line">         [ 3,  4,  5],</span><br><span class="line">         [ 6,  7,  8]],</span><br><span class="line"></span><br><span class="line">        [[ 9, 10, 11],</span><br><span class="line">         [12, 13, 14],</span><br><span class="line">         [15, 16, 17]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[[18, 19, 20],</span><br><span class="line">         [21, 22, 23],</span><br><span class="line">         [24, 25, 26]],</span><br><span class="line"></span><br><span class="line">        [[27, 28, 29],</span><br><span class="line">         [30, 31, 32],</span><br><span class="line">         [33, 34, 35]]]])</span><br><span class="line">&gt;&gt;&gt; b = a.reshape(2,2,-1) # 2-D特征图转换成1-D向量</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8],</span><br><span class="line">        [ 9, 10, 11, 12, 13, 14, 15, 16, 17]],</span><br><span class="line"></span><br><span class="line">       [[18, 19, 20, 21, 22, 23, 24, 25, 26],</span><br><span class="line">        [27, 28, 29, 30, 31, 32, 33, 34, 35]]])</span><br><span class="line">&gt;&gt;&gt; c = np.mean(b, axis=2) # 计算每个特征图均值</span><br><span class="line">&gt;&gt;&gt; c</span><br><span class="line">array([[ 4., 13.],</span><br><span class="line">       [22., 31.]])</span><br></pre></td></tr></table></figure>
<p>反向操作中，输入梯度大小为$N\times C$，单个梯度图所有像素点有相同梯度，输出数据体大小为$N\times C\times H\times W$，反向计算如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.arange(4).reshape(2,2)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[0, 1],</span><br><span class="line">       [2, 3]])</span><br><span class="line">&gt;&gt;&gt; b = a.reshape(4, -1)</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([[0],</span><br><span class="line">       [1],</span><br><span class="line">       [2],</span><br><span class="line">       [3]])</span><br><span class="line">&gt;&gt;&gt; c = np.repeat(b, 9, axis=1)</span><br><span class="line">&gt;&gt;&gt; c</span><br><span class="line">array([[0, 0, 0, 0, 0, 0, 0, 0, 0],</span><br><span class="line">       [1, 1, 1, 1, 1, 1, 1, 1, 1],</span><br><span class="line">       [2, 2, 2, 2, 2, 2, 2, 2, 2],</span><br><span class="line">       [3, 3, 3, 3, 3, 3, 3, 3, 3]])</span><br><span class="line">&gt;&gt;&gt; d = c.reshape(2,2,3,3)</span><br><span class="line">&gt;&gt;&gt; d</span><br><span class="line">array([[[[0, 0, 0],</span><br><span class="line">         [0, 0, 0],</span><br><span class="line">         [0, 0, 0]],</span><br><span class="line"></span><br><span class="line">        [[1, 1, 1],</span><br><span class="line">         [1, 1, 1],</span><br><span class="line">         [1, 1, 1]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[[2, 2, 2],</span><br><span class="line">         [2, 2, 2],</span><br><span class="line">         [2, 2, 2]],</span><br><span class="line"></span><br><span class="line">        [[3, 3, 3],</span><br><span class="line">         [3, 3, 3],</span><br><span class="line">         [3, 3, 3]]]])</span><br></pre></td></tr></table></figure>
<p>所以<code>GAP</code>类完整实现及测试如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-6-21 上午11:18</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">from nn.Layer import *</span><br><span class="line"></span><br><span class="line">__all__ = [&apos;GAP&apos;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class GAP(Layer):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    global average pooling layer</span><br><span class="line">    全局平均池化层</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(GAP, self).__init__()</span><br><span class="line">        self.input_shape = None</span><br><span class="line"></span><br><span class="line">    def __call__(self, inputs):</span><br><span class="line">        return self.forward(inputs)</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        # input.shape == [N, C, H, W]</span><br><span class="line">        assert len(inputs.shape) == 4</span><br><span class="line">        N, C, H, W = inputs.shape[:4]</span><br><span class="line"></span><br><span class="line">        z = np.mean(inputs.reshape(N, C, -1), axis=2)</span><br><span class="line">        self.input_shape = inputs.shape</span><br><span class="line"></span><br><span class="line">        return z</span><br><span class="line"></span><br><span class="line">    def backward(self, grad_out):</span><br><span class="line">        N, C, H, W = self.input_shape[:4]</span><br><span class="line">        dz = grad_out.reshape(N * C, -1)</span><br><span class="line">        da = np.repeat(dz, H * W, axis=1)</span><br><span class="line"></span><br><span class="line">        return da.reshape(N, C, H, W)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    gap = GAP()</span><br><span class="line"></span><br><span class="line">    inputs = np.arange(36).reshape(2, 2, 3, 3)</span><br><span class="line">    res = gap(inputs)</span><br><span class="line">    print(res)</span><br><span class="line"></span><br><span class="line">    grad_out = np.arange(4).reshape(2, 2)</span><br><span class="line">    da = gap.backward(grad_out)</span><br><span class="line">    print(da)</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[[ 4. 13.]</span><br><span class="line"> [22. 31.]]</span><br><span class="line">[[[[0 0 0]</span><br><span class="line">   [0 0 0]</span><br><span class="line">   [0 0 0]]</span><br><span class="line">  [[1 1 1]</span><br><span class="line">   [1 1 1]</span><br><span class="line">   [1 1 1]]]</span><br><span class="line"> [[[2 2 2]</span><br><span class="line">   [2 2 2]</span><br><span class="line">   [2 2 2]]</span><br><span class="line">  [[3 3 3]</span><br><span class="line">   [3 3 3]</span><br><span class="line">   [3 3 3]]]]</span><br></pre></td></tr></table></figure>
<h2 id="NIN定义"><a href="#NIN定义" class="headerlink" title="NIN定义"></a>NIN定义</h2><p>假定输入数据体空间尺寸为$32\times 32$，输出类别为$10$</p>
<p>共有<code>3</code>层<code>MLPConv</code>和<code>1</code>层<code>GAP</code>，其中每个<code>MLPConv</code>为<code>3</code>层<code>MLP</code>，完整实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class NIN(Net):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    NIN网络</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, in_channels=1, out_channels=10, momentum=0, nesterov=False, p_h=1.0):</span><br><span class="line">        super(NIN, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels, 5, 5, 192, stride=1, padding=2, momentum=momentum, nesterov=nesterov)</span><br><span class="line">        self.conv2 = nn.Conv2d(96, 5, 5, 192, stride=1, padding=2, momentum=momentum, nesterov=nesterov)</span><br><span class="line">        self.conv3 = nn.Conv2d(192, 3, 3, 192, stride=1, padding=1, momentum=momentum, nesterov=nesterov)</span><br><span class="line"></span><br><span class="line">        self.mlp1 = nn.Conv2d(192, 1, 1, 160, stride=1, padding=0, momentum=momentum, nesterov=nesterov)</span><br><span class="line">        self.mlp2 = nn.Conv2d(160, 1, 1, 96, stride=1, padding=0, momentum=momentum, nesterov=nesterov)</span><br><span class="line"></span><br><span class="line">        self.mlp2_1 = nn.Conv2d(192, 1, 1, 192, stride=1, padding=0, momentum=momentum, nesterov=nesterov)</span><br><span class="line">        self.mlp2_2 = nn.Conv2d(192, 1, 1, 192, stride=1, padding=0, momentum=momentum, nesterov=nesterov)</span><br><span class="line"></span><br><span class="line">        self.mlp3_1 = nn.Conv2d(192, 1, 1, 192, stride=1, padding=0, momentum=momentum, nesterov=nesterov)</span><br><span class="line">        self.mlp3_2 = nn.Conv2d(192, 1, 1, out_channels, stride=1, padding=0, momentum=momentum, nesterov=nesterov)</span><br><span class="line"></span><br><span class="line">        self.maxPool1 = nn.MaxPool(2, 2, 96, stride=2)</span><br><span class="line">        self.maxPool2 = nn.MaxPool(2, 2, 192, stride=2)</span><br><span class="line"></span><br><span class="line">        self.gap = nn.GAP()</span><br><span class="line"></span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.relu2 = nn.ReLU()</span><br><span class="line">        self.relu3 = nn.ReLU()</span><br><span class="line">        self.relu4 = nn.ReLU()</span><br><span class="line">        self.relu5 = nn.ReLU()</span><br><span class="line">        self.relu6 = nn.ReLU()</span><br><span class="line">        self.relu7 = nn.ReLU()</span><br><span class="line">        self.relu8 = nn.ReLU()</span><br><span class="line">        self.relu9 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.dropout = nn.Dropout2d()</span><br><span class="line"></span><br><span class="line">        self.p_h = p_h</span><br><span class="line">        self.U1 = None</span><br><span class="line">        self.U2 = None</span><br><span class="line"></span><br><span class="line">    def __call__(self, inputs):</span><br><span class="line">        return self.forward(inputs)</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        # inputs.shape = [N, C, H, W]</span><br><span class="line">        assert len(inputs.shape) == 4</span><br><span class="line">        x = self.relu1(self.conv1(inputs))</span><br><span class="line">        x = self.relu2(self.mlp1(x))</span><br><span class="line">        x = self.relu3(self.mlp2(x))</span><br><span class="line">        x = self.maxPool1(x)</span><br><span class="line">        self.U1 = self.dropout(x.shape, self.p_h)</span><br><span class="line">        x *= self.U1</span><br><span class="line"></span><br><span class="line">        x = self.relu4(self.conv2(x))</span><br><span class="line">        x = self.relu5(self.mlp2_1(x))</span><br><span class="line">        x = self.relu6(self.mlp2_2(x))</span><br><span class="line">        x = self.maxPool2(x)</span><br><span class="line">        self.U2 = self.dropout(x.shape, self.p_h)</span><br><span class="line">        x *= self.U2</span><br><span class="line"></span><br><span class="line">        x = self.relu7(self.conv3(x))</span><br><span class="line">        x = self.relu8(self.mlp3_1(x))</span><br><span class="line">        x = self.relu9(self.mlp3_2(x))</span><br><span class="line"></span><br><span class="line">        x = self.gap(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def backward(self, grad_out):</span><br><span class="line">        # grad_out.shape = [N, C]</span><br><span class="line">        assert len(grad_out.shape) == 2</span><br><span class="line">        da11 = self.gap.backward(grad_out)</span><br><span class="line"></span><br><span class="line">        dz11 = self.relu9.backward(da11)</span><br><span class="line">        da10 = self.mlp3_2.backward(dz11)</span><br><span class="line">        dz10 = self.relu8.backward(da10)</span><br><span class="line">        da9 = self.mlp3_1.backward(dz10)</span><br><span class="line">        dz9 = self.relu7.backward(da9)</span><br><span class="line">        da8 = self.conv3.backward(dz9)</span><br><span class="line"></span><br><span class="line">        da8 *= self.U2</span><br><span class="line">        da7 = self.maxPool2.backward(da8)</span><br><span class="line">        dz7 = self.relu6.backward(da7)</span><br><span class="line">        da6 = self.mlp2_2.backward(dz7)</span><br><span class="line">        dz6 = self.relu5.backward(da6)</span><br><span class="line">        da5 = self.mlp2_1.backward(dz6)</span><br><span class="line">        dz5 = self.relu4.backward(da5)</span><br><span class="line">        da4 = self.conv2.backward(dz5)</span><br><span class="line"></span><br><span class="line">        da4 *= self.U1</span><br><span class="line">        da3 = self.maxPool1.backward(da4)</span><br><span class="line">        dz3 = self.relu3.backward(da3)</span><br><span class="line">        da2 = self.mlp2.backward(dz3)</span><br><span class="line">        dz2 = self.relu2.backward(da2)</span><br><span class="line">        da1 = self.mlp1.backward(dz2)</span><br><span class="line">        dz1 = self.relu1.backward(da1)</span><br><span class="line">        da0 = self.conv1.backward(dz1)</span><br><span class="line"></span><br><span class="line">    def update(self, lr=1e-3, reg=1e-3):</span><br><span class="line">        self.mlp3_2.update(learning_rate=lr, regularization_rate=reg)</span><br><span class="line">        self.mlp3_1.update(learning_rate=lr, regularization_rate=reg)</span><br><span class="line">        self.conv3.update(learning_rate=lr, regularization_rate=reg)</span><br><span class="line"></span><br><span class="line">        self.mlp2_2.update(learning_rate=lr, regularization_rate=reg)</span><br><span class="line">        self.mlp2_1.update(learning_rate=lr, regularization_rate=reg)</span><br><span class="line">        self.conv2.update(learning_rate=lr, regularization_rate=reg)</span><br><span class="line"></span><br><span class="line">        self.mlp2.update(learning_rate=lr, regularization_rate=reg)</span><br><span class="line">        self.mlp1.update(learning_rate=lr, regularization_rate=reg)</span><br><span class="line">        self.conv1.update(learning_rate=lr, regularization_rate=reg)</span><br><span class="line"></span><br><span class="line">    def predict(self, inputs):</span><br><span class="line">        # inputs.shape = [N, C, H, W]</span><br><span class="line">        assert len(inputs.shape) == 4</span><br><span class="line">        x = self.relu1(self.conv1(inputs))</span><br><span class="line">        x = self.relu2(self.mlp1(x))</span><br><span class="line">        x = self.relu3(self.mlp2(x))</span><br><span class="line">        x = self.maxPool1(x)</span><br><span class="line"></span><br><span class="line">        x = self.relu4(self.conv2(x))</span><br><span class="line">        x = self.relu5(self.mlp2_1(x))</span><br><span class="line">        x = self.relu6(self.mlp2_2(x))</span><br><span class="line">        x = self.maxPool2(x)</span><br><span class="line"></span><br><span class="line">        x = self.relu7(self.conv3(x))</span><br><span class="line">        x = self.relu8(self.mlp3_1(x))</span><br><span class="line">        x = self.relu9(self.mlp3_2(x))</span><br><span class="line"></span><br><span class="line">        x = self.gap(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def get_params(self):</span><br><span class="line">        out = dict()</span><br><span class="line">        out[&apos;conv1&apos;] = self.conv1.get_params()</span><br><span class="line">        out[&apos;conv2&apos;] = self.conv2.get_params()</span><br><span class="line">        out[&apos;conv3&apos;] = self.conv3.get_params()</span><br><span class="line"></span><br><span class="line">        out[&apos;mlp1&apos;] = self.mlp1.get_params()</span><br><span class="line">        out[&apos;mlp2&apos;] = self.mlp2.get_params()</span><br><span class="line">        out[&apos;mlp2_1&apos;] = self.mlp2_1.get_params()</span><br><span class="line">        out[&apos;mlp2_2&apos;] = self.mlp2_2.get_params()</span><br><span class="line">        out[&apos;mlp3_1&apos;] = self.mlp3_1.get_params()</span><br><span class="line">        out[&apos;mlp3_2&apos;] = self.mlp3_2.get_params()</span><br><span class="line"></span><br><span class="line">        out[&apos;p_h&apos;] = self.p_h</span><br><span class="line"></span><br><span class="line">        return out</span><br><span class="line"></span><br><span class="line">    def set_params(self, params):</span><br><span class="line">        self.conv1.set_params(params[&apos;conv1&apos;])</span><br><span class="line">        self.conv2.set_params(params[&apos;conv2&apos;])</span><br><span class="line">        self.conv3.set_params(params[&apos;conv3&apos;])</span><br><span class="line"></span><br><span class="line">        self.mlp1.set_params(params[&apos;mlp1&apos;])</span><br><span class="line">        self.mlp2.set_params(params[&apos;mlp2&apos;])</span><br><span class="line">        self.mlp2_1.set_params(params[&apos;mlp2_1&apos;])</span><br><span class="line">        self.mlp2_2.set_params(params[&apos;mlp2_1&apos;])</span><br><span class="line">        self.mlp3_1.set_params(params[&apos;mlp3_1&apos;])</span><br><span class="line">        self.mlp3_2.set_params(params[&apos;mlp3_1&apos;])</span><br><span class="line"></span><br><span class="line">        self.p_h = params.get(&apos;p_h&apos;, 1.0)</span><br></pre></td></tr></table></figure>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>测试代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def nin_train():</span><br><span class="line">    x_train, x_test, y_train, y_test = vision.data.load_cifar10(data_path, shuffle=True)</span><br><span class="line"></span><br><span class="line">    # 标准化</span><br><span class="line">    x_train = x_train / 255.0 - 0.5</span><br><span class="line">    x_test = x_test / 255.0 - 0.5</span><br><span class="line"></span><br><span class="line">    net = models.nin(in_channels=3, p_h=p_h)</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    accuracy = vision.Accuracy()</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    train_list = []</span><br><span class="line">    test_list = []</span><br><span class="line">    best_train_accuracy = 0.995</span><br><span class="line">    best_test_accuracy = 0.995</span><br><span class="line"></span><br><span class="line">    range_list = np.arange(0, x_train.shape[0] - batch_size, step=batch_size)</span><br><span class="line">    for i in range(epochs):</span><br><span class="line">        total_loss = 0</span><br><span class="line">        num = 0</span><br><span class="line">        start = time.time()</span><br><span class="line">        for j in range_list:</span><br><span class="line">            data = x_train[j:j + batch_size]</span><br><span class="line">            labels = y_train[j:j + batch_size]</span><br><span class="line"></span><br><span class="line">            scores = net(data)</span><br><span class="line">            loss = criterion(scores, labels)</span><br><span class="line">            total_loss += loss</span><br><span class="line">            num += 1</span><br><span class="line"></span><br><span class="line">            grad_out = criterion.backward()</span><br><span class="line">            net.backward(grad_out)</span><br><span class="line">            net.update(lr=learning_rate, reg=reg)</span><br><span class="line">        end = time.time()</span><br><span class="line">        print(&apos;one epoch need time: %.3f&apos; % (end - start))</span><br><span class="line">        print(&apos;epoch: %d loss: %f&apos; % (i + 1, total_loss / num))</span><br><span class="line">        loss_list.append(total_loss / num)</span><br><span class="line"></span><br><span class="line">        if (i % 20) == 19:</span><br><span class="line">            # # 每隔20次降低学习率</span><br><span class="line">            # learning_rate *= 0.5</span><br><span class="line"></span><br><span class="line">            train_accuracy = accuracy.compute_v2(x_train, y_train, net, batch_size=batch_size)</span><br><span class="line">            test_accuracy = accuracy.compute_v2(x_test, y_test, net, batch_size=batch_size)</span><br><span class="line">            train_list.append(train_accuracy)</span><br><span class="line">            test_list.append(test_accuracy)</span><br><span class="line"></span><br><span class="line">            print(loss_list)</span><br><span class="line">            print(train_list)</span><br><span class="line">            print(test_list)</span><br><span class="line">            if train_accuracy &gt; best_train_accuracy and test_accuracy &gt; best_test_accuracy:</span><br><span class="line">                path = &apos;nin-epochs-%d.pkl&apos; % (i + 1)</span><br><span class="line">                utils.save_params(net.get_params(), path=path)</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    draw = vision.Draw()</span><br><span class="line">    draw(loss_list, xlabel=&apos;迭代/20次&apos;)</span><br><span class="line">    draw.multi_plot((train_list, test_list), (&apos;训练集&apos;, &apos;测试集&apos;), title=&apos;精度图&apos;, xlabel=&apos;迭代/20次&apos;, ylabel=&apos;精度值&apos;)</span><br></pre></td></tr></table></figure>
<p><em><code>numpy</code>实现的速度太慢，就看看如何实现的吧，不建议运行</em></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>NIN</tag>
      </tags>
  </entry>
  <entry>
    <title>NIN</title>
    <url>/posts/359ae103.html</url>
    <content><![CDATA[<p>文章<a href="https://arxiv.org/abs/1312.4400v3" target="_blank" rel="noopener">Network In Network</a>提出一种新的深度网络结构<code>mlpconv</code>，使用微神经网络（<code>micro neural network</code>）代替传统卷积层的线性滤波器，同时利用全局平均池化（<code>global average pooling</code>）代替全连接层作为分类器，在当时的<code>CIFAR-10</code>和<code>CIFAR-100</code>上实现了最好的检测结果</p><a id="more"></a>
<h2 id="多层感知器池化层"><a href="#多层感知器池化层" class="headerlink" title="多层感知器池化层"></a>多层感知器池化层</h2><h3 id="传统卷积层"><a href="#传统卷积层" class="headerlink" title="传统卷积层"></a>传统卷积层</h3><p>传统卷积层执行滤波器和局部感受野的内积操作（<code>inner product</code>），随后执行非线性激活函数，输出的结果称为特征图（<code>feature map</code>）。实现如下：</p>
<script type="math/tex; mode=display">
f_{i,j,k} = \max (w_{k}^{T}x_{i,j}, 0)</script><p>$(i,j)$表示特征图坐标，$x_{i,j}$表示输入数据体中以$(i,j)$为中心的局部数据块，$k$表示特征图的通道下标</p>
<p>卷积层滤波器是一个线性模型（<code>generalized linear model，GLM</code>），仅在输入数据是线性可分的情况下，<code>GLM</code>才能得到很好的抽象结果</p>
<p>为了能够在高度非线性数据中获取正确抽象信息，卷积层使用了过完备（<code>over-complete</code>）的滤波器，以此来涵盖所有潜在的变化，这会加重下一层滤波器的负担</p>
<h3 id="Maxout-Network"><a href="#Maxout-Network" class="headerlink" title="Maxout Network"></a>Maxout Network</h3><p><code>Maxout</code>网络在特征图上执行最大池化操作，其操作作为分段线性逼近器（<code>piecewise linear approximator</code>）能够近似所有的凸函数（<code>approximating any convex functions</code>）</p>
<p><code>Maxout</code>网络的缺陷在于它依赖于输入空间是一个凸集</p>
<h3 id="MLPConv"><a href="#MLPConv" class="headerlink" title="MLPConv"></a>MLPConv</h3><p>径向机网络（<code>radial basis network</code>）和多层感知器（<code>multilayer perceptron，MLP</code>）是已知通用的函数逼近器（<code>universal function approximators</code>），<code>MLPConv</code>使用了<code>MLP</code>作为滤波器，有以下理由：</p>
<ol>
<li><code>MLP</code>兼容于卷积神经网络结构，比如反向传播训练</li>
<li><code>MLP</code>同样是一个深度模型，符合特征重用精神（<code>the spirit of feature re-use</code>）</li>
</ol>
<p><code>MLPConv</code>结构如下</p>
<p><img src="/imgs/NIN/mlp_conv.png" alt></p>
<p>计算公式如下：</p>
<script type="math/tex; mode=display">
f^{(1)}_{i,j,k_{1}} = \max ((w^{(1)}_{k_{1}})^{T}x_{i,j}+b_{k_{1}}, 0)\\
...\\
f^{(n)}_{i,j,k_{n}} = \max ((w^{(n)}_{k_{n}})^{T}x_{i,j}+b_{k_{n}}, 0)</script><p>$n$表示<code>MLP</code>层数，在<code>MLP</code>的每层操作完成后使用<code>ReLU</code>作为激活函数</p>
<p>从跨通道（跨特征图）的角度来看，上式等同于在卷积层中执行<strong>级联</strong>跨通道参数池化（<code>cascaded cross channel parameteric pooling</code>）操作，每个跨通道参数池化层对输入特征图执行权重线性重组</p>
<p><strong>单个<code>MLPConv</code>操作等同于级联多个跨通道参数池化层</strong>，这种级联的跨通道参数池化结构允许跨通道信息的交互学习</p>
<p><strong>从实现上看，单个跨通道参数池化层等同于$1\times 1$卷积核大小的传统卷积层操作，其实现仅执行深度方向的降维重组，输出激活图不改变空间尺寸</strong></p>
<h2 id="全局平均池化层"><a href="#全局平均池化层" class="headerlink" title="全局平均池化层"></a>全局平均池化层</h2><p>传统神经网络中，使用卷积神经网络作为特征提取器，使用全连接层作为分类器，很难解释全连接层中发生的变化</p>
<p>使用全局平均池化层（<code>global average pooling layer, GAP</code>）替代全连接层作为分类器有以下优势：</p>
<ol>
<li>有很好的可解释性，它强制了特征映射和类别之间的对应，特征图可以解释为类别置信图</li>
<li>全连接层易于过拟合，强烈依赖于正则化策略，而GAP是一个天然的正则化器（没有参数），能够避免过拟合</li>
<li><code>GAP</code>求和了空间信息，对于输入数据的空间转换有更好的鲁棒性</li>
</ol>
<p><code>GAP</code>计算：最后一个<code>MLPConv</code>提取的特征图数据体作为<code>GAP</code>的输入，通过空间平均特征图得到二维结果特征图，将结果特征图向量化后作为输出直接输入到<code>softmax</code>分类器</p>
<p>比如输入特征图数据体大小为$5\times 5\times 10$，对每个特征图进行空间平均得到$1\times 1\times 10$，就是最后的输出</p>
<h2 id="NIN"><a href="#NIN" class="headerlink" title="NIN"></a>NIN</h2><p>文章提出新的网络模型<code>NIN</code>（<code>Network In Network</code>），底层使用多个<code>MLPConv</code>堆叠，顶层使用<code>GAP</code>和<code>softmax</code>分类器</p>
<p><img src="/imgs/NIN/nin.png" alt></p>
<h3 id="模型细节"><a href="#模型细节" class="headerlink" title="模型细节"></a>模型细节</h3><p>文章给出的模型内容</p>
<ul>
<li><p>共<code>3</code>个<code>MLPConv</code>，每个<code>MLPConv</code>使用一个<code>3</code>层<code>MLP</code></p>
</li>
<li><p>每个<code>MLPConv</code>后接一个<code>Max</code>池化层，步长为<code>2</code></p>
</li>
<li><p>模型最后是一个<code>GAP</code>和<code>softmax</code>分类器</p>
</li>
<li><p>随机失活操作作用于前<code>2</code>个<code>MLPConv</code>的输出</p>
</li>
</ul>
<p>参考<a href="https://embedai.wordpress.com/2017/07/23/network-in-network-implementation-using-tensorflow/" target="_blank" rel="noopener">Network-in-Network Implementation using TensorFlow</a>的实现细节如下：</p>
<p><img src="/imgs/NIN/model_detail.png" alt></p>
<p><strong>注意 1：上述模型假设输入数据体空间尺寸为$32\times 32$，输出$10$类结果，具体实现根据数据集进行调整</strong></p>
<p><strong>注意 2：经过计算，最大池化层步长为$2$更符合计算</strong></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>不同于<a href="https://zjzstu.github.io/posts/3f18ad9b.html#more" target="_blank" rel="noopener">可视化理解卷积神经网络</a>的思路，<code>NIN</code>专注于提高单层抽象能力，同样实现了模型性能的提升</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>NIN</tag>
      </tags>
  </entry>
  <entry>
    <title>可视化理解卷积神经网络</title>
    <url>/posts/3f18ad9b.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://blog.csdn.net/hjimce/article/details/50544370" target="_blank" rel="noopener">可视化理解卷积神经网络</a></p><p><a href="https://zhuanlan.zhihu.com/p/24833574" target="_blank" rel="noopener">Deep Visualization:可视化并理解CNN</a></p><p>文章<a href="https://arxiv.org/abs/1311.2901" target="_blank" rel="noopener">Visualizing and Understanding Convolutional Networks</a>提出一种可视化方法来观察中间层特征，以此发现不同模型层的性能分布，调整<code>AlexNet</code>参数的得到的<code>ZFNet</code>模型在<code>ImageNet</code>上得到了更好的分类性能；通过预训练<code>ImageNet</code>模型测试发现预训练大数据库能够提高模型的泛化能力</p><a id="more"></a>



<h2 id="可视化技术"><a href="#可视化技术" class="headerlink" title="可视化技术"></a>可视化技术</h2><p>卷积神经网络能够很好的执行分类、识别、检测等功能，但是对于其中原理和变化过程一直没有很好的解释</p>
<p>文章设计一种可视化技术研究中间特征层和分类器的操作，总结不同模型层的特征贡献</p>
<p>主要探究以下两个问题：</p>
<ol>
<li>为什么大型卷积网络模型执行结果如此好？</li>
<li>它们怎么样可以提高？</li>
</ol>
<h3 id="多层反卷积网络"><a href="#多层反卷积网络" class="headerlink" title="多层反卷积网络"></a>多层反卷积网络</h3><p>可视化技术是通过多层反卷积网络（<code>Multi-Layered Deconvolutional Network, deconvnet</code>）实现的，其目的是<strong>反向映射中间特征层激活到原始像素空间</strong>（<code>map these activities back to the input pixel space</code>）</p>
<p>反卷积网络可以看成是一个卷积网络模型，同样拥有卷积、池化、激活等操作，区别在于其执行反向操作，将特征映射回像素，对应关系如下：</p>
<p><img src="/imgs/可视化理解卷积神经网络/deconvnet.PNG" alt></p>
<p>卷积网络模型和对应反卷积网络模型的前3层如上所示，卷积网络的每一层在反卷积网络中都有对应反向操作</p>
<p><strong>反卷积过程</strong>：卷积网络和反卷积网络每层一一对应</p>
<p>第一步：将数据输入到卷积网络，逐层计算特征</p>
<p>第二步：为探究中间特征层激活，选择其中一个激活图，选取其中响应最大的激活值，设置该层其他激活为<code>0</code>，输入特征到绑定的反卷积层</p>
<p>第三步：执行反池化、反激活、反卷积，重构上一层的激活区域</p>
<p>第四步：重复步骤<code>3</code>，直到回到输入像素空间</p>
<p><img src="/imgs/可视化理解卷积神经网络/figure-1.png" alt></p>
<p>完整的反卷积过程相当于反向传播梯度，区别在于：</p>
<ol>
<li>独立执行激活函数</li>
<li>不使用任何反向正则化操作</li>
</ol>
<h4 id="反池化"><a href="#反池化" class="headerlink" title="反池化"></a>反池化</h4><p>反池化（<code>unpool</code>）操作将激活区域反向映射到池化层输入向量的最大值坐标上</p>
<p>在前向最大池化层操作过程中，设置一个变量<code>switch</code>来记录最大值坐标，在反池化（<code>unpool</code>）操作时，将特征重新映射到最大值对应位置</p>
<h4 id="反激活"><a href="#反激活" class="headerlink" title="反激活"></a>反激活</h4><p>反激活操作和激活操作一样，使用对应激活层的激活函数即可，比如<code>relu</code>激活</p>
<h4 id="反卷积"><a href="#反卷积" class="headerlink" title="反卷积"></a>反卷积</h4><p>使用对应卷积层滤波器的转置版本（<code>transposed version</code>），即水平和垂直翻转滤波器</p>
<h2 id="特征分析"><a href="#特征分析" class="headerlink" title="特征分析"></a>特征分析</h2><h3 id="特征可视化"><a href="#特征可视化" class="headerlink" title="特征可视化"></a>特征可视化</h3><p>使用<code>AlexNe</code>t在<code>ImageNet</code>上训练完成后，选取特征图中前<code>9</code>个响应最大的激活点，反向卷积到输入像素空间</p>
<p><img src="/imgs/可视化理解卷积神经网络/figure_2-1.png" alt></p>
<p><img src="/imgs/可视化理解卷积神经网络/figure_2-2.png" alt></p>
<p>从图中可看出卷积网络特征演化过程</p>
<ol>
<li>第<code>2</code>层响应角（<code>corner</code>）和其他边缘/颜色连接（<code>edge/color conjunction</code>）</li>
<li>第<code>3</code>层有更复杂的不变性（<code>complex invariance</code>），能够捕捉相似的纹理</li>
<li>第<code>4</code>层更多显示的是基于类（<code>class-specific</code>）的不变性</li>
<li>第<code>5</code>层显示具有显著姿势变化（<code>pose variation</code>）的整个对象</li>
</ol>
<h3 id="特征演化"><a href="#特征演化" class="headerlink" title="特征演化"></a>特征演化</h3><p>下图演示了各层最强激活点所表示的对应特征在训练过程中的变化</p>
<p><img src="/imgs/可视化理解卷积神经网络/figure-3.png" alt></p>
<p>上图中每一行表示指定激活图中最强特征点在不同迭代次数下（<code>1/2/5/10/20/30/40/64</code>）的变化</p>
<p><strong>从图中可以看出，底层特征在最开始几轮就已经拟合，高层特征需要更多的迭代过程（<em>上图是40-50轮</em>）才开始拟合</strong></p>
<h3 id="特征不变性"><a href="#特征不变性" class="headerlink" title="特征不变性"></a>特征不变性</h3><p>下图采样了<code>5</code>张图像，分别进行不同程度的平移（<code>translated</code>）、旋转（<code>rotated</code>）和缩放（<code>scaled</code>），观察其特征向量的变化</p>
<p><img src="/imgs/可视化理解卷积神经网络/figure-4.png" alt></p>
<p>模型对平移和缩放的不变性最好，也能够很好的支持旋转，除非是旋转对称的对象</p>
<h3 id="敏感度分析"><a href="#敏感度分析" class="headerlink" title="敏感度分析"></a>敏感度分析</h3><p>执行一个遮蔽敏感性（<code>Occlusion Sensitivity</code>）分析，通过遮掩输入图像的部分区域，揭示哪部分场景对于分类而言是重要的</p>
<p>文章图<code>7</code>给出了示例，<em>不过我没看懂，它的示例图像比较乱</em>，总结起来有以下两点：</p>
<ol>
<li>分类结果依赖于图像中的对象而不是图像对象的上下文环境</li>
<li>当原始图像中对应于激活部分被遮掩时，可以看到特征图中明显的活动下降</li>
</ol>
<h3 id="一致性分析"><a href="#一致性分析" class="headerlink" title="一致性分析"></a>一致性分析</h3><p>深度模型（<code>deep model</code>）没有显式建立特定对象部分之间的对应关系（比如脸部中的眼睛、鼻子），文章通过实验测试深度模型是否会隐式建立不同图像特定目标之间的对应关系</p>
<p><img src="/imgs/可视化理解卷积神经网络/figure_6.png" alt></p>
<p>随机选择<code>5</code>张不同的狗脸图像，遮掩住脸部同一区域进行比对（比如都遮掩住右眼）</p>
<p>首先计算原始图像和遮掩后的图像误差</p>
<script type="math/tex; mode=display">
\epsilon_{i}^{(l)} = x_{i}^{(l)} - \tilde{x}_{i}^{(l)}</script><p>$x_{i}^{(l)}$和$\tilde{x}_{i}^{(l)}$分别是原始图像和遮掩图像第第$l$层的特征向量</p>
<p>然后计算不同误差之间的一致性</p>
<script type="math/tex; mode=display">
\triangle_{l} = \sum_{i,j=1,i\neq j}^{5} H(sign(\epsilon_{i}^{(l)}), sign(\epsilon_{j}^{(l)}))</script><p>$H$指<a href="https://baike.baidu.com/item/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB" target="_blank" rel="noopener">汉明距离（Hamming Distance）</a>，更低的值表明更大的一致性</p>
<p>文章共比较了第<code>5</code>层和第<code>7</code>层的特征，遮掩了左眼、右眼、鼻子和随机部分，结果如下</p>
<p><img src="/imgs/可视化理解卷积神经网络/table_1.png" alt></p>
<p>相对于随机遮掩的结果，遮掩指定脸部区域能够得到更小的值，表明模型确实建立了一定程度的对应关系</p>
<h2 id="ZFNet"><a href="#ZFNet" class="headerlink" title="ZFNet"></a>ZFNet</h2><h3 id="AlexNet模型分析"><a href="#AlexNet模型分析" class="headerlink" title="AlexNet模型分析"></a>AlexNet模型分析</h3><p>可视化<code>AlexNet</code>第一和第二卷积层如下</p>
<p><img src="/imgs/可视化理解卷积神经网络/figure-5.png" alt></p>
<p>第一层特征可视化显示滤波器采集的是极度高频和低频（<code>extremely high and low frequency</code>）的图像信息，很少涉及中频（<code>the mid frequencies</code>）信息（图b）</p>
<p>第二层可视化显示了第一层卷积中使用的大步长导致的混淆现象（<code>aliasing artifacts</code>）（图d）</p>
<p>调整第一个卷积层参数</p>
<ol>
<li>滤波器大小：<code>11 -&gt; 7</code></li>
<li>滤波器步长：<code>4 -&gt; 2</code></li>
</ol>
<p>结果如图<code>c/e</code>所示，第一、二层能够得到更多的信息，能够进一步提高检测能力</p>
<h4 id="高频、中频和低频信息"><a href="#高频、中频和低频信息" class="headerlink" title="高频、中频和低频信息"></a>高频、中频和低频信息</h4><p>参考：</p>
<p><a href="https://www.hhyz.me/2018/06/22/2018-06-22-cv2/" target="_blank" rel="noopener">计算机视觉基础 </a></p>
<p><a href="https://stonema.github.io/2018/04/24/%E9%AB%98%E9%A2%91%E4%BF%A1%E5%8F%B7%E4%B8%8E%E4%BD%8E%E9%A2%91%E4%BF%A1%E5%8F%B7-%E5%9B%BE%E5%83%8F%E9%94%90%E5%8C%96%E4%B8%8E%E6%A8%A1%E7%B3%8A/" target="_blank" rel="noopener">高频信号与低频信号,图像锐化与模糊</a></p>
<p><a href="http://blog.sina.com.cn/s/blog_a98e39a201012hpp.html" target="_blank" rel="noopener">图像频率的理解</a></p>
<p>灰度变化慢的是低频信息，是图像颜色渐变区域；灰度变化快的是高频信息，比如图像边缘轮廓和噪声；夹在中间的是中频信息</p>
<p>中频信息确定了图像基本轮廓结构，高频信息强化对轮廓的细节，低频信息补充了轮廓的内容</p>
<h3 id="ZFNet模型"><a href="#ZFNet模型" class="headerlink" title="ZFNet模型"></a>ZFNet模型</h3><p>通过分析<code>AlexNet</code>模型，修改第一二卷积层的模型参数，得到<code>ZFNet</code>模型</p>
<ul>
<li>第一层的滤波器大小修改为7x7</li>
<li>第一和第二个卷积层的步长修改为2</li>
</ul>
<p><img src="/imgs/可视化理解卷积神经网络/ZFNet.png" alt></p>
<h4 id="ZFNet性能分析"><a href="#ZFNet性能分析" class="headerlink" title="ZFNet性能分析"></a>ZFNet性能分析</h4><p>文章使用<code>ImageNet 2011</code>和<code>2012</code>训练集，使用<code>AlexNet</code>和<code>ZFNet</code>模型，比较单个网络和集成多个网络平均结果的性能</p>
<p><img src="/imgs/可视化理解卷积神经网络/training_result.png" alt></p>
<ul>
<li>ZFNet模型比AlexNet模型实现更好的结果（<code>(Krizhevsky et al., 2012), 1 convnet</code> vs <code>1 convnet as per Fig. 3</code>）</li>
<li>集成多个<code>ZFNet</code>模型能够实现更好的结果（<code>6 convnets, (a) &amp; (b) combined</code>）</li>
</ul>
<h2 id="网络大小分析"><a href="#网络大小分析" class="headerlink" title="网络大小分析"></a>网络大小分析</h2><p>文章对<code>AlexNet</code>和<code>ZFNet</code>进行中间层移除和修改实验，<strong>表明模型的整体深度对于获得良好的性能很重要</strong></p>
<p><img src="/imgs/可视化理解卷积神经网络/table_2.png" alt></p>
<ul>
<li>删除<code>AlexNet</code>卷积层或全连接层会提高误差率</li>
<li>增大<code>ZFNet</code>卷积层或全连接层能够减少误差率</li>
</ul>
<h2 id="模型泛化"><a href="#模型泛化" class="headerlink" title="模型泛化"></a>模型泛化</h2><p>文章利用<code>ImageNet</code>训练<code>ZFNet</code>模型，然后保持<code>1-7</code>层模型参数，使用其他数据库重新训练<code>softmax</code>分类器，表明在卷积层中学习到的特性有很好的迁移能力</p>
<h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><ul>
<li><a href="http://image-net.org/index" target="_blank" rel="noopener">ImageNet</a>：超过1百万张图像和超过1000个类</li>
<li><a href="http://www.vision.caltech.edu/Image_Datasets/Caltech101/" target="_blank" rel="noopener">Caltech 101</a>：共有101类，每类40-800张</li>
<li><a href="http://www.vision.caltech.edu/Image_Datasets/Caltech256/" target="_blank" rel="noopener">Caltech 256</a>：共256类，每类80-827张</li>
<li><a href="http://host.robots.ox.ac.uk/pascal/VOC/" target="_blank" rel="noopener">Pascal VOC</a>：多目标图像</li>
</ul>
<h3 id="比较方式"><a href="#比较方式" class="headerlink" title="比较方式"></a>比较方式</h3><p>比较两个方面</p>
<ul>
<li>保证<code>1-7</code>层参数不变，仅重训练<code>softmax</code>分类器和初始化所有层参数，重新训练分类器的比较</li>
<li><code>ZFNet</code>模型和之前最好检测结果比较</li>
</ul>
<h3 id="比较结果"><a href="#比较结果" class="headerlink" title="比较结果"></a>比较结果</h3><p>在<code>Caltech-101</code>和<code>Caltech-256</code>数据库上，使用预训练模型能够达到最好的检测结果，重训练模型实现精度远远不及之前最好检测结果</p>
<p><img src="/imgs/可视化理解卷积神经网络/table_3.png" alt></p>
<p><img src="/imgs/可视化理解卷积神经网络/table_4.png" alt></p>
<ol>
<li><strong>利用<code>ImageNet</code>训练的特征提取器的强大性能</strong></li>
<li><strong>小数据集无法提高深度模型检测能力</strong></li>
</ol>
<p>在<code>PASCAL-2012</code>数据集上进行训练和测试发现，使用预训练模型无法实现理想的效果</p>
<p><strong>理由：<code>PASCAL</code>数据库（多目标）和<code>ImageNet</code>数据库（单目标）的使用场景不一致。在包含多对象的图像中进行检测，基于<code>ImageNet</code>预训练的分类器不适用</strong></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文提出的可视化技术有以下<strong>优点</strong>：</p>
<ol>
<li>能够帮助我们观察到特征在训练过程中的演化以及诊断模型潜在的问题，说明特征是可理解的</li>
<li>通过平移、旋转和缩放实验表明模型在对象变化过程中对平移和旋转有很好的鲁棒性，对缩放也有一定的不变性</li>
<li>通过一系列的遮挡实验证明模型在经过分类训练后，对图像中的局部结构高度敏感，而不是依赖于场景上下文</li>
</ol>
<p><strong>可视化技术缺点</strong>在于仅可视化单个激活，不涉及多层激活图之间的连接</p>
<p>通过可视化技术的应用有以下发现：</p>
<ol>
<li>大滤波器缺少对中频信息（图像基本结构）的采集</li>
<li>大步长会导致特征混淆现象</li>
<li>底层特征在训练过程中易于收敛，高层特征需要更多轮迭代才能完成</li>
<li>特征的演化经历从细节到整体的过程</li>
</ol>
<p>对<code>AlexNet</code>模型的第一二层卷积层减小滤波器大小和步长，得到的<code>ZFNet</code>模型在<code>ImageNet</code>数据集上有更好的性能</p>
<p>通过调整模型大小和层数发现：</p>
<ol>
<li>模型架构深度有助于性能提升</li>
<li>改变全连接层大小对性能影响不大</li>
<li>增加中间隐藏层的大小有助于性能提升</li>
<li>同时扩大隐藏层和全连接层会导致过拟合</li>
<li>多模型集成有助于提高性能</li>
</ol>
<p>通过多数据库训练和测试发现：</p>
<ol>
<li>大数据集有助于提高深度模型检测能力和泛化能力</li>
<li>不同场景数据集复用效果不强</li>
</ol>
<p>通过对以上内容的分析，下面的方向是未来模型性能提高的方向</p>
<ol>
<li>更大的数据库</li>
<li>更深更大的网络模型<br>2.1 更好的模型归一化策略<br>2.2 小的滤波器大小和步长</li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>ZFNet</tag>
      </tags>
  </entry>
  <entry>
    <title>AlexNet-pytorch</title>
    <url>/posts/ba337bfa.html</url>
    <content><![CDATA[<p>使用<code>pytorch</code>实现<code>AlexNet</code>，并进行<code>cifar-10</code>训练和测试</p><h2 id="Sequential"><a href="#Sequential" class="headerlink" title="Sequential"></a>Sequential</h2><p>函数<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential" target="_blank" rel="noopener">torch.nn.Sequential</a>是<code>pytorch</code>提供的顺序容器</p><a id="more"></a>

<blockquote>
<p>CLASS torch.nn.Sequential(*args)</p>
</blockquote>
<p>在构造器中添加的模块会按序执行</p>
<p>有两种添加方式，一种是在构造器中按序输入模块，另一种是使用<code>OrderedDict</code>进行构造</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torch.nn.modules.container import *</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    model = nn.Sequential(</span><br><span class="line">        nn.Conv2d(1, 20, 3),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(20, 64, 5),</span><br><span class="line">        nn.ReLU()</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    model2 = nn.Sequential(</span><br><span class="line">        OrderedDict([</span><br><span class="line">            (&apos;conv1&apos;, nn.Conv2d(1, 20, 3)),</span><br><span class="line">            (&apos;relu1&apos;, nn.ReLU()),</span><br><span class="line">            (&apos;conv2&apos;, nn.Conv2d(20, 64, 5)),</span><br><span class="line">            (&apos;relu2&apos;, nn.ReLU())</span><br><span class="line">        ])</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>打印如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">  (0): Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))</span><br><span class="line">  (1): ReLU()</span><br><span class="line">  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))</span><br><span class="line">  (3): ReLU()</span><br><span class="line">)</span><br><span class="line">Sequential(</span><br><span class="line">  (conv1): Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))</span><br><span class="line">  (relu1): ReLU()</span><br><span class="line">  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))</span><br><span class="line">  (relu2): ReLU()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>可以按下标或键值来获取对应模块</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = model.__getitem__(1)</span><br><span class="line">c = model2.__getattr__(&apos;conv1&apos;)</span><br><span class="line"># 输出</span><br><span class="line">ReLU()</span><br><span class="line">Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))</span><br></pre></td></tr></table></figure>
<h2 id="自适应平均池化层"><a href="#自适应平均池化层" class="headerlink" title="自适应平均池化层"></a>自适应平均池化层</h2><p>自适应平均池化层（<code>adaptive average pool layer</code>）有<code>1-D/2-D/3-D</code>实现</p>
<ul>
<li><a href="https://pytorch.org/docs/stable/nn.html#adaptiveavgpool1d" target="_blank" rel="noopener">AdaptiveAvgPool1d</a></li>
<li><a href="https://pytorch.org/docs/stable/nn.html#adaptiveavgpool2d" target="_blank" rel="noopener">AdaptiveAvgPool2d</a></li>
<li><a href="https://pytorch.org/docs/stable/nn.html#adaptiveavgpool3d" target="_blank" rel="noopener">AdaptiveAvgPool3d</a></li>
</ul>
<p><code>AdaptiveAvgPool</code>对单个输入通道进行操作，不影响数量和通道数，其特点是能够根据输入通道大小和输出通道大小自适应进行平均计算</p>
<p>其具体解释可参考：参考：<a href="https://discuss.pytorch.org/t/what-is-adaptiveavgpool2d/26897" target="_blank" rel="noopener">What is AdaptiveAvgPool2d?</a></p>
<p><em>计算过程还挺复杂，目的还是对邻近像素值取平均值</em></p>
<p>以<code>2-D</code>激活图为例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.arange(0, 25.).reshape(1,1,5,5)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">tensor([[[[ 0.,  1.,  2.,  3.,  4.],</span><br><span class="line">          [ 5.,  6.,  7.,  8.,  9.],</span><br><span class="line">          [10., 11., 12., 13., 14.],</span><br><span class="line">          [15., 16., 17., 18., 19.],</span><br><span class="line">          [20., 21., 22., 23., 24.]]]])</span><br><span class="line">&gt;&gt;&gt; m = nn.AdaptiveAvgPool2d((2,2))</span><br><span class="line">&gt;&gt;&gt; m(a)</span><br><span class="line">tensor([[[[ 6.,  8.],</span><br><span class="line">          [16., 18.]]]])</span><br></pre></td></tr></table></figure>
<h2 id="AlexNet实现"><a href="#AlexNet实现" class="headerlink" title="AlexNet实现"></a>AlexNet实现</h2><p><code>pytorch</code>提供了一个修改后<code>AlexNet</code>实现：<a href="https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py" target="_blank" rel="noopener"> vision/torchvision/models/alexnet.py </a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class AlexNet(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, num_classes=1000):</span><br><span class="line">        super(AlexNet, self).__init__()</span><br><span class="line">        self.features = nn.Sequential(</span><br><span class="line">            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">            nn.Conv2d(64, 192, kernel_size=5, padding=2),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">            nn.Conv2d(192, 384, kernel_size=3, padding=1),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Conv2d(384, 256, kernel_size=3, padding=1),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Conv2d(256, 256, kernel_size=3, padding=1),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">        )</span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(256 * 6 * 6, 4096),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(4096, 4096),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Linear(4096, num_classes),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        x = x.view(x.size(0), 256 * 6 * 6)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure>
<p>原始<code>AlexNet</code>实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class AlexNet(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, num_classes=1000):</span><br><span class="line">        super(AlexNet_Origin, self).__init__()</span><br><span class="line">        self.features = nn.Sequential(</span><br><span class="line">            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">        )</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(256 * 6 * 6, 4096),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(4096, 4096),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Linear(4096, num_classes),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = x.view(x.size(0), 256 * 6 * 6)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure>
<p><strong>相比于原实现，修改后的<code>AlexNet</code>网络减少了第一层滤波器个数（<code>96-&gt;64</code>）和第四个滤波器个数（<code>384-&gt;256</code>），在最后一个卷积层和第一个全连接进行了随机失活操作</strong></p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>操作<code>AlexNet</code>模型以及<code>Pytorch</code>实现，调整参数，训练如下<code>4</code>个网络</p>
<ol>
<li><code>AlexNet</code>(无失活)</li>
<li><code>AlexNet</code></li>
<li><code>AlexNet</code>(最后一个卷积层+全连接层随机失活)</li>
<li><code>pytorch_AlexNet</code></li>
</ol>
<p>训练参数如下：</p>
<ul>
<li>批量大小<code>batch_size=256</code></li>
<li>迭代次数<code>epochs=300</code></li>
<li>学习率<code>lr=1e-2</code></li>
<li>动量<code>momentum=0.9 + Nesterov</code>加速</li>
</ul>
<p>完整代码:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-6-8 下午1:57</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">import torchvision.datasets as datasets</span><br><span class="line"></span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"># 批量大小</span><br><span class="line">batch_size = 256</span><br><span class="line"># 迭代次数</span><br><span class="line">epochs = 300</span><br><span class="line"></span><br><span class="line"># 学习率</span><br><span class="line">lr = 1e-2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class AlexNet(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, num_classes=1000):</span><br><span class="line">        super(AlexNet, self).__init__()</span><br><span class="line">        self.features = nn.Sequential(</span><br><span class="line">            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">        )</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(256 * 6 * 6, 4096),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line"></span><br><span class="line">            nn.Linear(4096, 4096),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line"></span><br><span class="line">            nn.Linear(4096, num_classes),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = x.view(x.size(0), 256 * 6 * 6)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class AlexNet_v2(nn.Module):</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_cifar_10_data(batch_size=128, shuffle=False):</span><br><span class="line">    data_dir = &apos;/home/lab305/Documents/data/cifar_10/&apos;</span><br><span class="line">    # data_dir = &apos;/home/zj/zj/data/cifar_10/&apos;</span><br><span class="line"></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Resize((227, 227)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    train_data_set = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)</span><br><span class="line">    test_data_set = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)</span><br><span class="line"></span><br><span class="line">    train_loader = DataLoader(train_data_set, batch_size=batch_size, shuffle=shuffle, num_workers=8)</span><br><span class="line">    test_loader = DataLoader(test_data_set, batch_size=batch_size, shuffle=shuffle, num_workers=8)</span><br><span class="line"></span><br><span class="line">    return train_loader, test_loader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(loader, net, device):</span><br><span class="line">    total_accuracy = 0</span><br><span class="line">    num = 0</span><br><span class="line">    for item in loader:</span><br><span class="line">        data, labels = item</span><br><span class="line">        data = data.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        scores = net.forward(data)</span><br><span class="line">        predicted = torch.argmax(scores, dim=1)</span><br><span class="line">        total_accuracy += torch.mean((predicted == labels).float()).item()</span><br><span class="line">        num += 1</span><br><span class="line">    return total_accuracy / num</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    train_loader, test_loader = load_cifar_10_data(batch_size=batch_size, shuffle=True)</span><br><span class="line"></span><br><span class="line">    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">    # device = torch.device(&quot;cpu&quot;)</span><br><span class="line"></span><br><span class="line">    # net = AlexNet(num_classes=10).to(device)</span><br><span class="line">    net = AlexNet_v2(num_classes=10).to(device)</span><br><span class="line">    criterion = nn.CrossEntropyLoss().to(device)</span><br><span class="line">    optimer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, nesterov=True)</span><br><span class="line"></span><br><span class="line">    best_train_accuracy = 0.995</span><br><span class="line">    best_test_accuracy = 0</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    train_list = []</span><br><span class="line">    for i in range(epochs):</span><br><span class="line">        num = 0</span><br><span class="line">        total_loss = 0</span><br><span class="line">        start = time.time()</span><br><span class="line">        net.train()</span><br><span class="line">        for j, item in enumerate(train_loader, 0):</span><br><span class="line">            data, labels = item</span><br><span class="line">            data = data.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">            scores = net.forward(data)</span><br><span class="line">            loss = criterion.forward(scores, labels)</span><br><span class="line">            total_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            optimer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimer.step()</span><br><span class="line">            num += 1</span><br><span class="line">        end = time.time()</span><br><span class="line"></span><br><span class="line">        avg_loss = total_loss / num</span><br><span class="line">        loss_list.append(float(&apos;%.8f&apos; % avg_loss))</span><br><span class="line">        print(&apos;epoch: %d time: %.2f loss: %.8f&apos; % (i + 1, end - start, avg_loss))</span><br><span class="line"></span><br><span class="line">        if i % 20 == 19:</span><br><span class="line">            # 计算训练数据集检测精度</span><br><span class="line">            net.eval()</span><br><span class="line">            train_accuracy = compute_accuracy(train_loader, net, device)</span><br><span class="line">            train_list.append(float(&apos;%.4f&apos; % train_accuracy))</span><br><span class="line">            if best_train_accuracy &lt; train_accuracy:</span><br><span class="line">                best_train_accuracy = train_accuracy</span><br><span class="line"></span><br><span class="line">                test_accuracy = compute_accuracy(test_loader, net, device)</span><br><span class="line">                if best_test_accuracy &lt; test_accuracy:</span><br><span class="line">                    best_test_accuracy = test_accuracy</span><br><span class="line"></span><br><span class="line">            print(&apos;best train accuracy: %.2f %%   best test accuracy: %.2f %%&apos; % (</span><br><span class="line">                best_train_accuracy * 100, best_test_accuracy * 100))</span><br><span class="line">            print(loss_list)</span><br><span class="line">            print(train_list)</span><br></pre></td></tr></table></figure>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p><code>300</code>次训练完成后测试结果如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">训练精度</th>
<th style="text-align:center">测试精度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">AlexNet(无失活)</td>
<td style="text-align:center">100.00 %</td>
<td style="text-align:center">80.24 %</td>
</tr>
<tr>
<td style="text-align:center">AlexNet</td>
<td style="text-align:center">100.00 %</td>
<td style="text-align:center">84.48 %</td>
</tr>
<tr>
<td style="text-align:center">AlexNet (最后一个卷积层+全连接层随机失活)</td>
<td style="text-align:center">100.00 %</td>
<td style="text-align:center">87.00 %</td>
</tr>
<tr>
<td style="text-align:center">pytorch_AlexNet</td>
<td style="text-align:center">100.00 %</td>
<td style="text-align:center">86.76 %</td>
</tr>
</tbody>
</table>
</div>
<p>损失值和训练集精度如下：</p>
<p><img src="../imgs/Alexnet-pytorch/alexnet_loss.png" alt></p>
<p><img src="../imgs/Alexnet-pytorch/alexnet_accuracy.png" alt></p>
<p>从测试结果看到，<code>pytorch</code>提供的<code>AlexNet</code>模型能够提高泛化能力，同时自定义的<code>AlexNet</code>模型（最后一个卷积层+全连接层随机失活）能够实现最好的测试精度</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>AlexNet</tag>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>torchvision</tag>
      </tags>
  </entry>
  <entry>
    <title>AlexNet</title>
    <url>/posts/ca9994d1.html</url>
    <content><![CDATA[<p>参考：<a href="https://www.learnopencv.com/understanding-alexnet/" target="_blank" rel="noopener">Understanding AlexNet</a></p><p><code>AlexNet</code>在<code>ImageNet LSVRC-2010</code>的<code>1000</code>类分类比赛上实现了<code>37.5% top-1</code>和<code>17.0% top-5</code>的最小误差率，在<code>LSVRC-2012</code>上实现了<code>15.3% top-5</code>的最小误差率，这些数据是当时最好的识别结果，其实现代码也在<code>google code</code>上公开：<a href="https://code.google.com/archive/p/cuda-convnet/" target="_blank" rel="noopener">cuda-convnet</a></p><a id="more"></a>

<p>本文学习<code>AlexNet</code>网络结构及其训练方法</p>
<h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p><code>AlexNet</code>除了减去均值以外，没有执行任何预处理操作 </p>
<h2 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h2><p>首先介绍最初的双<code>GPU AlexNet</code>架构，再介绍单<code>GPU</code>的<code>AlexNet</code>架构</p>
<h3 id="双GPU-AlexNet"><a href="#双GPU-AlexNet" class="headerlink" title="双GPU AlexNet"></a>双GPU AlexNet</h3><p>在文章<a href="http://xueshu.baidu.com/usercenter/paper/show?paperid=bfdf67dfdf8cea0c47038f63e91b9df1&amp;site=xueshu_se" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a>中，<code>AlexNet</code>使用双<code>GPU</code>进行训练，其结构如下所示：</p>
<p><img src="/imgs/AlexNet/AlexNet.png" alt></p>
<p><code>AlexNet</code>包含<code>8</code>个可学习层：<code>5</code>个卷积层 + <code>3</code>个全连接层组成</p>
<ul>
<li>第二/四/五个卷积层的核仅与同一GPU的前一层进行连接</li>
<li>第三个卷积层的核与第二层全部连接</li>
<li>全连接层的核与前一层全部连接</li>
<li>局部归一化层跟随在第一二个卷积层后</li>
<li>重叠池化层跟随在局部归一化层后以及第<code>5</code>个卷积层后</li>
<li>第三、第四和第五个卷积层直接连接</li>
<li>卷积层和全连接层都使用<code>ReLU</code>作为激活函数</li>
</ul>
<h3 id="单GPU-AlexNet"><a href="#单GPU-AlexNet" class="headerlink" title="单GPU AlexNet"></a>单GPU AlexNet</h3><p><strong>单<code>GPU</code>训练的<code>AlexNet</code>模型如下（<em>已去除LRN</em>）：</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">输入大小</th>
<th style="text-align:center">滤波器大小</th>
<th style="text-align:center">步长</th>
<th style="text-align:center">零填充</th>
<th style="text-align:center">滤波器个数</th>
<th style="text-align:center">输出大小</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">CONV1</td>
<td style="text-align:center">227x227x3</td>
<td style="text-align:center">11x11x3</td>
<td style="text-align:center">4</td>
<td style="text-align:center">0</td>
<td style="text-align:center">96</td>
<td style="text-align:center">55x55x96</td>
</tr>
<tr>
<td style="text-align:center">POOL2</td>
<td style="text-align:center">55x55x96</td>
<td style="text-align:center">3x3</td>
<td style="text-align:center">2</td>
<td style="text-align:center">/</td>
<td style="text-align:center">96</td>
<td style="text-align:center">27x27x96</td>
</tr>
<tr>
<td style="text-align:center">CONV3</td>
<td style="text-align:center">27x27x96</td>
<td style="text-align:center">5x5x96</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
<td style="text-align:center">256</td>
<td style="text-align:center">27x27x256</td>
</tr>
<tr>
<td style="text-align:center">POOL4</td>
<td style="text-align:center">27x27x256</td>
<td style="text-align:center">3x3</td>
<td style="text-align:center">2</td>
<td style="text-align:center">/</td>
<td style="text-align:center">256</td>
<td style="text-align:center">13x13x256</td>
</tr>
<tr>
<td style="text-align:center">CONV5</td>
<td style="text-align:center">13x13x256</td>
<td style="text-align:center">3x3x256</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">384</td>
<td style="text-align:center">13x13x384</td>
</tr>
<tr>
<td style="text-align:center">CONV6</td>
<td style="text-align:center">13x13x384</td>
<td style="text-align:center">3x3x384</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">384</td>
<td style="text-align:center">13x13x384</td>
</tr>
<tr>
<td style="text-align:center">CONV7</td>
<td style="text-align:center">13x13x384</td>
<td style="text-align:center">3x3x384</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">256</td>
<td style="text-align:center">13x13x256</td>
</tr>
<tr>
<td style="text-align:center">POOL8</td>
<td style="text-align:center">13x13x256</td>
<td style="text-align:center">3x3</td>
<td style="text-align:center">2</td>
<td style="text-align:center">/</td>
<td style="text-align:center">256</td>
<td style="text-align:center">6x6x256</td>
</tr>
<tr>
<td style="text-align:center">FC9</td>
<td style="text-align:center">1x1x9216</td>
<td style="text-align:center">1x1</td>
<td style="text-align:center">/</td>
<td style="text-align:center">/</td>
<td style="text-align:center">4096</td>
<td style="text-align:center">1x1x4096</td>
</tr>
<tr>
<td style="text-align:center">FC10</td>
<td style="text-align:center">1x1x4096</td>
<td style="text-align:center">1x1</td>
<td style="text-align:center">/</td>
<td style="text-align:center">/</td>
<td style="text-align:center">4096</td>
<td style="text-align:center">1x1x4096</td>
</tr>
<tr>
<td style="text-align:center">FC11</td>
<td style="text-align:center">1x1x4096</td>
<td style="text-align:center">1x1</td>
<td style="text-align:center">/</td>
<td style="text-align:center">/</td>
<td style="text-align:center">1000</td>
<td style="text-align:center">1x1x1000</td>
</tr>
</tbody>
</table>
</div>
<h3 id="224还是227"><a href="#224还是227" class="headerlink" title="224还是227"></a><code>224</code>还是<code>227</code></h3><p>在原文中作者输入图像大小为<code>224x224</code>，不过经过推算不符合网络计算，应该使用<code>227x227</code>作为输入图像大小</p>
<h3 id="神经元和参数个数"><a href="#神经元和参数个数" class="headerlink" title="神经元和参数个数"></a>神经元和参数个数</h3><p>参考：</p>
<p><a href="https://vimsky.com/article/3664.html" target="_blank" rel="noopener">AlexNet中的参数数量</a></p>
<p><a href="https://stackoverflow.com/questions/40060949/how-to-calculate-the-number-of-parameters-of-alexnet" target="_blank" rel="noopener">How to calculate the number of parameters of AlexNet?</a></p>
<p>整个网络约有<code>6</code>千万个参数和<code>65</code>万个神经元，计算如下：</p>
<ul>
<li><p>输入层大小<code>227x227x3</code>，输入维数是<code>15,4587</code></p>
</li>
<li><p>第一层卷积层卷积核大小为<code>11x11x3</code>，步长<code>4</code>，滤波器个数<code>96</code>，所以参数个数是<code>(11x11x3)x96+96=3,4944</code>，输出大小为<code>55x55x96=29,0400</code></p>
<ul>
<li>池化层滤波器大小为<code>3x3</code>，步长<code>2</code>，所以输出大小为<code>27x27x96</code></li>
</ul>
</li>
<li><p>第二层卷积层卷积核大小为<code>5x5x96</code>，零填充<code>2</code>，滤波器个数<code>256</code>，所以参数个数是<code>(5x5x96)x256+256=61,4656</code>，输出大小为<code>27x27x256=18,6624</code></p>
<ul>
<li>池化层滤波器大小为<code>3x3</code>，步长<code>2</code>，所以输出大小为<code>13x13x256</code></li>
</ul>
</li>
<li><p>第三层卷积层卷积核大小为<code>3x3x256</code>，零填充<code>1</code>，滤波器个数是<code>384</code>个，所以参数个数是<code>(3x3x256)x384+384=88,5120</code>，输出大小为<code>13x13x384=6,4896</code></p>
</li>
<li><p>第四层卷积层卷积核大小为<code>3x3x384</code>，零填充<code>1</code>，滤波器个数是<code>384</code>个，所以参数个数是<code>(3x3x384)x384+384=132,7488</code>，输出大小为<code>13x13x384=6,4896</code></p>
</li>
<li><p>第五层卷积层卷积核大小为<code>3x3x384</code>，零填充<code>1</code>，滤波器个数是<code>256</code>，所以参数个数是<code>(3x3x384)x256+256=88,4992</code>，输出大小为<code>13x13x256=4,3264</code></p>
<ul>
<li>池化层滤波器大小为<code>3x3</code>，步长<code>2</code>，所以输出大小为<code>6x6x256</code></li>
</ul>
</li>
<li><p>第一层全连接层大小为<code>4096</code>，所以参数个数是<code>(6x6x256)x4096+4096=3775,2832</code>，输出大小为<code>4096</code></p>
</li>
<li><p>第二层全连接层大小为<code>4096</code>，所以参数个数是<code>4096x4096+4096=1678,1312</code>，输出大小为<code>4096</code></p>
</li>
<li><p>输出层大小为<code>1000</code>，所以参数个数是<code>4096x1000+1000=409,7000</code></p>
</li>
</ul>
<p>神经元总个数是<code>15,4587+29,0400+18,6624+6,4896+6,4896+4,3264+4096+4096+1000=81,3859</code>（<em>不包括输入层就是<code>65,9272</code></em>）</p>
<p>参数总个数是<code>3,4944+61,4656+88,5120+132,7488+88,4992+3775,2832+1678,1312+409,7000=6237,8344</code></p>
<h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><p>主要有<code>4</code>点：</p>
<ol>
<li>使用<code>ReLU</code>作为激活函数提高训练速度</li>
<li>多<code>GPU</code>训练</li>
<li>使用局部响应归一化(<code>LRN</code>)方法增加泛化能力</li>
<li>使用重叠池化层（<code>Overlapping Pool</code>）提高泛化能力</li>
</ol>
<h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p>之前标准的激活函数是<code>tanh()</code>和<code>sigmoid()</code>函数，文章中使用<code>ReLU(Rectified Linear Units，修正线性单元)</code>作为神经元激活函数</p>
<p>使用4层卷积神经网络训练<code>CIFAR-10</code>数据集，比较达到<code>25%</code>训练误差率的时间，使用<code>ReLU</code>能够比<code>tanh</code>快<code>6</code>倍</p>
<p><img src="/imgs/AlexNet/relu.png" alt></p>
<h3 id="多GPU训练"><a href="#多GPU训练" class="headerlink" title="多GPU训练"></a>多GPU训练</h3><p><code>AlexNet</code>使用两块<code>GTX 580 GPU</code>，在深度上进行切分，将每层一半神经元分别放置在不同<code>GPU</code>上进行训练</p>
<h3 id="局部响应归一化"><a href="#局部响应归一化" class="headerlink" title="局部响应归一化"></a>局部响应归一化</h3><p>参考：<a href="https://cloud.tencent.com/developer/article/1347792" target="_blank" rel="noopener">深度学习: 局部响应归一化 (Local Response Normalization，LRN)</a></p>
<p>数学实现如下：</p>
<p><img src="/imgs/AlexNet/lrn.png" alt></p>
<p>经过<code>ReLU</code>激活后的卷积图，第i层上的位置为<code>(x,y)</code>的神经元值<code>a</code>，需要除以其相邻<code>n</code>个层相同位置的神经元值之和。常量k，n，$\alpha$，$\beta$都是超参数，需要通过验证集设定，当前设定为$k=2，n=5，\alpha=10^{-4}，beta=0.75$</p>
<p>其目的是<strong>实现神经元的侧抑制</strong>（<code>lateral inhibition</code>），在不同层之间进行竞争，使响应值大的神经元变得更大，并抑制其他较小的神经元</p>
<p><code>LRN（Local Response Normalization，局部响应归一化）</code>能够提高泛化能力：在<code>ImageNet 1000</code>类分类任务中，<code>LRN</code>减少了<code>1.4% top-1</code>和<code>1.2% top5</code>的错误率；在<code>cifar-10</code>数据集测试中，一个<code>4</code>层神经网络能达到<code>13%</code>测试误差率（没有<code>LRN</code>）和<code>11%</code>测试误差率（有<code>LRN</code>）</p>
<p><strong><em>在之后其他网络的测试中发现<code>LRN</code>对训练结果提高几乎没有影响，所以不再使用</em></strong></p>
<h3 id="重叠池化层"><a href="#重叠池化层" class="headerlink" title="重叠池化层"></a>重叠池化层</h3><p>传统的池化层步长和滤波器大小相同（<code>s=z=2</code>），所以滤波器操作不会重叠</p>
<p><code>alexnet</code>使用重叠池化（<code>Overlapping Pool</code>）操作，步长小于滤波器大小（<code>s=2,x=3,s&lt;z</code>），这在<code>1000</code>类分类任务上能够实现<code>0.4% top-1</code>和<code>0.3% top-5</code>的提高。在训练过程中能够发现重叠池化模型更难以过拟合</p>
<h2 id="避免过拟合手段"><a href="#避免过拟合手段" class="headerlink" title="避免过拟合手段"></a>避免过拟合手段</h2><ol>
<li>数据扩充（<code>data augmentation</code>）</li>
<li>随机失活（<code>dropout</code>）</li>
</ol>
<h3 id="数据扩充"><a href="#数据扩充" class="headerlink" title="数据扩充"></a>数据扩充</h3><p>文章中提到了两种方式</p>
<p>第一种方式是生成图像转换和水平映射。在训练阶段，获取<code>256x256</code>大小的数据集，再从中随机获取<code>227x227</code>大小的训练图像，同时通过水平映像(<code>horizontal reflection</code>)操作来扩大数据集；在测试阶段，使用同样方式裁剪5个$227\times 227$大小图像，并进行水平翻转，平均这10个图像预测结果作为输出</p>
<p>第二种方式是改变训练数据的通道强度，对于每个<code>RGB</code>图像像素$I_{xy}=[I_{xy}^{B},I_{xy}^{G},I_{xy}^{B}]^{T}$，添加如下值：</p>
<p><img src="/imgs/AlexNet/pca.png" alt></p>
<p>其中$p_{i}$是第i个特征向量（<code>eigenvector</code>），$\lambda_{i}$是RGB像素值3x3协方差矩阵（<code>covariance matrix</code>）的特征值，$\alpha_{i}$是符合零均值(<code>mean zero</code>)和<code>0.1</code>标准方差(<code>standard deviation</code>)的服从高斯分布的随机变量，特定训练图像上的每个像素使用的$\alpha_{i}$都不相同，再次训练时需要重新设置$\alpha_{i}$</p>
<p>使用<code>PCA</code>改变图像强度的理论基础是自然图像的一个重要特性：物体同一性不随照明强度和颜色的变化而变化</p>
<p>这种方法减少了至少<code>1% top-1</code>误差率</p>
<h3 id="随机失活"><a href="#随机失活" class="headerlink" title="随机失活"></a>随机失活</h3><p>集合不同网络模型进行预测能够很好的减少测试误差，但是对于大网络而言需要耗费很多时间进行训练。随机失活（<code>dropout</code>）操作对中间隐含层进行操作，以<code>0.5</code>的概率判断该神经元是否失效，即这个神经元不进行前向操作，也不进行反向更新</p>
<p>有两点优势：</p>
<ol>
<li>每次进行训练都是在不同的网络架构上，与此同时这些不同的网络架构共享同一套权重</li>
<li>减少神经元复杂的共适应性（<code>co-adaptation</code>），神经元不能依赖于某个特定的神经元</li>
</ol>
<p>在测试阶段，对所有神经元的输出都乘以<code>0.5</code>，以获取指数多个<code>dropout</code>网络产生的预测分布的几何平均值</p>
<p><strong>在<code>alexnet</code>模型中，对前两个全连接层进行<code>dropout</code>操作</strong>。如果没有<code>dropout</code>，整个网络会严重过拟合，并且训练过程达到收敛的时间大致增加了一倍</p>
<h2 id="学习细节"><a href="#学习细节" class="headerlink" title="学习细节"></a>学习细节</h2><p>批量大小为<code>128</code>，使用动量值为<code>0.9</code>，权重衰减率为<code>5e-4</code>，权重更新公式如下：</p>
<script type="math/tex; mode=display">
v_{i+1} = 0.9\cdot v_{i} - 0.0005\cdot lr\cdot w_{i} - lr \triangledown w_{i}\\
w_{i+1} = w_{i} + v_{i+1}</script><p>权重初始化为<code>0</code>均值，<code>0.01</code>标准差的高斯分布</p>
<p>第二、第四、第五个卷积层层和全连接层的偏置值初始化为$1$，其他层的偏置值初始化为$0$</p>
<p>学习率初始化为<code>0.01</code>，在终止之前共减少了<code>3</code>次</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>AlexNet</tag>
      </tags>
  </entry>
  <entry>
    <title>随机失活-pytorch</title>
    <url>/posts/2bee4fce.html</url>
    <content><![CDATA[<p><code>pytorch</code>提供了多种失活函数实现</p><ol>
<li><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout" target="_blank" rel="noopener">torch.nn.Dropout</a></li>
<li><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout2d" target="_blank" rel="noopener">torch.nn.Dropout2d</a></li>
<li><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout3d" target="_blank" rel="noopener">torch.nn.Dropout3d</a></li>
<li><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.AlphaDropout" target="_blank" rel="noopener">torch.nn.AlphaDropout</a></li>
</ol><a id="more"></a>

<p>下面首先介绍<code>Dropout</code>和<code>Dropout2d</code>的使用，然后通过<code>LeNet-5</code>模型进行<code>cifar-10</code>的训练</p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>对每个神经元进行随机失活</p>
<blockquote>
<p>CLASS torch.nn.Dropout(p=0.5, inplace=False)</p>
</blockquote>
<p>默认失活概率为$p=0.5$</p>
<p>输入数组可以是任意大小，输出数组大小和输出数组一致</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; dropout = nn.Dropout()</span><br><span class="line">&gt;&gt;&gt; inputs = torch.randn(2,4)</span><br><span class="line">&gt;&gt;&gt; dropout(inputs)</span><br><span class="line">tensor([[ 3.5830,  5.0388, -0.0000,  0.0000],</span><br><span class="line">        [ 2.4098, -2.1856, -0.7015,  2.0616]])</span><br><span class="line">&gt;&gt;&gt; dropout(inputs)</span><br><span class="line">tensor([[ 3.5830,  5.0388, -0.0000,  0.0000],</span><br><span class="line">        [ 0.0000, -2.1856, -0.0000,  0.0000]])</span><br><span class="line">&gt;&gt;&gt; dropout(inputs)</span><br><span class="line">tensor([[0.0000, 0.0000, -0.0000, 1.7565],</span><br><span class="line">        [0.0000, -0.0000, -0.0000, 2.0616]])</span><br></pre></td></tr></table></figure>
<p><strong>注意：参数$p$表示失活概率，$p=1$表示全部置为$0$，$p=0$表示不执行失活操作</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; dropout = nn.Dropout(p=0)</span><br><span class="line">&gt;&gt;&gt; inputs = torch.randn(2,4)</span><br><span class="line">&gt;&gt;&gt; dropout(inputs)</span><br><span class="line">tensor([[ 1.2098,  0.3409,  1.4093,  0.6397],</span><br><span class="line">        [ 1.2380, -0.8287,  0.6893,  0.9666]])</span><br><span class="line">&gt;&gt;&gt; dropout(inputs)</span><br><span class="line">tensor([[ 1.2098,  0.3409,  1.4093,  0.6397],</span><br><span class="line">        [ 1.2380, -0.8287,  0.6893,  0.9666]])</span><br><span class="line">&gt;&gt;&gt; dropout = nn.Dropout(p=1)</span><br><span class="line">&gt;&gt;&gt; dropout(inputs)</span><br><span class="line">tensor([[0., 0., 0., 0.],</span><br><span class="line">        [0., -0., 0., 0.]])</span><br><span class="line">&gt;&gt;&gt; dropout(inputs)</span><br><span class="line">tensor([[0., 0., 0., 0.],</span><br><span class="line">        [0., -0., 0., 0.]])</span><br></pre></td></tr></table></figure>
<h2 id="Dropout2d"><a href="#Dropout2d" class="headerlink" title="Dropout2d"></a>Dropout2d</h2><p>对每个通道（一个通道表示一个激活图）进行随机失活</p>
<blockquote>
<p>CLASS torch.nn.Dropout2d(p=0.5, inplace=False)</p>
</blockquote>
<p>默认失活概率为$p=0.5$</p>
<p>输入数组大小至少为<code>2</code>维，默认为$[N, C, H, W]$，输出数组大小和输出数组一致</p>
<blockquote>
<p>RuntimeError: Feature dropout requires at least 2 dimensions in the input</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; dropout = nn.Dropout2d()</span><br><span class="line">&gt;&gt;&gt; inputs = torch.randn(2,3,2,2)</span><br><span class="line">&gt;&gt;&gt; dropout(inputs)</span><br><span class="line">tensor([[[[ 2.0601,  0.0035],</span><br><span class="line">          [-0.7429,  1.2160]],</span><br><span class="line"></span><br><span class="line">         [[-0.0000,  0.0000],</span><br><span class="line">          [-0.0000,  0.0000]],</span><br><span class="line"></span><br><span class="line">         [[-1.3138, -1.9364],</span><br><span class="line">          [-1.1147,  0.6847]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ 0.0000, -0.0000],</span><br><span class="line">          [-0.0000, -0.0000]],</span><br><span class="line"></span><br><span class="line">         [[-0.0000, -0.0000],</span><br><span class="line">          [-0.0000, -0.0000]],</span><br><span class="line"></span><br><span class="line">         [[-0.0000,  0.0000],</span><br><span class="line">          [-0.0000,  0.0000]]]])</span><br></pre></td></tr></table></figure>
<p><strong>注意：参数$p$表示失活概率，$p=1$表示全部置为$0$，$p=0$表示不执行失活操作</strong></p>
<h2 id="训练-测试阶段实现"><a href="#训练-测试阶段实现" class="headerlink" title="训练/测试阶段实现"></a>训练/测试阶段实现</h2><p><code>Pytorch</code>实现采用<strong>反向失活</strong>方式，在训练阶段，除了进行随机失活操作外，还将结果乘以缩放因子$\frac {1}{1-p}$，这样在测试阶段直接计算全部神经元即可</p>
<p>所以需要区分训练阶段和测试阶段，有两种方式</p>
<ol>
<li>设置标志位</li>
<li>添加测试函数</li>
</ol>
<h3 id="设置标志位"><a href="#设置标志位" class="headerlink" title="设置标志位"></a>设置标志位</h3><p>参考：</p>
<p><a href="https://discuss.pytorch.org/t/model-train-and-model-eval-vs-model-and-model-eval/5744" target="_blank" rel="noopener">Model.train() and model.eval() vs model and model.eval()</a></p>
<p><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.eval" target="_blank" rel="noopener">torch.nn.Module.eval</a></p>
<p><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.train" target="_blank" rel="noopener">torch.nn.Module.train</a></p>
<p><code>Pytorch</code>采用设置标志位的方式判断训练和测试阶段</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def train(self, mode=True):</span><br><span class="line">        self.training = mode</span><br><span class="line">        for module in self.children():</span><br><span class="line">                module.train(mode)</span><br><span class="line">        return self</span><br><span class="line">def eval(self):</span><br><span class="line">        return self.train(False)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">net.train()  # 训练模式</span><br><span class="line">net.eval()  # 测试模式</span><br></pre></td></tr></table></figure>
<h3 id="添加测试函数"><a href="#添加测试函数" class="headerlink" title="添加测试函数"></a>添加测试函数</h3><p>另一种方式是重写测试函数，将训练和测试实现分开即可</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def forward(self, inputs): # 训练实现</span><br><span class="line">        a1 = F.relu(self.conv1(inputs))</span><br><span class="line">        a1 = self.dropout2d(a1)</span><br><span class="line">        z2 = self.pool(a1)</span><br><span class="line"></span><br><span class="line">        a3 = F.relu(self.conv2(z2))</span><br><span class="line">        a3 = self.dropout2d(a3)</span><br><span class="line">        z4 = self.pool(a3)</span><br><span class="line"></span><br><span class="line">        a5 = F.relu(self.conv3(z4))</span><br><span class="line">        a5 = self.dropout2d(a5)</span><br><span class="line"></span><br><span class="line">        x = a5.view(-1, self.num_flat_features(a5))</span><br><span class="line"></span><br><span class="line">        a6 = F.relu(self.fc1(x))</span><br><span class="line">        a6 = self.dropout(a6)</span><br><span class="line">        return self.fc2(a6)</span><br><span class="line"></span><br><span class="line">def predict(self, inputs): # 测试实现</span><br><span class="line">        a1 = F.relu(self.conv1(inputs))</span><br><span class="line">        z2 = self.pool(a1)</span><br><span class="line"></span><br><span class="line">        a3 = F.relu(self.conv2(z2))</span><br><span class="line">        z4 = self.pool(a3)</span><br><span class="line"></span><br><span class="line">        a5 = F.relu(self.conv3(z4))</span><br><span class="line"></span><br><span class="line">        x = a5.view(-1, self.num_flat_features(a5))</span><br><span class="line"></span><br><span class="line">        a6 = F.relu(self.fc1(x))</span><br><span class="line">        return self.fc2(a6)</span><br></pre></td></tr></table></figure>
<h2 id="LeNet-5测试"><a href="#LeNet-5测试" class="headerlink" title="LeNet-5测试"></a>LeNet-5测试</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class LeNet5(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, in_channels, p=0.0):</span><br><span class="line">        super(LeNet5, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5, stride=1, padding=0, bias=True)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)</span><br><span class="line">        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1, padding=0, bias=True)</span><br><span class="line"></span><br><span class="line">        self.pool = nn.MaxPool2d((2, 2), stride=2)</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(in_features=120, out_features=84, bias=True)</span><br><span class="line">        self.fc2 = nn.Linear(84, 10, bias=True)</span><br><span class="line"></span><br><span class="line">        self.p = p</span><br><span class="line">        self.dropout2d = nn.Dropout2d(p=p)</span><br><span class="line">        self.dropout = nn.Dropout(p=p)</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        a1 = F.relu(self.conv1(inputs))</span><br><span class="line">        a1 = self.dropout2d(a1)</span><br><span class="line">        z2 = self.pool(a1)</span><br><span class="line"></span><br><span class="line">        a3 = F.relu(self.conv2(z2))</span><br><span class="line">        a3 = self.dropout2d(a3)</span><br><span class="line">        z4 = self.pool(a3)</span><br><span class="line"></span><br><span class="line">        a5 = F.relu(self.conv3(z4))</span><br><span class="line">        a5 = self.dropout2d(a5)</span><br><span class="line"></span><br><span class="line">        x = a5.view(-1, self.num_flat_features(a5))</span><br><span class="line"></span><br><span class="line">        a6 = F.relu(self.fc1(x))</span><br><span class="line">        a6 = self.dropout(a6)</span><br><span class="line">        return self.fc2(a6)</span><br><span class="line"></span><br><span class="line">    def predict(self, inputs):</span><br><span class="line">        a1 = F.relu(self.conv1(inputs))</span><br><span class="line">        z2 = self.pool(a1)</span><br><span class="line"></span><br><span class="line">        a3 = F.relu(self.conv2(z2))</span><br><span class="line">        z4 = self.pool(a3)</span><br><span class="line"></span><br><span class="line">        a5 = F.relu(self.conv3(z4))</span><br><span class="line"></span><br><span class="line">        x = a5.view(-1, self.num_flat_features(a5))</span><br><span class="line"></span><br><span class="line">        a6 = F.relu(self.fc1(x))</span><br><span class="line">        return self.fc2(a6)</span><br><span class="line"></span><br><span class="line">    def num_flat_features(self, x):</span><br><span class="line">        size = x.size()[1:]  # all dimensions except the batch dimension</span><br><span class="line">        num_features = 1</span><br><span class="line">        for s in size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        return num_features</span><br></pre></td></tr></table></figure>
<p>共测试<code>4</code>个网络</p>
<ul>
<li>网络$A$：标准神经网络</li>
<li>网络$B$：对全连接层进行失活操作</li>
<li>网络$C$：对卷积层进行失活操作</li>
<li>网络$D$：对所有隐藏层进行失活操作</li>
</ul>
<p>参考细节如下：</p>
<ul>
<li>批量大小<code>batch_size=256</code></li>
<li>迭代次数<code>epochs=1000</code></li>
<li>学习率<code>lr=1e-2</code></li>
<li>失活率<code>p=0.5</code></li>
<li>动量因子<code>momentum=0.9</code></li>
<li>每隔<code>150</code>轮迭代衰减一半学习率</li>
</ul>
<p>每隔<code>20</code>轮进行一次精度检测，实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-6-7 下午3:09</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import torch.optim as optim</span><br><span class="line">import torch.optim.lr_scheduler as lr_scheduler</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">import torchvision.datasets as datasets</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"># 批量大小</span><br><span class="line">batch_size = 256</span><br><span class="line"># 迭代次数</span><br><span class="line">epochs = 1000</span><br><span class="line"></span><br><span class="line"># 学习率</span><br><span class="line">lr = 1e-2</span><br><span class="line"># 失活率</span><br><span class="line">p_h = 0.5</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_cifar_10_data(batch_size=128, shuffle=False):</span><br><span class="line">    data_dir = &apos;/home/lab305/Documents/data/cifar_10/&apos;</span><br><span class="line"></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    train_data_set = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)</span><br><span class="line">    test_data_set = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)</span><br><span class="line"></span><br><span class="line">    train_loader = DataLoader(train_data_set, batch_size=batch_size, shuffle=shuffle)</span><br><span class="line">    test_loader = DataLoader(test_data_set, batch_size=batch_size, shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    return train_loader, test_loader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class LeNet5(nn.Module):</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">def compute_accuracy(loader, net, device):</span><br><span class="line">    total = 0</span><br><span class="line">    correct = 0</span><br><span class="line">    for item in loader:</span><br><span class="line">        data, labels = item</span><br><span class="line">        data = data.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        scores = net.predict(data)</span><br><span class="line">        predicted = torch.argmax(scores, dim=1)</span><br><span class="line">        total += labels.size(0)</span><br><span class="line">        correct += (predicted == labels).sum().item()</span><br><span class="line"></span><br><span class="line">    return correct / total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    train_loader, test_loader = load_cifar_10_data(batch_size=batch_size, shuffle=True)</span><br><span class="line"></span><br><span class="line">    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line"></span><br><span class="line">    net = LeNet5(3, p=p_h).to(device)</span><br><span class="line">    criterion = nn.CrossEntropyLoss().to(device)</span><br><span class="line">    optimer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)</span><br><span class="line">    stepLR = lr_scheduler.StepLR(optimer, step_size=150, gamma=0.5)</span><br><span class="line"></span><br><span class="line">    best_train_accuracy = 0.99</span><br><span class="line">    best_test_accuracy = 0</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    train_list = []</span><br><span class="line">    for i in range(epochs):</span><br><span class="line">        num = 0</span><br><span class="line">        total_loss = 0</span><br><span class="line">        start = time.time()</span><br><span class="line">        net.train()  # 训练模式</span><br><span class="line">        for j, item in enumerate(train_loader, 0):</span><br><span class="line">            data, labels = item</span><br><span class="line">            data = data.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">            scores = net.forward(data)</span><br><span class="line">            loss = criterion.forward(scores, labels)</span><br><span class="line"></span><br><span class="line">            optimer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimer.step()</span><br><span class="line"></span><br><span class="line">            total_loss += loss.item()</span><br><span class="line">            num += 1</span><br><span class="line">        end = time.time()</span><br><span class="line">        stepLR.step()</span><br><span class="line"></span><br><span class="line">        avg_loss = total_loss / num</span><br><span class="line">        loss_list.append(float(&apos;%.4f&apos; % avg_loss))</span><br><span class="line">        print(&apos;epoch: %d time: %.2f loss: %.4f&apos; % (i + 1, end - start, avg_loss))</span><br><span class="line"></span><br><span class="line">        if i % 20 == 19:</span><br><span class="line">            # 计算训练数据集检测精度</span><br><span class="line">            net.eval()  # 测试模式</span><br><span class="line">            train_accuracy = compute_accuracy(train_loader, net, device)</span><br><span class="line">            train_list.append(float(&apos;%.4f&apos; % train_accuracy))</span><br><span class="line">            if best_train_accuracy &lt; train_accuracy:</span><br><span class="line">                best_train_accuracy = train_accuracy</span><br><span class="line"></span><br><span class="line">                test_accuracy = compute_accuracy(test_loader, net, device)</span><br><span class="line">                if best_test_accuracy &lt; test_accuracy:</span><br><span class="line">                    best_test_accuracy = test_accuracy</span><br><span class="line"></span><br><span class="line">            print(&apos;best train accuracy: %.2f %%   best test accuracy: %.2f %%&apos; % (</span><br><span class="line">                best_train_accuracy * 100, best_test_accuracy * 100))</span><br><span class="line">            print(loss_list)</span><br><span class="line">            print(train_list)</span><br></pre></td></tr></table></figure>
<p><code>1000</code>轮迭代后的测试精度如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">最好训练集精度</th>
<th style="text-align:center">最好测试集精度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">A</td>
<td style="text-align:center">100%</td>
<td style="text-align:center">60.45 %</td>
</tr>
<tr>
<td style="text-align:center">B</td>
<td style="text-align:center">99.84%</td>
<td style="text-align:center">61.47%</td>
</tr>
<tr>
<td style="text-align:center">C</td>
<td style="text-align:center">57.04%</td>
<td style="text-align:center">/</td>
</tr>
<tr>
<td style="text-align:center">D</td>
<td style="text-align:center">50.93%</td>
<td style="text-align:center">/</td>
</tr>
</tbody>
</table>
</div>
<p>其损失值和训练集精度值变化如下：</p>
<p><img src="/imgs/随机失活-pytorch/lenet_5_loss.png" alt></p>
<p><img src="/imgs/随机失活-pytorch/lenet_5_accuracy.png" alt></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>从训练结果看出</p>
<ol>
<li>失活网络需要更多的时间训练才能收敛</li>
<li>失活操作能够提高泛化能力</li>
<li>对卷积层进行失活操作会导致损失值过早收敛</li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>最优化</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>torchvision</tag>
        <tag>matplotlib</tag>
        <tag>随机失活</tag>
      </tags>
  </entry>
  <entry>
    <title>随机失活</title>
    <url>/posts/20cc7a49.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://arxiv.org/abs/1207.0580" target="_blank" rel="noopener">Improving neural networks by preventing co-adaptation of feature detectors</a></p><a id="more"></a>

<p><a href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf" target="_blank" rel="noopener">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a></p>
<p><a href="http://cs231n.github.io/neural-networks-2/#reg" target="_blank" rel="noopener">Dropout</a></p>
<p>使用前馈神经网络进行检测，测试集的检测率总是低于训练集，尤其是训练集数量不大的情况下，原因在于神经网络在训练过程中不断调整参数以拟合训练数据，在此过程中也学习了训练集噪声，导致泛化能力减弱</p>
<p>随时失活（dropout）是一种正则化方法，其动机来自于进化中的性别作用理论（<code>a theory of the role of sex in evolution</code>），它通过训练多个不同网络模型，模拟模型组合的方式来提高网络性能，防止网络过拟合</p>
<p>主要内容如下：</p>
<ol>
<li>基础知识 - 伯努利分布/均匀分布</li>
<li>实现原理</li>
<li>模型描述及改进</li>
<li>3层神经网络测试</li>
</ol>
<h2 id="伯努利分布-均匀分布"><a href="#伯努利分布-均匀分布" class="headerlink" title="伯努利分布/均匀分布"></a>伯努利分布/均匀分布</h2><h3 id="伯努利分布"><a href="#伯努利分布" class="headerlink" title="伯努利分布"></a>伯努利分布</h3><p>参考：<a href="https://baike.baidu.com/item/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83/7167021?fr=aladdin" target="_blank" rel="noopener">伯努利分布</a></p>
<p>伯努利分布（<code>Bernoulli distribution</code>）是离散随机变量分布，如果随机变量$X$只取0和1两个值，并且相应的概率为</p>
<script type="math/tex; mode=display">
P(X=1) = p, P(X=0) = 1-p, 0<p<1</script><p>则称随机变量$X$服从参数为$p$的伯努利分布</p>
<h3 id="均匀分布"><a href="#均匀分布" class="headerlink" title="均匀分布"></a>均匀分布</h3><p>参考：<a href="https://baike.baidu.com/item/%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83/954451?fr=aladdin" target="_blank" rel="noopener">均匀分布</a></p>
<p>均匀分布（<code>Uniform distribution</code>）也称为矩形分布，它是对称分布，在相同长度间隔的分布概率是等可能的。均匀分布由两个参数$a$和$b$定义，分别表示数轴上的最小值和最大值，缩写为$U(a,b)$</p>
<h3 id="numpy实现"><a href="#numpy实现" class="headerlink" title="numpy实现"></a>numpy实现</h3><p><strong>失活掩模实现：先创建均匀分布在[0,1)中的数组，再比较忽略概率得到失火掩模</strong></p>
<p>函数<a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.ranf.html" target="_blank" rel="noopener">numpy.random.ranf</a>和<a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.rand.html" target="_blank" rel="noopener">numpy.random.rand</a>都实现了<code>[0,1)</code>之间均匀分布，<strong>区别在于<code>ranf</code>输入维数元组，<code>rand</code>分别输入每个维数大小</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># [0,1)之间的均匀分布实现</span><br><span class="line">&gt;&gt;&gt; size = (2,4)</span><br><span class="line">&gt;&gt;&gt; a = np.random.ranf(size)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[0.55782603, 0.3881068 , 0.30671933, 0.5932138 ],</span><br><span class="line">       [0.68501697, 0.31336583, 0.79142952, 0.09579494]])</span><br><span class="line"># 伯努利掩模实现</span><br><span class="line">&gt;&gt;&gt; p = 0.5</span><br><span class="line">&gt;&gt;&gt; b = a &lt; p</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([[False,  True,  True, False],</span><br><span class="line">       [False,  True, False,  True]])</span><br></pre></td></tr></table></figure>
<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>随机失活目的在于避免神经元之间的共适应性（<code>co-adaptation</code>），它鼓励每个隐藏单元在学习有用功能时不依赖于特定的其他隐藏单元来纠正错误</p>
<p>另一种解释是随机失活过程相当于多网络之间的模型平均（<code>modeling averaging with neural networks</code>）。通过模型集成方式，用多个不同网络进行预测，再通过平均预测结果能够有效减少测试集误差率。理论上$n$个隐藏层神经元可组成$2^{n}$个稀疏网络，随机失活在每次训练过程中随机忽略隐藏层的神经元（忽略概率$p$是一个超参数），相当于每次训练不同的神经网络</p>
<p><img src="/imgs/随机失活/dropout_net.png" alt></p>
<p>这些神经网络在同一个神经元上共享权重，最后在测试阶段，不再进行随机失活操作，使用神经网络所有隐藏神经元进行计算，但需要对权重乘以概率$p$，以此来平衡<code>平均网络（mean network）</code>多倍于<code>随机失活网络（dropout network）</code>的激活单元</p>
<p><img src="/imgs/随机失活/dropout_net_2.png" alt></p>
<p><strong>注意一：通常设置隐藏层随机忽略概率$p$为0.5</strong></p>
<p><strong>注意二：论文中还提到输入层神经元也可进行随机失活，其概率通常接近1，比如设置概率为0.9</strong></p>
<p><strong>注意三：多次实验发现输入层神经元失活极易出现损失无法收敛问题</strong></p>
<h2 id="模型描述及改进"><a href="#模型描述及改进" class="headerlink" title="模型描述及改进"></a>模型描述及改进</h2><h3 id="原始模型描述及实现"><a href="#原始模型描述及实现" class="headerlink" title="原始模型描述及实现"></a>原始模型描述及实现</h3><p>计算符号参考<a href="https://www.zhujian.tech/posts/cb820bb8.html#more">网络符号定义</a>，标准神经网络的前向计算过程如下：</p>
<script type="math/tex; mode=display">
z_{i}^{(l)} = a^{(l-1)}\cdot w_{i}^{(l)} + b_{i}^{(l)}</script><script type="math/tex; mode=display">
a_{i}^{(l)} = f(z_{i}^{(l)})</script><p>使用随机失活操作后，其前向计算如下：</p>
<script type="math/tex; mode=display">
r_{i}^{(l-1)} = Bernoulli(p)</script><script type="math/tex; mode=display">
\tilde{a_{i}}^{(l-1)} = a_{i}^{(l-1)} * r_{i}^{(l-1)}</script><script type="math/tex; mode=display">
z_{i}^{(l)} = \tilde{a_{i}}^{(l-1)}\cdot w_{i}^{(l)} + b_{i}^{(l)}</script><script type="math/tex; mode=display">
a_{i}^{(l)} = f(z_{i}^{(l)})</script><p><img src="/imgs/随机失活/dropout_net_3.png" alt></p>
<p><strong>注意：前向传播过程中失活的神经元在反向传播中其对应梯度为0</strong></p>
<h4 id="numpy实现-1"><a href="#numpy实现-1" class="headerlink" title="numpy实现"></a>numpy实现</h4><p>对3层神经网络进行随机失活操作如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class ThreeNet(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self, D_in, D_h1, D_h2, D_out, p_h=1.0):</span><br><span class="line">        ...</span><br><span class="line">        self.p_h = p_h</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        前向计算，计算评分函数值</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.N = inputs.shape[0]</span><br><span class="line">        self.a0 = inputs</span><br><span class="line"></span><br><span class="line">        self.z1 = inputs.dot(self.w) + self.b</span><br><span class="line">        self.a1 = np.maximum(0, self.z1)</span><br><span class="line">        # 创建失活掩模</span><br><span class="line">        U1 = np.random.ranf(self.a1.shape) &lt; self.p_h</span><br><span class="line">        self.a1 *= U1</span><br><span class="line"></span><br><span class="line">        self.z2 = self.a1.dot(self.w2) + self.b2</span><br><span class="line">        self.a2 = np.maximum(0, self.z2)</span><br><span class="line">        # 创建失活掩模</span><br><span class="line">        U2 = np.random.ranf(self.a2.shape) &lt; self.p_h</span><br><span class="line">        self.a2 *= U2</span><br><span class="line"></span><br><span class="line">        self.z3 = self.a2.dot(self.w3) + self.b3</span><br><span class="line">        expscores = np.exp(self.z3)</span><br><span class="line">        self.h = expscores / np.sum(expscores, axis=1, keepdims=True)</span><br><span class="line">        return self.h</span><br><span class="line"></span><br><span class="line">    def backward(self, output):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        反向传播，计算梯度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        delta = self.h</span><br><span class="line">        delta[range(self.N), output] -= 1</span><br><span class="line">        delta /= self.N</span><br><span class="line"></span><br><span class="line">        self.dw3 = self.a2.T.dot(delta)</span><br><span class="line">        self.db3 = np.sum(delta, axis=0, keepdims=True)</span><br><span class="line"></span><br><span class="line">        da2 = delta.dot(self.w3.T)</span><br><span class="line">        # 失活掩模</span><br><span class="line">        da2 *= self.U2</span><br><span class="line">        dz2 = da2</span><br><span class="line">        dz2[self.z2 &lt; 0] = 0</span><br><span class="line"></span><br><span class="line">        self.dw2 = self.a1.T.dot(dz2)</span><br><span class="line">        self.db2 = np.sum(dz2, axis=0, keepdims=True)</span><br><span class="line"></span><br><span class="line">        da1 = dz2.dot(self.w2.T)</span><br><span class="line">        # 失活掩模</span><br><span class="line">        da1 *= self.U1</span><br><span class="line">        dz1 = da1</span><br><span class="line">        dz1[self.z1 &lt; 0] = 0</span><br><span class="line"></span><br><span class="line">        self.dw = self.a0.T.dot(dz1)</span><br><span class="line">        self.db = np.sum(dz1, axis=0, keepdims=True)</span><br><span class="line"></span><br><span class="line">    def update(self, lr=1e-3, reg_rate=0.0):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    def predict(self, inputs):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        前向计算，计算评分函数值</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        z1 = inputs.dot(self.w) + self.b</span><br><span class="line">        # 输出向量乘以忽略概率p</span><br><span class="line">        a1 = np.maximum(0, z1) * self.p_h</span><br><span class="line"></span><br><span class="line">        z2 = a1.dot(self.w2) + self.b2</span><br><span class="line">        # 输出向量乘以忽略概率p</span><br><span class="line">        a2 = np.maximum(0, z2) * self.p_h</span><br><span class="line"></span><br><span class="line">        z3 = a2.dot(self.w3) + self.b3</span><br><span class="line">        expscores = np.exp(z3)</span><br><span class="line">        self.h = expscores / np.sum(expscores, axis=1, keepdims=True)</span><br><span class="line">        return self.h</span><br></pre></td></tr></table></figure>
<h3 id="改进一：反向失活"><a href="#改进一：反向失活" class="headerlink" title="改进一：反向失活"></a>改进一：反向失活</h3><p>原始模型针对前向/后向传播进行了失活掩模操作，对预测阶段隐藏层输出值进行了<strong>等比例缩放</strong></p>
<p>实际操作中预测时间越短越好，所以采用<strong>反向失活</strong>（<code>inverted dropout</code>）策略</p>
<p>假设原先隐藏层输出为$X$，所以在预测阶段需要称以概率$p$，最终值为$pX$</p>
<p>在反向失活操作中，将$X \rightarrow pX$，那么在预测阶段就不需要再乘以概率$p$，在训练阶段就需要修改为$pX / p = X$</p>
<p><strong>相当于在训练阶段进行数据放大，在预测阶段正常输出即可</strong></p>
<p>模型描述如下：</p>
<script type="math/tex; mode=display">
r_{i}^{(l-1)} = Bernoulli(p) / p</script><h4 id="numpy实现-2"><a href="#numpy实现-2" class="headerlink" title="numpy实现"></a>numpy实现</h4><p>反向失活操作如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def dropout(shape, p):</span><br><span class="line">    assert len(shape) == 2</span><br><span class="line">    res = (np.random.ranf(shape) &lt; p) / p</span><br><span class="line"></span><br><span class="line">    if np.sum(res) == 0:</span><br><span class="line">        return 1.0 / p</span><br><span class="line">    return res</span><br></pre></td></tr></table></figure>
<p>集成到网络中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class ThreeNet(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self, D_in, D_h1, D_h2, D_out, p_h=1.0):</span><br><span class="line">        ...</span><br><span class="line">        self.p_h = p_h</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        前向计算，计算评分函数值</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.N = inputs.shape[0]</span><br><span class="line">        self.a0 = inputs</span><br><span class="line"></span><br><span class="line">        self.z1 = inputs.dot(self.w) + self.b</span><br><span class="line">        self.a1 = np.maximum(0, self.z1)</span><br><span class="line">        # 创建失活掩模</span><br><span class="line">        U1 = (np.random.ranf(self.a1.shape) &lt; self.p_h) / self.p_h</span><br><span class="line">        self.a1 *= U1</span><br><span class="line"></span><br><span class="line">        self.z2 = self.a1.dot(self.w2) + self.b2</span><br><span class="line">        self.a2 = np.maximum(0, self.z2)</span><br><span class="line">        # 创建失活掩模</span><br><span class="line">        U2 = (np.random.ranf(self.a2.shape) &lt; self.p_h) / self.p_h</span><br><span class="line">        self.a2 *= U2</span><br><span class="line"></span><br><span class="line">        self.z3 = self.a2.dot(self.w3) + self.b3</span><br><span class="line">        expscores = np.exp(self.z3)</span><br><span class="line">        self.h = expscores / np.sum(expscores, axis=1, keepdims=True)</span><br><span class="line">        return self.h</span><br><span class="line"></span><br><span class="line">    def backward(self, output):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        反向传播，计算梯度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        delta = self.h</span><br><span class="line">        delta[range(self.N), output] -= 1</span><br><span class="line">        delta /= self.N</span><br><span class="line"></span><br><span class="line">        self.dw3 = self.a2.T.dot(delta)</span><br><span class="line">        self.db3 = np.sum(delta, axis=0, keepdims=True)</span><br><span class="line"></span><br><span class="line">        da2 = delta.dot(self.w3.T)</span><br><span class="line">        # 失活掩模</span><br><span class="line">        da2 *= self.U2</span><br><span class="line">        dz2 = da2</span><br><span class="line">        dz2[self.z2 &lt; 0] = 0</span><br><span class="line"></span><br><span class="line">        self.dw2 = self.a1.T.dot(dz2)</span><br><span class="line">        self.db2 = np.sum(dz2, axis=0, keepdims=True)</span><br><span class="line"></span><br><span class="line">        da1 = dz2.dot(self.w2.T)</span><br><span class="line">        # 失活掩模</span><br><span class="line">        da1 *= self.U1</span><br><span class="line">        dz1 = da1</span><br><span class="line">        dz1[self.z1 &lt; 0] = 0</span><br><span class="line"></span><br><span class="line">        self.dw = self.a0.T.dot(dz1)</span><br><span class="line">        self.db = np.sum(dz1, axis=0, keepdims=True)</span><br><span class="line"></span><br><span class="line">    def update(self, lr=1e-3, reg_rate=0.0):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    def predict(self, inputs):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        前向计算，计算评分函数值</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        z1 = inputs.dot(self.w) + self.b</span><br><span class="line">        a1 = np.maximum(0, z1)</span><br><span class="line"></span><br><span class="line">        z2 = a1.dot(self.w2) + self.b2</span><br><span class="line">        a2 = np.maximum(0, z2)</span><br><span class="line"></span><br><span class="line">        z3 = a2.dot(self.w3) + self.b3</span><br><span class="line">        expscores = np.exp(z3)</span><br><span class="line">        self.h = expscores / np.sum(expscores, axis=1, keepdims=True)</span><br><span class="line">        return self.h</span><br></pre></td></tr></table></figure>
<h3 id="空间失活"><a href="#空间失活" class="headerlink" title="空间失活"></a>空间失活</h3><p>参考：</p>
<p><a href="https://pytorch.org/docs/stable/nn.html#dropout2d" target="_blank" rel="noopener">Dropout2d</a></p>
<p><a href="https://discuss.pytorch.org/t/confusion-about-dropout2d/21958" target="_blank" rel="noopener">Confusion about dropout2d</a></p>
<p>在<code>4-D</code>张量中，相邻的特征可能是强相关的，因此标准失活操作将无法有效地规范网络，空间失活以通道为单位，随机对整个通道（<em>激活图</em>）进行清零</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; m = nn.Dropout2d(p=0.5)</span><br><span class="line">&gt;&gt;&gt; m(torch.arange(16).reshape(1,4,2,2).float())</span><br><span class="line">tensor([[[[ 0.,  2.],</span><br><span class="line">          [ 4.,  6.]],</span><br><span class="line"></span><br><span class="line">         [[ 8., 10.],</span><br><span class="line">          [12., 14.]],</span><br><span class="line"></span><br><span class="line">         [[ 0.,  0.],</span><br><span class="line">          [ 0.,  0.]],</span><br><span class="line"></span><br><span class="line">         [[ 0.,  0.],</span><br><span class="line">          [ 0.,  0.]]]])</span><br></pre></td></tr></table></figure>
<h4 id="numpy实现-3"><a href="#numpy实现-3" class="headerlink" title="numpy实现"></a>numpy实现</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def dropout2d(shape, p):</span><br><span class="line">    assert len(shape) == 4</span><br><span class="line">    N, C, H, W = shape[:4]</span><br><span class="line">    U = (np.random.rand(N * C, 1) &lt; p) / p</span><br><span class="line">    res = np.ones((N * C, H * W))</span><br><span class="line">    res *= U</span><br><span class="line"></span><br><span class="line">    if np.sum(res) == 0:</span><br><span class="line">        return 1.0 / p</span><br><span class="line">    return res.reshape(N, C, H, W)</span><br></pre></td></tr></table></figure>
<h2 id="3层神经网络测试"><a href="#3层神经网络测试" class="headerlink" title="3层神经网络测试"></a>3层神经网络测试</h2><p>3层随机失活神经网络实现如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class ThreeLayerNet(Net):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    实现3层神经网络</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, num_in, num_h_one, num_h_two, num_out, momentum=0, nesterov=False, p_h=1.0, p_in=1.0):</span><br><span class="line">        super(ThreeLayerNet, self).__init__()</span><br><span class="line">        self.fc1 = FC(num_in, num_h_one, momentum=momentum, nesterov=nesterov)</span><br><span class="line">        self.relu1 = ReLU()</span><br><span class="line">        self.fc2 = FC(num_h_one, num_h_two, momentum=momentum, nesterov=nesterov)</span><br><span class="line">        self.relu2 = ReLU()</span><br><span class="line">        self.fc3 = FC(num_h_two, num_out, momentum=momentum, nesterov=nesterov)</span><br><span class="line"></span><br><span class="line">        self.p_h = p_h</span><br><span class="line">        self.p_in = p_in</span><br><span class="line">        self.U1 = None</span><br><span class="line">        self.U2 = None</span><br><span class="line"></span><br><span class="line">    def __call__(self, inputs):</span><br><span class="line">        return self.forward(inputs)</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        # inputs.shape = [N, D_in]</span><br><span class="line">        assert len(inputs.shape) == 2</span><br><span class="line">        U0 = F.dropout(inputs.shape, self.p_in)</span><br><span class="line">        inputs *= U0</span><br><span class="line"></span><br><span class="line">        a1 = self.relu1(self.fc1(inputs))</span><br><span class="line">        self.U1 = F.dropout(a1.shape, self.p_h)</span><br><span class="line">        a1 *= self.U1</span><br><span class="line"></span><br><span class="line">        a2 = self.relu2(self.fc2(a1))</span><br><span class="line">        self.U2 = F.dropout(a2.shape, self.p_h)</span><br><span class="line">        a2 *= self.U2</span><br><span class="line"></span><br><span class="line">        z3 = self.fc3(a2)</span><br><span class="line"></span><br><span class="line">        return z3</span><br><span class="line"></span><br><span class="line">    def backward(self, grad_out):</span><br><span class="line">        da2 = self.fc3.backward(grad_out) * self.U2</span><br><span class="line">        dz2 = self.relu2.backward(da2)</span><br><span class="line">        da1 = self.fc2.backward(dz2) * self.U1</span><br><span class="line">        dz1 = self.relu1.backward(da1)</span><br><span class="line">        da0 = self.fc1.backward(dz1)</span><br><span class="line"></span><br><span class="line">    def update(self, lr=1e-3, reg=1e-3):</span><br><span class="line">        self.fc3.update(learning_rate=lr, regularization_rate=reg)</span><br><span class="line">        self.fc2.update(learning_rate=lr, regularization_rate=reg)</span><br><span class="line">        self.fc1.update(learning_rate=lr, regularization_rate=reg)</span><br><span class="line"></span><br><span class="line">    def predict(self, inputs):</span><br><span class="line">        # inputs.shape = [N, D_in]</span><br><span class="line">        assert len(inputs.shape) == 2</span><br><span class="line">        a1 = self.relu1(self.fc1(inputs))</span><br><span class="line">        a2 = self.relu2(self.fc2(a1))</span><br><span class="line">        z3 = self.fc3(a2)</span><br><span class="line"></span><br><span class="line">        return z3</span><br><span class="line"></span><br><span class="line">    def get_params(self):</span><br><span class="line">        return &#123;&apos;fc1&apos;: self.fc1.get_params(), &apos;fc2&apos;: self.fc2.get_params(), &apos;fc3&apos;: self.fc3.get_params(),</span><br><span class="line">                &apos;p_h&apos;: self.p_h, &apos;p_in&apos;: self.p_in&#125;</span><br><span class="line"></span><br><span class="line">    def set_params(self, params):</span><br><span class="line">        self.fc1.set_params(params[&apos;fc1&apos;])</span><br><span class="line">        self.fc2.set_params(params[&apos;fc2&apos;])</span><br><span class="line">        self.fc3.set_params(params[&apos;fc3&apos;])</span><br><span class="line">        self.p_h = params.get(&apos;p_h&apos;, 1.0)</span><br><span class="line">        self.p_in = params.get(&apos;p_in&apos;, 1.0)</span><br></pre></td></tr></table></figure>
<h3 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a>训练细节</h3><p>利用<a href="https://www.zhujian.tech/posts/43d7ec86.html">cifar-10</a>进行测试，原始图像大小为<code>(32, 32, 3)</code>，加载数据实现：<a href> PyNet/data/load_cifar_10.py </a></p>
<p>测试参数如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 迭代次数</span><br><span class="line">epochs = 300</span><br><span class="line"># 批量大小</span><br><span class="line">batch_size = 256</span><br><span class="line"># 输入维数</span><br><span class="line">D = 3072</span><br><span class="line"># 隐藏层大小</span><br><span class="line">H1 = 2000</span><br><span class="line">H2 = 800</span><br><span class="line"># 输出类别</span><br><span class="line">K = 40</span><br><span class="line"></span><br><span class="line"># 学习率</span><br><span class="line">lr = 1e-3</span><br><span class="line"># 正则化强度</span><br><span class="line">reg_rate = 1e-3</span><br><span class="line"># 隐藏层失活率</span><br><span class="line">p_h = 0.5</span><br></pre></td></tr></table></figure>
<p>每隔50次迭代学习率下降一半，共下降4次</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if i % 50 == 49 and i &lt; 200:</span><br><span class="line">    lr /= 2</span><br></pre></td></tr></table></figure>
<p>测试代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">    for i in range(epochs):</span><br><span class="line">        start = time.time()</span><br><span class="line">        total_loss = 0</span><br><span class="line">        for j in range_list:</span><br><span class="line">            data = x_train[j:j + batch_size]</span><br><span class="line">            labels = y_train[j:j + batch_size]</span><br><span class="line"></span><br><span class="line">            scores = net.forward(data)</span><br><span class="line">            loss = criterion.forward(scores, labels)</span><br><span class="line">            total_loss += loss</span><br><span class="line">            dout = criterion.backward()</span><br><span class="line">            net.backward(dout)</span><br><span class="line">            net.update(lr=lr, reg=reg_rate)</span><br><span class="line">        end = time.time()</span><br><span class="line"></span><br><span class="line">        avg_loss = total_loss / len(range_list)</span><br><span class="line">        loss_list.append(float(&apos;%.4f&apos; % avg_loss))</span><br><span class="line">        print(&apos;epoch: %d time: %.2f loss: %.4f&apos; % (i + 1, end - start, avg_loss))</span><br><span class="line"></span><br><span class="line">        if i % 10 == 9:</span><br><span class="line">            # 计算训练数据集检测精度</span><br><span class="line">            train_accuracy = compute_accuracy(x_train, y_train, net, batch_size=batch_size)</span><br><span class="line">            train_accuracy_list.append(float(&apos;%.4f&apos; % train_accuracy))</span><br><span class="line">            if best_train_accuracy &lt; train_accuracy:</span><br><span class="line">                best_train_accuracy = train_accuracy</span><br><span class="line"></span><br><span class="line">                test_accuracy = compute_accuracy(x_test, y_test, net, batch_size=batch_size)</span><br><span class="line">                if best_test_accuracy &lt; test_accuracy:</span><br><span class="line">                    best_test_accuracy = test_accuracy</span><br><span class="line">                    # save_params(net.get_params(), path=&apos;./three-nn-dropout-epochs-%d.pkl&apos; % (i + 1))</span><br><span class="line"></span><br><span class="line">            print(&apos;best train accuracy: %.2f %%   best test accuracy: %.2f %%&apos; % (</span><br><span class="line">                best_train_accuracy * 100, best_test_accuracy * 100))</span><br><span class="line">            print(loss_list)</span><br><span class="line">            print(train_accuracy_list)</span><br><span class="line"></span><br><span class="line">        if i % 50 == 49 and收敛 i &lt; 200:</span><br><span class="line">            lr /= 2收敛</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>完整代码地址：<a href="https://github.com/zjZSTU/PyNet/blo收敛b/master/src/three_nn_dropout_cifar_10.py" target="_blank" rel="noopener"> PyNet/src/t收敛hree_nn_dropout_cifar_10.py </a></p>
<h3 id="训练结果"><a href="#训练结果" class="headerlink" title="训练结果"></a>训练结果</h3><p>进行<code>2</code>种不同网络测试：</p>
<ul>
<li>标准神经网络$A$</li>
<li>失活神经网络$B$，隐藏层忽略概率为$p_h=0.5$</li>
</ul>
<p>训练<code>300</code>次后，最好的训练和测试精度如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">训练精度</th>
<th style="text-align:center">测试精度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">A</td>
<td style="text-align:center">100%</td>
<td style="text-align:center">57.63%</td>
</tr>
<tr>
<td style="text-align:center">B</td>
<td style="text-align:center">99.79%</td>
<td style="text-align:center">60.01%</td>
</tr>
</tbody>
</table>
</div>
<p>随机失活损失和训练精度如下：</p>
<p><img src="/imgs/随机失活/dropout_loss.png" alt></p>
<p><img src="/imgs/随机失活/dropout_accuracy.png" alt></p>
<p>标准3层神经网络损失和训练精度如下：</p>
<p><img src="/imgs/随机失活/nn_loss.png" alt></p>
<p><img src="/imgs/随机失活/nn_accuracy.png" alt></p>
<p>两者比较如下：</p>
<p><img src="/imgs/随机失活/dropout_nn_loss.png" alt></p>
<p><img src="/imgs/随机失活/dropout_nn_accuracy.png" alt></p>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>从训练结果可看出失活神经网络比标准神经网络泛化能力更强</p>
<p>从图中可以看出，失活神经网络比标准神经网络需要更多训练才能收敛</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>最优化</category>
        <category>数学</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>numpy</tag>
        <tag>概率论</tag>
        <tag>随机失活</tag>
      </tags>
  </entry>
  <entry>
    <title>主成分分析</title>
    <url>/posts/49729a62.html</url>
    <content><![CDATA[<p>主成分分析（<code>princial component analysis</code>，简称<code>PCA</code>）是一种无监督的数据降维操作，它通过最大化方差方法来寻找低维空间，能够有效减轻计算量的同时保证处理数据有效性</p><a id="more"></a>
<p>主要参考文章<a href="https://blog.csdn.net/u012005313/article/details/50877366" target="_blank" rel="noopener">PCA数学原理</a>，里面做了生动的数学原理分析</p>
<p>相关线性代数、几何学以及统计学数学内容参考：</p>
<p><a href="https://www.zhujian.tech/posts/b905521b.html#more">概率论基础</a></p>
<p><a href="https://www.zhujian.tech/posts/74e95c64.html#more">线性代数基础</a></p>
<p>本文主要内容如下：</p>
<ol>
<li>原理解析</li>
<li>如何重建原始数据</li>
<li>如何确定$k$值</li>
<li>操作步骤</li>
<li><code>numpy</code>实现</li>
</ol>
<h2 id="原理解析"><a href="#原理解析" class="headerlink" title="原理解析"></a>原理解析</h2><ul>
<li>为什么要进行数据降维？</li>
</ul>
<ol>
<li>减少内存或磁盘存储</li>
<li>加快算法运行</li>
<li>数据可视化（<em>将多维数据将为2维或3维，实现数据可视化</em>）</li>
</ol>
<ul>
<li>为什么能够进行数据降维?</li>
</ul>
<p>原始数据之间存在结构相关性，某些数据的丢失不影响后续对数据的处理</p>
<ul>
<li>数据降维过程应该注意哪些？</li>
</ul>
<ol>
<li>保留尽可能多的原始数据内部的结构信息</li>
<li>处理后的数据不存在相关性</li>
</ol>
<ul>
<li>如何保证能够得到尽可能多的原始数据内部的结构信息？</li>
</ul>
<p>原始数据内部的结构信息不会在投影后重叠在一起，低维空间数据尽可能分散，也即使说投影后每个字段数据的<strong>方差</strong>越大越好</p>
<p>假设有<code>M</code>个<code>N</code>维<strong>列向量</strong>数据$X\in R^{N\times M}$，第$i$个字段数据的方差计算如下：</p>
<script type="math/tex; mode=display">
Var(X_{,j}) = \frac {1}{M} \sum_{j=1}^{M} (X_{ij} - \mu_{i})^{2}</script><p>$\mu_{i}$表示第$i$个字段数据的均值</p>
<script type="math/tex; mode=display">
\mu_{i} = \frac {1}{M} \sum_{j=1}^{M}X_{ij}</script><ul>
<li>如何保证处理后的数据不存在相关性</li>
</ul>
<p>投影后不同字段之间的<strong>协方差</strong>为<code>0</code>，表示不存在相关性，数据完全独立</p>
<p>第$i$个和第$l$个字段数据之间的协方差计算如下：</p>
<script type="math/tex; mode=display">
Cov(X_{i}, X_{l}) = \frac {1}{M} \sum_{j=1}^{M} X_{i,j}X_{l,j}</script><ul>
<li>如何计算方差和协方差?</li>
</ul>
<p>原始数据$X$有$N$维，表示有$N$个字段，计算字段之间的协方差矩阵$C\in R^{N\times N}$，对角元素表示方差，非对角元素表示协方差</p>
<script type="math/tex; mode=display">
C = \begin{bmatrix}
c_{11} & c_{12} & \cdots & c_{1N}\\ 
c_{21} & c_{22} & \cdots & c_{2N}\\ 
\vdots & \vdots & \vdots & \vdots\\ 
c_{N1} & c_{N2} & \cdots & c_{NN}
\end{bmatrix}
=\frac {1}{M}XX^{T}</script><p>其中$c_{ii}$表示第$i$个字段的随机变量，$c_{ij}$表示第$i$个和第$j$个字段的随机变量</p>
<p><strong>目标是协方差值为<code>0</code>,也就是协方差矩阵对角化</strong></p>
<ul>
<li>如何计算协方差矩阵对角化？</li>
</ul>
<p>协方差矩阵$C$是实对称矩阵，所以存在正交矩阵$Q$，能得到</p>
<script type="math/tex; mode=display">
Q^{-1}CQ = Q^{T}CQ = \Lambda = diag(\lambda_{1}, \lambda_{2}, ..., \lambda_{n})</script><p>其中$\lambda_{1}, \lambda_{2}, …, \lambda_{n}$为$C$的特征值</p>
<p>正交矩阵$Q$由特征值对应的特征向量正交化且单位化后组成，<strong>$Q$的第$j$列特征向量对应特征值$\lambda_{j}$</strong></p>
<p><strong>所以计算协方差矩阵的特征值和特征向量，将特征值（<em>方差</em>）从大到小排列，取前$k$个对应的特征向量（<em>列向量</em>），就是低维空间的基</strong></p>
<ul>
<li>如何执行降维操作？</li>
</ul>
<p>前$k$个特征向量（<em>转置成行向量</em>）组成的矩阵$P\in R^{k\times N}$，所以</p>
<script type="math/tex; mode=display">
Y = PX \in R^{k\times M}</script><p>$Y$表示数据$X$投影到矩阵$P$为基的低维空间数据</p>
<h2 id="需不需要数据去量纲？"><a href="#需不需要数据去量纲？" class="headerlink" title="需不需要数据去量纲？"></a>需不需要数据去量纲？</h2><p>参考：</p>
<p><a href="https://www.jianshu.com/p/c21c0e2c403a" target="_blank" rel="noopener">PCA填坑篇——使用PCA到底需不需要数据去量纲？</a></p>
<p><a href="https://www.jianshu.com/p/ae9db78ebb0f" target="_blank" rel="noopener">PCA要对数据进行预处理的原因</a></p>
<p>需要对原始数据去量纲，也就是让属性成为单纯一个数，去除属性单位带来的影响（比如<code>cm</code>和<code>kg</code>）</p>
<p>需要统一单位，所以需要对原始数据进行标准化操作，原始数据减去均值后，再除以各字段的标准差</p>
<p><strong>注意：在图像操作中，每个字段取值均为<code>[0-255]</code>，可以不进行去量纲操作，减去均值即可</strong></p>
<h2 id="如何重建原始数据"><a href="#如何重建原始数据" class="headerlink" title="如何重建原始数据"></a>如何重建原始数据</h2><p>对投影数据进行逆操作</p>
<script type="math/tex; mode=display">
X_{approx} = P^{T}\cdot Y  = R^{N\times k}\cdot R^{k\times M} = R^{N\times M}</script><p>需要每个字段加上均值</p>
<script type="math/tex; mode=display">
(X_{approx})_{i} = (X_{approx})_{i} + \mu_{i}</script><p>还需要对每个字段乘以字段标准差</p>
<script type="math/tex; mode=display">
(X_{approx})_{i} = (X_{approx})_{i} * \sigma_{i}</script><h2 id="如何确定-k-值"><a href="#如何确定-k-值" class="headerlink" title="如何确定$k$值"></a>如何确定$k$值</h2><p>降维目的是保证能够大幅降低维度，同时能够最大限度保持原始数据内部结构信息，通过投影均方误差来评价投影结果</p>
<script type="math/tex; mode=display">
\frac {1}{M} ||X - X_{approx}||^{2}</script><p>计算投影均方误差和数据集方差（已减去均值）比值，如果要保持<code>99%</code>方差</p>
<script type="math/tex; mode=display">
\frac {\frac {1}{M} ||X - X_{approx}||^{2}}{\frac {1}{M} ||X||^{2}} \leq 0.01</script><p>可以利用特征值来加速计算</p>
<script type="math/tex; mode=display">
1 - \frac {\sum_{i=1}^{K} \lambda_{i}}{\sum_{i=1}^{N} \lambda_{i}} \leq 0.01
\Rightarrow
\frac {\sum_{i=1}^{K} \lambda_{i}}{\sum_{i=1}^{N} \lambda_{i}} \geq 0.99</script><h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h2><p>假设有$M$条$N$维列向量数据</p>
<ol>
<li>将原始数据按列排成$N$行$M$列矩阵$X\in R^{N\times M}$</li>
<li>对$X$进行标准化操作（<em>每行减去均值后再除以标准差</em>）</li>
<li>求协方差矩阵$C=\frac {1}{M}XX^{T}$</li>
<li>求协方差矩阵特征值及对应的特征向量</li>
<li>将特征向量（<em>行向量形式</em>）按对应特征值大小从上到下排列成矩阵，取前$k$行组成矩阵$P\in R^{k\times N}$</li>
<li>$Y=PX = R^{k\times N}\cdot R^{N\times M}=R^{k\times M}$即为降维到$k$维后的数据</li>
</ol>
<h2 id="numpy实现"><a href="#numpy实现" class="headerlink" title="numpy实现"></a>numpy实现</h2><h3 id="特征值和特征向量计算"><a href="#特征值和特征向量计算" class="headerlink" title="特征值和特征向量计算"></a>特征值和特征向量计算</h3><p>函数<a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eig.html" target="_blank" rel="noopener">numpy.linalg.eig</a>用于计算协方差矩阵的特征值和特征向量</p>
<blockquote>
<p>numpy.linalg.eig(a)</p>
</blockquote>
<p>输入参数$a$是方阵</p>
<p>返回两个数组：<code>eigenvalue、eigenvector</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; w, v = np.linalg.eig(np.diag((1,2,3)))</span><br><span class="line">&gt;&gt;&gt; w</span><br><span class="line">array([1., 2., 3.])</span><br><span class="line">&gt;&gt;&gt; v # 列向量</span><br><span class="line">array([[1., 0., 0.],</span><br><span class="line">       [0., 1., 0.],</span><br><span class="line">       [0., 0., 1.]])</span><br></pre></td></tr></table></figure>
<p>函数<a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.svd.html" target="_blank" rel="noopener">numpy.linalg.svd</a>用于奇异值分解</p>
<blockquote>
<p>numpy.linalg.svd(a, full_matrices=1, compute_uv=1)</p>
</blockquote>
<ul>
<li>$a$是大小为$M\times N$的实矩阵或复矩阵</li>
<li><code>full_matrices</code>默认为<code>True</code>，表示返回值$u$和$v$大小为$M\times M$和$N\times N$；否则形状为$M\times K$和$K\times N$，其中$K = min(M,N)$</li>
<li><code>compute_uv</code>默认为<code>True</code>，表示是否计算<code>u/v</code></li>
</ul>
<p>返回值是<code>3</code>个数组<code>u/s/v</code>，其中<code>s</code>表示特征值并且按从大到小排列，<code>u</code>表示其对应的<strong>特征列向量</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; X</span><br><span class="line">array([[3, 0, 0],</span><br><span class="line">       [0, 1, 0],</span><br><span class="line">       [0, 0, 2]])</span><br><span class="line">&gt;&gt;&gt; u,s,v = np.linalg.svd(X)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; u # 列向量</span><br><span class="line">array([[1., 0., 0.],</span><br><span class="line">       [0., 0., 1.],</span><br><span class="line">       [0., 1., 0.]])</span><br><span class="line">&gt;&gt;&gt; s</span><br><span class="line">array([3., 2., 1.])</span><br><span class="line">&gt;&gt;&gt; v</span><br><span class="line">array([[1., 0., 0.],</span><br><span class="line">       [0., 0., 1.],</span><br><span class="line">       [0., 1., 0.]])</span><br></pre></td></tr></table></figure>
<p><strong><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html" target="_blank" rel="noopener">scipy.linalg.svd</a>同样实现了奇异值分解</strong></p>
<p><strong>注意：除以标准差时需要注意除数不能为<code>0</code></strong></p>
<h3 id="pca实现"><a href="#pca实现" class="headerlink" title="pca实现"></a>pca实现</h3><p>完整实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-6-5 上午11:36</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import cv2</span><br><span class="line">import os</span><br><span class="line">import time</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_cifar_data(num, data_path):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载cifar数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    test_dir = os.path.join(data_path, &apos;test&apos;, &apos;0&apos;)</span><br><span class="line">    file_list = os.listdir(test_dir)</span><br><span class="line"></span><br><span class="line">    data_list = []</span><br><span class="line">    for i in range(num):</span><br><span class="line">        img_path = os.path.join(test_dir, file_list[i])</span><br><span class="line">        img = cv2.imread(img_path)</span><br><span class="line">        if img is not None:</span><br><span class="line">            data_list.append(img.reshape(-1))</span><br><span class="line"></span><br><span class="line">    return np.array(data_list).astype(np.uint8)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_mnist_data(num, data_path):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载mnist数据， 轮流提取每个类别的图像</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    test_dir = os.path.join(data_path, &apos;test&apos;)</span><br><span class="line"></span><br><span class="line">    data_list = []</span><br><span class="line">    for i in range(num):</span><br><span class="line">        img_path = os.path.join(test_dir, str(i % 10), &apos;%d.png&apos; % (i))</span><br><span class="line">        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">        if img is not None:</span><br><span class="line">            data_list.append(img.reshape(-1))</span><br><span class="line"></span><br><span class="line">    return np.array(data_list).astype(np.uint8)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def pca(X, ratio=0.99, **kwargs):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    pca降维</span><br><span class="line">    :param X: 大小为NxM，其中M是个数，N是维度，每个字段已是零均值</span><br><span class="line">    :param ratio: 表示投影均方误差和方差比值，默认为0.99,保持99%的方差</span><br><span class="line">    :param kwargs: 字典参数，如果指定了k值，则直接计算</span><br><span class="line">    :return: 降维后数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    N, M = X.shape[:2]</span><br><span class="line">    C = X.dot(X.T) / M</span><br><span class="line">    u, s, v = np.linalg.svd(C)</span><br><span class="line">    # u, s, v = linalg.svd(C)</span><br><span class="line"></span><br><span class="line">    k = 1</span><br><span class="line">    if &apos;k&apos; in kwargs:</span><br><span class="line">        k = kwargs[&apos;k&apos;]</span><br><span class="line">    else:</span><br><span class="line">        while k &lt; N:</span><br><span class="line">            s_k = np.sum(s[:k])</span><br><span class="line">            s_N = np.sum(s)</span><br><span class="line">            if (s_k * 1.0 / s_N) &gt;= ratio:</span><br><span class="line">                break</span><br><span class="line">            k += 1</span><br><span class="line">    p = u.transpose()[:k]</span><br><span class="line">    y = p.dot(X)</span><br><span class="line"></span><br><span class="line">    return y, p</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def make_image(data_array, N, W, H, is_gray=False):</span><br><span class="line">    if is_gray:</span><br><span class="line">        img = np.zeros((N * H, N * W))</span><br><span class="line">    else:</span><br><span class="line">        img = np.zeros((N * H, N * W, 3))</span><br><span class="line">    for i in range(N):</span><br><span class="line">        for j in range(N):</span><br><span class="line">            if is_gray:</span><br><span class="line">                img[i * H:(i + 1) * H, j * W:(j + 1) * W] = data_array[i * N + j].reshape(H, W)</span><br><span class="line">            else:</span><br><span class="line">                img[i * H:(i + 1) * H, j * W:(j + 1) * W, :] = data_array[i * N + j].reshape(H, W, 3)</span><br><span class="line">    return img.astype(np.uint8)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    mnist_path = &apos;/home/zj/data/decompress_mnist/&apos;</span><br><span class="line">    cifar_path = &apos;/home/zj/data/decompress_cifar_10/&apos;</span><br><span class="line">    N = 7</span><br><span class="line">    W = 32</span><br><span class="line">    H = 32</span><br><span class="line">    isGray = False</span><br><span class="line"></span><br><span class="line">    # data_array = load_mnist_data(N * N, mnist_path)</span><br><span class="line">    data_array = load_cifar_data(N * N, cifar_path)</span><br><span class="line">    img1 = make_image(data_array, N, W, H, is_gray=isGray)</span><br><span class="line"></span><br><span class="line">    if N == 1:</span><br><span class="line">        mu = 0</span><br><span class="line">    else:</span><br><span class="line">        mu = np.mean(data_array, axis=0, keepdims=True)</span><br><span class="line">    data_array = data_array - mu</span><br><span class="line"></span><br><span class="line">    print(data_array.shape)</span><br><span class="line">    start = time.time()</span><br><span class="line">    y, p = pca(data_array.T, ratio=0.99)</span><br><span class="line">    end = time.time()</span><br><span class="line">    print(&apos;pca need time: %f&apos; % (end - start))</span><br><span class="line">    print(y.shape)</span><br><span class="line">    X_reduced = (p.T.dot(y)).T</span><br><span class="line">    X_reduced += mu</span><br><span class="line"></span><br><span class="line">    img2 = make_image(X_reduced, N, W, H, is_gray=isGray)</span><br><span class="line"></span><br><span class="line">    plt.figure(1)</span><br><span class="line">    if isGray:</span><br><span class="line">        plt.imshow(img1, cmap=&apos;gray&apos;)</span><br><span class="line">    else:</span><br><span class="line">        plt.imshow(img1)</span><br><span class="line">    plt.axis(&apos;off&apos;)</span><br><span class="line"></span><br><span class="line">    plt.figure(2)</span><br><span class="line">    if isGray:</span><br><span class="line">        plt.imshow(img2, cmap=&apos;gray&apos;)</span><br><span class="line">    else:</span><br><span class="line">        plt.imshow(img2)</span><br><span class="line">    plt.axis(&apos;off&apos;)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>进行<code>mnist</code>图像降维，保留<code>99%</code>的方差，图像从<code>784</code>维降至<code>43</code>维</p>
<p>降维<code>(49, 784)</code>到<code>(49, 43)</code>耗时<code>0.088249</code>秒</p>
<p><img src="/imgs/主成分分析/mnist_origin.png" alt></p>
<p><img src="/imgs/主成分分析/mnist_deconstruct.png" alt></p>
<p>进行<code>cifar</code>图像降维，保留<code>99%</code>的方差，图像从<code>3072</code>维降至<code>49</code>维</p>
<p>降维<code>(49, 3072)</code>到<code>(49, 41)</code>耗时9.106328秒</p>
<p><img src="/imgs/主成分分析/cifar_origin.png" alt></p>
<p><img src="/imgs/主成分分析/cifar_deconstruct.png" alt></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>参考：<a href="https://www.zhihu.com/question/47121788?sort=created" target="_blank" rel="noopener">为什么PCA不被推荐用来避免过拟合？</a></p>
<p>PCA是通用的数据降维操作，但在卷积神经网络处理中不推荐使用PCA作为预处理操作，因为在无监督降维过程中，一些关键结构信息会因为方差小而被处理掉</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>主成分分析</tag>
      </tags>
  </entry>
  <entry>
    <title>线性代数基础</title>
    <url>/posts/74e95c64.html</url>
    <content><![CDATA[<p>参考<a href="https://blog.csdn.net/u012005313/article/details/50877366" target="_blank" rel="noopener">PCA数学原理</a>，小结<code>PCA</code>求解过程中相关的线性代数基础（<em>部分几何内容+概率论内容</em>）</p><ul>
<li>内积</li>
<li>投影</li>
<li>向量的线性相关/线性无关</li>
<li>向量空间的基</li>
<li>线性变换和线性映射</li>
<li>矩阵降维</li>
<li>特征值和特征向量</li>
<li>正交向量组和正交矩阵</li>
<li>实对称矩阵</li>
</ul><a id="more"></a>

<h2 id="内积"><a href="#内积" class="headerlink" title="内积"></a>内积</h2><p>参考：<a href="https://baike.baidu.com/item/%E7%82%B9%E7%A7%AF/9648528?fromtitle=%E5%86%85%E7%A7%AF&amp;fromid=422863&amp;fr=aladdin" target="_blank" rel="noopener">点积</a></p>
<p>响亮的内积既可以由向量坐标的代数运算得出，也可以通过引入两个向量的长度和角度的几何概念来计算得到</p>
<h3 id="代数运算"><a href="#代数运算" class="headerlink" title="代数运算"></a>代数运算</h3><p>给定$n$个实向量$\alpha = (a_{1},a_{2},…,a_{n})^{T}, \beta = (b_{1},b_{2},…,b_{n})^{T}$，称实数</p>
<script type="math/tex; mode=display">
[\alpha, \beta] = a_{1}b_{1} + a_{2}b_{2} + ... + a_{n}b_{n}</script><p>为向量$\alpha$与$\beta$的内积</p>
<h3 id="几何运算"><a href="#几何运算" class="headerlink" title="几何运算"></a>几何运算</h3><p>给定$n$元实向量$\alpha = (a_{1}, a_{2}, …, a_{n})^{T}$，称</p>
<script type="math/tex; mode=display">
||\alpha|| = \sqrt{[\alpha, \alpha]}
= \sqrt{a_{1}^{2} + a_{2}^{2} + ... + a_{n}^{2}}</script><p>为向量$\alpha$的长度（范数或模）。长度为$1$的向量称为<strong>单位向量</strong>，对任一非零向量$\alpha$，向量$\frac {\alpha}{||\alpha||}$为单位向量，这一过程称为<strong>将向量$\alpha$单位化（或规范化/标准化）</strong></p>
<p>设$\alpha, \beta$为$n$元实非零向量，记</p>
<script type="math/tex; mode=display">
< \alpha, \beta > = \arccos \frac {[\alpha, \beta]}{||\alpha|| ||\beta||}, 0\leq <\alpha, \beta> \leq \pi</script><p>称$&lt;\alpha, \beta&gt;$为向量$\alpha$和$\beta$的夹角</p>
<p><strong>设二维空间有两个向量$\alpha$和$\beta$，则内积定义如下：</strong></p>
<script type="math/tex; mode=display">
\alpha\cdot \beta = ||\alpha|| ||\beta|| \cos \theta</script><p><em>该定义只对二维和三维空间有效</em></p>
<h2 id="投影"><a href="#投影" class="headerlink" title="投影"></a>投影</h2><p>参考：<a href="https://baike.baidu.com/item/%E6%8A%95%E5%BD%B1/7565?fr=aladdin" target="_blank" rel="noopener">投影</a></p>
<p>设两个非零向量$\alpha$和$\beta$的夹角为$\theta$，则将$||\beta||\cdot \cos \theta$叫做向量$\beta$在向量$\alpha$方向上的投影，也称为标投影（scalar projection），是一个标量</p>
<p>引入$\alpha$的单位矢量$\alpha(A)$，称$||\beta||\cdot \cos \theta\cdot \alpha(A)$为$\beta$在$\alpha$上的矢投影（vector projection），是一个向量</p>
<h3 id="投影和内积关系"><a href="#投影和内积关系" class="headerlink" title="投影和内积关系"></a>投影和内积关系</h3><p>设向量$\beta$为$1$，则$\alpha$和$\beta$的内积等于$\alpha$向$\beta$所在直线投影的长度</p>
<script type="math/tex; mode=display">
\alpha \cdot \beta = ||\alpha||\cdot \cos (\theta)</script><h2 id="向量的线性相关-线性无关"><a href="#向量的线性相关-线性无关" class="headerlink" title="向量的线性相关/线性无关"></a>向量的线性相关/线性无关</h2><p>设向量组$\alpha_{1},\alpha_{2},…,\alpha_{m}\in R^{n}$，如果存在一组不全为零的数$k_{1},k_{2},…,k_{m}$，满足</p>
<script type="math/tex; mode=display">
k_{1}\alpha_{1} + k_{2}\alpha_{2} + ... + k_{m}\alpha_{m} = 0</script><p>则称向量组$\alpha_{1}, \alpha_{2},…,\alpha_{m}$ <strong>线性相关</strong>；当且仅当$k_{1}=k_{2}=…=k_{m}=0$时上式才成立，则称向量组$\alpha_{1},\alpha_{2},…,\alpha_{m}$ <strong>线性无关</strong></p>
<p><strong>几何解释：在二维平面上，线性相关指向量在同一直线上，线性无关指向量不再同一直线上</strong></p>
<h2 id="向量空间的基"><a href="#向量空间的基" class="headerlink" title="向量空间的基"></a>向量空间的基</h2><p>设$V$是一个向量空间，$\alpha_{1},\alpha_{2},…,\alpha_{r}$是$V$中的<strong>一组向量</strong>，如果满足</p>
<ol>
<li>$\alpha_{1},\alpha_{2},…,\alpha_{r}$线性无关</li>
<li>$V$中的任一向量都可由$\alpha_{1},\alpha_{2},…,\alpha_{r}$线性表示</li>
</ol>
<p>则称$\alpha_{1},\alpha_{2},…,\alpha_{r}$是$V$中的一组<strong>基</strong>，数$r$称为$V$的维数，记作$dim(V)=r$，并称$V$是$r$维向量空间</p>
<h3 id="正交基"><a href="#正交基" class="headerlink" title="正交基"></a>正交基</h3><p>参考：</p>
<p><a href="https://baike.baidu.com/item/%E6%AD%A3%E4%BA%A4/36310" target="_blank" rel="noopener">正交</a></p>
<p><a href="https://baike.baidu.com/item/%E6%A0%87%E5%87%86%E6%AD%A3%E4%BA%A4%E5%9F%BA/4729576?fr=aladdin" target="_blank" rel="noopener">标准正交基</a></p>
<p>称基中的向量为基向量，如果基向量两两正交（<em>向量内积为0</em>），则称基为正交基，如果正交基的基向量的模长都是单位长度$1$，则称正交基为标准正交基</p>
<p><strong>正交基中各基向量线性无关</strong></p>
<h3 id="基变换与坐标变换"><a href="#基变换与坐标变换" class="headerlink" title="基变换与坐标变换"></a>基变换与坐标变换</h3><p>设$\alpha_{1}, \alpha_{2}, …, \alpha_{r}$和$\beta_{1}, \beta_{2}, …, \beta_{r}$为向量空间$V$的基，有</p>
<script type="math/tex; mode=display">
(\beta_{1}, \beta_{2}, ..., \beta_{r})
= (\alpha_{1}, \alpha_{2}, ..., \alpha_{r}) P_{r\times r}</script><p>称$r$阶矩阵$P$是由基$\alpha_{1}, \alpha_{2}, …, \alpha_{r}$到基$\beta_{1}, \beta_{2}, …, \beta_{r}$的过渡矩阵，称上式为<strong>基变换公式</strong></p>
<p><em>矩阵$P$是可逆矩阵</em></p>
<p>设$V$是向量空间，$\alpha_{1}, \alpha_{2}, …, \alpha_{r}$和$\beta_{1}, \beta_{2}, …, \beta_{r}$分别为$V$的基，且</p>
<script type="math/tex; mode=display">
X = (x_{1}, x_{2}, ..., x_{r})^{T}\\
Y = (y_{1}, y_{2}, ..., y_{r})^{T}</script><p>分别是向量$a$在$\alpha_{1}, \alpha_{2}, …, \alpha_{r}$和$\beta_{1}, \beta_{2}, …, \beta_{r}$的坐标，则有</p>
<script type="math/tex; mode=display">
X = PY \ 或\ Y = P^{-1}X</script><p>其中$P$是由基$\alpha_{1}, \alpha_{2}, …, \alpha_{r}$到基$\beta_{1}, \beta_{2}, …, \beta_{r}$的过渡矩阵，称上式为<strong>坐标变换公式</strong></p>
<h2 id="线性变换和线性映射"><a href="#线性变换和线性映射" class="headerlink" title="线性变换和线性映射"></a>线性变换和线性映射</h2><p>参考：<a href="https://baike.baidu.com/item/%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/5904192?fr=aladdin" target="_blank" rel="noopener">线性变换</a></p>
<p>线性变换（linear transformation）指线性空间$V$到其自身的线性映射，也就是坐标变换</p>
<p>线性映射（linear mapping）指从一个向量空间$V$到另一个向量空间$W$的映射且保持加法和数量乘法运算</p>
<h2 id="矩阵降维"><a href="#矩阵降维" class="headerlink" title="矩阵降维"></a>矩阵降维</h2><p>假设有$M$个$N$维向量组成的向量空间$P$，想要将其映射到由$R$个$N$维向量组成的向量空间$A$，则计算如下：</p>
<script type="math/tex; mode=display">
PA=
\begin{pmatrix}
p_{1}\\ 
p_{2}\\ 
\vdots \\ 
p_{M}
\end{pmatrix}
(a_{1}, a_{2}, \cdots, a_{R})
\in R^{M\times R}</script><p>其中$p_{i}$表示长度为$N$的行向量，$a_{j}$表示长度为$N$的列向量</p>
<p><strong>向量空间的矩阵乘法属于线性映射</strong></p>
<p><strong>如果$R$小于$M$，可以称线性映射为$P$到$A$的投影</strong></p>
<h2 id="特征值和特征向量"><a href="#特征值和特征向量" class="headerlink" title="特征值和特征向量"></a>特征值和特征向量</h2><p>设$A$是$n$阶方阵，若存在数$\lambda$和$n$维非零向量$X$，使得</p>
<script type="math/tex; mode=display">
AX = \lambda X</script><p>则称数$\lambda$为方阵$A$的<strong>特征值</strong>；非零向量$X$称为$A$的对应于特征值$\lambda$的<strong>特征向量</strong></p>
<h3 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h3><p>定理一：设$A$是$n$阶矩阵，则$A^{T}$与$A$有相同的特征值</p>
<p>定理二：设$\lambda_{1}, \lambda_{2}, …, \lambda_{n}$为$n$阶方阵$A=(a_{ij})$的$n$个特征值，则</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{n} \lambda_{i}
=\sum_{i=1}^{n} a_{ii}</script><script type="math/tex; mode=display">
\prod_{i=1}^{n} \lambda_{i}
=|A|</script><p><strong>其中$\sum_{i=1}^{n} a_{ii}$是$A$的主对角线元素之和，称为方阵$A$的迹，记作$tr(A)$</strong></p>
<p>定理三：不同特征值对应的特征向量线性无关，也就是两两正交</p>
<h3 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h3><p>求解方阵$A$的特征值与特征向量:</p>
<ol>
<li><p>计算$A$的特征多项式：$f(\lambda) = | A - \lambda E |$，其根$\lambda_{1}, \lambda_{2}, …, \lambda_{s}(\lambda_{i} \neq \lambda_{j})$就是$A$的$s$个不同的特征值</p>
</li>
<li><p>对每个特征值$\lambda_{i}, i=1,2,…,s$，解方程组$(A-\lambda_{i}E)X=0$，其基础解系就是$A$的对应于特征值$\lambda_{i}$的线性无关的特征向量，其非零解就是$A$的对应于特征值$\lambda_{i}$的全部特征向量</p>
</li>
</ol>
<h3 id="特征值和投影关系"><a href="#特征值和投影关系" class="headerlink" title="特征值和投影关系"></a>特征值和投影关系</h3><p>参考：<a href="https://www.zhihu.com/question/20507061?sort=created" target="_blank" rel="noopener">线性代数中，特征值与特征向量在代数和几何层面的实际意义是什么？</a></p>
<p>矩阵乘法$AX$相当于矩阵$A$在向量$X$上的投影，$\lambda$表示投影大小（以$X$为基）</p>
<p>特征值越大表示数据分布越广，离散程度大，所以其方差越大</p>
<h2 id="正交向量组和正交矩阵"><a href="#正交向量组和正交矩阵" class="headerlink" title="正交向量组和正交矩阵"></a>正交向量组和正交矩阵</h2><p><strong>什么是正交向量?</strong></p>
<p>设$\alpha, \beta$是两个$n$元实向量，若$[\lambda, \beta]=0$，则称$\lambda$和$\beta$正交（或垂直），记为$\alpha \perp \beta $</p>
<p>向量$\alpha$和$\beta$正交的充分必要条件是$||\alpha + \beta||^{2} = ||\alpha||^{2} + ||\beta||^{2}$</p>
<p><strong>什么是正交向量组?</strong></p>
<p>若不含零向量的向量组中任意两个向量都正交，则称此向量组为<strong>正交向量组</strong></p>
<p>由单位向量构成的正交向量组叫做<strong>正交单位向量组（规范正交向量组或标准正交向量组）</strong></p>
<p><strong>什么是正交矩阵？</strong></p>
<p>设$A$为$n$阶矩阵，如果$AA^{T}=E$，则称$A$为正交矩阵</p>
<p>$A$为正交矩阵的充分必要条件是$A$的列（或行）向量组是单位正交向量组</p>
<h3 id="正交向量组和基的关系"><a href="#正交向量组和基的关系" class="headerlink" title="正交向量组和基的关系"></a>正交向量组和基的关系</h3><p>大小为$n$的正交向量组两两正交，比线性无关，可以视为$n$维空间的正交基</p>
<p>所以正交单位向量组可以视为标准正交基</p>
<h2 id="实对称矩阵"><a href="#实对称矩阵" class="headerlink" title="实对称矩阵"></a>实对称矩阵</h2><p>定理一：设$A$为$n$阶实对称矩阵，$\lambda_{0}$是$A$的$r$重特征值，则$A$的属于特征值$\lambda_{0}$恰有$r$个线性无关的特征向量，即$R(A-\lambda_{0}E) = n-r$</p>
<p>定理二：设$A$为$n$阶实对称矩阵，则存在$n$阶正交矩阵$Q$，使得</p>
<script type="math/tex; mode=display">
Q^{-1}AQ = Q^{T}AQ = \Lambda = diag(\lambda_{1}, \lambda_{2}, ..., \lambda_{n})</script><p>其中$\lambda_{1}, \lambda_{2}, …, \lambda_{n}$为$A$的特征值</p>
<p>正交矩阵$Q$由特征值对应的特征向量正交化且单位化后组成，$Q$的第$j$列对应特征值$\lambda_{j}$</p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论基础</title>
    <url>/posts/b905521b.html</url>
    <content><![CDATA[<p>参考<a href="https://blog.csdn.net/u012005313/article/details/50877366" target="_blank" rel="noopener">PCA数学原理</a>，小结<code>PCA</code>求解过程中相关的概率论基础</p><h2 id="方差和协方差"><a href="#方差和协方差" class="headerlink" title="方差和协方差"></a>方差和协方差</h2><p>参考：<a href="https://baike.baidu.com/item/%E5%8D%8F%E6%96%B9%E5%B7%AE" target="_blank" rel="noopener">协方差</a></p><p>方差参考<a href="https://www.zhujian.tech/posts/3d82a363.html">方差 标准差</a>，用于衡量一组数据的离散程度，值越大，表示数据分布越广</p><a id="more"></a>


<script type="math/tex; mode=display">
Var(X) = D(X) = \frac {1}{N} \sum_{i=1}^{N}(x_{i} - \mu)^{2}</script><p>协方差用于判断两组数据之间的相关程度，直观上看，协方差是两个变量总体误差的期望</p>
<script type="math/tex; mode=display">
Cov(X,Y) = E[(X-E(X)(Y-E(Y))]
=\frac {1}{N} \sum_{i=1}^{N}(x_{i} - \mu_{x})(y_{i} - \mu_{y})</script><h3 id="协方差矩阵"><a href="#协方差矩阵" class="headerlink" title="协方差矩阵"></a>协方差矩阵</h3><p>参考：</p>
<p><a href="https://baike.baidu.com/item/%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5/4773879?fr=aladdin" target="_blank" rel="noopener">实对称矩阵</a></p>
<p><a href="https://baike.baidu.com/item/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5/9822183?fr=aladdin" target="_blank" rel="noopener">协方差矩阵</a></p>
<p>设$X=(X_{1}, X_{2}, …, X_{N})^{T}$为$n$维随机变量，称矩阵</p>
<script type="math/tex; mode=display">
C = (c_{ij})_{n\times n}
=\begin{pmatrix}
c_{11} & c_{12} & \cdots & c_{1n}\\ 
c_{21} & c_{22} & \cdots & c_{2n}\\ 
\vdots & \vdots & \vdots & \vdots\\ 
c_{n1} & c_{n2} & \cdots & c_{nn}
\end{pmatrix}</script><p>为$n$维随机变量$X$的协方差矩阵（covariance matrix），记为$D(X)$，其中</p>
<script type="math/tex; mode=display">
c_{ij} = Cov(X_{i}, X_{j}),i,j=1,2,...,n</script><p>为$X$的分量$X_{i}$和$X_{j}$的协方差</p>
<p>以二维随机变量(X_{1}, X_{2})为例，协方差为</p>
<script type="math/tex; mode=display">
C = \begin{pmatrix}
E[X_{1} - E(X_{1})]^{2} & E[X_{1} - E(X_{1})]E[X_{2} - E(X_{2})]\\
E[X_{2} - E(X_{2})]E[X_{1} - E(X_{1})] & E[X_{2} - E(X_{2})]^{2}
\end{pmatrix}</script><p>所以协方差矩阵是<strong>实对称矩阵</strong>（<em>元素为实数，矩阵转置等于本身</em>）</p>
<p>协方差矩阵$C$的对角元素$c_{ii}$表示变量$X_{i}$的方差，非对角元素$c_{ij}$表示变量$X_{i}$和$X_{j}$的协方差</p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title>Nesterov加速梯度</title>
    <url>/posts/e51acd5.html</url>
    <content><![CDATA[<p><code>Nesterov</code>加速梯度（<code>Nesterov&#39;s Accelerated Gradient</code>，简称<code>NAG</code>）是梯度下降的一种优化方法，其收敛速度比动量更新方法更快，收敛曲线更加稳定</p><a id="more"></a>
<h2 id="实现公式"><a href="#实现公式" class="headerlink" title="实现公式"></a>实现公式</h2><p><code>NAG</code>计算公式参考<a href="http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf" target="_blank" rel="noopener">On the importance of initialization and momentum in deep learning</a></p>
<script type="math/tex; mode=display">
w_{t-1}^{ahead} =w_{t-1} + \mu v_{t-1}\\ 
v_{t} = \mu v_{t-1} - lr \triangledown f(w_{t-1}^{ahead})\\
w_{t} = w_{t-1} + v_{t}</script><p>其实现和经典动量的区别在于 <strong>NAG计算的是当前权重加上累积速度后的梯度</strong></p>
<p><img src="/imgs/Nesterov加速梯度/cm_nag.png" alt></p>
<h3 id="替换公式"><a href="#替换公式" class="headerlink" title="替换公式"></a>替换公式</h3><p>实际使用过程中使用替换公式，参考<a href="http://cs231n.github.io/neural-networks-3/#sgd" target="_blank" rel="noopener">Neural Networks Part 3: Learning and Evaluation </a></p>
<script type="math/tex; mode=display">
w_{t} = w_{t-1} + v_{t}\\
\Rightarrow w_{t} +\mu v_{t} + \mu v_{t-1}= w_{t-1} + v_{t} + \mu v_{t} + \mu v_{t-1}\\
\Rightarrow w_{t}^{ahead} + \mu v_{t-1} = w_{t-1}^{ahead} + (1+\mu) v_{t}\\
\Rightarrow w_{t}^{ahead} = w_{t-1}^{ahead} + (1+\mu) v_{t} - \mu v_{t-1}\\</script><p>所以替换公式为</p>
<script type="math/tex; mode=display">
v_{t} = \mu v_{t-1} - lr \triangledown f(w_{t-1}^{ahead})\\
w_{t}^{ahead} = w_{t-1}^{ahead} + (1+\mu) v_{t} - \mu v_{t-1}</script><script type="math/tex; mode=display">
\Rightarrow</script><script type="math/tex; mode=display">
v_{t} = \mu v_{t-1} - lr \triangledown f(w_{t-1})\\
w_{t} = w_{t-1} + (1+\mu) v_{t} - \mu v_{t-1}</script><p>将使用的权重向量替换为权重向量加上累积速度后的权重值</p>
<h2 id="numpy测试"><a href="#numpy测试" class="headerlink" title="numpy测试"></a>numpy测试</h2><p>参考：<a href="https://www.zhujian.tech/posts/2b34c959.html#more">动量更新</a></p>
<h3 id="原始公式实现"><a href="#原始公式实现" class="headerlink" title="原始公式实现"></a>原始公式实现</h3><p><code>NAG</code>实现代码如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def sgd_nesterov(x_start, lr, epochs=100, mu=0.5):</span><br><span class="line">    dots = [x_start]</span><br><span class="line"></span><br><span class="line">    x = x_start.copy()</span><br><span class="line">    v = np.zeros((2))</span><br><span class="line">    for i in range(epochs):</span><br><span class="line">        x_ahead = x + mu * v</span><br><span class="line">        grad = gradient(x_ahead)</span><br><span class="line">        v = mu * v - lr * grad</span><br><span class="line">        x += v</span><br><span class="line">        dots.append(x.copy())</span><br><span class="line">        if abs(np.sum(grad)) &lt; 1e-6:</span><br><span class="line">            break</span><br><span class="line">    return np.array(dots)</span><br></pre></td></tr></table></figure>
<h4 id="SGD-vs-CM-vs-NAG"><a href="#SGD-vs-CM-vs-NAG" class="headerlink" title="SGD vs CM vs NAG"></a>SGD vs CM vs NAG</h4><p>学习率<code>1e-3</code>，动量因子<code>0.5</code>，迭代<code>100</code>次结果</p>
<p><img src="/imgs/Nesterov加速梯度/sgd_cm_nag_1.png" alt></p>
<p>学习率<code>1e-2</code>，动量因子<code>0.5</code>，迭代<code>100</code>次结果</p>
<p><img src="/imgs/Nesterov加速梯度/sgd_cm_nag_2.png" alt></p>
<p><strong>经典动量和NAG方法的收敛速度均比标准梯度下降更快</strong></p>
<h4 id="CM-vs-NAG"><a href="#CM-vs-NAG" class="headerlink" title="CM vs NAG"></a>CM vs NAG</h4><p>学习率<code>1e-3</code>，动量因子<code>0.9</code>，迭代<code>100</code>次结果</p>
<p><img src="/imgs/Nesterov加速梯度/cm_nag_1.png" alt></p>
<p>学习率<code>1e-2</code>，动量因子<code>0.9</code>，迭代<code>100</code>次结果</p>
<p><img src="/imgs/Nesterov加速梯度/cm_nag_2.png" alt></p>
<p><strong>NAG方法的收敛曲线比经典动量方法更稳定</strong></p>
<h3 id="替换公式实现"><a href="#替换公式实现" class="headerlink" title="替换公式实现"></a>替换公式实现</h3><p>替换公式实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def sgd_nesterov_v2(x_start, lr, epochs=100, mu=0.5):</span><br><span class="line">    dots = [x_start]</span><br><span class="line"></span><br><span class="line">    x = x_start.copy()</span><br><span class="line">    v = 0</span><br><span class="line">    for i in range(epochs):</span><br><span class="line">        grad = gradient(x)</span><br><span class="line">        v_prev = v</span><br><span class="line">        v = mu * v - lr * grad</span><br><span class="line">        x += (1 + mu) * v - mu * v_prev</span><br><span class="line">        dots.append(x.copy())</span><br><span class="line">        if abs(np.sum(grad)) &lt; 1e-6:</span><br><span class="line">            break</span><br><span class="line">    return np.array(dots)</span><br></pre></td></tr></table></figure>
<h4 id="NAG-vs-NAG-alter"><a href="#NAG-vs-NAG-alter" class="headerlink" title="NAG vs NAG_alter"></a>NAG vs NAG_alter</h4><p>学习率<code>1e-3</code>，动量因子<code>0.9</code>，迭代<code>100</code>次结果</p>
<p><img src="/imgs/Nesterov加速梯度/nag_alter_1.png" alt></p>
<p>学习率<code>1e-2</code>，动量因子<code>0.9</code>，迭代<code>100</code>次结果</p>
<p><img src="/imgs/Nesterov加速梯度/nag_alter_2.png" alt></p>
<p>学习率<code>1e-2</code>，动量因子<code>0.5</code>，迭代<code>100</code>次结果</p>
<p><img src="/imgs/Nesterov加速梯度/nag_alter_3.png" alt></p>
<h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><p><a href="https://jlmelville.github.io/mize/nesterov.html" target="_blank" rel="noopener">Nesterov Accelerated Gradient and Momentum</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/22810533" target="_blank" rel="noopener">比Momentum更快：揭开Nesterov Accelerated Gradient的真面目</a></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>最优化</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>动量更新</tag>
      </tags>
  </entry>
  <entry>
    <title>动量更新</title>
    <url>/posts/2b34c959.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">Neural Networks Part 3: Learning and Evaluation </a></p><a id="more"></a>

<p><a href="https://zhuanlan.zhihu.com/p/21798784?refer=intelligentunit" target="_blank" rel="noopener">CS231n课程笔记翻译：神经网络笔记3（下）</a></p>
<p><a href="http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf" target="_blank" rel="noopener">On the importance of initialization and momentum in deep learning</a></p>
<p>动量（<code>momentum</code>）更新是梯度下降的一种优化方法，它能够加快损失函数收敛速度（<code>converge rate</code>）</p>
<h2 id="标准梯度下降"><a href="#标准梯度下降" class="headerlink" title="标准梯度下降"></a>标准梯度下降</h2><p>标准梯度下降公式如下：</p>
<script type="math/tex; mode=display">
w_{t} = w_{t-1} - lr\triangledown f(w_{t-1})</script><p>$lr$是固定值，表示步长，所以在假设梯度不变的情况下，每次更新沿着参数的负梯度方向前进固定步长</p>
<h2 id="经典动量"><a href="#经典动量" class="headerlink" title="经典动量"></a>经典动量</h2><p>经典动量（<code>classical momentum</code>，简称<code>CM</code>）公式如下</p>
<script type="math/tex; mode=display">
v_{t} = \mu v_{t-1} - lr\triangledown f(w_{t-1}) \\
w_{t} = w_{t-1} + v_{t}</script><p>$v$表示速度，初始化为0</p>
<p>$\mu$表示动量因子（<code>momentum coefficient</code>），大小为$[0,1]$，表示当前权重变化受过去累计梯度的影响</p>
<h3 id="物理视角"><a href="#物理视角" class="headerlink" title="物理视角"></a>物理视角</h3><p>参考：<a href="http://cs231n.github.io/neural-networks-3/#sgd" target="_blank" rel="noopener">Momentum update</a></p>
<p>从物理视角看损失函数收敛问题，将损失值看成丘陵地形（<code>hilly terrain</code>）的高度。对于初始化权重（$w$）而言，它相当于设置在某个位置的初始速度（<code>initial velocity</code> ）为<code>0</code>的粒子（<code>particle</code>）。所以优化过程（<code>optimization process</code>）等同于模拟粒子在陆地上滚动的过程</p>
<p>驱动粒子滚动的力就是势能负梯度（$F = -\triangledown U$），对于势能（$U=mgh$）而言，它和高度（$h$）呈正相关（$U\propto h$）</p>
<p>在标准梯度下降中，势能梯度直接用于修改粒子滚动的距离</p>
<p>在经典动量中，将力作用于粒子的速度和方向（$F=ma$），再间接影响滚动的距离</p>
<p><img src="/imgs/动量/momentum_step.png" alt></p>
<p><strong>当力作用方向和累计速度方向一致时，就能够加快粒子滚动速度；与此同时，当力作用方向和累积速度方向不一致时，无法立刻修改粒子滚动方向，造成收敛曲线振荡</strong></p>
<h3 id="加速倍率"><a href="#加速倍率" class="headerlink" title="加速倍率"></a>加速倍率</h3><p>和标准梯度下降相比，经典动量能够加快损失值收敛速度。参考<a href="https://zhuanlan.zhihu.com/p/21486826" target="_blank" rel="noopener">路遥知马力——Momentum</a>，计算极限情况下加速倍率</p>
<p>对于标准梯度下降而言</p>
<script type="math/tex; mode=display">
w_{1} = w_{0} - lr\triangledown f(w_{0})\\
w_{2} = w_{1} - lr\triangledown f(w_{1})
=w_{0} - lr\triangledown f(w_{0})- lr\triangledown f(w_{1})\\
w_{3} = w_{2} - lr\triangledown f(w_{2})
=w_{0} - lr\triangledown f(w_{0})- lr\triangledown f(w_{1})- lr\triangledown f(w_{2})\\
...\\
\Rightarrow w_{t} = w_{0} - lr(\triangledown f(w_{0}) + \triangledown f(w_{1}) + ... + \triangledown f(w_{t-1}))</script><p>对于经典动量更新而言</p>
<script type="math/tex; mode=display">
v_{1} = \mu v_{0} - lr\triangledown f(w_{0}) = - lr\triangledown f(w_{0})\\
w_{1} = w_{0} + v_{1}</script><script type="math/tex; mode=display">
v_{2} = \mu v_{1} - lr\triangledown f(w_{1})\\
w_{2} = w_{1} + v_{2}
=w_{0} + v_{1} + v_{2}\\
=w_{0} + v_{1} + \mu v_{1} - lr\triangledown f(w_{1})
=w_{0} + (1+\mu)v_{1} - lr\triangledown f(w_{1})\\
=w_{0} - (1+\mu)lr\triangledown f(w_{0}) - lr\triangledown f(w_{1})</script><script type="math/tex; mode=display">
v_{3} = \mu v_{2} - lr\triangledown f(w_{2})\\
w_{3} = w_{2} + v_{3}\\
=w_{0} - (1 + \mu + \mu^{2})lr\triangledown f(w_{0}) - (1+\mu)lr\triangledown f(w_{1}) - lr\triangledown f(w_{2})</script><script type="math/tex; mode=display">
...</script><script type="math/tex; mode=display">
v_{t} = \mu v_{t-1} - lr\triangledown f(w_{t-1})\\
w_{t} = w_{t-1} + v_{t}\\
=w_{0} - (1 + \mu + \mu^{2} + ... + \mu^{t-1})lr\triangledown f(w_{0}) - (1 + \mu + \mu^{2} + ... + \mu^{t-2})lr\triangledown f(w_{1}) - ... - lr\triangledown f(w_{t-1})</script><p>以$\triangledown f(w_{0})$为例</p>
<script type="math/tex; mode=display">
1 + \mu + \mu^{2} + ... + \mu^{t-1}</script><p>参考<a href="https://zh.wikipedia.org/wiki/%E7%AD%89%E6%AF%94%E6%95%B0%E5%88%97" target="_blank" rel="noopener">等比数列</a>求和公式</p>
<script type="math/tex; mode=display">
S_{n} = a_{1}\frac {1-q^{n}}{1-q}
\Rightarrow S_{t} = \frac {1-\mu^{t-1}}{1-\mu}</script><ul>
<li>当$\mu=0.5$时，$S_{t}=2$</li>
<li>当$\mu=0.9$时，$S_{t}=10$</li>
<li>当$\mu=0.99$时，$S_{t}=100$</li>
</ul>
<p>也就是说，在极限状态下，当$\mu$取值为$0.5,0.9,0.99$时，动量更新比标准梯度下降方法加快了$2,10,100$倍</p>
<h3 id="跳出局部最小值"><a href="#跳出局部最小值" class="headerlink" title="跳出局部最小值"></a>跳出局部最小值</h3><p>参考<a href="https://www.willamette.edu/~gorr/classes/cs449/momrate.html" target="_blank" rel="noopener">Momentum and Learning Rate Adaptation</a>，动量更新相比于标准梯度下降而言还有一个优点是它有可能能够跳出局部最小（<code>local minima</code>）点，找到全局最小（<code>global minima</code>）点</p>
<p><img src="/imgs/动量/minima.png" alt></p>
<h2 id="numpy测试"><a href="#numpy测试" class="headerlink" title="numpy测试"></a>numpy测试</h2><p>比较标准梯度下降和经典动量更新的损失值收敛梯度，比较不同动量因子（$\mu$）的收敛速度</p>
<p>高度计算公式为</p>
<script type="math/tex; mode=display">
h = x^{2} + 50y^{2}</script><h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-5-30 上午9:59</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">动量测试</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def height(x, y):</span><br><span class="line">    return x ** 2 + 50 * y ** 2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def gradient(x):</span><br><span class="line">    return np.array([2 * x[0], 100 * x[1]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def sgd(x_start, lr, epochs=100):</span><br><span class="line">    dots = [x_start]</span><br><span class="line"></span><br><span class="line">    x = x_start.copy()</span><br><span class="line">    for i in range(epochs):</span><br><span class="line">        grad = gradient(x)</span><br><span class="line">        x -= grad * lr</span><br><span class="line">        dots.append(x.copy())</span><br><span class="line">        if abs(np.sum(grad)) &lt; 1e-6:</span><br><span class="line">            break</span><br><span class="line">    return np.array(dots)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def sgd_momentum(x_start, lr, epochs=100, mu=0.5):</span><br><span class="line">    dots = [x_start]</span><br><span class="line"></span><br><span class="line">    x = x_start.copy()</span><br><span class="line">    v = 0</span><br><span class="line">    for i in range(epochs):</span><br><span class="line">        grad = gradient(x)</span><br><span class="line">        v = v * mu - lr * grad</span><br><span class="line">        x += v</span><br><span class="line">        dots.append(x.copy())</span><br><span class="line">        if abs(np.sum(grad)) &lt; 1e-6:</span><br><span class="line">            break</span><br><span class="line">        # if k &lt; 0.9:</span><br><span class="line">        #     k += 0.01</span><br><span class="line">    return np.array(dots)</span><br></pre></td></tr></table></figure>
<h3 id="sgd-vs-momentum"><a href="#sgd-vs-momentum" class="headerlink" title="sgd vs momentum"></a>sgd vs momentum</h3><p>设定学习率为<code>0.001/0.01</code>，动量因子为<code>0.5</code>，迭代<code>100</code>次的收敛情况</p>
<p><img src="/imgs/动量/sgd_loss.png" alt></p>
<p><img src="/imgs/动量/momentum_loss.png" alt></p>
<p><img src="/imgs/动量/sgd_momentum_loss.png" alt></p>
<p><strong>由结果可知，相同学习率和迭代数的情况下动量更新能够比标准梯度下降达到更快的收敛速度</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def draw(X, Y, Z, *arr):</span><br><span class="line">    sgd_dot_list, sgd_label_list, momentum_dot_list, momentum_label_list = arr</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(figsize=(10, 5))</span><br><span class="line"></span><br><span class="line">    plt.subplot(121)</span><br><span class="line">    item = sgd_dot_list[0]</span><br><span class="line">    label = sgd_label_list[0]</span><br><span class="line">    plt.plot(item[:, 0], item[:, 1], label=label)</span><br><span class="line"></span><br><span class="line">    item = momentum_dot_list[0]</span><br><span class="line">    label = momentum_label_list[0]</span><br><span class="line">    plt.plot(item[:, 0], item[:, 1], label=label)</span><br><span class="line"></span><br><span class="line">    plt.contour(X, Y, Z, colors=&apos;black&apos;)</span><br><span class="line">    plt.scatter(0, 0)</span><br><span class="line">    plt.legend()</span><br><span class="line"></span><br><span class="line">    plt.subplot(122)</span><br><span class="line">    item = sgd_dot_list[1]</span><br><span class="line">    label = sgd_label_list[1]</span><br><span class="line">    plt.plot(item[:, 0], item[:, 1], label=label)</span><br><span class="line"></span><br><span class="line">    item = momentum_dot_list[1]</span><br><span class="line">    label = momentum_label_list[1]</span><br><span class="line">    plt.plot(item[:, 0], item[:, 1], label=label)</span><br><span class="line"></span><br><span class="line">    plt.contour(X, Y, Z, colors=&apos;black&apos;)</span><br><span class="line">    plt.scatter(0, 0)</span><br><span class="line">    plt.legend()</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    x = np.linspace(-200, 200, 1000)</span><br><span class="line">    y = np.linspace(-100, 100, 1000)</span><br><span class="line">    X, Y = np.meshgrid(x, y)</span><br><span class="line">    Z = height(X, Y)</span><br><span class="line"></span><br><span class="line">    x_start = np.array([180, 90], dtype=np.float)</span><br><span class="line">    epochs = 100</span><br><span class="line">    mu = 0.5</span><br><span class="line">    lr_list = [1e-3, 1e-2]</span><br><span class="line">    sgd_label_list = [&apos;sgd 1e-3&apos;, &apos;sgd 1e-2&apos;]</span><br><span class="line">    momentum_label_list = [&apos;momentum 1e-3 k=0.5&apos;, &apos;momentum 1e-2 k=0.5&apos;]</span><br><span class="line">    sgd_dot_list = []</span><br><span class="line">    momentum_dot_list = []</span><br><span class="line">    for item in lr_list:</span><br><span class="line">        sgd_dot_list.append(sgd(x_start, item, epochs=epochs))</span><br><span class="line">        momentum_dot_list.append(sgd_momentum(x_start, item, epochs=epochs, mu=mu))</span><br><span class="line"></span><br><span class="line">    draw(X, Y, Z, sgd_dot_list, sgd_label_list, momentum_dot_list, momentum_label_list)</span><br></pre></td></tr></table></figure>
<h3 id="不同动量因子"><a href="#不同动量因子" class="headerlink" title="不同动量因子"></a>不同动量因子</h3><p>设定学习率为<code>0.001</code>，动量因子为<code>0.1/0.5,0.9</code>，计算迭代<code>100</code>次后的收敛情况</p>
<p><img src="/imgs/动量/momentum_1.png" alt></p>
<p>设定学习率为<code>0.01</code>，动量因子为<code>0.1/0.5,0.9</code>，计算迭代<code>100</code>次后的收敛情况</p>
<p><img src="/imgs/动量/momentum_2.png" alt></p>
<p><strong>从训练结果可知，动量因子增大能够加快收敛速度，但同时收敛曲线更加动荡</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def draw(X, Y, Z, *arr):</span><br><span class="line">    momentum_dot_list, momentum_label_list = arr</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(figsize=(15, 5))</span><br><span class="line"></span><br><span class="line">    plt.subplot(131)</span><br><span class="line">    item = momentum_dot_list[0]</span><br><span class="line">    label = momentum_label_list[0]</span><br><span class="line">    plt.plot(item[:, 0], item[:, 1], label=label)</span><br><span class="line"></span><br><span class="line">    plt.contour(X, Y, Z, colors=&apos;black&apos;)</span><br><span class="line">    plt.scatter(0, 0)</span><br><span class="line">    plt.legend()</span><br><span class="line"></span><br><span class="line">    plt.subplot(132)</span><br><span class="line">    item = momentum_dot_list[1]</span><br><span class="line">    label = momentum_label_list[1]</span><br><span class="line">    plt.plot(item[:, 0], item[:, 1], label=label)</span><br><span class="line"></span><br><span class="line">    plt.contour(X, Y, Z, colors=&apos;black&apos;)</span><br><span class="line">    plt.scatter(0, 0)</span><br><span class="line">    plt.legend()</span><br><span class="line"></span><br><span class="line">    plt.subplot(133)</span><br><span class="line">    item = momentum_dot_list[2]</span><br><span class="line">    label = momentum_label_list[2]</span><br><span class="line">    plt.plot(item[:, 0], item[:, 1], label=label)</span><br><span class="line"></span><br><span class="line">    plt.contour(X, Y, Z, colors=&apos;black&apos;)</span><br><span class="line">    plt.scatter(0, 0)</span><br><span class="line">    plt.legend()</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    x = np.linspace(-200, 200, 1000)</span><br><span class="line">    y = np.linspace(-100, 100, 1000)</span><br><span class="line">    X, Y = np.meshgrid(x, y)</span><br><span class="line">    Z = height(X, Y)</span><br><span class="line"></span><br><span class="line">    x_start = np.array([180, 90], dtype=np.float)</span><br><span class="line">    epochs = 100</span><br><span class="line">    mu_list = [0.1, 0.5, 0.9]</span><br><span class="line">    momentum_label_list = [&apos;momentum lr=1e-3 mu=0.1&apos;, &apos;momentum lr=1e-3 mu=0.5&apos;, &apos;momentum lr=1e-3 mu=0.9&apos;]</span><br><span class="line">    momentum_dot_list = []</span><br><span class="line">    for item in mu_list:</span><br><span class="line">        momentum_dot_list.append(sgd_momentum(x_start, 1e-2, epochs=epochs, mu=item))</span><br><span class="line"></span><br><span class="line">    draw(X, Y, Z, momentum_dot_list, momentum_label_list)</span><br></pre></td></tr></table></figure>
<h3 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h3><p>动量因子增大能够带来更快的收敛速度，同时也带来了更动荡的收敛曲线</p>
<p>造成收敛曲线不稳定的原因在于累计速度和当前更新方向不一致，这是因为早期小批量图片计算的梯度不能够正确拟合全部图片导致的</p>
<p>参考<a href="https://www.zhujian.tech/posts/936eda30.html#more">学习率退火</a>，在早期设置一个较小的动量因子，随着迭代次数增加慢慢增大。比如设置<code>mu=0.5</code>，每轮迭代增加<code>0.01</code>，当<code>mu=0,99</code>时不再增加</p>
<p><img src="/imgs/动量/momentum_optim.png" alt></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def sgd_momentum_v2(x_start, lr, epochs=100):</span><br><span class="line">    dots = [x_start]</span><br><span class="line"></span><br><span class="line">    x = x_start.copy()</span><br><span class="line">    v = 0</span><br><span class="line">    mu = 0.5</span><br><span class="line">    for i in range(epochs):</span><br><span class="line">        grad = gradient(x)</span><br><span class="line">        v = v * mu - lr * grad</span><br><span class="line">        x += v</span><br><span class="line">        dots.append(x.copy())</span><br><span class="line">        if abs(np.sum(grad)) &lt; 1e-6:</span><br><span class="line">            break</span><br><span class="line">        if mu &lt; 0.99:</span><br><span class="line">            mu += 0.01</span><br><span class="line">    return np.array(dots)</span><br></pre></td></tr></table></figure>
<h2 id="pytorch实现"><a href="#pytorch实现" class="headerlink" title="pytorch实现"></a>pytorch实现</h2><p><a href="https://pytorch.org/docs/stable/optim.html?highlight=optim%20sgd#torch.optim.SGD" target="_blank" rel="noopener">torch.optim.SGD</a>实现的动量更新公式有别于经典动量，使用的是重球法（<code>heavy ball method</code>，简称<code>HBM</code>）</p>
<script type="math/tex; mode=display">
v_{t} = \mu v_{t-1} + \triangledown f(w_{t-1})\\
w_{t} = w_{t-1} - lr v_{t}</script><p>其效果和经典动量类似</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def sgd_momentum_v3(x_start, lr, epochs=100, mu=0.5):</span><br><span class="line">    dots = [x_start]</span><br><span class="line"></span><br><span class="line">    x = x_start.copy()</span><br><span class="line">    v = 0</span><br><span class="line">    for i in range(epochs):</span><br><span class="line">        grad = gradient(x)</span><br><span class="line">        v = v * mu + grad</span><br><span class="line">        x -= lr * v</span><br><span class="line">        dots.append(x.copy())</span><br><span class="line">        if abs(np.sum(grad)) &lt; 1e-6:</span><br><span class="line">            break</span><br><span class="line">        &lt;!-- if mu &lt; 0.99:</span><br><span class="line">            mu += 0.01 --&gt;</span><br><span class="line">    return np.array(dots)</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/动量/hbm_1.png" alt></p>
<p><img src="/imgs/动量/hbm_2.png" alt></p>
<p><img src="/imgs/动量/hbm_3.png" alt></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>动量更新方法能够有效的加速训练过程，但需要注意学习率和动量因子的配合</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>最优化</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>动量更新</tag>
      </tags>
  </entry>
  <entry>
    <title>学习率退火</title>
    <url>/posts/936eda30.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="http://cs231n.github.io/neural-networks-3/#anneal" target="_blank" rel="noopener">Annealing the learning rate</a></p><p><a href="https://zhuanlan.zhihu.com/p/21798784" target="_blank" rel="noopener">学习率退火</a></p><p>在标准随机梯度下降过程中，每次更新使用固定学习率（<code>learning rate</code>），迭代一定次数后损失值不再下降，一种解释是因为权重在最优点周围打转，如果能够在迭代过程中减小学习率，就能够更加接近最优点，实现更高的检测精度</p><a id="more"></a>



<p>学习率退火（<code>annealing the learning rate</code>）属于优化策略的一种，有<code>3</code>种方式实现学习率随时间下降</p>
<ol>
<li>随步数衰减（<code>step decay</code>）</li>
<li>指数衰减（<code>exponential decay</code>）</li>
<li><code>1/t</code>衰减（<code>1/t decay</code>）</li>
</ol>
<p>下面介绍这<code>3</code>种学习率退火实现，然后用<code>numpy</code>编程进行验证</p>
<h2 id="随步数衰减"><a href="#随步数衰减" class="headerlink" title="随步数衰减"></a>随步数衰减</h2><p>随步数衰减（<code>step decay</code>）指的是多次迭代后降低学习率再继续迭代</p>
<p>如果选择固定迭代次数，实现公式如下：</p>
<script type="math/tex; mode=display">
lr = lr_{0} * \beta^{t/T}</script><ul>
<li>$lr$表示学习率</li>
<li>$lr_{0}$表示初始学习率</li>
<li>$\beta$表示衰减因子，通常是0.5</li>
<li>$t$表示迭代次数</li>
<li>$T$是一个常量，表示迭代次数</li>
</ul>
<p>其中$t/T$是一个整数除法，比如$2/4=0, 5/4=1$</p>
<p>迭代多少次才进行学习率衰减取决于实际问题和模型，如果无法确定可以先打印出标准的随机梯度下降过程的验证集误差（<code>val error</code>），选择验证集误差不再下降的时候降低学习率</p>
<h2 id="指数衰减"><a href="#指数衰减" class="headerlink" title="指数衰减"></a>指数衰减</h2><p>指数衰减（<code>exponential decay</code>）指的是学习率随迭代次数指数下降，数学公式如下：</p>
<script type="math/tex; mode=display">
lr = lr_{0} e^{-kt}</script><ul>
<li>$lr$表示学习率</li>
<li>$lr_{0}$表示初始学习率</li>
<li>$k$表示衰减因子</li>
<li>$t$是迭代次数</li>
</ul>
<p>其衰减速度随指数下降，一方面可以提高初始学习率，另一方面可以结合随步数衰减策略，多次迭代后再衰减，这样可以探索更大的权重空间</p>
<h2 id="1-t衰减"><a href="#1-t衰减" class="headerlink" title="1/t衰减"></a>1/t衰减</h2><p><code>1/t</code>衰减实现公式如下：</p>
<script type="math/tex; mode=display">
lr = lr_{0}/(1+kt)</script><ul>
<li>$lr$表示学习率</li>
<li>$lr_{0}$表示初始学习率</li>
<li>$k$表示衰减因子</li>
<li>$t$是迭代次数</li>
</ul>
<h2 id="衰减比较"><a href="#衰减比较" class="headerlink" title="衰减比较"></a>衰减比较</h2><p>假定初始学习率为<code>1e-3</code>，衰减因子<code>k=0.5</code>，随步长衰减方式每隔<code>10</code>次迭代衰减一次，结果如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    lr = 1e-3</span><br><span class="line">    k = 0.5</span><br><span class="line">    a = np.repeat(np.arange(10), 10)</span><br><span class="line">    print(a)</span><br><span class="line"></span><br><span class="line">    x = np.arange(0, 100)</span><br><span class="line">    y1 = lr * np.power(k, a)</span><br><span class="line">    y2 = lr * np.exp(x * k * -1)</span><br><span class="line">    y3 = lr / (1 + k * x)</span><br><span class="line"></span><br><span class="line">    plt.title(&apos;初始学习率1e-3，衰减因子k=0.5&apos;)</span><br><span class="line">    plt.plot(x, y1, label=&apos;step decay&apos;)</span><br><span class="line">    plt.plot(x, y2, label=&apos;exponential decay&apos;)</span><br><span class="line">    plt.plot(x, y3, label=&apos;1/t decay&apos;)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/学习率退火/annealing.png" alt></p>
<p>从数值上看，指数衰减最快，随步长衰减最不平滑，<code>1/t</code>衰减是前<code>2</code>者的折中</p>
<p>从概念上看，随步长衰减最具解释性</p>
<h2 id="Iris分类"><a href="#Iris分类" class="headerlink" title="Iris分类"></a>Iris分类</h2><p>参考<a href="https://www.zhujian.tech/posts/ba2ca878.html">iris数据集</a>，使用3层神经网络实现<code>Iris</code>数据集分类</p>
<p>网络和训练参数如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 批量大小</span><br><span class="line">N = 120</span><br><span class="line"># 输入维数</span><br><span class="line">D = 4</span><br><span class="line"># 隐藏层大小</span><br><span class="line">H1 = 20</span><br><span class="line">H2 = 20</span><br><span class="line"># 输出类别</span><br><span class="line">K = 3</span><br><span class="line"></span><br><span class="line"># 学习率</span><br><span class="line">learning_rate = 5e-2</span><br><span class="line"># 正则化强度</span><br><span class="line">lambda_rate = 1e-3</span><br></pre></td></tr></table></figure>
<p>训练<code>1</code>万次得到最好的训练集精度<code>98.33%</code>，验证集精度为<code>100.00%</code></p>
<p>使用随步数衰减方法，设置初始学习率为<code>1e-3</code>，每隔<code>1</code>万次迭代降低一半学习率</p>
<p><img src="/imgs/学习率退火/iris_loss.png" alt></p>
<p><img src="/imgs/学习率退火/iris_accuracy.png" alt></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">epoch: 23500 loss: 0.017741</span><br><span class="line">epoch: 24000 loss: 0.018153</span><br><span class="line">epoch: 24500 loss: 0.018558</span><br><span class="line">epoch: 25000 loss: 0.018764</span><br><span class="line">epoch: 25500 loss: 0.018719</span><br><span class="line">loss: [0.7379489541275116, 0.20908036151565673, 0.10376114688270188, 0.08329572639151012, 0.07412643490314004, 0.07430345900744695, 0.07329295342743611, 0.06805091543927848, 0.07108344457821464, 0.08216043914493876, 0.07653607556430879, 0.07156388982573988, 0.07343534475625284, 0.07208068217751779, 0.0720487384083792, 0.07222908671895177, 0.06718030446399169, 0.06926601609539103, 0.06213898417682324, 0.048173863501391634, 0.04090511152968822, 0.039191952291425525, 0.03774620932625705, 0.036470436045793926, 0.03520645248822737, 0.0339090050684377, 0.03254478210455497, 0.03136029152475116, 0.03083107298989087, 0.031088612177247885, 0.031830754113294016, 0.03244430157874315, 0.032756847542928104, 0.0328499065045292, 0.03287723349959883, 0.03279460842225148, 0.03199686035899375, 0.031768831964163566, 0.03155549009925631, 0.03148352140369718, 0.020641865478458574, 0.019643064986634092, 0.018938254489189885, 0.018306088376815275, 0.018001452040576762, 0.017746890705130948, 0.017741358711630295, 0.018153272132707534, 0.018558267622501148, 0.018764374296570147, 0.01871930452412146]</span><br><span class="line">train: [0.7, 0.9416666666666667, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.9333333333333333, 0.975, 0.975, 0.975, 0.975, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.9416666666666667, 0.9833333333333333, 0.9833333333333333, 0.975, 0.975, 0.975, 0.975, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9833333333333333, 0.9916666666666667, 0.9916666666666667, 0.9916666666666667, 0.9916666666666667, 0.9916666666666667, 0.9916666666666667, 0.9916666666666667, 0.9916666666666667, 0.9916666666666667, 0.9916666666666667, 1.0]</span><br><span class="line">test: [0.6, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</span><br></pre></td></tr></table></figure>
<p>共训练<code>25500</code>次实现<code>100%</code>的训练集精度和测试集精度</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    x_train, x_test, y_train, y_test = load_data(shuffle=True, tsize=0.8)</span><br><span class="line"></span><br><span class="line">    net = ThreeLayerNet(D, H1, H2, K)</span><br><span class="line">    criterion = CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    train_list = []</span><br><span class="line">    test_list = []</span><br><span class="line">    total_loss = 0</span><br><span class="line">    for i in range(epochs):</span><br><span class="line">        scores = net(x_train)</span><br><span class="line">        total_loss += criterion(scores, y_train)</span><br><span class="line"></span><br><span class="line">        grad_out = criterion.backward()</span><br><span class="line">        net.backward(grad_out)</span><br><span class="line">        net.update(lr=learning_rate, reg=0)</span><br><span class="line"></span><br><span class="line">        if (i % 500) == 499:</span><br><span class="line">            print(&apos;epoch: %d loss: %f&apos; % (i + 1, total_loss / 500))</span><br><span class="line">            loss_list.append(total_loss / 500)</span><br><span class="line">            total_loss = 0</span><br><span class="line"></span><br><span class="line">            train_accuracy = compute_accuracy(scores, y_train)</span><br><span class="line">            test_accuracy = compute_accuracy(net(x_test), y_test)</span><br><span class="line">            train_list.append(train_accuracy)</span><br><span class="line">            test_list.append(test_accuracy)</span><br><span class="line">            if train_accuracy &gt;= 0.9999 and test_accuracy &gt;= 0.9999:</span><br><span class="line">                save_params(net.get_params(), path=&apos;three_layer_net_iris.pkl&apos;)</span><br><span class="line">                break</span><br><span class="line">        if (i % 10000) == 9999:</span><br><span class="line">            # 每隔10000次降低学习率</span><br><span class="line">            learning_rate *= 0.5</span><br></pre></td></tr></table></figure>
<p>完整代码：<a href="https://github.com/zjZSTU/PyNet/blob/master/src/three_layer_net_iris.py" target="_blank" rel="noopener"> PyNet/src/three_layer_net_iris.py </a></p>
<p>参数地址：<a href="https://github.com/zjZSTU/PyNet/blob/master/model/three_layer_net_iris.pkl" target="_blank" rel="noopener"> PyNet/model/three_layer_net_iris.pkl </a></p>
<h2 id="Pytorch实现"><a href="#Pytorch实现" class="headerlink" title="Pytorch实现"></a>Pytorch实现</h2><p><code>Pytorch</code>提供模块<a href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate" target="_blank" rel="noopener">torch.optim.lr_scheduler</a>用于学习率退火实现</p>
<p>参考<a href="https://discuss.pytorch.org/t/how-to-use-torch-optim-lr-scheduler-exponentiallr/12444" target="_blank" rel="noopener">How to use torch.optim.lr_scheduler.ExponentialLR?</a>，<code>lr_scheduler</code>的<code>step</code>方法仅用于更新学习率，和反向传播无关</p>
<h3 id="随步长衰减"><a href="#随步长衰减" class="headerlink" title="随步长衰减"></a>随步长衰减</h3><p>有<code>3</code>种方法</p>
<ol>
<li>LambdaLR</li>
<li>StepLR</li>
<li>MultiStepLR</li>
</ol>
<h4 id="LambdaLR"><a href="#LambdaLR" class="headerlink" title="LambdaLR"></a>LambdaLR</h4><blockquote>
<p>class torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-1)</p>
</blockquote>
<ul>
<li><code>optimizer</code>是优化器</li>
<li><code>lr_lambda</code>是<code>lambda</code>函数，输入为迭代次数，用于计算衰减率</li>
</ul>
<p>每次迭代都通过<code>lambda</code>函数计算新的衰减率，再乘以初始学习率就是当前学习率</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-6-7 下午4:30</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">from torch.optim.lr_scheduler import LambdaLR</span><br><span class="line">import torch.optim as optim</span><br><span class="line">import torch.nn as nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Net(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.fc = nn.Linear(32, 12)</span><br><span class="line"></span><br><span class="line">    def forward(self, *input):</span><br><span class="line">        return self.fc(input)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"></span><br><span class="line">optimer = optim.SGD(net.parameters(), lr=0.1)</span><br><span class="line"></span><br><span class="line">lambda1 = lambda epoch: epoch // 5 + 1</span><br><span class="line">lambda2 = lambda epoch: 0.95 ** epoch</span><br><span class="line"></span><br><span class="line">scheduler = LambdaLR(optimer, lr_lambda=lambda1)</span><br><span class="line"></span><br><span class="line">for epoch in range(20):</span><br><span class="line">    scheduler.step()</span><br><span class="line">    lr = scheduler.get_lr()</span><br><span class="line">    print(lr)</span><br></pre></td></tr></table></figure>
<p><code>lambda1</code>函数功能是每隔<code>5</code>次迭代提高<code>1</code>倍学习率，结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[0.1]</span><br><span class="line">[0.1]</span><br><span class="line">[0.1]</span><br><span class="line">[0.1]</span><br><span class="line">[0.1]</span><br><span class="line">[0.2]</span><br><span class="line">[0.2]</span><br><span class="line">[0.2]</span><br><span class="line">[0.2]</span><br><span class="line">[0.2]</span><br><span class="line">[0.30000000000000004]</span><br><span class="line">[0.30000000000000004]</span><br><span class="line">[0.30000000000000004]</span><br><span class="line">[0.30000000000000004]</span><br><span class="line">[0.30000000000000004]</span><br><span class="line">[0.4]</span><br><span class="line">[0.4]</span><br><span class="line">[0.4]</span><br><span class="line">[0.4]</span><br><span class="line">[0.4]</span><br></pre></td></tr></table></figure>
<h4 id="StepLR"><a href="#StepLR" class="headerlink" title="StepLR"></a>StepLR</h4><blockquote>
<p>class torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1)</p>
</blockquote>
<p>每隔<code>step_size</code>次迭代降低<code>gamma</code>倍学习率</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">scheduler = StepLR(optimer, step_size=5, gamma=0.5)</span><br><span class="line"></span><br><span class="line">for epoch in range(20):</span><br><span class="line">    scheduler.step()</span><br><span class="line">    lr = scheduler.get_lr()</span><br><span class="line">    print(lr)</span><br></pre></td></tr></table></figure>
<p>每轮输出学习率如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[0.1]</span><br><span class="line">[0.1]</span><br><span class="line">[0.1]</span><br><span class="line">[0.1]</span><br><span class="line">[0.1]</span><br><span class="line">[0.05]</span><br><span class="line">[0.05]</span><br><span class="line">[0.05]</span><br><span class="line">[0.05]</span><br><span class="line">[0.05]</span><br><span class="line">[0.025]</span><br><span class="line">[0.025]</span><br><span class="line">[0.025]</span><br><span class="line">[0.025]</span><br><span class="line">[0.025]</span><br><span class="line">[0.0125]</span><br><span class="line">[0.0125]</span><br><span class="line">[0.0125]</span><br><span class="line">[0.0125]</span><br><span class="line">[0.0125]</span><br></pre></td></tr></table></figure>
<h4 id="MultiStepLR"><a href="#MultiStepLR" class="headerlink" title="MultiStepLR"></a>MultiStepLR</h4><blockquote>
<p>class torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1, last_epoch=-1)</p>
</blockquote>
<p><code>StepLR</code>只能指定固定次数进行衰减，并且衰减会一直持续下去</p>
<p><code>MultiStepLR</code>可以指定哪个迭代次数进行衰减，并指定衰减次数</p>
<p><code>milestones</code>是一个升序列表，表示迭代下标，只有当前迭代次数是列表中的值时才衰减一次</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scheduler = MultiStepLR(optimer, milestones=[3, 5, 10], gamma=0.5)</span><br><span class="line"></span><br><span class="line">for epoch in range(20):</span><br><span class="line">    scheduler.step()</span><br><span class="line">    lr = scheduler.get_lr()</span><br><span class="line">    print(lr)</span><br></pre></td></tr></table></figure>
<p>每轮输出学习率如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[0.1]</span><br><span class="line">[0.1]</span><br><span class="line">[0.1]</span><br><span class="line">[0.05]</span><br><span class="line">[0.05]</span><br><span class="line">[0.025]</span><br><span class="line">[0.025]</span><br><span class="line">[0.025]</span><br><span class="line">[0.025]</span><br><span class="line">[0.025]</span><br><span class="line">[0.0125]</span><br><span class="line">[0.0125]</span><br><span class="line">[0.0125]</span><br><span class="line">[0.0125]</span><br><span class="line">[0.0125]</span><br><span class="line">[0.0125]</span><br><span class="line">[0.0125]</span><br><span class="line">[0.0125]</span><br><span class="line">[0.0125]</span><br><span class="line">[0.0125]</span><br></pre></td></tr></table></figure>
<h3 id="指数衰减-1"><a href="#指数衰减-1" class="headerlink" title="指数衰减"></a>指数衰减</h3><blockquote>
<p>class torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma, last_epoch=-1)</p>
</blockquote>
<p>每轮迭代中学习率乘以<code>gamma</code>衰减因子</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>最优化</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>学习率衰减</tag>
      </tags>
  </entry>
  <entry>
    <title>LeNet5实现-pytorch</title>
    <url>/posts/a2db6d6b.html</url>
    <content><![CDATA[<p>参考：<a href="https://www.zhujian.tech/posts/5a77dbca.html#more">神经网络实现-pytorch</a></p><p>完整代码：<a href="https://github.com/zjZSTU/PyNet/blob/master/pytorch/lenet5_test.py" target="_blank" rel="noopener"> PyNet/pytorch/lenet5_test.py </a></p><a id="more"></a>

<h2 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h2><p><code>pytorch</code>提供模块<code>torchvision</code>，用于数据的加载、预处理和批量化</p>
<ul>
<li><code>torchvision.datasets</code>内置类<code>MNIST</code>用于<code>mnist</code>数据集下载和加载</li>
<li><code>torchvision.transforms</code>对数据进行预处理</li>
<li><code>torchvision.DataLoader</code>对数据进行批量化</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def load_mnist_data(batch_size=128, shuffle=False):</span><br><span class="line">    data_dir = &apos;/home/zj/data/&apos;</span><br><span class="line"></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Grayscale(),</span><br><span class="line">        transforms.Resize(size=(32, 32)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=(0.5,), std=(0.5,))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    train_data_set = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)</span><br><span class="line">    test_data_set = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)</span><br><span class="line"></span><br><span class="line">    train_loader = DataLoader(train_data_set, batch_size=batch_size, shuffle=shuffle)</span><br><span class="line">    test_loader = DataLoader(test_data_set, batch_size=batch_size, shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    return train_loader, test_loader</span><br></pre></td></tr></table></figure>
<h2 id="网络定义"><a href="#网络定义" class="headerlink" title="网络定义"></a>网络定义</h2><p><code>LeNet-5</code>模型定义参考<a href="https://www.zhujian.tech/posts/3accb62a.html#more">卷积神经网络推导-单张图片矩阵计算</a></p>
<p><code>torch.nn</code>模块实现了网络层类，包括卷积层（<code>Conv2d</code>）、最大池化层（<code>MaxPool2d</code>）、全连接层（<code>Linear</code>）和其他激活层</p>
<p><code>torch.nn</code>模块提供<code>functional</code>类用于网络层类的实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class LeNet5(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(LeNet5, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0, bias=True)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)</span><br><span class="line">        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1, padding=0, bias=True)</span><br><span class="line"></span><br><span class="line">        self.pool = nn.MaxPool2d((2, 2), stride=2)</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(in_features=120, out_features=84, bias=True)</span><br><span class="line">        self.fc2 = nn.Linear(84, 10, bias=True)</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        x = self.pool(F.relu(self.conv1(input)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line"></span><br><span class="line">        x = x.view(-1, self.num_flat_features(x))</span><br><span class="line"></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        return self.fc2(x)</span><br><span class="line"></span><br><span class="line">    def num_flat_features(self, x):</span><br><span class="line">        size = x.size()[1:]  # all dimensions except the batch dimension</span><br><span class="line">        num_features = 1</span><br><span class="line">        for s in size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        return num_features</span><br></pre></td></tr></table></figure>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>训练参数如下</p>
<ol>
<li>学习率<code>lr = 1e-3</code></li>
<li>批量大小<code>batch_size = 128</code></li>
<li>迭代次数<code>epochs = 500</code></li>
</ol>
<h3 id="训练结果"><a href="#训练结果" class="headerlink" title="训练结果"></a>训练结果</h3><p>训练时间</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">CPU</th>
<th style="text-align:center">GPU</th>
<th style="text-align:center">单次迭代时间</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">8核 Intel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz</td>
<td style="text-align:center">GeForce 940MX</td>
<td style="text-align:center">约13秒</td>
</tr>
</tbody>
</table>
</div>
<p>迭代<code>500</code>次训练结果</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">训练集精度</th>
<th style="text-align:center">测试集精度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">99.40%</td>
<td style="text-align:center">98.63%</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/imgs/LeNet5实现-pytorch/pytorch_lenet5_mnist_accuracy.png" alt></p>
<p><img src="/imgs/LeNet5实现-pytorch/pytorch_lenet5_mnist_loss.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>torchvision</tag>
        <tag>LeNet-5</tag>
      </tags>
  </entry>
  <entry>
    <title>LeNet5实现-numpy</title>
    <url>/posts/c300ea0f.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://www.zhujian.tech/posts/ab1e719c.html#more">卷积神经网络推导-批量图片矩阵计算</a></p><p><a href="https://www.zhujian.tech/posts/cc37c46b.html#more">im2col解析1</a></p><p>使用<code>numpy</code>实现<code>LeNet-5</code>网络，参考<a href="https://github.com/toxtli/lenet-5-mnist-from-scratch-numpy" target="_blank" rel="noopener">toxtli/lenet-5-mnist-from-scratch-numpy</a>模块化网络层</p><a id="more"></a>



<p>完整代码：<a href="https://github.com/zjZSTU/PyNet" target="_blank" rel="noopener">zjZSTU/PyNet</a></p>
<h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><p>前向传播过程中各变量大小变化如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">变量</th>
<th style="text-align:center">大小</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">input</td>
<td style="text-align:center">[N,C,H,W]</td>
</tr>
<tr>
<td style="text-align:center">a</td>
<td style="text-align:center">[N*out_h*out_w, C*filter_h*filter_w]</td>
</tr>
<tr>
<td style="text-align:center">W</td>
<td style="text-align:center">[C*filter_h*filter_w, filter_num]</td>
</tr>
<tr>
<td style="text-align:center">b</td>
<td style="text-align:center">[1, filter_num]</td>
</tr>
<tr>
<td style="text-align:center">z</td>
<td style="text-align:center">[N*out_h*out_w, filter_num]</td>
</tr>
<tr>
<td style="text-align:center">output</td>
<td style="text-align:center">[N, filter_num, out_h,out_w]</td>
</tr>
</tbody>
</table>
</div>
<p>有以下注意：</p>
<ul>
<li><p>需要将输入参数<code>input</code>转换成<code>2</code>维行向量矩阵<code>a</code></p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">im2row_indices(x, field_height, field_width, padding=1, stride=1)</span><br></pre></td></tr></table></figure></li>
<li><p>需要将<code>2</code>维矩阵<code>z</code>转换成<code>4</code>维数据体<code>output</code></p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conv_fc2output(inputs, batch_size, out_height, out_width):</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>反向传播过程中各变量梯度大小变化如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">变量</th>
<th style="text-align:center">大小</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">doutput</td>
<td style="text-align:center">[N, filter_num, out_h,out_w]</td>
</tr>
<tr>
<td style="text-align:center">dz</td>
<td style="text-align:center">[N*C*out_h*out_w, filter_num]</td>
</tr>
<tr>
<td style="text-align:center">dW</td>
<td style="text-align:center">[filter_h*filter_w, filter_num]</td>
</tr>
<tr>
<td style="text-align:center">db</td>
<td style="text-align:center">[1, filter_num]</td>
</tr>
<tr>
<td style="text-align:center">da</td>
<td style="text-align:center">[N*out_h*out_w, C*filter_h*filter_w]</td>
</tr>
<tr>
<td style="text-align:center">dinput</td>
<td style="text-align:center">[C,N,H,W]</td>
</tr>
</tbody>
</table>
</div>
<p>有以下注意：</p>
<ul>
<li><p>需要将<code>4</code>维输入<code>doutput</code>转换成<code>2</code>维梯度矩阵<code>da</code></p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conv_output2fc(inputs):</span><br></pre></td></tr></table></figure></li>
<li><p>需要将<code>2</code>维梯度矩阵<code>da</code>转换成<code>4</code>维梯度数据体<code>dinput</code></p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">row2im_indices(rows, x_shape, field_height=3, field_width=3, padding=1, stride=1, isstinct=False):</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化层和卷积层的最大差别在于每次池化层操作仅对单个激活图进行</p>
<p>前向传播过程中各变量大小变化如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">变量</th>
<th style="text-align:center">大小</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">input</td>
<td style="text-align:center">[N, C, H, W]</td>
</tr>
<tr>
<td style="text-align:center">a</td>
<td style="text-align:center">[N*C*out_h*out_w, filter_h*filter_w]</td>
</tr>
<tr>
<td style="text-align:center">z</td>
<td style="text-align:center">[N*C*out_h*out_w]</td>
</tr>
<tr>
<td style="text-align:center">onput</td>
<td style="text-align:center">[N, C, out_h, out_w]</td>
</tr>
</tbody>
</table>
</div>
<p>有以下注意：</p>
<ul>
<li><p>需要将输入参数<code>input</code>转换成<code>2</code>维行向量矩阵<code>a</code></p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pool2row_indices(x, field_height, field_width, stride=1):</span><br></pre></td></tr></table></figure></li>
<li><p>需要将<code>1</code>维矩阵<code>z</code>转换成<code>4</code>维数据体<code>output</code></p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pool_fc2output(inputs, batch_size, out_height, out_width):</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>反向传播过程中各变量大小变化如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">变量</th>
<th style="text-align:center">大小</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">doutput</td>
<td style="text-align:center">[N, C, out_h, out_w]</td>
</tr>
<tr>
<td style="text-align:center">dz</td>
<td style="text-align:center">[N*C*out_h*out_w]</td>
</tr>
<tr>
<td style="text-align:center">da</td>
<td style="text-align:center">[N*C*out_h*out_w, filter_h*filter_w]</td>
</tr>
<tr>
<td style="text-align:center">dinput</td>
<td style="text-align:center">[N, C, H, W]</td>
</tr>
</tbody>
</table>
</div>
<p>有以下注意：</p>
<ul>
<li><p>需要将<code>4</code>维输入<code>doutput</code>转换成<code>1</code>维矩阵<code>dz</code></p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pool_output2fc(inputs):</span><br></pre></td></tr></table></figure></li>
<li><p>需要将<code>2</code>维梯度矩阵<code>da</code>转换成<code>4</code>维梯度数据体<code>dinput</code></p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">row2pool_indices(rows, x_shape, field_height=2, field_width=2, stride=2, isstinct=False):</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="层定义"><a href="#层定义" class="headerlink" title="层定义"></a>层定义</h2><p>基本层定义分<code>3</code>部分功能：</p>
<ol>
<li>初始化</li>
<li>前向传播</li>
<li>反向传播</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Layer(metaclass=ABCMeta):</span><br><span class="line"></span><br><span class="line">    @abstractmethod</span><br><span class="line">    def __init__(self):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">    @abstractmethod</span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">    @abstractmethod</span><br><span class="line">    def backward(self, grad_out):</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>
<p>对于有参数的层额外实现更新参数、获取参数和设置参数函数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def update(self, lr=1e-3, reg=1e-3):</span><br><span class="line">    self.fc2.update(lr, reg)</span><br><span class="line">    self.fc1.update(lr, reg)</span><br><span class="line"></span><br><span class="line">def get_params(self):</span><br><span class="line">    return &#123;&apos;fc1&apos;: self.fc1.get_params(), &apos;fc2&apos;: self.fc2.get_params()&#125;</span><br><span class="line"></span><br><span class="line">def set_params(self, params):</span><br><span class="line">    self.fc1.set_params(params[&apos;fc1&apos;])</span><br><span class="line">    self.fc2.set_params(params[&apos;fc2&apos;])</span><br></pre></td></tr></table></figure>
<p>层实现代码：<a href="https://github.com/zjZSTU/PyNet/blob/master/nn/layers.py" target="_blank" rel="noopener"> PyNet/nn/layers.py </a></p>
<h2 id="网络定义"><a href="#网络定义" class="headerlink" title="网络定义"></a>网络定义</h2><p>网络实现以下功能：</p>
<ol>
<li>初始化</li>
<li>前向传播</li>
<li>反向传播</li>
<li>参数更新</li>
<li>获取参数</li>
<li>设置参数</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Net(metaclass=ABCMeta):</span><br><span class="line"></span><br><span class="line">    @abstractmethod</span><br><span class="line">    def __init__(self):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">    @abstractmethod</span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">    @abstractmethod</span><br><span class="line">    def backward(self, grad_out):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">    @abstractmethod</span><br><span class="line">    def update(self, lr=1e-3, reg=1e-3):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">    @abstractmethod</span><br><span class="line">    def get_params(self):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">    @abstractmethod</span><br><span class="line">    def set_params(self, params):</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>
<p>网络实现代码：<a href="https://github.com/zjZSTU/PyNet/blob/master/nn/nets.py" target="_blank" rel="noopener"> PyNet/nn/nets.py </a></p>
<p><code>LeNet-5</code>定义如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class LeNet5(Net):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    LeNet-5网络</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.conv1 = Conv2d(1, 5, 5, 6, stride=1, padding=0)</span><br><span class="line">        self.conv2 = Conv2d(6, 5, 5, 16, stride=1, padding=0)</span><br><span class="line">        self.conv3 = Conv2d(16, 5, 5, 120, stride=1, padding=0)</span><br><span class="line"></span><br><span class="line">        self.maxPool1 = MaxPool(2, 2, 6, stride=2)</span><br><span class="line">        self.maxPool2 = MaxPool(2, 2, 16, stride=2)</span><br><span class="line">        self.fc1 = FC(120, 84)</span><br><span class="line">        self.fc2 = FC(84, 10)</span><br><span class="line"></span><br><span class="line">        self.relu1 = ReLU()</span><br><span class="line">        self.relu2 = ReLU()</span><br><span class="line">        self.relu3 = ReLU()</span><br><span class="line">        self.relu4 = ReLU()</span><br><span class="line"></span><br><span class="line">    def __call__(self, inputs):</span><br><span class="line">        return self.forward(inputs)</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        # inputs.shape = [N, C, H, W]</span><br><span class="line">        assert len(inputs.shape) == 4</span><br><span class="line">        x = self.relu1(self.conv1(inputs))</span><br><span class="line">        x = self.maxPool1(x)</span><br><span class="line">        x = self.relu2(self.conv2(x))</span><br><span class="line">        x = self.maxPool2(x)</span><br><span class="line">        x = self.relu3(self.conv3(x))</span><br><span class="line">        # (N, C, 1, 1) -&gt; (N, C)</span><br><span class="line">        x = x.squeeze()</span><br><span class="line">        x = self.relu4(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line"></span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def backward(self, grad_out):</span><br><span class="line">        da6 = self.fc2.backward(grad_out)</span><br><span class="line"></span><br><span class="line">        dz6 = self.relu4.backward(da6)</span><br><span class="line">        da5 = self.fc1.backward(dz6)</span><br><span class="line">        # [N, C] -&gt; [N, C, 1, 1]</span><br><span class="line">        N, C = da5.shape[:2]</span><br><span class="line">        da5 = da5.reshape(N, C, 1, 1)</span><br><span class="line"></span><br><span class="line">        dz5 = self.relu3.backward(da5)</span><br><span class="line">        da4 = self.conv3.backward(dz5)</span><br><span class="line"></span><br><span class="line">        dz4 = self.maxPool2.backward(da4)</span><br><span class="line"></span><br><span class="line">        dz3 = self.relu2.backward(dz4)</span><br><span class="line">        da2 = self.conv2.backward(dz3)</span><br><span class="line"></span><br><span class="line">        da1 = self.maxPool1.backward(da2)</span><br><span class="line">        dz1 = self.relu1.backward(da1)</span><br><span class="line"></span><br><span class="line">        self.conv1.backward(dz1)</span><br><span class="line"></span><br><span class="line">    def update(self, lr=1e-3, reg=1e-3):</span><br><span class="line">        self.fc2.update(lr, reg)</span><br><span class="line">        self.fc1.update(lr, reg)</span><br><span class="line">        self.conv3.update(lr, reg)</span><br><span class="line">        self.conv2.update(lr, reg)</span><br><span class="line">        self.conv1.update(lr, reg)</span><br><span class="line"></span><br><span class="line">    def get_params(self):</span><br><span class="line">        out = dict()</span><br><span class="line">        out[&apos;conv1&apos;] = self.conv1.get_params()</span><br><span class="line">        out[&apos;conv2&apos;] = self.conv2.get_params()</span><br><span class="line">        out[&apos;conv3&apos;] = self.conv3.get_params()</span><br><span class="line"></span><br><span class="line">        out[&apos;fc1&apos;] = self.fc1.get_params()</span><br><span class="line">        out[&apos;fc2&apos;] = self.fc2.get_params()</span><br><span class="line"></span><br><span class="line">        return out</span><br><span class="line"></span><br><span class="line">    def set_params(self, params):</span><br><span class="line">        self.conv1.set_params(params[&apos;conv1&apos;])</span><br><span class="line">        self.conv2.set_params(params[&apos;conv2&apos;])</span><br><span class="line">        self.conv3.set_params(params[&apos;conv3&apos;])</span><br><span class="line"></span><br><span class="line">        self.fc1.set_params(params[&apos;fc1&apos;])</span><br><span class="line">        self.fc2.set_params(params[&apos;fc2&apos;])</span><br></pre></td></tr></table></figure>
<h2 id="保存和加载参数"><a href="#保存和加载参数" class="headerlink" title="保存和加载参数"></a>保存和加载参数</h2><p>将参数保存成文件，同时能够从文件中加载参数，使用<code>python</code>的<code>pickle</code>模块，参数以字典形式保存</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def save_params(params, path=&apos;params.pkl&apos;):</span><br><span class="line">    with open(path, &apos;wb&apos;) as f:</span><br><span class="line">        pickle.dump(params, f, -1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_params(path=&apos;params.pkl&apos;):</span><br><span class="line">    with open(path, &apos;rb&apos;) as f:</span><br><span class="line">        param = pickle.load(f)</span><br><span class="line">    return param</span><br></pre></td></tr></table></figure>
<p>完整代码：<a href="https://github.com/zjZSTU/PyNet/blob/master/nn/net_utils.py" target="_blank" rel="noopener"> PyNet/nn/net_utils.py </a></p>
<h2 id="mnist数据"><a href="#mnist数据" class="headerlink" title="mnist数据"></a>mnist数据</h2><p>参考：<a href="https://www.zhujian.tech/posts/ba2ca878.html#more">mnist数据集</a></p>
<p>将<code>mnist</code>数据集下载解压后，加载过程中完成以下步骤：</p>
<ol>
<li>转换成<code>(32,32)</code>大小</li>
<li>转换维数顺序：<code>[H, W, C] -&gt; [C, H, W]</code></li>
</ol>
<p>完整代码：<a href="https://github.com/zjZSTU/PyNet/blob/master/src/load_mnist.py" target="_blank" rel="noopener"> PyNet/src/load_mnist.py </a></p>
<p>加载完成后还需要进行数据标准化，因为图像取值为<code>[0,255]</code>，参考<code>pytorch</code>使用，简易操作如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 标准化</span><br><span class="line">x_train = x_train / 255.0 - 0.5</span><br><span class="line">x_test = x_test / 255.0 - 0.5</span><br></pre></td></tr></table></figure>
<h2 id="LeNet-5训练"><a href="#LeNet-5训练" class="headerlink" title="LeNet-5训练"></a>LeNet-5训练</h2><p>训练参数如下：</p>
<ol>
<li>学习率<code>lr = 1e-3</code></li>
<li>正则化强度<code>reg = 1e-3</code></li>
<li>批量大小<code>batch_size = 128</code></li>
<li>迭代次数<code>epochs = 1000</code></li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">net = LeNet5()</span><br><span class="line">criterion = CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">loss_list = []</span><br><span class="line">range_list = np.arange(0, x_train.shape[0] - batch_size, step=batch_size)</span><br><span class="line">for i in range(epochs):</span><br><span class="line">    total_loss = 0</span><br><span class="line">    num = 0</span><br><span class="line">    start = time.time()</span><br><span class="line">    for j in range_list:</span><br><span class="line">        data = x_train[j:j + batch_size]</span><br><span class="line">        labels = y_train[j:j + batch_size]</span><br><span class="line"></span><br><span class="line">        scores = net(data)</span><br><span class="line">        loss = criterion(scores, labels)</span><br><span class="line">        total_loss += loss</span><br><span class="line">        num += 1</span><br><span class="line"></span><br><span class="line">        grad_out = criterion.backward()</span><br><span class="line">        net.backward(grad_out)</span><br><span class="line">        net.update(lr=lr, reg=reg)</span><br><span class="line">    end = time.time()</span><br><span class="line">    print(&apos;one epoch need time: %.3f&apos; % (end - start))</span><br><span class="line">    print(&apos;epoch: %d loss: %f&apos; % (i + 1, total_loss / num))</span><br><span class="line">    loss_list.append(total_loss / num)</span><br><span class="line">    # draw(loss_list)</span><br><span class="line">    if i % 50 == 49:</span><br><span class="line">        path = &apos;lenet5-epochs-%d.pkl&apos; % (i + 1)</span><br><span class="line">        params = net.get_params()</span><br><span class="line">        save_params(params, path=path)</span><br><span class="line">        test_accuracy = compute_accuracy(x_test, y_test, net, batch_size=batch_size)</span><br><span class="line">        print(&apos;epochs: %d test_accuracy: %f&apos; % (i + 1, test_accuracy))</span><br><span class="line">        print(&apos;loss: %s&apos; % loss_list)</span><br></pre></td></tr></table></figure>
<p>完整代码：<a href="https://github.com/zjZSTU/PyNet/blob/master/src/lenet-5_test.py" target="_blank" rel="noopener"> PyNet/src/lenet-5_test.py </a></p>
<h2 id="训练结果"><a href="#训练结果" class="headerlink" title="训练结果"></a>训练结果</h2><p>训练时间</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">计算机硬件</th>
<th style="text-align:center">单次迭代时间</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">12核 Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz</td>
<td style="text-align:center">约166秒</td>
</tr>
</tbody>
</table>
</div>
<p>训练结果</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">训练集精度</th>
<th style="text-align:center">测试集精度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">99.99%</td>
<td style="text-align:center">99.04%</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/imgs/LeNet5实现-numpy/lenet5-loss.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>LeNet-5</tag>
      </tags>
  </entry>
  <entry>
    <title>im2col解析5</title>
    <url>/posts/5e1da4ba.html</url>
    <content><![CDATA[<p>前面实现了卷积层和全连接层的相互转换，下面实现池化层和全连接层的相互转换</p><h2 id="原理解析"><a href="#原理解析" class="headerlink" title="原理解析"></a>原理解析</h2><p><strong>池化层操作和卷积层操作的不同之处在于池化层操作没有零填充，不包含深度，它仅对输入数据体的每一个激活图进行<code>2</code>维操作</strong></p><a id="more"></a>

<p>比如输入数据体大小为$128\times 6\times 28\times 28$，池化层过滤器空间尺寸为$2\times 2$，步长为$2$</p>
<script type="math/tex; mode=display">
(28 - 2)/2 + 1=14</script><p>那么输出数据体大小为$128\times 6\times 14\times 14$</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_pool2row_indices(x_shape, field_height, field_width, stride=1):</span><br><span class="line">    # First figure out what the size of the output should be</span><br><span class="line">    N, C, H, W = x_shape</span><br><span class="line">    assert (H - field_height) % stride == 0</span><br><span class="line">    assert (W - field_height) % stride == 0</span><br><span class="line">    out_height = int((H - field_height) / stride + 1)</span><br><span class="line">    out_width = int((W - field_width) / stride + 1)</span><br><span class="line"></span><br><span class="line">    # 行坐标</span><br><span class="line">    i0 = stride * np.repeat(np.arange(out_height), out_width)</span><br><span class="line">    i0 = np.tile(i0, C)</span><br><span class="line">    i1 = np.repeat(np.arange(field_height), field_width)</span><br><span class="line"></span><br><span class="line">    # 列坐标</span><br><span class="line">    j0 = stride * np.tile(np.arange(out_width), out_height * C)</span><br><span class="line">    j1 = np.tile(np.arange(field_width), field_height)</span><br><span class="line"></span><br><span class="line">    i = i0.reshape(-1, 1) + i1.reshape(1, -1)</span><br><span class="line">    j = j0.reshape(-1, 1) + j1.reshape(1, -1)</span><br><span class="line"></span><br><span class="line">    k = np.repeat(np.arange(C), out_height * out_width).reshape(-1, 1)</span><br><span class="line"></span><br><span class="line">    return (k, i, j)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def pool2row_indices(x, field_height, field_width, stride=1):</span><br><span class="line">    k, i, j = get_pool2row_indices(x.shape, field_height, field_width, stride)</span><br><span class="line"></span><br><span class="line">    rows = x[:, k, i, j]</span><br><span class="line">    C = x.shape[1]</span><br><span class="line">    # 逐图像采集</span><br><span class="line">    rows = rows.reshape(-1, field_height * field_width)</span><br><span class="line">    return rows</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def row2pool_indices(rows, x_shape, field_height=2, field_width=2, stride=2, isstinct=False):</span><br><span class="line">    N, C, H, W = x_shape</span><br><span class="line">    x = np.zeros(x_shape, dtype=rows.dtype)</span><br><span class="line">    k, i, j = get_pool2row_indices(x_shape, field_height, field_width, stride)</span><br><span class="line">    rows_reshaped = rows.reshape(N, -1, field_height * field_width)</span><br><span class="line">    np.add.at(x, (slice(None), k, i, j), rows_reshaped)</span><br><span class="line"></span><br><span class="line">    if isstinct and (stride &lt; field_height or stride &lt; field_width):</span><br><span class="line">        x_ones = np.ones(x.shape)</span><br><span class="line">        rows_ones = x_ones[:, k, i, j]</span><br><span class="line">        x_zeros = np.zeros(x.shape)</span><br><span class="line">        np.add.at(x_zeros, (slice(None), k, i, j), rows_ones)</span><br><span class="line">        return x / x_zeros</span><br><span class="line"></span><br><span class="line">    return x</span><br></pre></td></tr></table></figure>
<p>修改如下：</p>
<ol>
<li>行向量大小为<code>field_width * field_height</code>，每个激活图的行/列坐标矩阵，所以在坐标矩阵列方向重复</li>
<li>当步长等于滤波器长宽时，行向量转图像得到的就是原来的数据体，不需要进一步转换</li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>卷积神经网络</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>im2col解析4</title>
    <url>/posts/291a942c.html</url>
    <content><![CDATA[<p>之前实现了一个图像和行向量相互转换的函数，逐图像进行局部连接矩阵的转换</p><p>其实现原理较下标计算更易理解，<strong>通过循环，逐个图像对局部连接矩阵进行切片操作，得到矩阵后拉平为向量，以行向量方式进行保存</strong></p><a id="more"></a>

<p>反向转换图像可以设置标志位<code>isstinct</code>，是否返回叠加图像还是原图，<strong>其实现原理是在指定位置赋值过程中是执行累加还是执行覆盖</strong></p>
<h2 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def convert_conv_to_fc(input, filter_height=3, filter_width=3, stride=1, padding=0):</span><br><span class="line">    input_padded = np.pad(input, ((0, 0), (0, 0), (padding, padding), (padding, padding)),</span><br><span class="line">                          &apos;constant&apos;, constant_values=(0, 0))</span><br><span class="line">    # [N, C, H, W]</span><br><span class="line">    num, depth, height, width = input_padded.shape[:4]</span><br><span class="line"></span><br><span class="line">    res = []</span><br><span class="line">    for k in range(num):</span><br><span class="line">        i = 0</span><br><span class="line">        while i &lt; height:</span><br><span class="line">            j = 0</span><br><span class="line">            while j &lt; width:</span><br><span class="line">                arr = input_padded[k, :, i:i + filter_height, j:j + filter_width]</span><br><span class="line">                res.append(arr.flatten())</span><br><span class="line">                j += stride</span><br><span class="line">                if (j + filter_width) &gt; width:</span><br><span class="line">                    break</span><br><span class="line">            i += stride</span><br><span class="line">            if (i + filter_height) &gt; height:</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    return np.array(res)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def deconvert_fc_to_conv(input, output_shape, filter_height=3, filter_width=3, stride=2, padding=0, isstinct=False):</span><br><span class="line">    output = np.zeros(output_shape)</span><br><span class="line">    output_padded = np.pad(output, ((0, 0), (0, 0), (padding, padding), (padding, padding)),</span><br><span class="line">                           &apos;constant&apos;, constant_values=(0, 0))</span><br><span class="line">    # [N, C, H, W]</span><br><span class="line">    num, depth, height, width = output_padded.shape[:4]</span><br><span class="line"></span><br><span class="line">    number = 0</span><br><span class="line">    for k in range(num):</span><br><span class="line">        i = 0</span><br><span class="line">        while i &lt; height:</span><br><span class="line">            j = 0</span><br><span class="line">            while j &lt; width:</span><br><span class="line">                if isstinct:</span><br><span class="line">                    output_padded[k, :, i:i + filter_height, j:j + filter_width] = \</span><br><span class="line">                        input[number].reshape(depth, filter_height, filter_width)</span><br><span class="line">                else:</span><br><span class="line">                    output_padded[k, :, i:i + filter_height, j:j + filter_width] += \</span><br><span class="line">                        input[number].reshape(depth, filter_height, filter_width)</span><br><span class="line">                j += stride</span><br><span class="line">                number += 1</span><br><span class="line">                if (j + filter_width) &gt; width:</span><br><span class="line">                    break</span><br><span class="line">            i += stride</span><br><span class="line">            if (i + filter_height) &gt; height:</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    if padding == 0:</span><br><span class="line">        return output_padded</span><br><span class="line"></span><br><span class="line">    return output_padded[:, :, padding:-padding, padding:-padding]</span><br></pre></td></tr></table></figure>
<h2 id="时间测试"><a href="#时间测试" class="headerlink" title="时间测试"></a>时间测试</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">大小(128x3x32x32) 卷积核(3x3) 步长(1) 零填充(0)</th>
<th style="text-align:center">大小(128x3x227x227) 卷积核(3x3) 步长(1) 零填充(0)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">im2row 图像转行向量</td>
<td style="text-align:center">0.087</td>
<td style="text-align:center">0.941</td>
</tr>
<tr>
<td style="text-align:center">自定义 图像转行向量</td>
<td style="text-align:center">0.257</td>
<td style="text-align:center">3.475</td>
</tr>
<tr>
<td style="text-align:center">im2row  行向量转图像</td>
<td style="text-align:center">0.238</td>
<td style="text-align:center">3.519</td>
</tr>
<tr>
<td style="text-align:center">自定义  行向量转图像</td>
<td style="text-align:center">0.411</td>
<td style="text-align:center">7.413</td>
</tr>
</tbody>
</table>
</div>
<p>经过测试发现，下标计算方式快过循环计算方式，并且图像转行向量操作比行向量转图像操作快</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>卷积神经网络</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>im2col解析3</title>
    <url>/posts/b77e018f.html</url>
    <content><![CDATA[<p>前面实现了图像转列向量，在之前推导过程中使用的是行向量，所以修改<code>im2col.py</code>，实现<code>im2row</code>的功能</p><a id="more"></a>
<p>卷积核大小为$2\times 2$，步长为<code>1</code>，零填充为<code>0</code></p>
<ul>
<li>field_height = 2</li>
<li>field_width = 2</li>
<li>stride = 1</li>
<li>padding = 0</li>
</ul>
<p><code>2</code>维图像大小为$3\times 3$，3维图像大小为$2\times 3\times 3$，4维图像大小为$2\times 2\times 3\times 3$</p>
<p>所以输出数据体的空间尺寸为$2\times 2$，深度为<code>2</code>，数量为<code>2</code></p>
<ul>
<li>out_height = 2</li>
<li>out_width = 2</li>
<li>depth = 2</li>
<li>N = 2</li>
</ul>
<h2 id="图像转行向量"><a href="#图像转行向量" class="headerlink" title="图像转行向量"></a>图像转行向量</h2><h3 id="2维图像"><a href="#2维图像" class="headerlink" title="2维图像"></a>2维图像</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.arange(9).reshape(3,3)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[0, 1, 2],</span><br><span class="line">       [3, 4, 5],</span><br><span class="line">       [6, 7, 8]])</span><br></pre></td></tr></table></figure>
<h4 id="行坐标矩阵"><a href="#行坐标矩阵" class="headerlink" title="行坐标矩阵"></a>行坐标矩阵</h4><p>对于行坐标矩阵而言，每一行表示一个局部连接矩阵</p>
<p>局部连接矩阵中同一行的行坐标相等，相邻行的行坐标加<code>1</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># i1 = np.repeat(np.arange(field_height), field_width)</span><br><span class="line">&gt;&gt;&gt; i1 = np.repeat(np.arange(2), 2)</span><br><span class="line">&gt;&gt;&gt; i1</span><br><span class="line">array([0, 0, 1, 1])</span><br></pre></td></tr></table></figure>
<p>行坐标矩阵的列数表示局部连接的个数</p>
<p>图像中同一行局部连接的行坐标相等，相邻行之间的局部连接行坐标相差<code>stride</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># i0 = stride * np.repeat(np.arange(out_height), out_width)</span><br><span class="line">&gt;&gt;&gt; i0 = 1 * np.repeat(np.arange(2), 2)</span><br><span class="line">&gt;&gt;&gt; i0</span><br><span class="line">array([0, 0, 1, 1])</span><br></pre></td></tr></table></figure>
<p>计算行坐标矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># i = i0.reshape(-1, 1) + i1.reshape(1, -1)</span><br><span class="line">&gt;&gt;&gt; i = i0.reshape(-1, 1) + i1.reshape(1, -1)</span><br><span class="line">&gt;&gt;&gt; i</span><br><span class="line">array([[0, 0, 1, 1],</span><br><span class="line">       [0, 0, 1, 1],</span><br><span class="line">       [1, 1, 2, 2],</span><br><span class="line">       [1, 1, 2, 2]])</span><br></pre></td></tr></table></figure>
<h4 id="列坐标矩阵"><a href="#列坐标矩阵" class="headerlink" title="列坐标矩阵"></a>列坐标矩阵</h4><p>对于列坐标矩阵而言，每一行表示一个局部连接矩阵</p>
<p>局部连接矩阵中同一列的列坐标相等，相邻列的列坐标加<code>1</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># j1 = np.tile(np.arange(field_width), field_height)</span><br><span class="line">&gt;&gt;&gt; j1 = np.tile(np.arange(2), 2)</span><br><span class="line">&gt;&gt;&gt; j1</span><br><span class="line">array([0, 1, 0, 1])</span><br></pre></td></tr></table></figure>
<p>列坐标矩阵的列数表示局部连接的个数</p>
<p>图像中同一行的相邻局部连接相差<code>stride</code>距离，同一列的局部连接距离该行最左端的距离相等</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># j0 = stride * np.tile(np.arange(out_width), out_height)</span><br><span class="line">&gt;&gt;&gt; j0 = 1 * np.tile(np.arange(2), 2)</span><br><span class="line">&gt;&gt;&gt; j0</span><br><span class="line">array([0, 1, 0, 1])</span><br></pre></td></tr></table></figure>
<p>计算列坐标矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># j = j0.reshape(-1, 1) + j1.reshape(1, -1)</span><br><span class="line">&gt;&gt;&gt; j = j0.reshape(-1, 1) + j1.reshape(1, -1)</span><br><span class="line">&gt;&gt;&gt; j</span><br><span class="line">array([[0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2],</span><br><span class="line">       [0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2]])</span><br></pre></td></tr></table></figure>
<h4 id="行向量"><a href="#行向量" class="headerlink" title="行向量"></a>行向量</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a[i,j]</span><br><span class="line">array([[0, 1, 3, 4],</span><br><span class="line">       [1, 2, 4, 5],</span><br><span class="line">       [3, 4, 6, 7],</span><br><span class="line">       [4, 5, 7, 8]])</span><br></pre></td></tr></table></figure>
<h3 id="3维图像"><a href="#3维图像" class="headerlink" title="3维图像"></a>3维图像</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.arange(18).reshape(2,3,3)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[[ 0,  1,  2],</span><br><span class="line">        [ 3,  4,  5],</span><br><span class="line">        [ 6,  7,  8]],</span><br><span class="line"></span><br><span class="line">       [[ 9, 10, 11],</span><br><span class="line">        [12, 13, 14],</span><br><span class="line">        [15, 16, 17]]])</span><br></pre></td></tr></table></figure>
<h4 id="行坐标矩阵-1"><a href="#行坐标矩阵-1" class="headerlink" title="行坐标矩阵"></a>行坐标矩阵</h4><p>多通道图像仅改变单个局部连接矩阵大小，不改变数量</p>
<p>并且单个局部连接在每个通道的行坐标相同</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># i1 = np.repeat(np.arange(field_height), field_width)</span><br><span class="line"># i1 = np.tile(i1, C)</span><br><span class="line">&gt;&gt;&gt; i1 = np.repeat(np.arange(2), 2)</span><br><span class="line">&gt;&gt;&gt; i1</span><br><span class="line">array([0, 0, 1, 1])</span><br><span class="line">&gt;&gt;&gt; i1 = np.tile(i1, 2)</span><br><span class="line">&gt;&gt;&gt; i1</span><br><span class="line">array([0, 0, 1, 1, 0, 0, 1, 1])</span><br></pre></td></tr></table></figure>
<p>计算行坐标矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; i0 = 1 * np.repeat(np.arange(2), 2)</span><br><span class="line">&gt;&gt;&gt; i0</span><br><span class="line">array([0, 0, 1, 1])</span><br><span class="line">&gt;&gt;&gt; i = i0.reshape(-1, 1) + i1.reshape(1, -1)</span><br><span class="line">&gt;&gt;&gt; i</span><br><span class="line">array([[0, 0, 1, 1, 0, 0, 1, 1],</span><br><span class="line">       [0, 0, 1, 1, 0, 0, 1, 1],</span><br><span class="line">       [1, 1, 2, 2, 1, 1, 2, 2],</span><br><span class="line">       [1, 1, 2, 2, 1, 1, 2, 2]])</span><br></pre></td></tr></table></figure>
<h4 id="列坐标矩阵-1"><a href="#列坐标矩阵-1" class="headerlink" title="列坐标矩阵"></a>列坐标矩阵</h4><p>多通道图像仅改变单个局部连接矩阵大小，不改变数量</p>
<p>并且单个局部连接在每个通道的列坐标相同</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># j1 = np.tile(np.arange(field_width), field_height * C)</span><br><span class="line">&gt;&gt;&gt; j1 = np.tile(np.arange(2), 2*2)</span><br><span class="line">&gt;&gt;&gt; j1</span><br><span class="line">array([0, 1, 0, 1, 0, 1, 0, 1])</span><br></pre></td></tr></table></figure>
<p>计算列坐标矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; j0 = 1 * np.tile(np.arange(2), 2)</span><br><span class="line">&gt;&gt;&gt; j = j0.reshape(-1, 1) + j1.reshape(1, -1)</span><br><span class="line">&gt;&gt;&gt; j</span><br><span class="line">array([[0, 1, 0, 1, 0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2, 1, 2, 1, 2],</span><br><span class="line">       [0, 1, 0, 1, 0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2, 1, 2, 1, 2]])</span><br></pre></td></tr></table></figure>
<h4 id="通道向量"><a href="#通道向量" class="headerlink" title="通道向量"></a>通道向量</h4><p>需要指定哪个通道图像进行数据提取</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># k = np.repeat(np.arange(C), field_width * field_height).reshape(-1, 1)</span><br><span class="line">&gt;&gt;&gt; k = np.repeat(np.arange(2), 2*2).reshape(1,-1)</span><br><span class="line">&gt;&gt;&gt; k</span><br><span class="line">array([[0, 0, 0, 0, 1, 1, 1, 1]])</span><br></pre></td></tr></table></figure>
<h4 id="行向量-1"><a href="#行向量-1" class="headerlink" title="行向量"></a>行向量</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a[k,i,j]</span><br><span class="line">array([[ 0,  1,  3,  4,  9, 10, 12, 13],</span><br><span class="line">       [ 1,  2,  4,  5, 10, 11, 13, 14],</span><br><span class="line">       [ 3,  4,  6,  7, 12, 13, 15, 16],</span><br><span class="line">       [ 4,  5,  7,  8, 13, 14, 16, 17]])</span><br></pre></td></tr></table></figure>
<h3 id="4维图像"><a href="#4维图像" class="headerlink" title="4维图像"></a>4维图像</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.arange(36).reshape(2,2,3,3)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[[[ 0,  1,  2],</span><br><span class="line">         [ 3,  4,  5],</span><br><span class="line">         [ 6,  7,  8]],</span><br><span class="line"></span><br><span class="line">        [[ 9, 10, 11],</span><br><span class="line">         [12, 13, 14],</span><br><span class="line">         [15, 16, 17]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[[18, 19, 20],</span><br><span class="line">         [21, 22, 23],</span><br><span class="line">         [24, 25, 26]],</span><br><span class="line"></span><br><span class="line">        [[27, 28, 29],</span><br><span class="line">         [30, 31, 32],</span><br><span class="line">         [33, 34, 35]]]])</span><br></pre></td></tr></table></figure>
<p>对于批量图像进行行向量转换</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; rows = a[:,k,i,j]</span><br><span class="line">&gt;&gt;&gt; rows</span><br><span class="line">array([[[ 0,  1,  3,  4,  9, 10, 12, 13],</span><br><span class="line">        [ 1,  2,  4,  5, 10, 11, 13, 14],</span><br><span class="line">        [ 3,  4,  6,  7, 12, 13, 15, 16],</span><br><span class="line">        [ 4,  5,  7,  8, 13, 14, 16, 17]],</span><br><span class="line"></span><br><span class="line">       [[18, 19, 21, 22, 27, 28, 30, 31],</span><br><span class="line">        [19, 20, 22, 23, 28, 29, 31, 32],</span><br><span class="line">        [21, 22, 24, 25, 30, 31, 33, 34],</span><br><span class="line">        [22, 23, 25, 26, 31, 32, 34, 35]]])</span><br></pre></td></tr></table></figure>
<p>还需要进一步变形</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; rows.shape</span><br><span class="line">(2, 4, 8)</span><br><span class="line">&gt;&gt;&gt; rows.reshape(-1, 8)</span><br><span class="line">array([[ 0,  1,  3,  4,  9, 10, 12, 13],</span><br><span class="line">       [ 1,  2,  4,  5, 10, 11, 13, 14],</span><br><span class="line">       [ 3,  4,  6,  7, 12, 13, 15, 16],</span><br><span class="line">       [ 4,  5,  7,  8, 13, 14, 16, 17],</span><br><span class="line">       [18, 19, 21, 22, 27, 28, 30, 31],</span><br><span class="line">       [19, 20, 22, 23, 28, 29, 31, 32],</span><br><span class="line">       [21, 22, 24, 25, 30, 31, 33, 34],</span><br><span class="line">       [22, 23, 25, 26, 31, 32, 34, 35]])</span><br></pre></td></tr></table></figure>
<p><strong>最终实现结果的采样方式：逐图像按照从左到右、从上到下的顺序采集局部连接矩阵</strong></p>
<p>如果要实现逐坐标的采集局部连接矩阵，需要先进行维数转换，再完成变形</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; rows = np.transpose(rows, (1,0,2))</span><br><span class="line">&gt;&gt;&gt; rows.shape</span><br><span class="line">(4, 2, 8)</span><br><span class="line">&gt;&gt;&gt; rows.reshape(-1, 8)</span><br><span class="line">array([[ 0,  1,  3,  4,  9, 10, 12, 13],</span><br><span class="line">       [18, 19, 21, 22, 27, 28, 30, 31],</span><br><span class="line">       [ 1,  2,  4,  5, 10, 11, 13, 14],</span><br><span class="line">       [19, 20, 22, 23, 28, 29, 31, 32],</span><br><span class="line">       [ 3,  4,  6,  7, 12, 13, 15, 16],</span><br><span class="line">       [21, 22, 24, 25, 30, 31, 33, 34],</span><br><span class="line">       [ 4,  5,  7,  8, 13, 14, 16, 17],</span><br><span class="line">       [22, 23, 25, 26, 31, 32, 34, 35]])</span><br></pre></td></tr></table></figure>
<h2 id="行向量转图像"><a href="#行向量转图像" class="headerlink" title="行向量转图像"></a>行向量转图像</h2><h3 id="2维图像-1"><a href="#2维图像-1" class="headerlink" title="2维图像"></a>2维图像</h3><p>已知图像大小，行/列坐标矩阵和行向量矩阵，用<code>numpy.add.at</code>就能完成映射</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; b = np.zeros(a.shape)</span><br><span class="line">&gt;&gt;&gt; np.add.at(b, (i,j), rows)</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([[ 0.,  2.,  2.],</span><br><span class="line">       [ 6., 16., 10.],</span><br><span class="line">       [ 6., 14.,  8.]])</span><br></pre></td></tr></table></figure>
<p>计算叠加倍数，得到原始图像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; c = np.ones(a.shape)</span><br><span class="line">&gt;&gt;&gt; rows_c = c[i,j]</span><br><span class="line">&gt;&gt;&gt; d = np.zeros(c.shape)</span><br><span class="line">&gt;&gt;&gt; np.add.at(d, (i,j), rows_c)</span><br><span class="line">&gt;&gt;&gt; d</span><br><span class="line">array([[1., 2., 1.],</span><br><span class="line">       [2., 4., 2.],</span><br><span class="line">       [1., 2., 1.]])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; b/d</span><br><span class="line">array([[0., 1., 2.],</span><br><span class="line">       [3., 4., 5.],</span><br><span class="line">       [6., 7., 8.]])</span><br></pre></td></tr></table></figure>
<h4 id="3维图像-1"><a href="#3维图像-1" class="headerlink" title="3维图像"></a>3维图像</h4><p>已知图像大小，行/列坐标矩阵、深度向量和行向量矩阵，用<code>numpy.add.at</code>就能完成映射</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; b = np.zeros(a.shape)</span><br><span class="line">&gt;&gt;&gt; np.add.at(b, (k,i,j), rows)</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([[[ 0.,  2.,  2.],</span><br><span class="line">        [ 6., 16., 10.],</span><br><span class="line">        [ 6., 14.,  8.]],</span><br><span class="line"></span><br><span class="line">       [[ 9., 20., 11.],</span><br><span class="line">        [24., 52., 28.],</span><br><span class="line">        [15., 32., 17.]]])</span><br></pre></td></tr></table></figure>
<p>计算叠加倍数，得到原始图像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; c = np.ones(a.shape)</span><br><span class="line">&gt;&gt;&gt; rows_c = c[k,i,j]</span><br><span class="line">&gt;&gt;&gt; d = np.zeros(a.shape)</span><br><span class="line">&gt;&gt;&gt; np.add.at(d, (k,i,j), rows_c)</span><br><span class="line">&gt;&gt;&gt; d</span><br><span class="line">array([[[1., 2., 1.],</span><br><span class="line">        [2., 4., 2.],</span><br><span class="line">        [1., 2., 1.]],</span><br><span class="line"></span><br><span class="line">       [[1., 2., 1.],</span><br><span class="line">        [2., 4., 2.],</span><br><span class="line">        [1., 2., 1.]]])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; b/d</span><br><span class="line">array([[[ 0.,  1.,  2.],</span><br><span class="line">        [ 3.,  4.,  5.],</span><br><span class="line">        [ 6.,  7.,  8.]],</span><br><span class="line"></span><br><span class="line">       [[ 9., 10., 11.],</span><br><span class="line">        [12., 13., 14.],</span><br><span class="line">        [15., 16., 17.]]])</span><br></pre></td></tr></table></figure>
<h4 id="4维图像-1"><a href="#4维图像-1" class="headerlink" title="4维图像"></a>4维图像</h4><p>已知图像大小，行/列坐标矩阵、深度向量和行向量矩阵，用<code>numpy.add.at</code>就能完成映射</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; rows</span><br><span class="line">array([[ 0,  1,  3,  4,  9, 10, 12, 13],</span><br><span class="line">       [ 1,  2,  4,  5, 10, 11, 13, 14],</span><br><span class="line">       [ 3,  4,  6,  7, 12, 13, 15, 16],</span><br><span class="line">       [ 4,  5,  7,  8, 13, 14, 16, 17],</span><br><span class="line">       [18, 19, 21, 22, 27, 28, 30, 31],</span><br><span class="line">       [19, 20, 22, 23, 28, 29, 31, 32],</span><br><span class="line">       [21, 22, 24, 25, 30, 31, 33, 34],</span><br><span class="line">       [22, 23, 25, 26, 31, 32, 34, 35]])</span><br><span class="line">&gt;&gt;&gt; rows_reshaped = rows.reshape(2, 4, 8)</span><br><span class="line">&gt;&gt;&gt; rows_reshaped</span><br><span class="line">array([[[ 0,  1,  3,  4,  9, 10, 12, 13],</span><br><span class="line">        [ 1,  2,  4,  5, 10, 11, 13, 14],</span><br><span class="line">        [ 3,  4,  6,  7, 12, 13, 15, 16],</span><br><span class="line">        [ 4,  5,  7,  8, 13, 14, 16, 17]],</span><br><span class="line"></span><br><span class="line">       [[18, 19, 21, 22, 27, 28, 30, 31],</span><br><span class="line">        [19, 20, 22, 23, 28, 29, 31, 32],</span><br><span class="line">        [21, 22, 24, 25, 30, 31, 33, 34],</span><br><span class="line">        [22, 23, 25, 26, 31, 32, 34, 35]]])</span><br><span class="line">&gt;&gt;&gt; b = np.zeros(a.shape)</span><br><span class="line">&gt;&gt;&gt; np.add.at(b, (slice(None),k,i,j), rows_reshaped)</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([[[[  0.,   2.,   2.],</span><br><span class="line">         [  6.,  16.,  10.],</span><br><span class="line">         [  6.,  14.,   8.]],</span><br><span class="line"></span><br><span class="line">        [[  9.,  20.,  11.],</span><br><span class="line">         [ 24.,  52.,  28.],</span><br><span class="line">         [ 15.,  32.,  17.]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[[ 18.,  38.,  20.],</span><br><span class="line">         [ 42.,  88.,  46.],</span><br><span class="line">         [ 24.,  50.,  26.]],</span><br><span class="line"></span><br><span class="line">        [[ 27.,  56.,  29.],</span><br><span class="line">         [ 60., 124.,  64.],</span><br><span class="line">         [ 33.,  68.,  35.]]]])</span><br></pre></td></tr></table></figure>
<p>计算叠加倍数，得到原始图像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; c = np.ones(a.shape)</span><br><span class="line">&gt;&gt;&gt; cols_c = c[:,k,i,j]</span><br><span class="line">&gt;&gt;&gt; d = np.zeros(a.shape)</span><br><span class="line">&gt;&gt;&gt; np.add.at(d, (slice(None),k,i,j), cols_c)</span><br><span class="line">&gt;&gt;&gt; d</span><br><span class="line">array([[[[1., 2., 1.],</span><br><span class="line">         [2., 4., 2.],</span><br><span class="line">         [1., 2., 1.]],</span><br><span class="line"></span><br><span class="line">        [[1., 2., 1.],</span><br><span class="line">         [2., 4., 2.],</span><br><span class="line">         [1., 2., 1.]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[[1., 2., 1.],</span><br><span class="line">         [2., 4., 2.],</span><br><span class="line">         [1., 2., 1.]],</span><br><span class="line"></span><br><span class="line">        [[1., 2., 1.],</span><br><span class="line">         [2., 4., 2.],</span><br><span class="line">         [1., 2., 1.]]]])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; b/d</span><br><span class="line">array([[[[ 0.,  1.,  2.],</span><br><span class="line">         [ 3.,  4.,  5.],</span><br><span class="line">         [ 6.,  7.,  8.]],</span><br><span class="line"></span><br><span class="line">        [[ 9., 10., 11.],</span><br><span class="line">         [12., 13., 14.],</span><br><span class="line">         [15., 16., 17.]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[[18., 19., 20.],</span><br><span class="line">         [21., 22., 23.],</span><br><span class="line">         [24., 25., 26.]],</span><br><span class="line"></span><br><span class="line">        [[27., 28., 29.],</span><br><span class="line">         [30., 31., 32.],</span><br><span class="line">         [33., 34., 35.]]]])</span><br></pre></td></tr></table></figure>
<h2 id="im2row"><a href="#im2row" class="headerlink" title="im2row"></a>im2row</h2><p>仿照<code>im2col.py</code>，<code>im2row</code>实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-5-25 下午4:17</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">from builtins import range</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_im2row_indices(x_shape, field_height, field_width, padding=1, stride=1):</span><br><span class="line">    # First figure out what the size of the output should be</span><br><span class="line">    N, C, H, W = x_shape</span><br><span class="line">    assert (H + 2 * padding - field_height) % stride == 0</span><br><span class="line">    assert (W + 2 * padding - field_height) % stride == 0</span><br><span class="line">    out_height = int((H + 2 * padding - field_height) / stride + 1)</span><br><span class="line">    out_width = int((W + 2 * padding - field_width) / stride + 1)</span><br><span class="line"></span><br><span class="line">    # 行坐标</span><br><span class="line">    i0 = stride * np.repeat(np.arange(out_height), out_width)</span><br><span class="line">    i1 = np.repeat(np.arange(field_height), field_width)</span><br><span class="line">    i1 = np.tile(i1, C)</span><br><span class="line"></span><br><span class="line">    # 列坐标</span><br><span class="line">    j0 = stride * np.tile(np.arange(out_width), out_height)</span><br><span class="line">    j1 = np.tile(np.arange(field_width), field_height * C)</span><br><span class="line"></span><br><span class="line">    i = i0.reshape(-1, 1) + i1.reshape(1, -1)</span><br><span class="line">    j = j0.reshape(-1, 1) + j1.reshape(1, -1)</span><br><span class="line"></span><br><span class="line">    k = np.repeat(np.arange(C), field_height * field_width).reshape(1, -1)</span><br><span class="line"></span><br><span class="line">    return (k, i, j)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def im2row_indices(x, field_height, field_width, padding=1, stride=1):</span><br><span class="line">    # Zero-pad the input</span><br><span class="line">    p = padding</span><br><span class="line">    x_padded = np.pad(x, ((0, 0), (0, 0), (p, p), (p, p)), mode=&apos;constant&apos;)</span><br><span class="line"></span><br><span class="line">    k, i, j = get_im2row_indices(x.shape, field_height, field_width, padding, stride)</span><br><span class="line"></span><br><span class="line">    rows = x_padded[:, k, i, j]</span><br><span class="line">    C = x.shape[1]</span><br><span class="line">    # 逐图像采集</span><br><span class="line">    rows = rows.reshape(-1, field_height * field_width * C)</span><br><span class="line">    return rows</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def row2im_indices(rows, x_shape, field_height=3, field_width=3, padding=1, stride=1, isstinct=False):</span><br><span class="line">    N, C, H, W = x_shape</span><br><span class="line">    H_padded, W_padded = H + 2 * padding, W + 2 * padding</span><br><span class="line">    x_padded = np.zeros((N, C, H_padded, W_padded), dtype=rows.dtype)</span><br><span class="line">    k, i, j = get_im2row_indices(x_shape, field_height, field_width, padding,</span><br><span class="line">                                 stride)</span><br><span class="line">    rows_reshaped = rows.reshape(N, -1, C * field_height * field_width)</span><br><span class="line">    np.add.at(x_padded, (slice(None), k, i, j), rows_reshaped)</span><br><span class="line"></span><br><span class="line">    if isstinct:</span><br><span class="line">        # 计算叠加倍数，恢复原图</span><br><span class="line">        x_ones = np.ones(x_padded.shape)</span><br><span class="line">        rows_ones = x_ones[:, k, i, j]</span><br><span class="line">        x_zeros = np.zeros(x_padded.shape)</span><br><span class="line">        np.add.at(x_zeros, (slice(None), k, i, j), rows_ones)</span><br><span class="line">        x_padded = x_padded / x_zeros</span><br><span class="line"></span><br><span class="line">    if padding == 0:</span><br><span class="line">        return x_padded</span><br><span class="line"></span><br><span class="line">    return x_padded[:, :, padding:-padding, padding:-padding]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    pass</span><br></pre></td></tr></table></figure>
<p>修改如下：</p>
<ol>
<li>实现图像转行向量</li>
<li>实现逐图像的行向量转换（<em><code>im2cols.py</code>实现的是逐坐标的列向量转换</em>）</li>
<li>添加行向量转换回原图功能（<em>符号位<code>isstinct</code></em>）</li>
</ol>
<h2 id="卷积层和全连接层相互转换"><a href="#卷积层和全连接层相互转换" class="headerlink" title="卷积层和全连接层相互转换"></a>卷积层和全连接层相互转换</h2><p>批量图像数据大小为$2\times 3\times 4\times 4$，卷积核大小为$3\times 3$，步长为$1$，零填充为0</p>
<p>单个局部连接矩阵大小为$3\times 3\times 3=27$，共有8个</p>
<p>行向量矩阵大小为$8\times 27$</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x = np.arange(96).reshape(2, 3, 4, 4)</span><br><span class="line"># print(x)</span><br><span class="line">rows = im2row_indices(x, 3, 3, padding=0, stride=1)</span><br><span class="line">print(rows)</span><br><span class="line">print(rows.shape)</span><br><span class="line"># output = row2im_indices(rows, x.shape, field_height=3, field_width=3, padding=0, stride=1)</span><br><span class="line"># print(output)</span><br><span class="line">output = row2im_indices(rows, x.shape, field_height=3, field_width=3, padding=0, stride=1, isstinct=True)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[[ 0  1  2  4  5  6  8  9 10 16 17 18 20 21 22 24 25 26 32 33 34 36 37 38</span><br><span class="line">  40 41 42]</span><br><span class="line"> [ 1  2  3  5  6  7  9 10 11 17 18 19 21 22 23 25 26 27 33 34 35 37 38 39</span><br><span class="line">  41 42 43]</span><br><span class="line"> [ 4  5  6  8  9 10 12 13 14 20 21 22 24 25 26 28 29 30 36 37 38 40 41 42</span><br><span class="line">  44 45 46]</span><br><span class="line"> [ 5  6  7  9 10 11 13 14 15 21 22 23 25 26 27 29 30 31 37 38 39 41 42 43</span><br><span class="line">  45 46 47]</span><br><span class="line"> [48 49 50 52 53 54 56 57 58 64 65 66 68 69 70 72 73 74 80 81 82 84 85 86</span><br><span class="line">  88 89 90]</span><br><span class="line"> [49 50 51 53 54 55 57 58 59 65 66 67 69 70 71 73 74 75 81 82 83 85 86 87</span><br><span class="line">  89 90 91]</span><br><span class="line"> [52 53 54 56 57 58 60 61 62 68 69 70 72 73 74 76 77 78 84 85 86 88 89 90</span><br><span class="line">  92 93 94]</span><br><span class="line"> [53 54 55 57 58 59 61 62 63 69 70 71 73 74 75 77 78 79 85 86 87 89 90 91</span><br><span class="line">  93 94 95]]</span><br><span class="line">(8, 27)</span><br><span class="line">[[[[ 0.  1.  2.  3.]</span><br><span class="line">   [ 4.  5.  6.  7.]</span><br><span class="line">   [ 8.  9. 10. 11.]</span><br><span class="line">   [12. 13. 14. 15.]]</span><br><span class="line">  [[16. 17. 18. 19.]</span><br><span class="line">   [20. 21. 22. 23.]</span><br><span class="line">   [24. 25. 26. 27.]</span><br><span class="line">   [28. 29. 30. 31.]]</span><br><span class="line">  [[32. 33. 34. 35.]</span><br><span class="line">   [36. 37. 38. 39.]</span><br><span class="line">   [40. 41. 42. 43.]</span><br><span class="line">   [44. 45. 46. 47.]]]</span><br><span class="line"> [[[48. 49. 50. 51.]</span><br><span class="line">   [52. 53. 54. 55.]</span><br><span class="line">   [56. 57. 58. 59.]</span><br><span class="line">   [60. 61. 62. 63.]]</span><br><span class="line">  [[64. 65. 66. 67.]</span><br><span class="line">   [68. 69. 70. 71.]</span><br><span class="line">   [72. 73. 74. 75.]</span><br><span class="line">   [76. 77. 78. 79.]]</span><br><span class="line">  [[80. 81. 82. 83.]</span><br><span class="line">   [84. 85. 86. 87.]</span><br><span class="line">   [88. 89. 90. 91.]</span><br><span class="line">   [92. 93. 94. 95.]]]]</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>卷积神经网络</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>im2col解析2</title>
    <url>/posts/597060a3.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://www.zhihu.com/question/28385679" target="_blank" rel="noopener">在 Caffe 中如何计算卷积？</a></p><p><a href="https://www.zhujian.tech/posts/ab1e719c.html#more">卷积神经网络推导-批量图片矩阵计算</a></p><p><code>im2col</code>表示<code>image to column</code>，将图像转换成列向量</p><a id="more"></a>



<p><strong>卷积操作步骤</strong>：首先将卷积核映射到<code>x_padded</code>左上角，然后沿着行方向操作，每次滑动<code>stride</code>距离；到达最右端后，将卷积核往列方向滑动<code>stride</code>距离，再实现从左到右的滑动</p>
<h2 id="图像转列向量"><a href="#图像转列向量" class="headerlink" title="图像转列向量"></a>图像转列向量</h2><p>在以下操作中，假设感受野大小为<code>field_height = field_width = 2</code>，零填充<code>padding = 0</code>，步长<code>stride = 2</code></p>
<h3 id="2维图像"><a href="#2维图像" class="headerlink" title="2维图像"></a>2维图像</h3><p><strong>以(3,3)大小矩阵为例</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.arange(9).reshape(3,3)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[0, 1, 2],</span><br><span class="line">       [3, 4, 5],</span><br><span class="line">       [6, 7, 8]])</span><br></pre></td></tr></table></figure>
<p>那么得到的局部连接数为</p>
<script type="math/tex; mode=display">
(3 - 2 + 2*0)/1 + 1 = 2\\
num = 2*2 = 4</script><p>所以共有4个局部连接，分别是</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
0 & 1\\ 
3 & 4
\end{bmatrix}\ \ 
\begin{bmatrix}
1 & 2\\ 
4 & 5
\end{bmatrix}\ \  
\begin{bmatrix}
3 & 4\\ 
6 & 7
\end{bmatrix}
\begin{bmatrix}
4 & 5\\ 
7 & 8
\end{bmatrix}</script><p>其坐标分别为</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
(0,0) & (0,1)\\ 
(1,0) & (1,1)
\end{bmatrix}\ \ 
\begin{bmatrix}
(0,1) & (0,2)\\
(1,1) & (1,2)
\end{bmatrix}\ \  
\begin{bmatrix}
(1,0) & (1,1)\\
(2,0) & (2,1)
\end{bmatrix}
\begin{bmatrix}
(1,1) & (1,2)\\
(2,1) & (2,2)
\end{bmatrix}</script><p>将其列向量化，可得</p>
<script type="math/tex; mode=display">
matrix=
\begin{bmatrix}
0 & 1 & 3 & 4\\ 
1 & 2 & 4 & 5\\ 
3 & 4 & 6 & 7\\ 
4 & 5 & 7 & 8
\end{bmatrix}</script><script type="math/tex; mode=display">
indexs=
\begin{bmatrix}
(0,0) & (0,1) & (1,0) & (1,1)\\ 
(0,1) & (0,2) & (1,1) & (1,2)\\ 
(1,0) & (1,1) & (2,0) & (2,1)\\ 
(1,1) & (1,2) & (2,1) & (2,2)
\end{bmatrix}</script><p>进行行列坐标分离</p>
<script type="math/tex; mode=display">
rows_{index}=
\begin{bmatrix}
0 & 0 & 1 & 1\\ 
0 & 0 & 1 & 1\\ 
1 & 1 & 2 & 2\\ 
1 & 1 & 2 & 2
\end{bmatrix}</script><script type="math/tex; mode=display">
columns_{index}=
\begin{bmatrix}
0 & 1 & 0 & 1\\ 
1 & 2 & 1 & 2\\ 
0 & 1 & 0 & 1\\ 
1 & 2 & 1 & 2
\end{bmatrix}</script><p>对卷积核而言，每行的行坐标一致，共有<code>field_width</code>个，每个卷积核有<code>field_height</code>行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># i0 = np.repeat(np.arange(field_height), field_width)</span><br><span class="line">&gt;&gt;&gt; i0 = np.repeat(np.arange(2), 2)</span><br><span class="line">&gt;&gt;&gt; i0</span><br><span class="line">array([0, 0, 1, 1])</span><br></pre></td></tr></table></figure>
<p>每行共有<code>out_width</code>个局部连接矩阵，每个矩阵相隔<code>stride</code>，共有<code>out_height</code>行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># i1 = stride * np.repeat(np.arange(out_height), out_width)</span><br><span class="line">&gt;&gt;&gt; i1 = 1 * np.repeat(np.arange(2), 2)</span><br><span class="line">&gt;&gt;&gt; i1</span><br><span class="line">array([0, 0, 1, 1])</span><br></pre></td></tr></table></figure>
<p>对于局部连接矩阵的行坐标为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># i = i0.reshape(-1, 1) + i1.reshape(1, -1)</span><br><span class="line">&gt;&gt;&gt; i0.reshape(-1,1)</span><br><span class="line">array([[0],</span><br><span class="line">       [0],</span><br><span class="line">       [1],</span><br><span class="line">       [1]])</span><br><span class="line">&gt;&gt;&gt; i1.reshape(1,-1)</span><br><span class="line">array([[0, 0, 1, 1]])</span><br><span class="line">&gt;&gt;&gt; i = i0.reshape(-1,1)+i1.reshape(1,-1)</span><br><span class="line">&gt;&gt;&gt; i</span><br><span class="line">array([[0, 0, 1, 1],</span><br><span class="line">       [0, 0, 1, 1],</span><br><span class="line">       [1, 1, 2, 2],</span><br><span class="line">       [1, 1, 2, 2]])</span><br></pre></td></tr></table></figure>
<p>同样的，对于卷积核的列来说，其相邻列相差<code>1</code>，长<code>field_width</code>，共有<code>field_height</code>行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># j0 = np.tile(np.arange(field_width), field_height * C)</span><br><span class="line">&gt;&gt;&gt; j0 = np.tile(np.arange(2),2)</span><br><span class="line">&gt;&gt;&gt; j0</span><br><span class="line">array([0, 1, 0, 1])</span><br></pre></td></tr></table></figure>
<p>每行有<code>out_width</code>个局部连接矩阵，矩阵之间相差<code>stride</code>步长，同一列矩阵相对于该行最左侧的距离相同</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># j1 = stride * np.tile(np.arange(out_width), out_height)</span><br><span class="line">&gt;&gt;&gt; j1 = 1*np.tile(np.arange(2), 2)</span><br><span class="line">&gt;&gt;&gt; j1</span><br><span class="line">array([0, 1, 0, 1])</span><br></pre></td></tr></table></figure>
<p>计算局部连接矩阵的行坐标</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># j = j0.reshape(-1, 1) + j1.reshape(1, -1)</span><br><span class="line">&gt;&gt;&gt; j0.reshape(-1,1)</span><br><span class="line">array([[0],</span><br><span class="line">       [1],</span><br><span class="line">       [0],</span><br><span class="line">       [1]])</span><br><span class="line">&gt;&gt;&gt; j1.reshape(1,-1)</span><br><span class="line">array([[0, 1, 0, 1]])</span><br><span class="line">&gt;&gt;&gt; j = j0.reshape(-1,1) + j1.reshape(1,-1)</span><br><span class="line">&gt;&gt;&gt; j</span><br><span class="line">array([[0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2],</span><br><span class="line">       [0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2]])</span><br></pre></td></tr></table></figure>
<p>得到列向量矩阵的行坐标和列坐标后，求取局部连接矩阵的列向量矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a[i,j]</span><br><span class="line">array([[0, 1, 3, 4],</span><br><span class="line">       [1, 2, 4, 5],</span><br><span class="line">       [3, 4, 6, 7],</span><br><span class="line">       [4, 5, 7, 8]])</span><br></pre></td></tr></table></figure>
<h3 id="3维图像"><a href="#3维图像" class="headerlink" title="3维图像"></a>3维图像</h3><p>如果图像有多通道，每个通道图像的卷积操作一致，局部连接总数不变，仅扩展每个卷积矩阵的大小，所以仅需在行/列坐标矩阵的列方向扩展即可</p>
<p>比如有$2\times 3\times 3$大小图像，通道数为<code>2</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.arange(18).reshape(2,3,3)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[[ 0,  1,  2],</span><br><span class="line">        [ 3,  4,  5],</span><br><span class="line">        [ 6,  7,  8]],</span><br><span class="line"></span><br><span class="line">       [[ 9, 10, 11],</span><br><span class="line">        [12, 13, 14],</span><br><span class="line">        [15, 16, 17]]])</span><br></pre></td></tr></table></figure>
<p>局部连接矩阵大小为$2\times 2\times 2$，比如</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[[ 0,  1],</span><br><span class="line">        [ 3,  4],</span><br><span class="line"></span><br><span class="line">       [[ 9, 10],</span><br><span class="line">        [12, 13]]])</span><br></pre></td></tr></table></figure>
<p>对于行坐标矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; i0 = np.repeat(np.arange(2), 2)</span><br><span class="line">&gt;&gt;&gt; i0</span><br><span class="line">array([0, 0, 1, 1])</span><br><span class="line">&gt;&gt;&gt; i0 = np.tile(i0, 2)</span><br><span class="line">&gt;&gt;&gt; i0</span><br><span class="line">array([0, 0, 1, 1, 0, 0, 1, 1])</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; i1 = 1 * np.repeat(np.arange(2), 2)</span><br><span class="line">&gt;&gt;&gt; i1</span><br><span class="line">array([0, 0, 1, 1])</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; i = i0.reshape(-1,1) + i1.reshape(1, -1)</span><br><span class="line">&gt;&gt;&gt; i</span><br><span class="line">array([[0, 0, 1, 1],</span><br><span class="line">       [0, 0, 1, 1],</span><br><span class="line">       [1, 1, 2, 2],</span><br><span class="line">       [1, 1, 2, 2],</span><br><span class="line">       [0, 0, 1, 1],</span><br><span class="line">       [0, 0, 1, 1],</span><br><span class="line">       [1, 1, 2, 2],</span><br><span class="line">       [1, 1, 2, 2]])</span><br></pre></td></tr></table></figure>
<p>对于列坐标矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; j0 = np.tile(np.arange(2), 2*2)</span><br><span class="line">&gt;&gt;&gt; j0</span><br><span class="line">array([0, 1, 0, 1, 0, 1, 0, 1])</span><br><span class="line">&gt;&gt;&gt; j1 = 1 * np.tile(np.arange(2), 2)</span><br><span class="line">&gt;&gt;&gt; j1</span><br><span class="line">array([0, 1, 0, 1])</span><br><span class="line">&gt;&gt;&gt; j = j0.reshape(-1, 1) + j1.reshape(1, -1)</span><br><span class="line">&gt;&gt;&gt; j</span><br><span class="line">array([[0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2],</span><br><span class="line">       [0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2],</span><br><span class="line">       [0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2],</span><br><span class="line">       [0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2]])</span><br></pre></td></tr></table></figure>
<p><strong>还需要计算通道向量k，用于指定哪个通道图像</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; k = np.repeat(np.arange(2), 2*2).reshape(-1,1)</span><br><span class="line">&gt;&gt;&gt; k</span><br><span class="line">array([[0],</span><br><span class="line">       [0],</span><br><span class="line">       [0],</span><br><span class="line">       [0],</span><br><span class="line">       [1],</span><br><span class="line">       [1],</span><br><span class="line">       [1],</span><br><span class="line">       [1]])</span><br></pre></td></tr></table></figure>
<p>最后求取局部连接矩阵的列向量矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a[k,i,j]</span><br><span class="line">array([[ 0,  1,  3,  4],</span><br><span class="line">       [ 1,  2,  4,  5],</span><br><span class="line">       [ 3,  4,  6,  7],</span><br><span class="line">       [ 4,  5,  7,  8],</span><br><span class="line">       [ 9, 10, 12, 13],</span><br><span class="line">       [10, 11, 13, 14],</span><br><span class="line">       [12, 13, 15, 16],</span><br><span class="line">       [13, 14, 16, 17]])</span><br></pre></td></tr></table></figure>
<h3 id="4维图像"><a href="#4维图像" class="headerlink" title="4维图像"></a>4维图像</h3><p>批量处理多通道图像，比如批量图像数据大小为$2\times 2\times 3\times 3$，共<code>2</code>张图片，每张图像<code>2</code>通道，大小为$3\times 3$</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.arange(36).reshape(2,2,3,3)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[[[ 0,  1,  2],</span><br><span class="line">         [ 3,  4,  5],</span><br><span class="line">         [ 6,  7,  8]],</span><br><span class="line"></span><br><span class="line">        [[ 9, 10, 11],</span><br><span class="line">         [12, 13, 14],</span><br><span class="line">         [15, 16, 17]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[[18, 19, 20],</span><br><span class="line">         [21, 22, 23],</span><br><span class="line">         [24, 25, 26]],</span><br><span class="line"></span><br><span class="line">        [[27, 28, 29],</span><br><span class="line">         [30, 31, 32],</span><br><span class="line">         [33, 34, 35]]]])</span><br></pre></td></tr></table></figure>
<p>对于行/列坐标矩阵<code>i,j</code>以及通道向量<code>k</code>与<code>3</code>维图像操作一致</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a[:,k,i,j]</span><br><span class="line">array([[[ 0,  1,  3,  4],</span><br><span class="line">        [ 1,  2,  4,  5],</span><br><span class="line">        [ 3,  4,  6,  7],</span><br><span class="line">        [ 4,  5,  7,  8],</span><br><span class="line">        [ 9, 10, 12, 13],</span><br><span class="line">        [10, 11, 13, 14],</span><br><span class="line">        [12, 13, 15, 16],</span><br><span class="line">        [13, 14, 16, 17]],</span><br><span class="line"></span><br><span class="line">       [[18, 19, 21, 22],</span><br><span class="line">        [19, 20, 22, 23],</span><br><span class="line">        [21, 22, 24, 25],</span><br><span class="line">        [22, 23, 25, 26],</span><br><span class="line">        [27, 28, 30, 31],</span><br><span class="line">        [28, 29, 31, 32],</span><br><span class="line">        [30, 31, 33, 34],</span><br><span class="line">        [31, 32, 34, 35]]])</span><br><span class="line">&gt;&gt;&gt; a[:,k,i,j].shape</span><br><span class="line">(2, 8, 4)</span><br></pre></td></tr></table></figure>
<p>得到的是一个<code>3</code>维数据体，第一维表示图像数，第二维表示单个矩阵向量，第三维表示每个图片的局部矩阵数</p>
<p>先进行维数转换，再变形为2维矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; c = np.transpose(b, (1,2,0))</span><br><span class="line">&gt;&gt;&gt; c.shape</span><br><span class="line">(8, 4, 2)</span><br><span class="line">&gt;&gt;&gt; c.reshape(8, -1)</span><br><span class="line">array([[ 0, 18,  1, 19,  3, 21,  4, 22],</span><br><span class="line">       [ 1, 19,  2, 20,  4, 22,  5, 23],</span><br><span class="line">       [ 3, 21,  4, 22,  6, 24,  7, 25],</span><br><span class="line">       [ 4, 22,  5, 23,  7, 25,  8, 26],</span><br><span class="line">       [ 9, 27, 10, 28, 12, 30, 13, 31],</span><br><span class="line">       [10, 28, 11, 29, 13, 31, 14, 32],</span><br><span class="line">       [12, 30, 13, 31, 15, 33, 16, 34],</span><br><span class="line">       [13, 31, 14, 32, 16, 34, 17, 35]])</span><br></pre></td></tr></table></figure>
<p>最后得到了<code>2</code>维矩阵，每列表示一个局部连接矩阵向量，其排列方式为依次加入每个图像的相同位置局部连接矩阵，再向左向下滑动（<strong><code>im2col.py</code>实现方式</strong>）</p>
<p><strong>如果想要先完成单个图像所有局部连接矩阵，再进行下一个图像的转换，可以修改维数变换如下</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; c = np.transpose(b, (1,0,2))</span><br><span class="line">&gt;&gt;&gt; c.shape</span><br><span class="line">(8, 2, 4)</span><br><span class="line">&gt;&gt;&gt; c.reshape(8, -1)</span><br><span class="line">array([[ 0,  1,  3,  4, 18, 19, 21, 22],</span><br><span class="line">       [ 1,  2,  4,  5, 19, 20, 22, 23],</span><br><span class="line">       [ 3,  4,  6,  7, 21, 22, 24, 25],</span><br><span class="line">       [ 4,  5,  7,  8, 22, 23, 25, 26],</span><br><span class="line">       [ 9, 10, 12, 13, 27, 28, 30, 31],</span><br><span class="line">       [10, 11, 13, 14, 28, 29, 31, 32],</span><br><span class="line">       [12, 13, 15, 16, 30, 31, 33, 34],</span><br><span class="line">       [13, 14, 16, 17, 31, 32, 34, 35]])</span><br></pre></td></tr></table></figure>
<h2 id="列向量转图像"><a href="#列向量转图像" class="headerlink" title="列向量转图像"></a>列向量转图像</h2><p>将图像转列向量小节中得到的列向量矩阵重新映射回图像</p>
<h3 id="2维图像-1"><a href="#2维图像-1" class="headerlink" title="2维图像"></a>2维图像</h3><p>已知图像大小为$3\times 3$，卷积核大小为$2\times 2$，步长为<code>2</code>，零填充为<code>0</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.arange(9).reshape(3,3)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[0, 1, 2],</span><br><span class="line">       [3, 4, 5],</span><br><span class="line">       [6, 7, 8]])</span><br><span class="line"># 列向量矩阵</span><br><span class="line">&gt;&gt;&gt; a[i,j]</span><br><span class="line">array([[0, 1, 3, 4],</span><br><span class="line">       [1, 2, 4, 5],</span><br><span class="line">       [3, 4, 6, 7],</span><br><span class="line">       [4, 5, 7, 8]])</span><br></pre></td></tr></table></figure>
<p>根据图像数据和参数获取行/列坐标矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; i</span><br><span class="line">array([[0, 0, 1, 1],</span><br><span class="line">       [0, 0, 1, 1],</span><br><span class="line">       [1, 1, 2, 2],</span><br><span class="line">       [1, 1, 2, 2]])</span><br><span class="line">&gt;&gt;&gt; j</span><br><span class="line">array([[0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2],</span><br><span class="line">       [0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2]])</span><br></pre></td></tr></table></figure>
<p>获取<code>2</code>维列矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; cols = a[i,j]</span><br><span class="line">&gt;&gt;&gt; cols</span><br><span class="line">array([[0, 1, 3, 4],</span><br><span class="line">       [1, 2, 4, 5],</span><br><span class="line">       [3, 4, 6, 7],</span><br><span class="line">       [4, 5, 7, 8]])</span><br></pre></td></tr></table></figure>
<p>将<code>2</code>维列矩阵映射到图像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; b = np.zeros(a.shape)</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([[0., 0., 0.],</span><br><span class="line">       [0., 0., 0.],</span><br><span class="line">       [0., 0., 0.]])</span><br><span class="line">&gt;&gt;&gt; np.add.at(b, (i,j), cols)</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([[ 0.,  2.,  2.],</span><br><span class="line">       [ 6., 16., 10.],</span><br><span class="line">       [ 6., 14.,  8.]])</span><br></pre></td></tr></table></figure>
<p><strong>反向映射得到的图像数据和原先图像数据不一致，因为卷积操作中许多下标的位置被多次采集</strong></p>
<p>如果想要得到原图，<strong>需要除以叠加的倍数</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; c = np.zeros(a.shape)</span><br><span class="line">&gt;&gt;&gt; c</span><br><span class="line">array([[0., 0., 0.],</span><br><span class="line">       [0., 0., 0.],</span><br><span class="line">       [0., 0., 0.]])</span><br><span class="line">&gt;&gt;&gt; c = np.ones(a.shape)</span><br><span class="line">&gt;&gt;&gt; c</span><br><span class="line">array([[1., 1., 1.],</span><br><span class="line">       [1., 1., 1.],</span><br><span class="line">       [1., 1., 1.]])</span><br><span class="line">&gt;&gt;&gt; cols_c = c[i,j]</span><br><span class="line">&gt;&gt;&gt; cols_c</span><br><span class="line">array([[1., 1., 1., 1.],</span><br><span class="line">       [1., 1., 1., 1.],</span><br><span class="line">       [1., 1., 1., 1.],</span><br><span class="line">       [1., 1., 1., 1.]])</span><br><span class="line">&gt;&gt;&gt; d = np.zeros(c.shape)</span><br><span class="line">&gt;&gt;&gt; d</span><br><span class="line">array([[0., 0., 0.],</span><br><span class="line">       [0., 0., 0.],</span><br><span class="line">       [0., 0., 0.]])</span><br><span class="line">&gt;&gt;&gt; np.add.at(d, (i,j), cols_c)</span><br><span class="line">&gt;&gt;&gt; d</span><br><span class="line">array([[1., 2., 1.],</span><br><span class="line">       [2., 4., 2.],</span><br><span class="line">       [1., 2., 1.]])</span><br><span class="line">&gt;&gt;&gt; b/d</span><br><span class="line">array([[0., 1., 2.],</span><br><span class="line">       [3., 4., 5.],</span><br><span class="line">       [6., 7., 8.]])</span><br><span class="line">&gt;&gt;&gt; b/d == a</span><br><span class="line">array([[ True,  True,  True],</span><br><span class="line">       [ True,  True,  True],</span><br><span class="line">       [ True,  True,  True]])</span><br></pre></td></tr></table></figure>
<h3 id="3维图像-1"><a href="#3维图像-1" class="headerlink" title="3维图像"></a>3维图像</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.arange(18).reshape(2,3,3)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[[ 0,  1,  2],</span><br><span class="line">        [ 3,  4,  5],</span><br><span class="line">        [ 6,  7,  8]],</span><br><span class="line"></span><br><span class="line">       [[ 9, 10, 11],</span><br><span class="line">        [12, 13, 14],</span><br><span class="line">        [15, 16, 17]]])</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; i</span><br><span class="line">array([[0, 0, 1, 1],</span><br><span class="line">       [0, 0, 1, 1],</span><br><span class="line">       [1, 1, 2, 2],</span><br><span class="line">       [1, 1, 2, 2],</span><br><span class="line">       [0, 0, 1, 1],</span><br><span class="line">       [0, 0, 1, 1],</span><br><span class="line">       [1, 1, 2, 2],</span><br><span class="line">       [1, 1, 2, 2]])</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; j</span><br><span class="line">array([[0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2],</span><br><span class="line">       [0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2],</span><br><span class="line">       [0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2],</span><br><span class="line">       [0, 1, 0, 1],</span><br><span class="line">       [1, 2, 1, 2]])</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; k</span><br><span class="line">array([[0],</span><br><span class="line">       [0],</span><br><span class="line">       [0],</span><br><span class="line">       [0],</span><br><span class="line">       [1],</span><br><span class="line">       [1],</span><br><span class="line">       [1],</span><br><span class="line">       [1]])</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; cols = a[k,i,j]</span><br><span class="line">&gt;&gt;&gt; cols</span><br><span class="line">array([[ 0,  1,  3,  4],</span><br><span class="line">       [ 1,  2,  4,  5],</span><br><span class="line">       [ 3,  4,  6,  7],</span><br><span class="line">       [ 4,  5,  7,  8],</span><br><span class="line">       [ 9, 10, 12, 13],</span><br><span class="line">       [10, 11, 13, 14],</span><br><span class="line">       [12, 13, 15, 16],</span><br><span class="line">       [13, 14, 16, 17]])</span><br></pre></td></tr></table></figure>
<p>反向计算图像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; np.add.at(b, (k, i, j), cols)</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([[[ 0.,  2.,  2.],</span><br><span class="line">        [ 6., 16., 10.],</span><br><span class="line">        [ 6., 14.,  8.]],</span><br><span class="line"></span><br><span class="line">       [[ 9., 20., 11.],</span><br><span class="line">        [24., 52., 28.],</span><br><span class="line">        [15., 32., 17.]]])</span><br></pre></td></tr></table></figure>
<p>除以叠加倍数，转变回原图</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; c = np.ones(a.shape)</span><br><span class="line">&gt;&gt;&gt; cols_c = c[k,i,j]</span><br><span class="line">&gt;&gt;&gt; cols_c</span><br><span class="line">array([[1., 1., 1., 1.],</span><br><span class="line">       [1., 1., 1., 1.],</span><br><span class="line">       [1., 1., 1., 1.],</span><br><span class="line">       [1., 1., 1., 1.],</span><br><span class="line">       [1., 1., 1., 1.],</span><br><span class="line">       [1., 1., 1., 1.],</span><br><span class="line">       [1., 1., 1., 1.],</span><br><span class="line">       [1., 1., 1., 1.]])</span><br><span class="line">&gt;&gt;&gt; d = np.zeros(c.shape)</span><br><span class="line">&gt;&gt;&gt; d</span><br><span class="line">array([[[0., 0., 0.],</span><br><span class="line">        [0., 0., 0.],</span><br><span class="line">        [0., 0., 0.]],</span><br><span class="line"></span><br><span class="line">       [[0., 0., 0.],</span><br><span class="line">        [0., 0., 0.],</span><br><span class="line">        [0., 0., 0.]]])</span><br><span class="line">&gt;&gt;&gt; np.add.at(d, (k,i,j), cols_c)</span><br><span class="line">&gt;&gt;&gt; d</span><br><span class="line">array([[[1., 2., 1.],</span><br><span class="line">        [2., 4., 2.],</span><br><span class="line">        [1., 2., 1.]],</span><br><span class="line"></span><br><span class="line">       [[1., 2., 1.],</span><br><span class="line">        [2., 4., 2.],</span><br><span class="line">        [1., 2., 1.]]])</span><br><span class="line">&gt;&gt;&gt; b/d</span><br><span class="line">array([[[ 0.,  1.,  2.],</span><br><span class="line">        [ 3.,  4.,  5.],</span><br><span class="line">        [ 6.,  7.,  8.]],</span><br><span class="line"></span><br><span class="line">       [[ 9., 10., 11.],</span><br><span class="line">        [12., 13., 14.],</span><br><span class="line">        [15., 16., 17.]]])</span><br><span class="line">&gt;&gt;&gt; b/d == a</span><br><span class="line">array([[[ True,  True,  True],</span><br><span class="line">        [ True,  True,  True],</span><br><span class="line">        [ True,  True,  True]],</span><br><span class="line"></span><br><span class="line">       [[ True,  True,  True],</span><br><span class="line">        [ True,  True,  True],</span><br><span class="line">        [ True,  True,  True]]])</span><br></pre></td></tr></table></figure>
<h3 id="4维图像-1"><a href="#4维图像-1" class="headerlink" title="4维图像"></a>4维图像</h3><p><strong>最终要实现的是批量图片列向量矩阵的反卷积操作</strong></p>
<p>从批量图像数据中通过坐标矩阵获取的列向量矩阵是<code>3</code>维大小，还需要通过维数转换和变形</p>
<p>列向量转图像需要执行反向操作，首先进行数据变形，再进行维数转换，最后通过坐标矩阵叠加</p>
<p>在上一小节中最后得到了两种排列的列向量矩阵，一种是<strong>先提取同一位置局部连接矩阵</strong>，另一种是<strong>先提取同一图片局部连接矩阵</strong></p>
<p>如果前向操作如下（第二种）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; cols = np.transpose(b, (1,2,0))</span><br><span class="line">&gt;&gt;&gt; cols.shape</span><br><span class="line">(8, 4, 2)</span><br><span class="line">&gt;&gt;&gt; cols.reshape(8, -1)</span><br><span class="line">array([[ 0,  1,  3,  4, 18, 19, 21, 22],</span><br><span class="line">       [ 1,  2,  4,  5, 19, 20, 22, 23],</span><br><span class="line">       [ 3,  4,  6,  7, 21, 22, 24, 25],</span><br><span class="line">       [ 4,  5,  7,  8, 22, 23, 25, 26],</span><br><span class="line">       [ 9, 10, 12, 13, 27, 28, 30, 31],</span><br><span class="line">       [10, 11, 13, 14, 28, 29, 31, 32],</span><br><span class="line">       [12, 13, 15, 16, 30, 31, 33, 34],</span><br><span class="line">       [13, 14, 16, 17, 31, 32, 34, 35]])</span><br></pre></td></tr></table></figure>
<p>那么反向操作为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; N=2</span><br><span class="line">&gt;&gt;&gt; cols_reshaped = cols.reshape(cols.shape[0], N, -1)</span><br><span class="line">&gt;&gt;&gt; cols_reshaped.shape</span><br><span class="line">(8, 2, 4)</span><br><span class="line">&gt;&gt;&gt; np.transpose(cols_reshaped, (1,0,2))</span><br><span class="line">array([[[ 0,  1,  3,  4],</span><br><span class="line">        [ 1,  2,  4,  5],</span><br><span class="line">        [ 3,  4,  6,  7],</span><br><span class="line">        [ 4,  5,  7,  8],</span><br><span class="line">        [ 9, 10, 12, 13],</span><br><span class="line">        [10, 11, 13, 14],</span><br><span class="line">        [12, 13, 15, 16],</span><br><span class="line">        [13, 14, 16, 17]],</span><br><span class="line"></span><br><span class="line">       [[18, 19, 21, 22],</span><br><span class="line">        [19, 20, 22, 23],</span><br><span class="line">        [21, 22, 24, 25],</span><br><span class="line">        [22, 23, 25, 26],</span><br><span class="line">        [27, 28, 30, 31],</span><br><span class="line">        [28, 29, 31, 32],</span><br><span class="line">        [30, 31, 33, 34],</span><br><span class="line">        [31, 32, 34, 35]]])</span><br></pre></td></tr></table></figure>
<p>批量图片大小为$2\times 2\times 3\times 3$，得到最终的反向结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">b = np.zeros(a.shape)</span><br><span class="line">&gt;&gt;&gt; np.add.at(b, (slice(None), k, i,j), cols_reshaped)</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([[[[  0.,   2.,   2.],</span><br><span class="line">         [  6.,  16.,  10.],</span><br><span class="line">         [  6.,  14.,   8.]],</span><br><span class="line"></span><br><span class="line">        [[  9.,  20.,  11.],</span><br><span class="line">         [ 24.,  52.,  28.],</span><br><span class="line">         [ 15.,  32.,  17.]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[[ 18.,  38.,  20.],</span><br><span class="line">         [ 42.,  88.,  46.],</span><br><span class="line">         [ 24.,  50.,  26.]],</span><br><span class="line"></span><br><span class="line">        [[ 27.,  56.,  29.],</span><br><span class="line">         [ 60., 124.,  64.],</span><br><span class="line">         [ 33.,  68.,  35.]]]])</span><br></pre></td></tr></table></figure>
<p>除以叠加倍数，得到最初的图像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; c = np.ones(a.shape)</span><br><span class="line">&gt;&gt;&gt; cols_c = c[:,k,i,j]</span><br><span class="line">&gt;&gt;&gt; cols_c</span><br><span class="line">array([[[1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.]],</span><br><span class="line"></span><br><span class="line">       [[1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1.]]])</span><br><span class="line">&gt;&gt;&gt; d = np.zeros(c.shape)</span><br><span class="line">&gt;&gt;&gt; d</span><br><span class="line">array([[[[0., 0., 0.],</span><br><span class="line">         [0., 0., 0.],</span><br><span class="line">         [0., 0., 0.]],</span><br><span class="line"></span><br><span class="line">        [[0., 0., 0.],</span><br><span class="line">         [0., 0., 0.],</span><br><span class="line">         [0., 0., 0.]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[[0., 0., 0.],</span><br><span class="line">         [0., 0., 0.],</span><br><span class="line">         [0., 0., 0.]],</span><br><span class="line"></span><br><span class="line">        [[0., 0., 0.],</span><br><span class="line">         [0., 0., 0.],</span><br><span class="line">         [0., 0., 0.]]]])</span><br><span class="line">&gt;&gt;&gt; np.add.at(d, (slice(None), k,i,j), cols_c)</span><br><span class="line">&gt;&gt;&gt; d</span><br><span class="line">array([[[[1., 2., 1.],</span><br><span class="line">         [2., 4., 2.],</span><br><span class="line">         [1., 2., 1.]],</span><br><span class="line"></span><br><span class="line">        [[1., 2., 1.],</span><br><span class="line">         [2., 4., 2.],</span><br><span class="line">         [1., 2., 1.]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[[1., 2., 1.],</span><br><span class="line">         [2., 4., 2.],</span><br><span class="line">         [1., 2., 1.]],</span><br><span class="line"></span><br><span class="line">        [[1., 2., 1.],</span><br><span class="line">         [2., 4., 2.],</span><br><span class="line">         [1., 2., 1.]]]])</span><br><span class="line">&gt;&gt;&gt; b/d</span><br><span class="line">array([[[[ 0.,  1.,  2.],</span><br><span class="line">         [ 3.,  4.,  5.],</span><br><span class="line">         [ 6.,  7.,  8.]],</span><br><span class="line"></span><br><span class="line">        [[ 9., 10., 11.],</span><br><span class="line">         [12., 13., 14.],</span><br><span class="line">         [15., 16., 17.]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[[18., 19., 20.],</span><br><span class="line">         [21., 22., 23.],</span><br><span class="line">         [24., 25., 26.]],</span><br><span class="line"></span><br><span class="line">        [[27., 28., 29.],</span><br><span class="line">         [30., 31., 32.],</span><br><span class="line">         [33., 34., 35.]]]])</span><br><span class="line">&gt;&gt;&gt; b/d == a</span><br><span class="line">array([[[[ True,  True,  True],</span><br><span class="line">         [ True,  True,  True],</span><br><span class="line">         [ True,  True,  True]],</span><br><span class="line"></span><br><span class="line">        [[ True,  True,  True],</span><br><span class="line">         [ True,  True,  True],</span><br><span class="line">         [ True,  True,  True]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[[ True,  True,  True],</span><br><span class="line">         [ True,  True,  True],</span><br><span class="line">         [ True,  True,  True]],</span><br><span class="line"></span><br><span class="line">        [[ True,  True,  True],</span><br><span class="line">         [ True,  True,  True],</span><br><span class="line">         [ True,  True,  True]]]])</span><br></pre></td></tr></table></figure>
<h2 id="im2col-py"><a href="#im2col-py" class="headerlink" title="im2col.py"></a>im2col.py</h2><p><code>im2col.py</code>实现代码如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from builtins import range</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_im2col_indices(x_shape, field_height, field_width, padding=1, stride=1):</span><br><span class="line">    # First figure out what the size of the output should be</span><br><span class="line">    N, C, H, W = x_shape</span><br><span class="line">    assert (H + 2 * padding - field_height) % stride == 0</span><br><span class="line">    assert (W + 2 * padding - field_height) % stride == 0</span><br><span class="line">    out_height = (H + 2 * padding - field_height) / stride + 1</span><br><span class="line">    out_width = (W + 2 * padding - field_width) / stride + 1</span><br><span class="line"></span><br><span class="line">    i0 = np.repeat(np.arange(field_height), field_width)</span><br><span class="line">    i0 = np.tile(i0, C)</span><br><span class="line">    i1 = stride * np.repeat(np.arange(out_height), out_width)</span><br><span class="line">    j0 = np.tile(np.arange(field_width), field_height * C)</span><br><span class="line">    j1 = stride * np.tile(np.arange(out_width), out_height)</span><br><span class="line">    i = i0.reshape(-1, 1) + i1.reshape(1, -1)</span><br><span class="line">    j = j0.reshape(-1, 1) + j1.reshape(1, -1)</span><br><span class="line"></span><br><span class="line">    k = np.repeat(np.arange(C), field_height * field_width).reshape(-1, 1)</span><br><span class="line"></span><br><span class="line">    return (k, i, j)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def im2col_indices(x, field_height, field_width, padding=1, stride=1):</span><br><span class="line">    &quot;&quot;&quot; An implementation of im2col based on some fancy indexing &quot;&quot;&quot;</span><br><span class="line">    # Zero-pad the input</span><br><span class="line">    p = padding</span><br><span class="line">    x_padded = np.pad(x, ((0, 0), (0, 0), (p, p), (p, p)), mode=&apos;constant&apos;)</span><br><span class="line"></span><br><span class="line">    k, i, j = get_im2col_indices(x.shape, field_height, field_width, padding,</span><br><span class="line">                                 stride)</span><br><span class="line"></span><br><span class="line">    cols = x_padded[:, k, i, j]</span><br><span class="line">    C = x.shape[1]</span><br><span class="line">    cols = cols.transpose(1, 2, 0).reshape(field_height * field_width * C, -1)</span><br><span class="line">    return cols</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def col2im_indices(cols, x_shape, field_height=3, field_width=3, padding=1,</span><br><span class="line">                   stride=1):</span><br><span class="line">    &quot;&quot;&quot; An implementation of col2im based on fancy indexing and np.add.at &quot;&quot;&quot;</span><br><span class="line">    N, C, H, W = x_shape</span><br><span class="line">    H_padded, W_padded = H + 2 * padding, W + 2 * padding</span><br><span class="line">    x_padded = np.zeros((N, C, H_padded, W_padded), dtype=cols.dtype)</span><br><span class="line">    k, i, j = get_im2col_indices(x_shape, field_height, field_width, padding,</span><br><span class="line">                                 stride)</span><br><span class="line">    cols_reshaped = cols.reshape(C * field_height * field_width, -1, N)</span><br><span class="line">    cols_reshaped = cols_reshaped.transpose(2, 0, 1)</span><br><span class="line">    np.add.at(x_padded, (slice(None), k, i, j), cols_reshaped)</span><br><span class="line">    if padding == 0:</span><br><span class="line">        return x_padded</span><br><span class="line">    return x_padded[:, :, padding:-padding, padding:-padding]</span><br></pre></td></tr></table></figure>
<p>包含两部分功能：图像转列向量以及列向量转图像</p>
<p>函数<code>get_im2col_indices</code>的功能是计算单个图像行/列坐标矩阵以及通道向量</p>
<p>函数<code>im2col_indices</code>的功能是实现图像转列向量</p>
<p>函数<code>col2im_indices</code>的功能是实现列向量转图像</p>
<p><strong>注意，<code>col2im_indices</code>得到的图像不等于原图，是叠加后的结果</strong></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>卷积神经网络</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>im2col解析1</title>
    <url>/posts/cc37c46b.html</url>
    <content><![CDATA[<p>在<code>cs231n</code>课程<a href="http://cs231n.github.io/convolutional-networks/#fc" target="_blank" rel="noopener">Convolutional Neural Networks: Architectures, Convolution / Pooling Layers </a>中提到使用矩阵乘法方式完成卷积层及池化层操作，同时在<a href="http://cs231n.github.io/assignments2019/assignment2/" target="_blank" rel="noopener">Assignment #2: Fully-Connected Nets, Batch Normalization, Dropout, Convolutional Nets</a>中给出了一个卷积层转全连接层的实现 - <code>im2col.py</code></p><a id="more"></a>
<p><code>im2col</code>表示将滤波器局部连接矩阵向量化为列向量（<code>column vector</code>），在行方向进行堆叠，最终得到<code>2-D</code>矩阵</p>
<p><code>im2col.py</code>使用 <strong><em>花式下标求解</em></strong> 的方式，让我觉得应该写篇文章好好学习一下</p>
<p>本文介绍一些<code>numpy</code>实现，下一篇介绍<code>im2col</code>实现，第三篇实现<code>im2row</code>，第四篇介绍另一种实现图像和行向量互换的方式，最后实现池化层图像和行向量的互换<code>pool2row</code></p>
<ol>
<li>数组扩展</li>
<li>数组变形</li>
<li>数组填充</li>
<li>维数转换</li>
<li>矩阵提取</li>
<li>数据叠加</li>
</ol>
<h2 id="数组扩展"><a href="#数组扩展" class="headerlink" title="数组扩展"></a>数组扩展</h2><p><code>numpy</code>提供了<a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html" target="_blank" rel="noopener">numpy.repeat</a>以及<a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html" target="_blank" rel="noopener">numpy.tile</a>实现基于数组原先数据的扩展</p>
<p><code>numpy.repeat</code>会重复数组中的每个元素</p>
<blockquote>
<p>numpy.repeat(a, repeats, axis=None)</p>
</blockquote>
<ul>
<li><code>a</code>表示输入数组</li>
<li><code>repeats</code>表示重复次数</li>
<li><code>axis</code>表示沿着哪个轴进行重复，<code>axis=0</code>表示沿着列，<code>axis=1</code>表示沿着行（注意：<code>axis</code>不能超出<code>a</code>的维度）。默认会将输入数组拉平（<code>flattened</code>），再沿着行进行重复</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 对1-D数组进行扩展</span><br><span class="line">&gt;&gt;&gt; x = np.arange(3)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([0, 1, 2])</span><br><span class="line">&gt;&gt;&gt; np.repeat(x, 4)</span><br><span class="line">array([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2])</span><br><span class="line">&gt;&gt;&gt; np.repeat(x, 4, axis=0) # 当x仅有1维时，axis失效</span><br><span class="line">array([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 对2-D数组进行扩展</span><br><span class="line">&gt;&gt;&gt; x = np.arange(6).reshape(2,3)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([[0, 1, 2],</span><br><span class="line">       [3, 4, 5]])</span><br><span class="line">&gt;&gt;&gt; np.repeat(x, 2) # 默认情况下会先将输入数组拉平，再进行扩展</span><br><span class="line">array([0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5])</span><br><span class="line">&gt;&gt;&gt; np.repeat(x, 2, axis=0) # axis=0表示沿着列进行扩展</span><br><span class="line">array([[0, 1, 2],</span><br><span class="line">       [0, 1, 2],</span><br><span class="line">       [3, 4, 5],</span><br><span class="line">       [3, 4, 5]])</span><br><span class="line">&gt;&gt;&gt; np.repeat(x, 2, axis=1) # axis=1表示沿着行进行扩展</span><br><span class="line">array([[0, 0, 1, 1, 2, 2],</span><br><span class="line">       [3, 3, 4, 4, 5, 5]])</span><br><span class="line">&gt;&gt;&gt; np.repeat(x, (2,3), axis=0) # 还可以指定扩展个数，本例表示沿着列进行扩展，其中输入数组第一行扩展2次，第二行扩展3次</span><br><span class="line">array([[0, 1, 2],</span><br><span class="line">       [0, 1, 2],</span><br><span class="line">       [3, 4, 5],</span><br><span class="line">       [3, 4, 5],</span><br><span class="line">       [3, 4, 5]])</span><br></pre></td></tr></table></figure>
<p><strong><code>np.repeat</code>对逐元素进行重复，而<code>np.tile</code>对逐数组进行重复</strong></p>
<blockquote>
<p>numpy.tile(A, reps)</p>
</blockquote>
<ul>
<li><code>A</code>表示输入数组</li>
<li><code>reps</code>表示重复次数</li>
</ul>
<p>有两种情况</p>
<ol>
<li>当<code>A.ndim &lt; reps.ndim</code>时，输入数组会扩展到reps相同维数，比如<code>A.shape=(3,)</code>，那么扩展到<code>2-D</code>就是<code>(3,) -&gt; (1,3)</code>，扩展到<code>3-D</code>就是<code>(3,) -&gt; (1,1,3)</code></li>
<li>当<code>A.ndim &gt; reps.ndim</code>时，<code>reps</code>会先扩展到和A相同维数，扩展维数用<code>1</code>填充，比如<code>A.shape = (2,3,4,5)，reps.shape = (2,3)</code>，那么<code>reps</code>首先扩展到<code>(1,1,2,3)</code>，再对<code>A</code>进行扩展，结果为<code>(2,3,8,15)</code></li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.arange(3)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([0, 1, 2])</span><br><span class="line">&gt;&gt;&gt; a.shape</span><br><span class="line">(3,)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([[0, 1, 2],</span><br><span class="line">       [3, 4, 5]])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># A.ndim = reps.ndim，不改变数组维数，沿着维数方向进行扩展</span><br><span class="line">&gt;&gt;&gt; np.tile(a, 3) </span><br><span class="line">array([0, 1, 2, 0, 1, 2, 0, 1, 2])</span><br><span class="line">&gt;&gt;&gt; np.tile(a, (2,3))</span><br><span class="line">array([[0, 1, 2, 0, 1, 2, 0, 1, 2],</span><br><span class="line">       [0, 1, 2, 0, 1, 2, 0, 1, 2]])</span><br><span class="line">&gt;&gt;&gt; np.tile(x, 2)</span><br><span class="line">array([[0, 1, 2, 0, 1, 2],</span><br><span class="line">       [3, 4, 5, 3, 4, 5]])</span><br><span class="line">&gt;&gt;&gt; np.tile(x, (2,2))</span><br><span class="line">array([[0, 1, 2, 0, 1, 2],</span><br><span class="line">       [3, 4, 5, 3, 4, 5],</span><br><span class="line">       [0, 1, 2, 0, 1, 2],</span><br><span class="line">       [3, 4, 5, 3, 4, 5]])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># A.ndim &lt; reps.ndim，扩展A维数，再进行扩展</span><br><span class="line">&gt;&gt;&gt; np.tile(a, (3,1)) # 扩展到2-D，再沿着列方向进行扩展</span><br><span class="line">array([[0, 1, 2],</span><br><span class="line">       [0, 1, 2],</span><br><span class="line">       [0, 1, 2]])</span><br><span class="line">&gt;&gt;&gt; np.tile(a, (1,3)) # 扩展到2-D，再沿着行方向进行扩展</span><br><span class="line">array([[0, 1, 2, 0, 1, 2, 0, 1, 2]])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># A.ndim &gt; reps.ndim, 先扩展reps维度，再扩展A数组</span><br><span class="line">&gt;&gt;&gt; A=np.ones((2,3,4,5))</span><br><span class="line">&gt;&gt;&gt; reps=(2,3)</span><br><span class="line">&gt;&gt;&gt; np.tile(A, reps).shape</span><br><span class="line">(2, 3, 8, 15)</span><br></pre></td></tr></table></figure>
<h2 id="数组变形"><a href="#数组变形" class="headerlink" title="数组变形"></a>数组变形</h2><p><code>numpy</code>提供了方法<a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html" target="_blank" rel="noopener">numpy.reshape</a>用于数组变形</p>
<p><code>numpy.reshape</code>在不改变数组数据的情况下变换数组大小</p>
<blockquote>
<p>numpy.reshape(a, newshape, order=’C’)</p>
</blockquote>
<ul>
<li><code>a</code>表示输入数组</li>
<li><code>newshape</code>表示新的数组大小，其中一个维度值可以为<code>-1</code>，这样该维度大小将通过数组长度和剩余维数判断得出。<strong>注意：新的数组大小应该和输入数组大小一致</strong></li>
<li><code>order</code>表示索引读取元素顺序，默认读取方式和<code>C</code>语言一致（大多数情况下就是这种方式）：最后一个轴索引（<code>the last axis index</code>）变化最快，第一个轴索引（<code>the first axis index</code>）变化最慢。比如<code>2-D</code>数组，先变化第二个轴，也就是按行读取，再变化第一个轴，也就是按列读取</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(24)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,</span><br><span class="line">       17, 18, 19, 20, 21, 22, 23])</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; y = x.reshape(2,3,4)</span><br><span class="line">&gt;&gt;&gt; y</span><br><span class="line">array([[[ 0,  1,  2,  3],</span><br><span class="line">        [ 4,  5,  6,  7],</span><br><span class="line">        [ 8,  9, 10, 11]],</span><br><span class="line"></span><br><span class="line">       [[12, 13, 14, 15],</span><br><span class="line">        [16, 17, 18, 19],</span><br><span class="line">        [20, 21, 22, 23]]])</span><br><span class="line"># 最后一个轴先进行读取</span><br><span class="line">&gt;&gt;&gt; y[0,0,:]</span><br><span class="line"># 然后是中间轴</span><br><span class="line">array([0, 1, 2, 3])</span><br><span class="line">&gt;&gt;&gt; y[0,1,:]</span><br><span class="line">array([4, 5, 6, 7])</span><br><span class="line">&gt;&gt;&gt; y[0,2,:]</span><br><span class="line">array([ 8,  9, 10, 11])</span><br><span class="line"># 最后是第一个轴</span><br><span class="line">&gt;&gt;&gt; y[1,:,:]</span><br><span class="line">array([[12, 13, 14, 15],</span><br><span class="line">       [16, 17, 18, 19],</span><br><span class="line">       [20, 21, 22, 23]])</span><br></pre></td></tr></table></figure>
<h2 id="数组填充"><a href="#数组填充" class="headerlink" title="数组填充"></a>数组填充</h2><p>在进行卷积神经网络计算时，需要零填充操作，<code>numpy</code>提供了<a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html#numpy-pad" target="_blank" rel="noopener">numpy.pad</a>操作</p>
<blockquote>
<p>numpy.pad(array, pad_width, mode, **kwargs)</p>
</blockquote>
<ul>
<li><code>array</code>表示输入数组</li>
<li><code>pad_width</code>表示每轴填充的宽度，其格式为<code>((before_1, after_1), … (before_N, after_N))</code>。如果所有轴都使用相同填充宽度，可以简化为<code>(before, after)</code>，或者<code>(pad,)</code></li>
<li><code>mode</code>表示填充模式，最常用的是<code>constant</code> - 填充一个常数，默认为<code>0</code></li>
<li><code>constant_values</code>是可选参数，表示常数值</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.arange(1, 5).reshape(2,2)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[1, 2],</span><br><span class="line">       [3, 4]])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 以下三种方法等价</span><br><span class="line">&gt;&gt;&gt; np.pad(a, (2), mode=&apos;constant&apos;)</span><br><span class="line">array([[0, 0, 0, 0, 0, 0],</span><br><span class="line">       [0, 0, 0, 0, 0, 0],</span><br><span class="line">       [0, 0, 1, 2, 0, 0],</span><br><span class="line">       [0, 0, 3, 4, 0, 0],</span><br><span class="line">       [0, 0, 0, 0, 0, 0],</span><br><span class="line">       [0, 0, 0, 0, 0, 0]])</span><br><span class="line">&gt;&gt;&gt; np.pad(a, (2,2), mode=&apos;constant&apos;)</span><br><span class="line">array([[0, 0, 0, 0, 0, 0],</span><br><span class="line">       [0, 0, 0, 0, 0, 0],</span><br><span class="line">       [0, 0, 1, 2, 0, 0],</span><br><span class="line">       [0, 0, 3, 4, 0, 0],</span><br><span class="line">       [0, 0, 0, 0, 0, 0],</span><br><span class="line">       [0, 0, 0, 0, 0, 0]])</span><br><span class="line">&gt;&gt;&gt; np.pad(a, ((2,2),(2,2)), mode=&apos;constant&apos;)</span><br><span class="line">array([[0, 0, 0, 0, 0, 0],</span><br><span class="line">       [0, 0, 0, 0, 0, 0],</span><br><span class="line">       [0, 0, 1, 2, 0, 0],</span><br><span class="line">       [0, 0, 3, 4, 0, 0],</span><br><span class="line">       [0, 0, 0, 0, 0, 0],</span><br><span class="line">       [0, 0, 0, 0, 0, 0]])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#可以指定不同的轴填充个数</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[[ 1,  2,  3,  4],</span><br><span class="line">        [ 5,  6,  7,  8],</span><br><span class="line">        [ 9, 10, 11, 12]],</span><br><span class="line"></span><br><span class="line">       [[13, 14, 15, 16],</span><br><span class="line">        [17, 18, 19, 20],</span><br><span class="line">        [21, 22, 23, 24]]])</span><br><span class="line">&gt;&gt;&gt; a.shape</span><br><span class="line">(2, 3, 4)</span><br><span class="line"># 仅填充最后一轴</span><br><span class="line">&gt;&gt;&gt; np.pad(a, ((0,),(0,),(1,)), mode=&apos;constant&apos;)</span><br><span class="line">array([[[ 0,  1,  2,  3,  4,  0],</span><br><span class="line">        [ 0,  5,  6,  7,  8,  0],</span><br><span class="line">        [ 0,  9, 10, 11, 12,  0]],</span><br><span class="line"></span><br><span class="line">       [[ 0, 13, 14, 15, 16,  0],</span><br><span class="line">        [ 0, 17, 18, 19, 20,  0],</span><br><span class="line">        [ 0, 21, 22, 23, 24,  0]]])</span><br><span class="line">&gt;&gt;&gt; np.pad(a, ((0,),(0,),(1,)), mode=&apos;constant&apos;).shape</span><br><span class="line">(2, 3, 6)</span><br></pre></td></tr></table></figure>
<h2 id="维数转换"><a href="#维数转换" class="headerlink" title="维数转换"></a>维数转换</h2><p><code>numpy</code>提供了<a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html" target="_blank" rel="noopener">numpy.transpose</a>用于维数转换</p>
<blockquote>
<p>numpy.transpose(a, axes=None)</p>
</blockquote>
<ul>
<li><code>a</code>表示输入数组</li>
<li><code>axes</code>表示待转换的轴，是<code>int</code>类型的元组（<code>tuple</code>）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 2维数组转换相当于矩阵转置操作</span><br><span class="line">&gt;&gt;&gt; x = np.arange(12).reshape(3,4)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([[ 0,  1,  2,  3],</span><br><span class="line">       [ 4,  5,  6,  7],</span><br><span class="line">       [ 8,  9, 10, 11]])</span><br><span class="line">&gt;&gt;&gt; x.shape</span><br><span class="line">(3, 4)</span><br><span class="line">&gt;&gt;&gt; np.transpose(x, (1,0))</span><br><span class="line">array([[ 0,  4,  8],</span><br><span class="line">       [ 1,  5,  9],</span><br><span class="line">       [ 2,  6, 10],</span><br><span class="line">       [ 3,  7, 11]])</span><br><span class="line">&gt;&gt;&gt; np.transpose(x, (1,0)).shape</span><br><span class="line">(4, 3)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(24).reshape(2,3,4)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([[[ 0,  1,  2,  3],</span><br><span class="line">        [ 4,  5,  6,  7],</span><br><span class="line">        [ 8,  9, 10, 11]],</span><br><span class="line"></span><br><span class="line">       [[12, 13, 14, 15],</span><br><span class="line">        [16, 17, 18, 19],</span><br><span class="line">        [20, 21, 22, 23]]])</span><br><span class="line">&gt;&gt;&gt; x.shape</span><br><span class="line">(2, 3, 4)</span><br><span class="line">&gt;&gt;&gt; np.transpose(x, (1,2,0))</span><br><span class="line">array([[[ 0, 12],</span><br><span class="line">        [ 1, 13],</span><br><span class="line">        [ 2, 14],</span><br><span class="line">        [ 3, 15]],</span><br><span class="line"></span><br><span class="line">       [[ 4, 16],</span><br><span class="line">        [ 5, 17],</span><br><span class="line">        [ 6, 18],</span><br><span class="line">        [ 7, 19]],</span><br><span class="line"></span><br><span class="line">       [[ 8, 20],</span><br><span class="line">        [ 9, 21],</span><br><span class="line">        [10, 22],</span><br><span class="line">        [11, 23]]])</span><br><span class="line">&gt;&gt;&gt; np.transpose(x, (1,2,0)).shape</span><br><span class="line">(3, 4, 2)</span><br><span class="line">&gt;&gt;&gt; np.transpose(x, (1,0,2))</span><br><span class="line">array([[[ 0,  1,  2,  3],</span><br><span class="line">        [12, 13, 14, 15]],</span><br><span class="line"></span><br><span class="line">       [[ 4,  5,  6,  7],</span><br><span class="line">        [16, 17, 18, 19]],</span><br><span class="line"></span><br><span class="line">       [[ 8,  9, 10, 11],</span><br><span class="line">        [20, 21, 22, 23]]])</span><br><span class="line">&gt;&gt;&gt; np.transpose(x, (1,0,2)).shape</span><br><span class="line">(3, 2, 4)</span><br></pre></td></tr></table></figure>
<h2 id="矩阵提取"><a href="#矩阵提取" class="headerlink" title="矩阵提取"></a>矩阵提取</h2><p>当在多维数组中取一个<code>2</code>维矩阵时，通常会使用切片方式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[[ 1,  2,  3,  4],</span><br><span class="line">        [ 5,  6,  7,  8],</span><br><span class="line">        [ 9, 10, 11, 12]],</span><br><span class="line"></span><br><span class="line">       [[13, 14, 15, 16],</span><br><span class="line">        [17, 18, 19, 20],</span><br><span class="line">        [21, 22, 23, 24]]])</span><br><span class="line">&gt;&gt;&gt; a[0, 0:2, 0:2]</span><br><span class="line">array([[1, 2],</span><br><span class="line">       [5, 6]])</span><br><span class="line">&gt;&gt;&gt; a[0, slice(0, 2, 1), slice(0, 2, 1)]</span><br><span class="line">array([[1, 2],</span><br><span class="line">       [5, 6]])</span><br></pre></td></tr></table></figure>
<p>还可以先获取矩阵对应数据下标，再进行计算</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; x</span><br><span class="line">[[0, 0], [1, 1]]</span><br><span class="line">&gt;&gt;&gt; y</span><br><span class="line">[[0, 1], [0, 1]]</span><br><span class="line">&gt;&gt;&gt; a[0, x, y]</span><br><span class="line">array([[1, 2],</span><br><span class="line">       [5, 6]])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 结合矩阵扩展和维数转换方法</span><br><span class="line">&gt;&gt;&gt; z</span><br><span class="line">array([0, 1])</span><br><span class="line">&gt;&gt;&gt; x = np.tile(z, (2,1))</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([[0, 1],</span><br><span class="line">       [0, 1]])</span><br><span class="line">&gt;&gt;&gt; x = np.transpose(x, (1,0))</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([[0, 0],</span><br><span class="line">       [1, 1]])</span><br><span class="line">&gt;&gt;&gt; y = np.tile(z, (2,1))</span><br><span class="line">&gt;&gt;&gt; y</span><br><span class="line">array([[0, 1],</span><br><span class="line">       [0, 1]])</span><br><span class="line">&gt;&gt;&gt; a[0, x, y]</span><br><span class="line">array([[1, 2],</span><br><span class="line">       [5, 6]])</span><br></pre></td></tr></table></figure>
<h2 id="数据叠加"><a href="#数据叠加" class="headerlink" title="数据叠加"></a>数据叠加</h2><p>参考：<a href="https://stackoverflow.com/questions/45473896/np-add-at-indexing-with-array" target="_blank" rel="noopener">np.add.at indexing with array</a></p>
<p><code>numpy</code>提供函数<a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ufunc.at.html" target="_blank" rel="noopener">numpy.add.at</a>用于批量添加数据</p>
<blockquote>
<p>ufunc.at(a, indices, b=None)</p>
</blockquote>
<ul>
<li><code>a</code>表示目标数组</li>
<li><code>indices</code>表示指定下标，可以是数组或者元组结构</li>
<li><code>b</code>是添加的数据，可以是标量或者数组，必须能够在<code>a</code>上可广播（<code>broadcastable</code>）</li>
</ul>
<p><code>np.add.at</code>函数功能等同于<code>a[indices]=b</code>，区别在于<code>np.add.at</code>执行无缓冲即时操作（<code>unbuffered in place operation</code>），也就是说同一个下标可以累加多次</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(5)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([0, 1, 2, 3, 4])</span><br><span class="line">&gt;&gt;&gt; np.add.at(x, [0, 1, 2, 3, 3], 2) # 累加下标3共2次</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([2, 3, 4, 7, 4])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.zeros((2,3))</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([[0., 0., 0.],</span><br><span class="line">       [0., 0., 0.]])</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; np.add.at(x, ([0,1], [0,2]), 3) # 指定行列坐标</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([[3., 0., 0.],</span><br><span class="line">       [0., 0., 3.]])</span><br><span class="line">&gt;&gt;&gt; np.add.at(x, ([1], [0,2]), 1)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([[3., 0., 0.],</span><br><span class="line">       [1., 0., 4.]])</span><br><span class="line">&gt;&gt;&gt; np.add.at(x, ([1], [0,2]), [5,6])</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([[ 3.,  0.,  0.],</span><br><span class="line">       [ 6.,  0., 10.]])</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>卷积神经网络</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络推导-批量图片矩阵计算</title>
    <url>/posts/ab1e719c.html</url>
    <content><![CDATA[<p>参考：<a href="https://www.zhujian.tech/posts/3accb62a.html#more">卷积神经网络推导-单张图片矩阵计算</a></p><p>之前推导<code>LeNet-5</code>网络输入单个图像数据的前后向传播，现在实现批量图像数据的前后向传播</p><a id="more"></a>

<h2 id="计算符号"><a href="#计算符号" class="headerlink" title="计算符号"></a>计算符号</h2><ul>
<li>$N$表示批量数据</li>
<li>$C$表示深度</li>
<li>$H$表示高度</li>
<li>$W$表示宽度</li>
<li>$output^{x}$表示第$x$层输出数据体</li>
</ul>
<h2 id="通道转换"><a href="#通道转换" class="headerlink" title="通道转换"></a>通道转换</h2><p>使用<code>OpenCV</code>或<code>PIL</code>读取一张图片，保存为<code>numpy ndarray</code>结构，图像尺寸前<code>3</code>位分别表示长度、宽度和深度：$[H, W, C]$</p>
<p>批量处理图像数据相当于在深度上进行累加，为方便计算，先转换成深度、长度和宽度：$[C, H, W]$</p>
<h2 id="网络输出"><a href="#网络输出" class="headerlink" title="网络输出"></a>网络输出</h2><p>对输入层</p>
<script type="math/tex; mode=display">
X\in R^{N\times C_{0}\times H_{0}\times W_{0}} = R^{N\times 1\times 32\times 32}</script><p>对卷积层$C1$</p>
<script type="math/tex; mode=display">
output^{(1)}\in R^{N\times C_{1}\times H_{1}\times W_{1}} = R^{N\times 6\times 28\times 28}</script><p>对池化层$S2$</p>
<script type="math/tex; mode=display">
output^{(2)}\in R^{N\times C_{2}\times H_{2}\times W_{2}} = R^{N\times 6\times 14\times 14}</script><p>对卷积层$C3$</p>
<script type="math/tex; mode=display">
output^{(3)}\in R^{N\times C_{3}\times H_{3}\times W_{3}} = R^{N\times 16\times 10\times 10}</script><p>对池化层$S4$</p>
<script type="math/tex; mode=display">
output^{(4)}\in R^{N\times C_{4}\times H_{4}\times W_{4}} = R^{N\times 16\times 5\times 5}</script><p>对卷积层$C5$</p>
<script type="math/tex; mode=display">
output^{(5)}\in R^{N\times C_{5}\times H_{5}\times W_{5}} = R^{N\times 120}</script><p>对全连接层$F6$</p>
<script type="math/tex; mode=display">
output^{(6)}\in R^{N\times C_{6}\times H_{6}\times W_{6}} = R^{N\times 84}</script><p>对输出层$F7$</p>
<script type="math/tex; mode=display">
output^{(7)}\in R^{N\times C_{7}\times H_{7}\times W_{7}} = R^{N\times 10}</script><h2 id="前向计算"><a href="#前向计算" class="headerlink" title="前向计算"></a>前向计算</h2><p><strong>输入层</strong></p>
<script type="math/tex; mode=display">
X\in R^{N\times 1\times 32\times 32}</script><p><strong>卷积层$C1$</strong></p>
<p>共6个滤波器，每个滤波器空间尺寸为$5\times 5$，步长为$1$, 零填充为$0$</p>
<p>输出空间尺寸为$(32-5-2\cdot 0)/1+1=28$</p>
<p>所以单次卷积操作的向量大小为$1\cdot 5\cdot 5=25$，单个滤波器有$28\cdot 28=784$个局部连接，$N$张图片有$N\cdot 784$个局部连接</p>
<script type="math/tex; mode=display">
a^{(0)}\in R^{(N\cdot 784)\times 25}\\
W^{(1)}\in R^{25\times 6}\\
b^{(1)}\in R^{1\times 6}\\
\Rightarrow z^{(1)}=a^{(0)}\cdot W^{(1)}+b^{(1)}
\in R^{(N\cdot 784)\times 6}\\
\Rightarrow y^{(1)}=relu(z^{(1)})
\in R^{(N\cdot 784)\times 6}\\</script><p>重置$y^{(1)}$大小，输出数据体$output^{(1)}\in R^{N\times 6\times 28\times 28}$</p>
<p><strong>池化层$S2$</strong></p>
<p>执行$\max$运算，每个滤波器空间尺寸$2\times 2$，步长为$2$</p>
<p>输出空间尺寸为$(28-2)/2+1=14$</p>
<p>所以单次$\max$操作的向量大小为$2\cdot 2=4$，单个滤波器有$6\cdot 14\cdot 14=1176$个局部连接, $N$张图片有$N\cdot 1176$个局部连接</p>
<script type="math/tex; mode=display">
a^{(1)}\in R^{(N\cdot 1176)\times 4}\\
z^{(2)}=\max (a^{(1)})\in R^{(N\cdot 1176)}</script><p>$argz^{(2)} = argmax(a^{(1)})\in R^{(N\cdot 1176)}$，每个值表示单次局部连接最大值下标</p>
<p>重置$z^{(2)}$大小，输出数据体$output^{(2)}\in R^{N\times 6\times 14\times 14}$</p>
<p><strong>卷积层$C3$</strong></p>
<p>共16个滤波器，每个滤波器空间尺寸为$5\times 5$，步长为$1$, 零填充为$0$</p>
<p>输出空间尺寸为$(14-5+2\cdot 0)/1+1=10$</p>
<p>所以单次卷积操作的向量大小为$5\cdot 5\cdot 6=150$，单个滤波器有$10\cdot 10=100$个局部连接, $N$张图片有$N\cdot 100$个局部连接</p>
<script type="math/tex; mode=display">
a^{(2)}\in R^{(N\cdot 100)\times 150}\\
W^{(3)}\in R^{150\times 16}\\
b^{(3)}\in R^{1\times 16}\\
\Rightarrow z^{(3)}=a^{(2)}\cdot W^{(3)}+b^{(3)}
\in R^{(N\cdot 100)\times 16}\\
\Rightarrow y^{(3)}=relu(z^{(3)})
\in R^{(N\cdot 100)\times 16}\\</script><p>重置$y^{(3)}$大小，输出数据体$output^{(3)}\in R^{N\times 16\times 10\times 10}$</p>
<p><strong>池化层$S4$</strong></p>
<p>执行$\max$运算，每个滤波器空间尺寸$2\times 2$，步长为$2$</p>
<p>输出空间尺寸为$(10-2)/2+1=5$</p>
<p>所以单次$\max$操作的向量大小为$2\cdot 2=4$，单个滤波器有$16\cdot 5\cdot 5=400$个局部连接, $N$张图片有$N\cdot 400$个局部连接</p>
<script type="math/tex; mode=display">
a^{(3)}\in R^{(N\cdot 400)\times 4}\\
z^{(4)}=\max (a^{(3)})\in R^{(N\cdot 400)}</script><p>$argz^{(4)} = argmax(a^{(3)})\in R^{(N\cdot 400)}$，每个值表示单次局部连接最大值下标</p>
<p>重置$z^{(4)}$大小，输出数据体$output^{(4)}\in R^{N\times 16\times 5\times 5}$</p>
<p><strong>卷积层$C5$</strong></p>
<p>共120个滤波器，每个滤波器空间尺寸为$5\times 5$，步长为$1$, 零填充为$0$</p>
<p>输出空间尺寸为$(5-5+2\cdot 0)/1+1=1$</p>
<p>所以单次卷积操作的向量大小为$5\cdot 5\cdot 16=400$，单个滤波器有$1\cdot 1=1$个局部连接, $N$张图片有$N\cdot 1$个局部连接</p>
<script type="math/tex; mode=display">
a^{(4)}\in R^{N\times 400}\\
W^{(5)}\in R^{400\times 120}\\
b^{(5)}\in R^{1\times 120}\\
\Rightarrow z^{(5)}=a^{(4)}\cdot W^{(5)}+b^{(5)}\in R^{N\times 120}\\
\Rightarrow y^{(5)}=relu(z^{(5)})\in R^{N\times 120}\\</script><p>输出数据体$output^{(5)}\in R^{N\times 120}$</p>
<p><strong>全连接层$F6$</strong></p>
<p>神经元个数为$84$</p>
<script type="math/tex; mode=display">
a^{(5)}=y^{(5)}\in R^{N\times 120}\\
W^{(6)}\in R^{120\times 84}\\
b^{(6)}\in R^{1\times 84}\\
\Rightarrow z^{(6)}=a^{(5)}\cdot W^{(6)}+b^{(6)}\in R^{N\times 84}\\
\Rightarrow y^{(6)}=relu(z^{(6)})\in R^{N\times 84}\\</script><p>输出数据体$output^{(6)}\in R^{N\times 84}$</p>
<p><strong>输出层$F7$</strong></p>
<p>神经元个数为$10$</p>
<script type="math/tex; mode=display">
a^{(6)}=y^{(6)}\in R^{N\times 84}\\
W^{(7)}\in R^{84\times 10}\\
b^{(7)}\in R^{1\times 10}\\
\Rightarrow z^{(7)}=a^{(6)}\cdot W^{(7)}+b^{(7)}\in R^{N\times 10}\\</script><p>输出数据体$output^{(7)}\in R^{N\times 10}$</p>
<p><strong>分类概率</strong></p>
<script type="math/tex; mode=display">
probs=h(z^{(7)})=\frac {exp(z^{(7)})}{exp(z^{(7)})\cdot A\cdot B^{T}}</script><p><strong>$A\in R^{10\times 1}, B\in R^{10\times 1}$都是全$1$向量</strong></p>
<p><strong>损失值</strong></p>
<script type="math/tex; mode=display">
dataLoss = -\frac {1}{N} 1^{T}\cdot \ln \frac {exp(z^{(7)}* Y\cdot A)}{exp(z^{(7)})\cdot A}</script><script type="math/tex; mode=display">
regLoss = 0.5\cdot reg\cdot (||W^{(1)}||^{2} + ||W^{(3)}||^{2} + ||W^{(5)}||^{2} + ||W^{(6)}||^{2} + ||W^{(7)}||^{2})</script><script type="math/tex; mode=display">
J(z^{(7)})=dataLoss + regLoss</script><p><strong>$Y\in R^{N\times 10}$，仅有正确类别为<code>1</code>, 其余为<code>0</code></strong></p>
<h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p><strong>输出层$F7$</strong></p>
<p>求输入向量$z^{(7)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=d(-\frac {1}{N} 1^{T}\cdot \ln \frac {exp(z^{(7)}* Y\cdot A)}{exp(z^{(7)})\cdot A})
=tr(-\frac {1}{N} (probs^{T} - Y^{T})\cdot dz^{(7)})</script><script type="math/tex; mode=display">
\Rightarrow D_{z^{(7)}}f(z^{(7)})=\frac {1}{N} (probs^{T} - Y^{T})\in R^{10\times N}\\
\Rightarrow \bigtriangledown_{z^{(7)}}f(z^{(7)})=\frac {1}{N} (probs - Y)\in R^{N\times 10}</script><p>其他梯度</p>
<script type="math/tex; mode=display">
z^{(7)}=a^{(6)}\cdot W^{(7)}+b^{(7)} \\
dz^{(7)}=da^{(6)}\cdot W^{(7)} + a^{(6)}\cdot dW^{(7)} + db^{(7)}</script><script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(7)}}f(z^{(7)})\cdot dz^{(7)})
=tr(D_{z^{(7)}}f(z^{(7)})\cdot (da^{(6)}\cdot W^{(7)} + a^{(6)}\cdot dW^{(7)} + db^{(7)}))\\
=tr(D_{z^{(7)}}f(z^{(7)})\cdot da^{(6)}\cdot W^{(7)})
+tr(D_{z^{(7)}}f(z^{(7)})\cdot a^{(6)}\cdot dW^{(7)})
+tr(D_{z^{(7)}}f(z^{(7)})\cdot db^{(7)}))</script><p>求权重矩阵$W^{(7)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(7)}}f(z^{(7)})\cdot a^{(6)}\cdot dW^{(7)})</script><script type="math/tex; mode=display">
\Rightarrow D_{W^{(7)}}f(W^{(7)})=D_{z^{(7)}}f(z^{(7)})\cdot a^{(6)}\\
\Rightarrow \bigtriangledown_{W^{(7)}}f(W^{(7)})
=(a^{(6)})^{T}\cdot \bigtriangledown_{z^{(7)}}f(z^{(7)})
=R^{84\times 10}\cdot R^{N\times 10}
=R^{84\times 10}</script><p>求偏置向量$b^{(7)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{M} \sum_{i=1}^{M} D_{z^{(7)}}f(z^{(7)})\cdot db^{(7)}))</script><script type="math/tex; mode=display">
\Rightarrow D_{b^{(7)}}f(b^{(7)})=\frac {1}{M} \sum_{i=1}^{M} D_{z^{(7)}}f(z^{(7)})\\
\Rightarrow \bigtriangledown_{b^{(7)}}f(b^{(7)})=\frac {1}{M} \sum_{i=1}^{M} \bigtriangledown_{z^{(7)}}f(z^{(7)})\in R^{1\times 10}</script><p>$M=N$，表示$dz^{(7)}$的行数</p>
<p>求上一层输出向量$a^{(6)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(7)}}f(z^{(7)})\cdot da^{(6)}\cdot W^{(7)})
=tr(W^{(7)}\cdot D_{z^{(7)}}f(z^{(7)})\cdot da^{(6)})</script><script type="math/tex; mode=display">
\Rightarrow D_{a^{(6)}}f(a^{(6)})=W^{(7)}\cdot D_{z^{(7)}}f(z^{(7)})\\
\Rightarrow \bigtriangledown_{a^{(6)}}f(a^{(6)})=\bigtriangledown_{z^{(7)}}f(z^{(7)})\cdot (W^{(7)})^{T}=R^{N\times 10}\cdot R^{10\times 84}=R^{N\times 84}</script><p><strong>全连接层$F6$</strong></p>
<p>求输入向量$z^{(6)}$梯度</p>
<script type="math/tex; mode=display">
a^{(6)}=y^{(6)}=relu(z^{(6)})\\
da^{(6)}=1(z^{(6)}\geq 0)* dz^{(6)}</script><script type="math/tex; mode=display">
d(dataloss)=tr(D_{a^{(6)}}f(a^{(6)}) da^{(6)})=tr(D_{a^{(6)}}f(a^{(6)})\cdot (1(z^{(6)}\geq 0)* dz^{(6)}))\\
=tr(D_{a^{(6)}}f(a^{(6)})* 1(z^{(6)}\geq 0)^{T}\cdot dz^{(6)})</script><script type="math/tex; mode=display">
\Rightarrow D_{z^{(6)}}f(z^{(6)})=D_{a^{(6)}}f(a^{(6)})* 1(z^{(6)}\geq 0)^{T}\\
\Rightarrow \bigtriangledown_{z^{(6)}}f(z^{(6)})=\bigtriangledown_{a^{(6)}}f(a^{(6)})* 1(z^{(6)}\geq 0)\in R^{N\times 84}</script><p>其他梯度</p>
<script type="math/tex; mode=display">
z^{(6)}=a^{(5)}\cdot W^{(6)}+b^{(6)} \\
dz^{(6)}=da^{(5)}\cdot W^{(6)}+a^{(5)}\cdot dW^{(6)}+db^{(6)}</script><script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(6)}}f(z^{(6)})\cdot dz^{(6)})\\
=tr(D_{z^{(6)}}f(z^{(6)})\cdot (da^{(5)}\cdot W^{(6)} + a^{(5)}\cdot dW^{(6)} + db^{(6)}))\\
=tr(D_{z^{(6)}}f(z^{(6)})\cdot da^{(5)}\cdot W^{(6)})
+tr(D_{z^{(6)}}f(z^{(6)})\cdot a^{(5)}\cdot dW^{(6)})
+tr(D_{z^{(6)}}f(z^{(6)})\cdot db^{(6)}))</script><p>求权重矩阵$w^{(6)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(6)}}f(z^{(6)})\cdot a^{(5)}\cdot dW^{(6)})</script><script type="math/tex; mode=display">
\Rightarrow D_{W^{(6)}}f(W^{(6)})=D_{z^{(6)}}f(z^{(6)})\cdot a^{(5)}\\
\Rightarrow \bigtriangledown_{W^{(6)}}f(W^{(6)})
=(a^{(5)})^{T}\cdot \bigtriangledown_{z^{(6)}}f(z^{(6)})
=R^{120\times N}\cdot R^{N\times 84}
=R^{120\times 84}</script><p>求偏置向量$b^{(6)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{M} \sum_{i=1}^{M} D_{z^{(6)}}f(z^{(6)})\cdot db^{(6)}))</script><script type="math/tex; mode=display">
\Rightarrow D_{b^{(6)}}f(b^{(6)})
=\frac {1}{M} \sum_{i=1}^{M} D_{z^{(6)}}f(z^{(6)})\\
\Rightarrow \bigtriangledown_{b^{(6)}}f(b^{(6)})
=\frac {1}{M} \sum_{i=1}^{M} \bigtriangledown_{z^{(6)}}f(z^{(6)})
\in R^{1\times 84}</script><p>$M=N$，表示$dz^{(6)}$的行数</p>
<p>求上一层输出向量$a^{(5)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(6)}}f(z^{(6)})\cdot da^{(5)}\cdot W^{(6)})
=tr(W^{(6)}\cdot D_{z^{(6)}}f(z^{(6)})\cdot da^{(5)})</script><script type="math/tex; mode=display">
\Rightarrow D_{a^{(5)}}f(a^{(5)})
=W^{(6)}\cdot D_{z^{(6)}}f(z^{(6)})\\
\Rightarrow \bigtriangledown_{a^{(5)}}f(a^{(5)})
=\bigtriangledown_{z^{(6)}}f(z^{(6)})\cdot (W^{(6)})^{T}
=R^{N\times 84}\cdot R^{84\times 120}
=R^{N\times 120}</script><p><strong>卷积层$C5$</strong></p>
<p>求输入向量$z^{(5)}$梯度</p>
<script type="math/tex; mode=display">
a^{(5)}=y^{(5)}=relu(z^{(5)})\\
da^{(5)}=1(z^{(5)}\geq 0)* dz^{(5)}\\</script><script type="math/tex; mode=display">
d(dataloss)=tr(D_{a^{(5)}}f(a^{(5)}) da^{(5)})=tr(D_{a^{(5)}}f(a^{(5)})\cdot (1(z^{(5)}\geq 0)* dz^{(5)}))\\
=tr(D_{a^{(5)}}f(a^{(5)})* 1(z^{(5)}\geq 0)^{T}\cdot dz^{(5)})</script><script type="math/tex; mode=display">
\Rightarrow D_{z^{(5)}}f(z^{(5)})
=D_{a^{(5)}}f(a^{(5)})* 1(z^{(5)}\geq 0)^{T}\\
\Rightarrow \bigtriangledown_{z^{(5)}}f(z^{(5)})
=\bigtriangledown_{a^{(5)}}f(a^{(5)})* 1(z^{(5)}\geq 0)
\in R^{N\times 120}</script><p>其他梯度</p>
<script type="math/tex; mode=display">
z^{(5)}=a^{(4)}\cdot W^{(5)}+b^{(5)} \\
dz^{(5)}=da^{(4)}\cdot W^{(5)}+a^{(4)}\cdot dW^{(5)}+db^{(5)}</script><script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(5)}}f(z^{(5)})\cdot dz^{(5)})
=tr(D_{z^{(5)}}f(z^{(5)})\cdot (da^{(4)}\cdot W^{(5)} + a^{(4)}\cdot dW^{(5)} + db^{(5)}))\\
=tr(D_{z^{(5)}}f(z^{(5)})\cdot da^{(4)}\cdot W^{(5)})
+tr(D_{z^{(5)}}f(z^{(5)})\cdot a^{(4)}\cdot dW^{(5)})
+tr(D_{z^{(5)}}f(z^{(5)})\cdot db^{(5)}))</script><p>求权重矩阵$W^{(5)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(5)}}f(z^{(5)})\cdot a^{(4)}\cdot dW^{(5)})</script><script type="math/tex; mode=display">
\Rightarrow D_{W^{(5)}}f(W^{(5)})
=D_{z^{(5)}}f(z^{(5)})\cdot a^{(4)}\\
\Rightarrow \bigtriangledown_{W^{(5)}}f(W^{(5)})
=(a^{(4)})^{T}\cdot \bigtriangledown_{z^{(5)}}f(z^{(5)})
=R^{400\times N}\cdot R^{N\times 120}
=R^{400\times 120}</script><p>求偏置向量$b^{(5)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{M} \sum_{i=1}^{M} D_{z^{(5)}}f(z^{(5)})\cdot db^{(5)})</script><script type="math/tex; mode=display">
\Rightarrow D_{b^{(5)}}f(b^{(5)})=\frac {1}{M} \sum_{i=1}^{M} D_{z^{(5)}}f(z^{(5)})\\
\Rightarrow \bigtriangledown_{b^{(5)}}f(b^{(5)})
=\frac {1}{M} \sum_{i=1}^{M} \bigtriangledown_{z^{(5)}}f(z^{(5)})
\in R^{1\times 120}</script><p>$M=N$, 表示$dz^{(5)}$的行数</p>
<p>求上一层输出向量$a^{(4)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(5)}}f(z^{(5)})\cdot da^{(4)}\cdot W^{(5)})
=tr(W^{(5)}\cdot D_{z^{(5)}}f(z^{(5)})\cdot da^{(4)})</script><script type="math/tex; mode=display">
\Rightarrow D_{a^{(4)}}f(a^{(4)})
=W^{(5)}\cdot D_{z^{(5)}}f(z^{(5)})\\
\Rightarrow \bigtriangledown_{a^{(4)}}f(a^{(4)})
=\bigtriangledown_{z^{(5)}}f(z^{(5)})\cdot (W^{(5)})^{T}
=R^{N\times 120}\cdot R^{120\times 400}
=R^{N\times 400}</script><p><strong>池化层$S4$</strong></p>
<p>计算$z^{(4)}$梯度</p>
<p>因为$a^{(4)}\in R^{N\times 400}$，$output^{(4)}\in R^{N\times 16\times 5\times 5}$，$z^{(4)}\in R^{(N\cdot 400)}$，卷积层$C5$滤波器空间尺寸为$5\times 5$，和激活图大小一致，所以$z^{(4)}$梯度是$a^{(4)}$梯度矩阵的向量化</p>
<script type="math/tex; mode=display">
dz^{(4)} = dvec(a^{(4)})</script><script type="math/tex; mode=display">
\Rightarrow D_{z^{(4)}}f(z^{(4)})=vec(D_{a^{(4)}}f(a^{(4)}))\\
\Rightarrow \bigtriangledown_{z^{(4)}}f(z^{(4)})=vec(\bigtriangledown_{a^{(4)}}f(a^{(4)}))</script><p>上一层输出向量$a^{(3)}$梯度</p>
<script type="math/tex; mode=display">
z^{(4)}=\max (a^{(3)})\\
dz^{(4)}=1(a^{(3)}\ is\ the\ max)* da^{(3)}</script><p>配合$argz^{(4)}$，最大值梯度和$z^{(4)}$一致，其余梯度为$0$</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(4)}}f(z^{(4)}) dz^{(4)})\\
=tr(D_{z^{(4)}}f(z^{(4)})\cdot 1(a^{(3)}\ is\ the\ max)* da^{(3)})
=tr(D_{z^{(4)}}f(z^{(4)})* 1(a^{(3)}\ is\ the\ max)^{T}\cdot da^{(3)}</script><script type="math/tex; mode=display">
\Rightarrow D_{a^{(3)}}f(a^{(3)})=D_{z^{(4)}}f(z^{(4)})* 1(a^{(3)}\ is\ the\ max)^{T}\\
\Rightarrow \bigtriangledown_{a^{(3)}}f(a^{(3)})
=\bigtriangledown_{z^{(4)}}f(z^{(4)})* 1(a^{(3)}\ is\ the\ max)
\in R^{(N\cdot 400)\times 4}</script><p><strong>卷积层$C3$</strong></p>
<p>计算$y^{(3)}$梯度</p>
<p>因为$a^{(3)}\in R^{(N\cdot 400)\times 4}$，$output^{(3)}\in R^{N\times 16\times 10\times 10}$，$y^{(3)}\in R^{(N\cdot 100)\times 16}$，池化层$S4$滤波器空间尺寸为$5\times 5$，步长为$1$，按照采样顺序将$a^{(3)}$梯度重置回$output^{(3)}$梯度，再重置为$y^{(3)}$梯度</p>
<p>求输入向量$z^{(3)}$梯度</p>
<script type="math/tex; mode=display">
y^{(3)} = relu(z^{(3)})\\
dy^{(3)} = 1(z^{(3)} \geq 0)*dz^{(3)}</script><script type="math/tex; mode=display">
d(dataloss)
=tr(D_{y^{(3)}}f(y^{(3)})\cdot dy^{(3)})\\
=tr(D_{y^{(3)}}f(y^{(3)})\cdot (1(z^{(3)} \geq 0)*dz^{(3)}))\\
=tr(D_{y^{(3)}}f(y^{(3)})* 1(z^{(3)} \geq 0)^{T}\cdot dz^{(3)})</script><script type="math/tex; mode=display">
\Rightarrow D_{z^{(3)}}f(z^{(3)})
=D_{y^{(3)}}f(y^{(3)})* 1(z^{(3)} \geq 0)^{T}\\
\Rightarrow \bigtriangledown_{z^{(3)}}f(z^{(3)})
=\bigtriangledown_{y^{(3)}}f(y^{(3)})* 1(z^{(3)} \geq 0)
\in R^{(N\cdot 100)\times 16}</script><p>其他梯度</p>
<script type="math/tex; mode=display">
z^{(3)}=a^{(2)}\cdot W^{(3)}+b^{(3)} \\
dz^{(3)}=da^{(2)}\cdot W^{(3)}+a^{(2)}\cdot dW^{(3)}+db^{(3)}</script><script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(3)}}f(z^{(3)})\cdot dz^{(3)})\\
=tr(D_{z^{(3)}}f(z^{(3)})\cdot (da^{(2)}\cdot W^{(3)} + a^{(2)}\cdot dW^{(3)} + db^{(3)}))\\
=tr(D_{z^{(3)}}f(z^{(3)})\cdot da^{(2)}\cdot W^{(3)})
+tr(D_{z^{(3)}}f(z^{(3)})\cdot a^{(2)}\cdot dW^{(3)})
+tr(D_{z^{(3)}}f(z^{(3)})\cdot db^{(3)}))</script><p>求权重矩阵$W^{(3)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(3)}}f(z^{(3)})\cdot a^{(2)}\cdot dW^{(3)})</script><script type="math/tex; mode=display">
\Rightarrow D_{W^{(3)}}f(W^{(3)})
=D_{z^{(3)}}f(z^{(3)})\cdot a^{(2)}\\
\Rightarrow \bigtriangledown_{W^{(3)}}f(W^{(3)})
=(a^{(2)})^{T}\cdot \bigtriangledown_{z^{(3)}}f(z^{(3)})
=R^{150\times (N\cdot 100)}\cdot R^{(N\cdot 100)\times 16}
=R^{150\times 16}</script><p>求偏置向量$b^{(3)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=\frac {1}{M} \sum_{i=1}^{M} tr(D_{z^{(3)}}f(z^{(3)})\cdot db^{(3)})</script><script type="math/tex; mode=display">
\Rightarrow D_{b^{(3)}}f(b^{(3)})
=\frac {1}{M} \sum_{i=1}^{M} D_{z^{(3)}}f(z^{(3)})\\
\Rightarrow \bigtriangledown_{b^{(3)}}f(b^{(3)})
=\frac {1}{M} \sum_{i=1}^{M} \bigtriangledown_{z^{(3)}}f(z^{(3)})
=R^{1\times 16}</script><p>$M=N\cdot 100$，表示$dz^{(3)}$的行数</p>
<p>求上一层输出向量$a^{(2)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(3)}}f(z^{(3)})\cdot da^{(2)}\cdot W^{(3)})
=tr(W^{(3)}\cdot D_{z^{(3)}}f(z^{(3)})\cdot da^{(2)})</script><script type="math/tex; mode=display">
\Rightarrow D_{a^{(2)}}f(a^{(2)})
=W^{(3)}\cdot D_{z^{(3)}}f(z^{(3)})\\
\Rightarrow \bigtriangledown_{a^{(2)}}f(a^{(2)})
=\bigtriangledown_{z^{(3)}}f(z^{(3)})\cdot (W^{(3)})^{T}
=R^{(N\cdot 100)\times 16}\cdot R^{16\times 150}
=R^{(N\cdot 100)\times 150}</script><p><strong>池化层$S2$</strong></p>
<p>计算$z^{(2)}$梯度</p>
<p>因为$a^{(2)}\in R^{(N\cdot 100)\times 150}$，$output^{(2)}\in R^{N\times 6\times 14\times 14}$，$z^{(2)}\in R^{(N\cdot 1176)}$，卷积层$C3$滤波器空间尺寸为$5\times 5$，步长为$1$，所以按照采样顺序将$a^{(2)}$梯度重置回$output^{(2)}$梯度，再重置为$z^{(2)}$梯度</p>
<p>上一层输出向量$a^{(1)}$梯度</p>
<script type="math/tex; mode=display">
z^{(2)}=\max (a^{(1)})\\
dz^{(2)}=1(a^{(1)}\ is\ the\ max)* da^{(1)}</script><p>配合$argz^{(2)}$，最大值梯度和$z^{(2)}$一致，其余梯度为$0$</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(2)}}f(z^{(2)}) dz^{(2)})\\
=tr(D_{z^{(2)}}f(z^{(2)})\cdot 1(a^{(1)}\ is\ the\ max)* da^{(1)})
=tr(D_{z^{(2)}}f(z^{(2)})* 1(a^{(1)}\ is\ the\ max)^{T}\cdot da^{(1)}</script><script type="math/tex; mode=display">
\Rightarrow D_{a^{(1)}}f(a^{(1)})=D_{z^{(2)}}f(z^{(2)})* 1(a^{(1)}\ is\ the\ max)^{T}\\
\Rightarrow \bigtriangledown_{a^{(1)}}f(a^{(1)})
=\bigtriangledown_{z^{(2)}}f(z^{(2)})* 1(a^{(1)}\ is\ the\ max)
\in R^{(N\cdot 1176)\times 4}</script><p><strong>卷积层$C1$</strong></p>
<p>计算$y^{(1)}$梯度</p>
<p>因为$a^{(1)}\in R^{(N\cdot 1176)\times 4}$，$output^{(1)}\in R^{N\times 6\times 28\times 28}$，$y^{(1)}\in R^{(N\cdot 784)\times 6}$，池化层$S2$滤波器空间尺寸为$2\times 2$，步长为$2$，按照采样顺序将$a^{(1)}$梯度重置回$output^{(1)}$梯度，再重置为$y^{(1)}$梯度</p>
<p>求输入向量$z^{(1)}$梯度</p>
<script type="math/tex; mode=display">
y^{(1)} = relu(z^{(1)})\\
dy^{(1)} = 1(z^{(1)} \geq 0)*dz^{(1)}</script><script type="math/tex; mode=display">
d(dataloss)
=tr(D_{y^{(1)}}f(y^{(1)})\cdot dy^{(1)})\\
=tr(D_{y^{(1)}}f(y^{(1)})\cdot (1(z^{(1)} \geq 0)*dz^{(1)}))\\
=tr(D_{y^{(1)}}f(y^{(1)})* 1(z^{(1)} \geq 0)^{T}\cdot dz^{(1)})</script><script type="math/tex; mode=display">
\Rightarrow D_{z^{(1)}}f(z^{(1)})=D_{y^{(1)}}f(y^{(1)})* 1(z^{(1)} \geq 0)^{T}\\
\Rightarrow \bigtriangledown_{z^{(1)}}f(z^{(1)})
=\bigtriangledown_{y^{(1)}}f(y^{(1)})* 1(z^{(1)} \geq 0)
\in R^{N\times 784\times 6}</script><p>其他梯度</p>
<script type="math/tex; mode=display">
z^{(1)}=a^{(0)}\cdot W^{(1)}+b^{(1)} \\
dz^{(1)}=da^{(0)}\cdot W^{(1)}+a^{(0)}\cdot dW^{(1)}+db^{(1)}</script><script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(1)}}f(z^{(1)})\cdot dz^{(1)})
=tr(D_{z^{(1)}}f(z^{(1)})\cdot (da^{(0)}\cdot W^{(1)} + a^{(0)}\cdot dW^{(1)} + db^{(1)}))\\
=tr(D_{z^{(1)}}f(z^{(1)})\cdot da^{(0)}\cdot W^{(1)})
+tr(D_{z^{(1)}}f(z^{(1)})\cdot a^{(0)}\cdot dW^{(1)})
+tr(D_{z^{(1)}}f(z^{(1)})\cdot db^{(1)}))</script><p>求权重矩阵$W^{(1)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(1)}}f(z^{(1)})\cdot a^{(0)}\cdot dW^{(1)})</script><script type="math/tex; mode=display">
\Rightarrow D_{W^{(1)}}f(W^{(1)})
=D_{z^{(1)}}f(z^{(1)})\cdot a^{(0)}\\
\Rightarrow \bigtriangledown_{W^{(1)}}f(W^{(1)})
=(a^{(0)})^{T}\cdot \bigtriangledown_{z^{(1)}}f(z^{(1)})
=R^{25\times (N\cdot 784)}\cdot R^{(N\times 784)\times 6}
=R^{25\times 6}</script><p>求偏置向量$b^{(1)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=\frac {1}{M} \sum_{i=1}^{M} tr(D_{z^{(1)}}f(z^{(1)})\cdot db^{(1)})</script><script type="math/tex; mode=display">
\Rightarrow D_{b^{(1)}}f(b^{(1)})=\frac {1}{M} \sum_{i=1}^{M} D_{z^{(1)}}f(z^{(1)})\\
\Rightarrow \bigtriangledown_{b^{(1)}}f(b^{(1)})=\frac {1}{M} \sum_{i=1}^{M} \bigtriangledown_{z^{(1)}}f(z^{(1)})
\in R^{1\times 6}</script><p>$M=N\cdot 784$, 表示$dz^{(1)}$的行数</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>矩阵计算的优缺点</p>
<ul>
<li>优点：逻辑简单，易于理解</li>
<li>缺点：占用额外内存（<em>因为计算过程中每层数据体的值都应用在矩阵多个位置</em>）</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>深度学习</category>
        <category>数学</category>
        <category>卷积神经网络</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络推导-单张图片矩阵计算</title>
    <url>/posts/3accb62a.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://www.zhujian.tech/posts/1dd3ebad.html#more">神经网络推导-矩阵计算</a></p><p><a href="https://www.zhujian.tech/posts/ba2ca878.html#more">神经网络实现-numpy</a></p><p>以<code>LeNet-5</code>为例，进行卷积神经网络的矩阵推导</p><h2 id="计算符号"><a href="#计算符号" class="headerlink" title="计算符号"></a>计算符号</h2><a id="more"></a>



<p>参考<a href="https://link.zhihu.com/?target=http%3A//yann.lecun.com/exdb/publis/pdf/lecun-98.pdf">lecun-98</a>，卷积层标记为$Cx$，池化层标记为$Sx$，全连接层标记为$Fx$，比如$C1$表示第一层是卷积层</p>
<h2 id="LeNet-5简介"><a href="#LeNet-5简介" class="headerlink" title="LeNet-5简介"></a><code>LeNet-5</code>简介</h2><p><code>LeNet-5</code>共有<code>7</code>层（不包含输入层）</p>
<p><img src="../imgs/卷积神经网络推导-矩阵计算/LeNet-5.png" alt></p>
<ul>
<li><p>$C1$有<code>6</code>个滤波器，感受野尺寸为$5\times 5$，步长为$1$，零填充为$0$，所以$C1$共有$5\cdot 5\cdot 6+6=156$个训练参数，输出激活图尺寸为$28\times 28$</p>
</li>
<li><p>$S2$感受野大小为$2\times 2$，步长为$2$，将输入数据体4个神经元相加后乘以一个可训练参数，再加上一个偏置值，最后进行$sigmoid$操作，所以$S2$共有$2\times 6=12$个训练参数，输出激活图尺寸为$14\times 14$</p>
</li>
<li><p>$C3$有<code>16</code>个滤波器，感受野尺寸为$5\times 5$，步长为$1$, 零填充为$0$，所以输出激活图尺寸为$10\times 10$</p>
<ul>
<li>$C3$的滤波器没有和$S2$完全连接：前6个滤波器和$S2$连续的3个激活图交互，接下来6个滤波器和$S2$连续的4个激活图交互，接下来3个滤波器和$S2$不连续的4个激活图交互，最后一个滤波器和$S2$全连接</li>
<li>$C3$的参数个数是$(5\cdot 5)\cdot (3\cdot 6+4\cdot 6+4\cdot 3+6\cdot 1)+16=1516$</li>
</ul>
</li>
<li><p>$S4$和$S2$一样，所以共有$2\times 16=32$个可学习参数，输出激活图尺寸为$5\times 5$</p>
</li>
<li><p>$C5$有<code>120</code>个滤波器，感受野大小为$5\times 5$，步长为$1$，零填充为$0$，所以$C5$共有$5\cdot 5\cdot 16\cdot 120+120=48120$个参数，输出激活图尺寸为$1\times 1$，输出大小为$1\times 1\times 120$</p>
</li>
<li><p>$F6$有<code>84</code>个神经元，激活函数是$tanh$，参数个数是$120\times 84+84=10164$个训练参数</p>
</li>
<li><p>$F7$有<code>10</code>个神经元，得到84个输入后，不再执行点积运算，而是执行欧氏径向基函数（euclidean radial basis function）：</p>
<script type="math/tex; mode=display">
  y_{i}=\sum_{j}(x_{i}-w_{ij})^{2}</script></li>
<li><p>损失函数是均方误差（<code>Mean Squared Error, MSE</code>）</p>
</li>
</ul>
<p>最早的<code>LeNet-5</code>在<code>1998</code>年提出，经过多年发展，一些实现细节发生了变化，其中一个版本如下</p>
<p><img src="../imgs/卷积神经网络推导-矩阵计算/LeNet-5_v2.png" alt></p>
<ul>
<li><p>$C1$有<code>6</code>个滤波器，感受野尺寸为$5\times 5$，步长为$1$，零填充为$0$，激活函数是$relu$，所以$C1$共有$5\cdot 5\cdot 6+6=156$个训练参数，输出激活图尺寸为$28\times 28$</p>
</li>
<li><p>$S2$感受野大小为$2\times 2$，步长为$2$，使用$\max$运算，所以输出激活图尺寸为$14\times 14$</p>
</li>
<li><p>$C3$有<code>16</code>个滤波器，感受野尺寸为$5\times 5$，步长为$1$, 零填充为$0$，激活函数是$relu$，所以$C3$参数个数是$5\cdot 5\cdot 6\cdot 16+16=2416$，输出激活图尺寸为$10\times 10$</p>
</li>
<li><p>$S4$和$S2$一样，步长为$2$，使用$\max$运算，所以输出激活图尺寸为$5\times 5$</p>
</li>
<li><p>$C5$有<code>120</code>个滤波器，感受野大小为$5\times 5$，步长为$1$，零填充为$0$，激活函数为$relu$，所以$C5$共有$5\cdot 5\cdot 16\cdot 120+120=48120$，输出激活图尺寸为$1\times 1$，输出大小为$1\times 120$</p>
</li>
<li><p>$F6$有<code>84</code>个神经元，激活函数是$relu$，参数个数是$120\times 84+84=10164$个训练参数，输出大小为$1\times 84$</p>
</li>
<li><p>$F7$有<code>10</code>个神经元，参数个数是$84\times 10+10=850$个，输出大小为$1\times 10$</p>
</li>
<li><p>评分函数使用$softmax$</p>
</li>
<li><p>损失函数是交叉熵损失（<code>Cross Entropy Loss</code>）</p>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">输入</th>
<th style="text-align:center">卷积核</th>
<th style="text-align:center">步长</th>
<th style="text-align:center">零填充</th>
<th style="text-align:center">输出</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">C1</td>
<td style="text-align:center">32x32x3</td>
<td style="text-align:center">5x5</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">28x28x6</td>
</tr>
<tr>
<td style="text-align:center">S2</td>
<td style="text-align:center">28x28x6</td>
<td style="text-align:center">2x2</td>
<td style="text-align:center">2</td>
<td style="text-align:center">\</td>
<td style="text-align:center">14x14x6</td>
</tr>
<tr>
<td style="text-align:center">C3</td>
<td style="text-align:center">14x14x6</td>
<td style="text-align:center">5x5</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">10x10x16</td>
</tr>
<tr>
<td style="text-align:center">S4</td>
<td style="text-align:center">10x10x16</td>
<td style="text-align:center">2x2</td>
<td style="text-align:center">2</td>
<td style="text-align:center">\</td>
<td style="text-align:center">5x5x16</td>
</tr>
<tr>
<td style="text-align:center">C5</td>
<td style="text-align:center">5x5x16</td>
<td style="text-align:center">120</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1x120</td>
</tr>
<tr>
<td style="text-align:center">F6</td>
<td style="text-align:center">1x120</td>
<td style="text-align:center">84</td>
<td style="text-align:center">\</td>
<td style="text-align:center">\</td>
<td style="text-align:center">1x84</td>
</tr>
<tr>
<td style="text-align:center">F7</td>
<td style="text-align:center">1x84</td>
<td style="text-align:center">10</td>
<td style="text-align:center">\</td>
<td style="text-align:center">\</td>
<td style="text-align:center">1x10</td>
</tr>
</tbody>
</table>
</div>
<h2 id="卷积层转全连接层"><a href="#卷积层转全连接层" class="headerlink" title="卷积层转全连接层"></a>卷积层转全连接层</h2><p>参考：<a href="http://cs231n.github.io/convolutional-networks/#fc" target="_blank" rel="noopener">Implementation as Matrix Multiplication</a></p>
<p>卷积层滤波器在输入数据体的局部区域执行点积操作，将每次局部连接数据体拉伸为行向量，那么卷积操作就等同于矩阵乘法，变成全连接层运算</p>
<p>比如输入图像大小为$32\times 32\times 3$，卷积层滤波器大小为$5\times 5\times 3$，步长为$1$，零填充为$0$，共有6个</p>
<p>那么等同于全连接层的输入维度为$5\cdot 5\cdot 3=125$，共有$((32-5)/1+1)=784$个局部连接，所以矩阵运算如下：</p>
<script type="math/tex; mode=display">
X\in R^{784\times 125}\\
W\in R^{125\times 6}\\
b\in R^{1\times 6}\\
Y=X\cdot W+B\in R^{784\times 6}</script><p>得到输出数据$Y$后再拉伸回$55\times 55\times 6$，就是下一层的输入数据体</p>
<h2 id="池化层转全连接层"><a href="#池化层转全连接层" class="headerlink" title="池化层转全连接层"></a>池化层转全连接层</h2><p>池化层滤波器在输入数据体的激活图上执行$\max$操作，将每次局部连接区域拉伸为行向量，同样可以将池化层操作转换成全连接层操作</p>
<p>比如输入数据体大小为$28\times 28\times 6$，池化层滤波器空间尺寸$2\times 2$，步长为$2$</p>
<p>那么每次连接的向量大小是$2\cdot 2=4$，每个激活图共有$(28/2)^{2}=196$次局部连接，整个输入数据体共有$196\cdot 6=1176$次局部连接，所以运算如下：</p>
<script type="math/tex; mode=display">
X\in R^{1176\times 4}\\
Y = \max(X)\in R^{1176\times 1}</script><p>得到输出数据$Y$后再拉伸回$14\times 14\times 6$，就是下一层的输入数据体</p>
<h2 id="矩阵计算"><a href="#矩阵计算" class="headerlink" title="矩阵计算"></a>矩阵计算</h2><p>进行MNIST数据集的分类</p>
<h3 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h3><p><strong>输入层</strong></p>
<script type="math/tex; mode=display">
X\in R^{32\times 32\times 1}</script><p><strong>卷积层$C1$</strong></p>
<p>共6个滤波器，每个滤波器空间尺寸为$5\times 5$，步长为$1$, 零填充为$0$</p>
<p>输出空间尺寸为$(32-5-2\cdot 0)/1+1=28$</p>
<p>所以单次卷积操作的向量大小为$5\cdot 5\cdot 1=25$，单个滤波器有$28\cdot 28=784$个局部连接</p>
<script type="math/tex; mode=display">
a^{(0)}\in R^{784\times 25}\\
W^{(1)}\in R^{25\times 6}\\
b^{(1)}\in R^{1\times 6}\\
\Rightarrow z^{(1)}=a^{(0)}\cdot W^{(1)}+b^{(1)}\in R^{784\times 6}\\
\Rightarrow y^{(1)}=relu(z^{(1)})\\</script><p>输出数据体$output^{(1)}\in R^{28\times 28\times 6}$</p>
<p><strong>池化层$S2$</strong></p>
<p>执行$\max$运算，每个滤波器空间尺寸$2\times 2$，步长为$2$</p>
<p>输出空间尺寸为$(28-2)/2+1=14$</p>
<p>所以单次$\max$操作的向量大小为$2\cdot 2=4$，单个滤波器有$14\cdot 14\cdot 6=1176$个局部连接</p>
<script type="math/tex; mode=display">
a^{(1)}\in R^{1176\times 4}\\
z^{(2)}=\max (a^{(1)})\in R^{1176\times 1}</script><p>$argz^{(2)} = argmax(a^{(1)})\in R^{1176}$，每个值表示$a^{(1)}$中每行最大值下标</p>
<p>输出数据体$output^{(2)}\in R^{14\times 14\times 6}$</p>
<p><strong>卷积层$C3$</strong></p>
<p>共16个滤波器，每个滤波器空间尺寸为$5\times 5$，步长为$1$, 零填充为$0$</p>
<p>输出空间尺寸为$(14-5+2\cdot 0)/1+1=10$</p>
<p>所以单次卷积操作的向量大小为$5\cdot 5\cdot 6=150$，单个滤波器有$10\cdot 10=100$个局部连接</p>
<script type="math/tex; mode=display">
a^{(2)}\in R^{100\times 150}\\
W^{(3)}\in R^{150\times 16}\\
b^{(3)}\in R^{1\times 16}\\
\Rightarrow z^{(3)}=a^{(2)}\cdot W^{(3)}+b^{(3)}\in R^{100\times 16}\\
\Rightarrow y^{(3)}=relu(z^{(3)})\\</script><p>输出数据体$output^{(3)}\in R^{10\times 10\times 16}$</p>
<p><strong>池化层$S4$</strong></p>
<p>执行$\max$运算，每个滤波器空间尺寸$2\times 2$，步长为$2$</p>
<p>输出空间尺寸为$(10-2)/2+1=5$</p>
<p>所以单次$\max$操作的向量大小为$2\cdot 2=4$，单个滤波器有$5\cdot 5\cdot 16=400$个局部连接</p>
<script type="math/tex; mode=display">
a^{(3)}\in R^{400\times 4}\\
z^{(4)}=\max (a^{(3)})\in R^{400\times 1}</script><p>$argz^{(4)} = argmax(a^{(3)})\in R^{400}$，每个值表示$a^{(3)}$中每行最大值下标</p>
<p>输出数据体$output^{(4)}\in R^{5\times 5\times 16}$</p>
<p><strong>卷积层$C5$</strong></p>
<p>共120个滤波器，每个滤波器空间尺寸为$5\times 5$，步长为$1$, 零填充为$0$</p>
<p>输出空间尺寸为$(5-5+2\cdot 0)/1+1=1$</p>
<p>所以单次卷积操作的向量大小为$5\cdot 5\cdot 16=400$，单个滤波器有$1\cdot 1=1$个局部连接</p>
<script type="math/tex; mode=display">
a^{(4)}\in R^{1\times 400}\\
W^{(5)}\in R^{400\times 120}\\
b^{(5)}\in R^{1\times 120}\\
\Rightarrow z^{(5)}=a^{(4)}\cdot W^{(5)}+b^{(5)}\in R^{1\times 120}\\
\Rightarrow y^{(5)}=relu(z^{(5)})\\</script><p>输出数据体$output^{(5)}\in R^{1\times 120}$</p>
<p><strong>全连接层$F6$</strong></p>
<p>神经元个数为$84$</p>
<script type="math/tex; mode=display">
a^{(5)}=y^{(5)}\in R^{1\times 120}\\
W^{(6)}\in R^{120\times 84}\\
b^{(6)}\in R^{1\times 84}\\
\Rightarrow z^{(6)}=a^{(5)}\cdot W^{(6)}+b^{(6)}\in R^{1\times 84}\\
\Rightarrow y^{(6)}=relu(z^{(6)})\\</script><p>输出数据体$output^{(6)}\in R^{1\times 84}$</p>
<p><strong>输出层$F7$</strong></p>
<p>神经元个数为$10$</p>
<script type="math/tex; mode=display">
a^{(6)}=y^{(6)}\in R^{1\times 84}\\
W^{(7)}\in R^{84\times 10}\\
b^{(7)}\in R^{1\times 10}\\
\Rightarrow z^{(7)}=a^{(6)}\cdot W^{(7)}+b^{(7)}\in R^{1\times 10}\\</script><p>输出数据体$output^{(7)}\in R^{1\times 10}$</p>
<p><strong>分类概率</strong></p>
<script type="math/tex; mode=display">
probs=h(z^{(7)})=\frac {exp(z^{(7)})}{exp(z^{(7)})\cdot A\cdot B^{T}}</script><p><strong>$A\in R^{10\times 1}, B\in R^{10\times 1}$都是全$1$向量</strong></p>
<p><strong>损失值</strong></p>
<script type="math/tex; mode=display">
dataLoss = -\frac {1}{N} 1^{T}\cdot \ln \frac {exp(z^{(7)}* Y\cdot A)}{exp(z^{(7)})\cdot A}</script><script type="math/tex; mode=display">
regLoss = 0.5\cdot reg\cdot (||W^{(1)}||^{2} + ||W^{(3)}||^{2} + ||W^{(5)}||^{2} + ||W^{(6)}||^{2} + ||W^{(7)}||^{2})</script><script type="math/tex; mode=display">
J(z^{(7)})=dataLoss + regLoss</script><p><strong>$Y\in R^{1\times 10}$，仅有正确类别为<code>1</code>, 其余为<code>0</code></strong></p>
<h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p><strong>输出层$F7$</strong></p>
<p>求输入向量$z^{(7)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=d(1^{T}\cdot \ln \frac {exp(z^{(7)}* Y\cdot A)}{exp(z^{(7)})\cdot A})=tr((probs^{T} - Y^{T})\cdot dz^{(7)})</script><script type="math/tex; mode=display">
\Rightarrow D_{z^{(7)}}f(z^{(7)})=probs^{T} - Y^{T}\\
\Rightarrow \bigtriangledown_{z^{(7)}}f(z^{(7)})=probs - Y</script><p>其他梯度</p>
<script type="math/tex; mode=display">
z^{(7)}=a^{(6)}\cdot W^{(7)}+b^{(7)} \\
dz^{(7)}=da^{(6)}\cdot W^{(7)} + a^{(6)}\cdot dW^{(7)} + db^{(7)}\\
d(dataloss)=tr(D_{z^{(7)}}f(z^{(7)})\cdot dz^{(7)})\\
=tr(D_{z^{(7)}}f(z^{(7)})\cdot (da^{(6)}\cdot W^{(7)} + a^{(6)}\cdot dW^{(7)} + db^{(7)}))\\
=tr(D_{z^{(7)}}f(z^{(7)})\cdot da^{(6)}\cdot W^{(7)})
+tr(D_{z^{(7)}}f(z^{(7)})\cdot a^{(6)}\cdot dW^{(7)})
+tr(D_{z^{(7)}}f(z^{(7)})\cdot db^{(7)}))</script><p>求权重矩阵$W^{(7)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(7)}}f(z^{(7)})\cdot a^{(6)}\cdot dW^{(7)})</script><script type="math/tex; mode=display">
\Rightarrow D_{W^{(7)}}f(W^{(7)})=D_{z^{(7)}}f(z^{(7)})\cdot a^{(6)}\\
\Rightarrow \bigtriangledown_{W^{(7)}}f(W^{(7)})=(a^{(6)})^{T}\cdot \bigtriangledown_{z^{(7)}}f(z^{(7)})</script><p>求偏置向量$b^{(7)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(7)}}f(z^{(7)})\cdot db^{(7)}))</script><script type="math/tex; mode=display">
\Rightarrow D_{b^{(7)}}f(b^{(7)})=D_{z^{(7)}}f(z^{(7)})\\
\Rightarrow \bigtriangledown_{b^{(7)}}f(b^{(7)})=\bigtriangledown_{z^{(7)}}f(z^{(7)})</script><p>求上一层输出向量$a^{(6)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(7)}}f(z^{(7)})\cdot da^{(6)}\cdot W^{(7)})
=tr(W^{(7)}\cdot D_{z^{(7)}}f(z^{(7)})\cdot da^{(6)})</script><script type="math/tex; mode=display">
\Rightarrow D_{a^{(6)}}f(a^{(6)})=W^{(7)}\cdot D_{z^{(7)}}f(z^{(7)})\\
\Rightarrow \bigtriangledown_{a^{(6)}}f(a^{(6)})=\bigtriangledown_{z^{(7)}}f(z^{(7)})\cdot (W^{(7)})^{T}</script><p><strong>全连接层$F6$</strong></p>
<p>求输入向量$z^{(6)}$梯度</p>
<script type="math/tex; mode=display">
a^{(6)}=y^{(6)}=relu(z^{(6)})\\
da^{(6)}=1(z^{(6)}\geq 0)* dz^{(6)}</script><script type="math/tex; mode=display">
d(dataloss)=tr(D_{a^{(6)}}f(a^{(6)}) da^{(6)})=tr(D_{a^{(6)}}f(a^{(6)})\cdot (1(z^{(6)}\geq 0)* dz^{(6)}))\\
=tr(D_{a^{(6)}}f(a^{(6)})* 1(z^{(6)}\geq 0)^{T}\cdot dz^{(6)})</script><script type="math/tex; mode=display">
\Rightarrow D_{z^{(6)}}f(z^{(6)})=D_{a^{(6)}}f(a^{(6)})* 1(z^{(6)}\geq 0)^{T}\\
\Rightarrow \bigtriangledown_{z^{(6)}}f(z^{(6)})=\bigtriangledown_{a^{(6)}}f(a^{(6)})* 1(z^{(6)}\geq 0)</script><p>其他梯度</p>
<script type="math/tex; mode=display">
z^{(6)}=a^{(5)}\cdot W^{(6)}+b^{(6)} \\
dz^{(6)}=da^{(5)}\cdot W^{(6)}+a^{(5)}\cdot dW^{(6)}+db^{(6)}\\
d(dataloss)=tr(D_{z^{(6)}}f(z^{(6)})\cdot dz^{(6)})\\
=tr(D_{z^{(6)}}f(z^{(6)})\cdot (da^{(5)}\cdot W^{(6)} + a^{(5)}\cdot dW^{(6)} + db^{(6)}))\\
=tr(D_{z^{(6)}}f(z^{(6)})\cdot da^{(5)}\cdot W^{(6)})
+tr(D_{z^{(6)}}f(z^{(6)})\cdot a^{(5)}\cdot dW^{(6)})
+tr(D_{z^{(6)}}f(z^{(6)})\cdot db^{(6)}))</script><p>求权重矩阵$w^{(6)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(6)}}f(z^{(6)})\cdot a^{(5)}\cdot dW^{(6)})</script><script type="math/tex; mode=display">
\Rightarrow D_{W^{(6)}}f(W^{(6)})=D_{z^{(6)}}f(z^{(6)})\cdot a^{(5)}\\
\Rightarrow \bigtriangledown_{W^{(6)}}f(W^{(6)})=(a^{(5)})^{T}\cdot \bigtriangledown_{z^{(6)}}f(z^{(6)})</script><p>求偏置向量$b^{(6)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(6)}}f(z^{(6)})\cdot db^{(6)}))</script><script type="math/tex; mode=display">
\Rightarrow D_{b^{(6)}}f(b^{(6)})=D_{z^{(6)}}f(z^{(6)})\\
\Rightarrow \bigtriangledown_{b^{(6)}}f(b^{(6)})=\bigtriangledown_{z^{(6)}}f(z^{(6)})</script><p>求上一层输出向量$a^{(5)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(6)}}f(z^{(6)})\cdot da^{(5)}\cdot W^{(6)})
=tr(W^{(6)}\cdot D_{z^{(6)}}f(z^{(6)})\cdot da^{(5)})</script><script type="math/tex; mode=display">
\Rightarrow D_{a^{(5)}}f(a^{(5)})=W^{(6)}\cdot D_{z^{(6)}}f(z^{(6)})\\
\Rightarrow \bigtriangledown_{a^{(5)}}f(a^{(5)})=\bigtriangledown_{z^{(6)}}f(z^{(6)})\cdot (W^{(6)})^{T}</script><p><strong>卷积层$C5$</strong></p>
<p>求输入向量$z^{(5)}$梯度</p>
<script type="math/tex; mode=display">
a^{(5)}=y^{(5)}=relu(z^{(5)})\\
da^{(5)}=1(z^{(5)}\geq 0)* dz^{(5)}\\</script><script type="math/tex; mode=display">
d(dataloss)=tr(D_{a^{(5)}}f(a^{(5)}) da^{(5)})=tr(D_{a^{(5)}}f(a^{(5)})\cdot (1(z^{(5)}\geq 0)* dz^{(5)}))\\
=tr(D_{a^{(5)}}f(a^{(5)})* 1(z^{(5)}\geq 0)^{T}\cdot dz^{(5)})</script><script type="math/tex; mode=display">
\Rightarrow D_{z^{(5)}}f(z^{(5)})=D_{a^{(5)}}f(a^{(5)})* 1(z^{(5)}\geq 0)^{T}\\
\Rightarrow \bigtriangledown_{z^{(5)}}f(z^{(5)})=\bigtriangledown_{a^{(5)}}f(a^{(5)})* 1(z^{(5)}\geq 0)</script><p>其他梯度</p>
<script type="math/tex; mode=display">
z^{(5)}=a^{(4)}\cdot W^{(5)}+b^{(5)} \\
dz^{(5)}=da^{(4)}\cdot W^{(5)}+a^{(4)}\cdot dW^{(5)}+db^{(5)}\\
d(dataloss)=tr(D_{z^{(5)}}f(z^{(5)})\cdot dz^{(5)})\\
=tr(D_{z^{(5)}}f(z^{(5)})\cdot (da^{(4)}\cdot W^{(5)} + a^{(4)}\cdot dW^{(5)} + db^{(5)}))\\
=tr(D_{z^{(5)}}f(z^{(5)})\cdot da^{(4)}\cdot W^{(5)})
+tr(D_{z^{(5)}}f(z^{(5)})\cdot a^{(4)}\cdot dW^{(5)})
+tr(D_{z^{(5)}}f(z^{(5)})\cdot db^{(5)}))</script><p>求权重矩阵$W^{(5)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(5)}}f(z^{(5)})\cdot a^{(4)}\cdot dW^{(5)})</script><script type="math/tex; mode=display">
\Rightarrow D_{W^{(5)}}f(W^{(5)})=D_{z^{(5)}}f(z^{(5)})\cdot a^{(4)}\\
\Rightarrow \bigtriangledown_{W^{(5)}}f(W^{(5)})=(a^{(4)})^{T}\cdot \bigtriangledown_{z^{(5)}}f(z^{(5)})</script><p>求偏置向量$b^{(5)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(5)}}f(z^{(5)})\cdot db^{(5)})</script><script type="math/tex; mode=display">
\Rightarrow D_{b^{(5)}}f(b^{(5)})=D_{z^{(5)}}f(z^{(5)})\\
\Rightarrow \bigtriangledown_{b^{(5)}}f(b^{(5)})=\bigtriangledown_{z^{(5)}}f(z^{(5)})</script><p>求上一层输出向量$a^{(4)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(5)}}f(z^{(5)})\cdot da^{(4)}\cdot W^{(5)})
=tr(W^{(5)}\cdot D_{z^{(5)}}f(z^{(5)})\cdot da^{(4)})</script><script type="math/tex; mode=display">
\Rightarrow D_{a^{(4)}}f(a^{(4)})=W^{(5)}\cdot D_{z^{(5)}}f(z^{(5)})\\
\Rightarrow \bigtriangledown_{a^{(4)}}f(a^{(4)})=\bigtriangledown_{z^{(5)}}f(z^{(5)})\cdot (W^{(5)})^{T}</script><p><strong>池化层$S4$</strong></p>
<p>将$a^{(4)}$梯度重置回$output^{(4)}$梯度，再重置为$y^{(4)}$梯度</p>
<p>因为卷积层$C5$滤波器的空间尺寸和$output^{(4)}$的空间尺寸一致，所以不需要将$a^{(4)}$先转换成$output^{(4)}$，再转换成$y^{(4)}$，可以一步到位</p>
<p>求输入向量$z^{(4)}$梯度</p>
<script type="math/tex; mode=display">
z^{(4)}\in R^{400\times 1},\ a^{(4)}\in R^{1\times 400}\\
\Rightarrow a^{(4)} = (z^{(4)})^{T}\\
\Rightarrow da^{(4)} = d(z^{(4)})^{T}</script><script type="math/tex; mode=display">
d(dataloss)=tr(D_{a^{(4)}}f(a^{(4)}) da^{(4)})=tr(D_{a^{(4)}}f(a^{(4)})\cdot d(z^{(4)})^{T})\\
=tr(D_{a^{(4)}}f(a^{(4)})^{T}\cdot dz^{(4)})</script><script type="math/tex; mode=display">
\Rightarrow D_{z^{(4)}}f(z^{(4)})=D_{a^{(4)}}f(a^{(4)})^{T}\\
\Rightarrow \bigtriangledown_{z^{(4)}}f(z^{(4)})=D_{a^{(4)}}f(a^{(4)})</script><p>上一层输出向量$a^{(3)}$梯度</p>
<script type="math/tex; mode=display">
z^{(4)}=\max (a^{(3)})\\
dz^{(4)}=1(a^{(3)}\ is\ the\ max)* da^{(3)}</script><p>配合$argz^{(4)}$，最大值梯度和$z^{(4)}$一致，其余梯度为$0$</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(4)}}f(z^{(4)}) dz^{(4)})\\
=tr(D_{z^{(4)}}f(z^{(4)})\cdot 1(a^{(3)}\ is\ the\ max)* da^{(3)})
=tr(D_{z^{(4)}}f(z^{(4)})* 1(a^{(3)}\ is\ the\ max)^{T}\cdot da^{(3)}</script><script type="math/tex; mode=display">
\Rightarrow D_{a^{(3)}}f(a^{(3)})=D_{z^{(4)}}f(z^{(4)})* 1(a^{(3)}\ is\ the\ max)^{T}\\
\Rightarrow \bigtriangledown_{a^{(3)}}f(a^{(3)})=\bigtriangledown_{z^{(4)}}f(z^{(4)})* 1(a^{(3)}\ is\ the\ max)</script><p><strong>卷积层$C3$</strong></p>
<p>将$a^{(3)}$梯度重置回$output^{(3)}$梯度，再重置为$y^{(3)}$梯度</p>
<p>求输入向量$z^{(3)}$梯度</p>
<script type="math/tex; mode=display">
y^{(3)} = relu(z^{(3)})\\
dy^{(3)} = 1(z^{(3)} \geq 0)*dz^{(3)}</script><script type="math/tex; mode=display">
d(dataloss)
=tr(D_{y^{(3)}}f(y^{(3)})\cdot dy^{(3)})\\
=tr(D_{y^{(3)}}f(y^{(3)})\cdot (1(z^{(3)} \geq 0)*dz^{(3)}))\\
=tr(D_{y^{(3)}}f(y^{(3)})* 1(z^{(3)} \geq 0)^{T}\cdot dz^{(3)})</script><script type="math/tex; mode=display">
\Rightarrow D_{z^{(3)}}f(z^{(3)})=D_{y^{(3)}}f(y^{(3)})* 1(z^{(3)} \geq 0)^{T}\\
\Rightarrow \bigtriangledown_{z^{(3)}}f(z^{(3)})=\bigtriangledown_{y^{(3)}}f(y^{(3)})* 1(z^{(3)} \geq 0)</script><p>其他梯度</p>
<script type="math/tex; mode=display">
z^{(3)}=a^{(2)}\cdot W^{(3)}+b^{(3)} \\
dz^{(3)}=da^{(2)}\cdot W^{(3)}+a^{(2)}\cdot dW^{(3)}+db^{(3)}\\
d(dataloss)=tr(D_{z^{(3)}}f(z^{(3)})\cdot dz^{(3)})\\
=tr(D_{z^{(3)}}f(z^{(3)})\cdot (da^{(2)}\cdot W^{(3)} + a^{(2)}\cdot dW^{(3)} + db^{(3)}))\\
=tr(D_{z^{(3)}}f(z^{(3)})\cdot da^{(2)}\cdot W^{(3)})
+tr(D_{z^{(3)}}f(z^{(3)})\cdot a^{(2)}\cdot dW^{(3)})
+tr(D_{z^{(3)}}f(z^{(3)})\cdot db^{(3)}))</script><p>求权重矩阵$W^{(3)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(3)}}f(z^{(3)})\cdot a^{(2)}\cdot dW^{(3)})</script><script type="math/tex; mode=display">
\Rightarrow D_{W^{(3)}}f(W^{(3)})=D_{z^{(3)}}f(z^{(3)})\cdot a^{(2)}\\
\Rightarrow \bigtriangledown_{W^{(3)}}f(W^{(3)})=(a^{(2)})^{T}\cdot \bigtriangledown_{z^{(3)}}f(z^{(3)})</script><p>求偏置向量$b^{(3)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=\frac {1}{N} \sum_{i=1}^{N} tr(D_{z^{(3)}}f(z^{(3)})\cdot db^{(3)})</script><script type="math/tex; mode=display">
\Rightarrow D_{b^{(3)}}f(b^{(3)})=\frac {1}{N} \sum_{i=1}^{N} D_{z^{(3)}}f(z^{(3)})\\
\Rightarrow \bigtriangledown_{b^{(3)}}f(b^{(3)})=\frac {1}{N} \sum_{i=1}^{N} \bigtriangledown_{z^{(3)}}f(z^{(3)})</script><p>$N$表示$dz^{(3)}$的行数</p>
<p>求上一层输出向量$a^{(2)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(3)}}f(z^{(3)})\cdot da^{(2)}\cdot W^{(3)})
=tr(W^{(3)}\cdot D_{z^{(3)}}f(z^{(3)})\cdot da^{(2)})</script><script type="math/tex; mode=display">
\Rightarrow D_{a^{(2)}}f(a^{(2)})=W^{(3)}\cdot D_{z^{(3)}}f(z^{(3)})\\
\Rightarrow \bigtriangledown_{a^{(2)}}f(a^{(2)})=\bigtriangledown_{z^{(3)}}f(z^{(3)})\cdot (W^{(3)})^{T}</script><p><strong>池化层$S2$</strong></p>
<p>$C3$输入层梯度大小为$100\times 150$，是在$S2$输出数据体$output^{(2)}$上采样获得，将$da^{(2)}$重采样回$output^{(2)}$梯度矩阵，再重置回$1176\times 1$大小，就是$z^{(2)}$的梯度</p>
<p>上一层输出向量$a^{(1)}$梯度</p>
<script type="math/tex; mode=display">
z^{(2)}=\max (a^{(1)})\\
dz^{(2)}=1(a^{(1)}\ is\ the\ max)* da^{(1)}</script><p>配合$argz^{(2)}$，最大值梯度和$z^{(2)}$一致，其余梯度为$0$</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(2)}}f(z^{(2)}) dz^{(2)})\\
=tr(D_{z^{(2)}}f(z^{(2)})\cdot 1(a^{(1)}\ is\ the\ max)* da^{(1)})
=tr(D_{z^{(2)}}f(z^{(2)})* 1(a^{(1)}\ is\ the\ max)^{T}\cdot da^{(1)}</script><script type="math/tex; mode=display">
\Rightarrow D_{a^{(1)}}f(a^{(1)})=D_{z^{(2)}}f(z^{(2)})* 1(a^{(1)}\ is\ the\ max)^{T}\\
\Rightarrow \bigtriangledown_{a^{(1)}}f(a^{(1)})=\bigtriangledown_{z^{(2)}}f(z^{(2)})* 1(a^{(1)}\ is\ the\ max)</script><p><strong>卷积层$C1$</strong></p>
<p>将$a^{(1)}$梯度重置回$output^{(1)}$梯度，再重置为$y^{(1)}$梯度</p>
<p>求输入向量$z^{(1)}$梯度</p>
<script type="math/tex; mode=display">
y^{(1)} = relu(z^{(1)})\\
dy^{(1)} = 1(z^{(1)} \geq 0)*dz^{(1)}</script><script type="math/tex; mode=display">
d(dataloss)
=tr(D_{y^{(1)}}f(y^{(1)})\cdot dy^{(1)})\\
=tr(D_{y^{(1)}}f(y^{(1)})\cdot (1(z^{(1)} \geq 0)*dz^{(1)}))\\
=tr(D_{y^{(1)}}f(y^{(1)})* 1(z^{(1)} \geq 0)^{T}\cdot dz^{(1)})</script><script type="math/tex; mode=display">
\Rightarrow D_{z^{(1)}}f(z^{(1)})=D_{y^{(1)}}f(y^{(1)})* 1(z^{(1)} \geq 0)^{T}\\
\Rightarrow \bigtriangledown_{z^{(1)}}f(z^{(1)})=\bigtriangledown_{y^{(1)}}f(y^{(1)})* 1(z^{(1)} \geq 0)</script><p>其他梯度</p>
<script type="math/tex; mode=display">
z^{(1)}=a^{(0)}\cdot W^{(1)}+b^{(1)} \\
dz^{(1)}=da^{(0)}\cdot W^{(1)}+a^{(0)}\cdot dW^{(1)}+db^{(1)}\\
d(dataloss)=tr(D_{z^{(1)}}f(z^{(1)})\cdot dz^{(1)})\\
=tr(D_{z^{(1)}}f(z^{(1)})\cdot (da^{(0)}\cdot W^{(1)} + a^{(0)}\cdot dW^{(1)} + db^{(1)}))\\
=tr(D_{z^{(1)}}f(z^{(1)})\cdot da^{(0)}\cdot W^{(1)})
+tr(D_{z^{(1)}}f(z^{(1)})\cdot a^{(0)}\cdot dW^{(1)})
+tr(D_{z^{(1)}}f(z^{(1)})\cdot db^{(1)}))</script><p>求权重矩阵$W^{(1)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(D_{z^{(1)}}f(z^{(1)})\cdot a^{(0)}\cdot dW^{(1)})</script><script type="math/tex; mode=display">
\Rightarrow D_{W^{(1)}}f(W^{(1)})=D_{z^{(1)}}f(z^{(1)})\cdot a^{(0)}\\
\Rightarrow \bigtriangledown_{W^{(1)}}f(W^{(1)})=(a^{(0)})^{T}\cdot \bigtriangledown_{z^{(1)}}f(z^{(1)})</script><p>求偏置向量$b^{(1)}$梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=\frac {1}{N} \sum_{i=1}^{N} tr(D_{z^{(1)}}f(z^{(1)})\cdot db^{(1)})</script><script type="math/tex; mode=display">
\Rightarrow D_{b^{(1)}}f(b^{(1)})=\frac {1}{N} \sum_{i=1}^{N} D_{z^{(1)}}f(z^{(1)})\\
\Rightarrow \bigtriangledown_{b^{(1)}}f(b^{(1)})=\frac {1}{N} \sum_{i=1}^{N} \bigtriangledown_{z^{(1)}}f(z^{(1)})</script><p>$N$表示$dz^{(1)}$的行数</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>深度学习</category>
        <category>数学</category>
        <category>卷积神经网络</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络概述</title>
    <url>/posts/3b660279.html</url>
    <content><![CDATA[<p>参考：<a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit" target="_blank" rel="noopener">CS231n课程笔记翻译：卷积神经网络笔记</a></p><p>卷积神经网络（<code>convolutional neural network</code>）在神经网络（<code>neural network</code>）的基础上进一步发展，实现更强大的分类、识别性能</p><a id="more"></a>

<p>结合<code>cs231n</code>课程<a href="http://cs231n.github.io/convolutional-networks/#architectures" target="_blank" rel="noopener">Convolutional Neural Networks: Architectures, Convolution / Pooling Layers </a>，介绍卷积层和池化层，以及基于卷积层、池化层和全连接层的卷积神经网络常用的组成模式</p>
<p><em>暂不涉及之后发展的网络结构和组成模式</em></p>
<p>卷积神经网络以神经元为单位进行网络组织，不同于神经网络的<code>2-D</code>处理，卷积神经网络假定输入数据是图像（<code>image</code>），每层的输入输出都是一个<code>3</code>维数据体（<code>3-D volume</code>），各层神经元不仅在<code>2-D</code>空间上进行排列，还在深度（<code>depth</code>）上进行组织</p>
<p>卷积神经网络主要的层类型有卷积层（<code>convolutional layer</code>）、池化层（<code>pooling layer</code>）和全连接层（<code>fully-connected layer</code>）</p>
<h2 id="输入层"><a href="#输入层" class="headerlink" title="输入层"></a>输入层</h2><p>输入层不实现任何功能，仅表示输入数据，有<code>3</code>个维度：长度（<code>height</code>）、宽度（<code>width</code>）和深度（<code>depth</code>），其中深度就是图像通道数（<code>channels</code>）</p>
<p>比如<code>cifar-10</code>数据库的图像是$32\times 32$大小的彩色图像，通道数是$3$，所以输入层数据为$32\times 32\times 3$</p>
<h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><p>卷积层以滤波器（<code>filter</code>）为单位，滤波器以神经元（<code>neuron</code>）为单位</p>
<p>卷积层有两个特性：局部连接（<code>local connectivity</code>）和参数共享（<code>parameter sharing</code>）</p>
<h3 id="局部连接"><a href="#局部连接" class="headerlink" title="局部连接"></a>局部连接</h3><p>滤波器是<code>3</code>维结构，有<code>3</code>个超参数：</p>
<ul>
<li>长度（<code>height</code>）</li>
<li>宽度（<code>width</code>）</li>
<li>深度（<code>depth</code>）</li>
</ul>
<p>滤波器神经元和前一层输出数据体局部区域神经元一一连接，其空间尺寸称为感受野（receptive field），也就是滤波器空间大小；滤波器深度和上一层输出数据体的深度一致</p>
<p>比如滤波器大小为$3\times 3\times 6$，那么感受野大小是$3\times 3$，前一层输出数据体的深度是$6$，滤波器神经元个数是$3\cdot 3\cdot 6=54$个</p>
<p>卷积层滤波器空间大小（长度和宽度）通常为$1\times 1$、$3\times 3$或$5\times 5$（<em>奇数结构</em>），滤波器每次只能和前一层输出数据体的局部数据进行交互，然后上下左右移动滤波器，再次进行交互，就像卷积（<code>convolution</code>）操作一样</p>
<p>为保证前一层数据体和滤波器能够完整的执行卷积操作，有以下超参数：</p>
<ul>
<li>步长（stride）`</li>
<li>零填充（zero-padding）</li>
</ul>
<p><strong>步长表示滤波器每次移动的步长；零填充用于扩展数据体的边界，控制输出数据体的空间大小</strong></p>
<p>假设输入数据体空间大小为$W$（也就是输入数据体宽度和高度为$W$），感受野大小为$F$，步长大小为$S$，零填充大小为$P$，所以经过滤波器卷积操作后的激活图空间大小为</p>
<script type="math/tex; mode=display">
(W-F+2P)/S+1</script><p>比如输入数据体空间大小是$32\times 32$，感受野大小是$5\times 5$，步长为$1$，零填充为$0$，所以激活图大小为</p>
<script type="math/tex; mode=display">
(32-5+2*0)/1+1=28</script><p>卷积层包含多个滤波器，每个滤波器和前一层输出数据体进行交互后生成一张<code>2</code>维激活图（activation map），多张激活图在深度方向进行堆叠，输出<code>3</code>维数据体。比如输入数据体大小为$227\times 227\times 3$，卷积层共有$96$个滤波器，滤波器大小为$11\times 11\times 3$，步长为$4$，零填充为$0$，那么输出激活图大小为</p>
<script type="math/tex; mode=display">
(227-11+2*0)/2+1=55</script><p>所以输出数据体大小为$55\times 55\times 96$</p>
<p><strong><em>如果想要输入数据体和输出数据体空间尺寸一致，通常设置$S=1, P=(F-1)/2$，比如$F=3, S=1, P=1$</em></strong></p>
<h4 id="感受野尺寸"><a href="#感受野尺寸" class="headerlink" title="感受野尺寸"></a>感受野尺寸</h4><p>感受野表示卷积层滤波器连接到数据体局部区域的空间尺寸</p>
<ul>
<li><p>默认针对上一层输出数据体，称为局部感受野（<code>local receptive field</code>）</p>
</li>
<li><p>针对原始输入图像的局部空间尺寸，称为有效感受野（<code>effective receptive field</code>）</p>
</li>
</ul>
<p>比如原始图像大小为$32\times 32$</p>
<p>如果卷积层滤波器$A$大小为$3\times 3$，步长为$1$，零填充为$0$</p>
<p>第一次卷积操作后激活图空间大小为$30\times 30$；第二次卷积操作后激活图空间大小为$28\times 28$</p>
<p>如果卷积层滤波器$B$大小为$5\times 5$，步长为$1$，零填充为$0$</p>
<p>第一次卷积操作后激活图大小为$28\times 28$</p>
<p>所以滤波器$A$两次卷积操作等同于滤波器$B$一次卷积操作，滤波器$A$第二次卷积操作的局部感受野尺寸为$3\times 3$，有效感受野尺寸为$5\times 5$</p>
<p>类似的，滤波器$A$3次卷积操作等同于$7\times 7$大小的滤波器$C$一次卷积操作，所以$A$第三次卷积操作的有效感受野尺寸为$7\times 7$</p>
<p>参考<a href="https://zhuanlan.zhihu.com/p/31004121" target="_blank" rel="noopener">如何计算感受野(Receptive Field)——原理</a>，使用<a href="https://fomoro.com/projects/project/receptive-field-calculator#3,1,1,VALID;3,1,1,VALID;3,1,1,VALID;3,1,1,VALID" target="_blank" rel="noopener">Receptive Field Calculator</a>能够实现在线计算有效感受野大小</p>
<h4 id="滤波器空间尺寸"><a href="#滤波器空间尺寸" class="headerlink" title="滤波器空间尺寸"></a>滤波器空间尺寸</h4><p>参考：<a href="http://cs231n.github.io/convolutional-networks/#architectures" target="_blank" rel="noopener">Prefer a stack of small filter CONV to one large receptive field CONV layer.</a></p>
<p>通常使用更小的空间尺寸（$3$或者$5$）而不是大的空间尺寸（$7$或者更大）</p>
<p>原因如下：</p>
<ol>
<li>多次卷积操作能够增加非线性，有利于特征提取</li>
<li>小卷积操作能够减少参数，有利于防止过拟合，增强泛化性。比如每层输出数据通道数均为$C$，那么$(7\times 7\times C)\times C$大小卷积层参数数量为$7\cdot 7\cdot C\cdot C=49C^{2}$，而$(3\times 3\times C)\times C$大小卷积层经过3轮卷积操作后能够实现同样的有效感受野，参数总数是$3\cdot 3\cdot C\cdot C\cdot 3=27C^{2}$</li>
</ol>
<h4 id="滤波器空间大小为啥是奇数"><a href="#滤波器空间大小为啥是奇数" class="headerlink" title="滤波器空间大小为啥是奇数?"></a>滤波器空间大小为啥是奇数?</h4><p>偶数空间大小的滤波器同样能够完成卷积操作，不过滤波器空间大小通常选择奇数（<code>3/5/7/9...</code>），参考<a href="https://www.zhihu.com/question/51603070" target="_blank" rel="noopener">为什么CNN中的卷积核一般都是奇数<em>奇数，没有偶数</em>偶数的？</a>，有以下原因：</p>
<ol>
<li>更容易确定中心点</li>
<li>方便对称进行零填充</li>
</ol>
<h3 id="参数共享"><a href="#参数共享" class="headerlink" title="参数共享"></a>参数共享</h3><p>参数共享是卷积操作的特性，也就是滤波器在前一层输出数据体上不同区域进行点积操作时使用同一套参数</p>
<p><code>cs231n</code>课程的描述意思是因为使用了局部连接和参数共享的特性，所以滤波器操作看起来向卷积操作，所以称为卷积层。不过我感觉是因为要使用卷积操作（<em>因为卷积操作有很好的特征提取能力</em>），所以称为卷积层，有局部连接和参数共享的特征</p>
<blockquote>
<p>Notice that if all neurons in a single depth slice are using the same weight vector, then the forward pass of the CONV layer can in each depth slice be computed as a convolution of the neuron’s weights with the input volume (Hence the name: Convolutional Layer). This is why it is common to refer to the sets of weights as a filter (or a kernel), that is convolved with the input.</p>
</blockquote>
<p><code>cs231n</code>课程同样提到另外一种情况：就是对于有明确中心结构的训练图像（比如人脸），期望不同的特征（比如眼睛特征或者头发特征）能够在不同位置被学习，那么可以放松参数共享的限制，称之为局部连接层（<code>Locally-Connected Layer</code>）</p>
<h3 id="卷积层大小评判"><a href="#卷积层大小评判" class="headerlink" title="卷积层大小评判"></a>卷积层大小评判</h3><p>假设输入图像尺寸是$32\times 32\times 3$</p>
<p>对于全连接层而言，单个神经元的参数个数是$32\times 32\times 3+1=3073$</p>
<p>如果输入图像尺寸扩展到$227\times 227\times 3$</p>
<p>那么全连接层单个神经元的参数个数是$227\times 227\times 3+1=154588$，</p>
<p><strong>当图像尺寸扩大越<code>50</code>倍后，全连接层单个神经元的参数个数也扩大了约<code>50</code>倍，所以大尺寸图像会导致神经网络计算量爆炸</strong></p>
<p>对于卷积层而言，单个神经元的参数个数是<code>1</code>，假设滤波器大小为$5\times 5\times 3$，共有$16$个滤波器，那么总的参数个数是$5\times 5\times 3\times 16+16=1216$（每个滤波器有一个偏置值），其个数不随图像尺寸而变化</p>
<p><strong>卷积层局部连接和参数共享的特性保证了参数个数不随图像尺寸变化，这允许卷积神经网络在大尺寸图像上进行有效计算，而大尺寸图像也能够提供更多的信息</strong></p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>假设输入数据体为$W_{1}\times H_{1}\times D_{1}$</p>
<p>卷积层有$K$个滤波器，滤波器空间大小$F$，步长$S$以及零填充$P$</p>
<p>那么输入数据体$W_{2}\times H_{2}\times D_{2}$计算如下</p>
<script type="math/tex; mode=display">
W_{2}=(W_{1}-F+2P)/S+1\\
H_{2}=(H_{1}-F+2P)/S+1\\
D_{2}=K</script><p>每个滤波器的参数有$F\cdot F\cdot D_{1}$，总的参数个数是$(F\cdot F\cdot D_{1})\cdot K$，偏置向量个数是$K$</p>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>参考：<a href="https://www.zhihu.com/question/36686900" target="_blank" rel="noopener">CNN网络的pooling层有什么用？</a></p>
<p>池化层执行降采样（<code>downsampling</code>）操作，减小数据体空间尺寸，其目的是</p>
<ol>
<li>减少计算量以及内存缓存</li>
<li>降低参数个数，防止过拟合</li>
<li>增大有效感受野</li>
</ol>
<p>有两个超参数：</p>
<ul>
<li>空间尺寸$F$</li>
<li>步长$S$</li>
</ul>
<p>比如输入数据体大小为$W_{1}\times H_{1}\times D_{1}$</p>
<p>那么输入数据体$W_{2}\times H_{2}\times D_{2}$计算如下</p>
<script type="math/tex; mode=display">
W_{2}=(W_{1}-F)/S+1\\
H_{2}=(H_{1}-F)/S+1\\
D_{2}=D_{1}</script><p>最常用的池化层运算是对前一层输出数据体的每一个激活图执行$\max$运算，类似于卷积操作：对每个$2\times 2$大小的数据进行$\max$运算，然后左右移动$S$个距离后再次进行</p>
<p>常用的超参数组合有$F=2, S=2$，以及$F=3, S=2$（这也称为重叠池化层（<code>overlapping pooling</code>））</p>
<h2 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h2><p>卷积神经网络的全连接层和神经网络一致，参考：<a href="https://www.zhujian.tech/posts/7ca31f7.html#more">神经网络概述</a></p>
<h2 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h2><p>常用的网络架构如下：</p>
<script type="math/tex; mode=display">
INPUT \rightarrow  [[CONV \rightarrow  RELU]*N \rightarrow  POOL?]*M \rightarrow  [FC \rightarrow  RELU]*K \rightarrow  FC</script><ul>
<li>$INPUT$表示输入层</li>
<li>$CONV$表示卷积层</li>
<li>$RELU$表示激活函数操作</li>
<li>$POOL$表示池化层</li>
<li>$FC$表示全连接层</li>
<li>$*$号表示重复操作</li>
<li>$?$号表示可选操作</li>
<li>$N, M, K$表示数字</li>
</ul>
<p>通常$N\in [0, 3], M\geq 0, K\in [0,3]$</p>
<p>以<code>LeNet-5</code>为例</p>
<p><img src="/imgs/卷积神经网络概述/LeNet-5.png" alt></p>
<p>其网络架构为</p>
<script type="math/tex; mode=display">
INPUT  \rightarrow [CONV \rightarrow  RELU] \rightarrow  POOL \rightarrow [CONV \rightarrow  RELU] \rightarrow  POOL\\
\rightarrow [CONV \rightarrow  RELU] \rightarrow  [FC \rightarrow  RELU] \rightarrow  FC</script><p>所以$N=3, M=2, K=1$</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>深度学习</category>
        <category>卷积神经网络</category>
      </categories>
  </entry>
  <entry>
    <title>神经网络实现-pytorch</title>
    <url>/posts/5a77dbca.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://www.zhujian.tech/posts/ba2ca878.html#more">神经网络实现-numpy</a></p><p><a href="https://www.zhujian.tech/posts/dd673751.html#more">使用softmax回归进行mnist分类</a></p><p><a href="https://www.jiqizhixin.com/articles/2019-04-09-9" target="_blank" rel="noopener">PyTorch 进阶之路（四）：在 GPU 上训练深度神经网络</a></p><a id="more"></a>



<p>使用<code>pytorch</code>实现<code>3</code>层神经网络模型<code>ThreeNet</code></p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p><code>ThreeNet</code>是一个<code>3</code>层神经网络，输入层大小为<code>784</code>，隐藏层大小分别为<code>200</code>和<code>60</code>，输出层大小为<code>10</code>，激活函数使用<code>relu</code>，评分函数使用<code>softmax</code></p>
<p>网络参数如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 批量大小</span><br><span class="line">batch_size = 256</span><br><span class="line"># 输入维数</span><br><span class="line">D = 784</span><br><span class="line"># 隐藏层大小</span><br><span class="line">H1 = 200</span><br><span class="line">H2 = 60</span><br><span class="line"># 输出类别</span><br><span class="line">K = 10</span><br><span class="line"></span><br><span class="line"># 学习率</span><br><span class="line">learning_rate = 1e-2</span><br><span class="line"></span><br><span class="line"># 迭代次数</span><br><span class="line">epoches = 500</span><br></pre></td></tr></table></figure>
<p>网络定义如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class NNModule(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(NNModule, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(D, H1)</span><br><span class="line">        self.fc2 = nn.Linear(H1, H2)</span><br><span class="line">        self.fc3 = nn.Linear(H2, K)</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        x = F.relu(self.fc1(input))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = F.log_softmax(self.fc3(x))</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def __copy__(self, device):</span><br><span class="line">        module = NNModule().to(device=device)</span><br><span class="line">        module.fc1.weight = copy.deepcopy(self.fc1.weight)</span><br><span class="line">        module.fc1.bias = copy.deepcopy(self.fc1.bias)</span><br><span class="line"></span><br><span class="line">        module.fc2.weight = copy.deepcopy(self.fc2.weight)</span><br><span class="line">        module.fc2.bias = copy.deepcopy(self.fc2.bias)</span><br><span class="line"></span><br><span class="line">        module.fc3.weight = copy.deepcopy(self.fc3.weight)</span><br><span class="line">        module.fc3.bias = copy.deepcopy(self.fc3.bias)</span><br><span class="line"></span><br><span class="line">        return module</span><br></pre></td></tr></table></figure>
<h2 id="mnist数据"><a href="#mnist数据" class="headerlink" title="mnist数据"></a>mnist数据</h2><p><code>pytorch</code>的<code>torchvision</code>模块内置了<code>MNIST</code>类，用于下载<code>mnist</code>数据集`</p>
<p>利用<code>torchvision.transforms</code>将数据转换为<code>Tensor</code>结构并进行初始化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.Grayscale(),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=(0.5,), std=(0.5,))</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<ul>
<li><p><code>Grayscale()</code>将<code>PIL</code>图像转换为灰度图像</p>
</li>
<li><p><code>ToTensor()</code>将<code>PIL</code>图像或<code>numpy.ndarray</code>数据转换为<code>tensor</code>，将原先$(H\times W\times C)$通道转换成$(C\times H\times W)$，同时将取值范围<code>[0,255]</code>压缩到<code>[0.0, 1.0]</code></p>
</li>
<li><p><code>Normalize()</code>对数据进行归一化，均值为<code>0.5</code>，标准差为<code>0.5</code></p>
</li>
</ul>
<script type="math/tex; mode=display">
y = \frac {x-mean}{std}</script><p>利用<code>torch.utils.data.DataLoader</code>保存数据，方便打乱和批量加载</p>
<p>代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def load_data(batch_size=128, shuffle=False):</span><br><span class="line">    data_dir = &apos;../data/&apos;</span><br><span class="line"></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Grayscale(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=(0.5,), std=(0.5,))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    train_data_set = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)</span><br><span class="line">    test_data_set = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)</span><br><span class="line"></span><br><span class="line">    train_loader = DataLoader(train_data_set, batch_size=batch_size, shuffle=shuffle)</span><br><span class="line">    test_loader = DataLoader(test_data_set, batch_size=batch_size, shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    return train_loader, test_loader</span><br></pre></td></tr></table></figure>
<h2 id="pytorch实现"><a href="#pytorch实现" class="headerlink" title="pytorch实现"></a>pytorch实现</h2><p>完整代码如下，实现<code>pytorch gpu</code>训练</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-5-18 下午3:03</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from torchvision import datasets</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import time</span><br><span class="line">import copy</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line"># 批量大小</span><br><span class="line">batch_size = 256</span><br><span class="line"># 输入维数</span><br><span class="line">D = 784</span><br><span class="line"># 隐藏层大小</span><br><span class="line">H1 = 200</span><br><span class="line">H2 = 60</span><br><span class="line"># 输出类别</span><br><span class="line">K = 10</span><br><span class="line"></span><br><span class="line"># 学习率</span><br><span class="line">learning_rate = 1e-2</span><br><span class="line"></span><br><span class="line"># 迭代次数</span><br><span class="line">epoches = 500</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(batch_size=128, shuffle=False):</span><br><span class="line">    data_dir = &apos;../data/&apos;</span><br><span class="line"></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Grayscale(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=(0.5,), std=(0.5,))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    train_data_set = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)</span><br><span class="line">    test_data_set = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)</span><br><span class="line"></span><br><span class="line">    train_loader = DataLoader(train_data_set, batch_size=batch_size, shuffle=shuffle)</span><br><span class="line">    test_loader = DataLoader(test_data_set, batch_size=batch_size, shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    return train_loader, test_loader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(module, dataLoader, device=torch.device(&apos;cpu&apos;)):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param module: 计算模型</span><br><span class="line">    :param dataLoader: 数据加载器</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    accuracy = 0</span><br><span class="line">    for i, items in enumerate(dataLoader, 0):</span><br><span class="line">        data, labels = items</span><br><span class="line">        data = data.reshape((data.size()[0], -1))</span><br><span class="line">        data, labels = data.to(device=device), labels.to(device=device)</span><br><span class="line"></span><br><span class="line">        scores = module.forward(data)</span><br><span class="line">        predictions = torch.argmax(scores, dim=1)</span><br><span class="line">        res = (predictions == labels.squeeze())</span><br><span class="line">        accuracy += 1.0 * torch.sum(res).item() / scores.size()[0]</span><br><span class="line">    return accuracy / dataLoader.__len__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(loss_list, title=&apos;损失图&apos;, ylabel=&apos;损失值&apos;, xlabel=&apos;迭代/20次&apos;):</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.ylabel(ylabel)</span><br><span class="line">    plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(loss_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class NNModule(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(NNModule, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(D, H1)</span><br><span class="line">        self.fc2 = nn.Linear(H1, H2)</span><br><span class="line">        self.fc3 = nn.Linear(H2, K)</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        x = F.relu(self.fc1(input))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = F.log_softmax(self.fc3(x))</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def __copy__(self, device):</span><br><span class="line">        module = NNModule().to(device=device)</span><br><span class="line">        module.fc1.weight = copy.deepcopy(self.fc1.weight)</span><br><span class="line">        module.fc1.bias = copy.deepcopy(self.fc1.bias)</span><br><span class="line"></span><br><span class="line">        module.fc2.weight = copy.deepcopy(self.fc2.weight)</span><br><span class="line">        module.fc2.bias = copy.deepcopy(self.fc2.bias)</span><br><span class="line"></span><br><span class="line">        module.fc3.weight = copy.deepcopy(self.fc3.weight)</span><br><span class="line">        module.fc3.bias = copy.deepcopy(self.fc3.bias)</span><br><span class="line"></span><br><span class="line">        return module</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient_descent(batch_size=8, epoches=2000):</span><br><span class="line">    train_loader, test_loader = load_data(batch_size=batch_size, shuffle=True)</span><br><span class="line"></span><br><span class="line">    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line"></span><br><span class="line">    # softmax模型</span><br><span class="line">    module = NNModule().to(device=device)</span><br><span class="line">    # 损失函数</span><br><span class="line">    criterion = nn.NLLLoss().to(device=device)</span><br><span class="line">    # 优化器</span><br><span class="line">    optimizer = optim.SGD(module.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestA = 0</span><br><span class="line">    bestModule = None</span><br><span class="line"></span><br><span class="line">    batch_len = train_loader.__len__()</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        start = time.time()</span><br><span class="line">        for j, items in enumerate(train_loader, 0):</span><br><span class="line">            data, labels = items</span><br><span class="line">            data = data.reshape((data.size()[0], -1))</span><br><span class="line">            data, labels = data.to(device=device), labels.to(device=device)</span><br><span class="line"></span><br><span class="line">            scores = module.forward(data)</span><br><span class="line">            loss = criterion(scores, labels.squeeze())</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            # 反向传播</span><br><span class="line">            loss.backward()</span><br><span class="line">            # 梯度更新</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            if j == (batch_len - 1):</span><br><span class="line">                loss_list.append(loss.item())</span><br><span class="line">        end = time.time()</span><br><span class="line">        print(&apos;epoch： %d time: %.2f s&apos; % (i + 1, end - start))</span><br><span class="line">        if i % 20 == 19:  # 每个20次进行一次检测</span><br><span class="line">            start = time.time()</span><br><span class="line">            accuracy = compute_accuracy(module, train_loader, device)</span><br><span class="line">            accuracy_list.append(accuracy)</span><br><span class="line">            if accuracy &gt;= bestA:</span><br><span class="line">                bestA = accuracy</span><br><span class="line">                bestModule = module.__copy__(device)</span><br><span class="line">            end = time.time()</span><br><span class="line">            print(&apos;epoch: %d time: %.2f s accuracy: %.3f %%&apos; % (i + 1, end - start, accuracy * 100))</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;mnist&apos;, xlabel=&apos;迭代/次&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度&apos;, ylabel=&apos;检测精度&apos;, xlabel=&apos;迭代/20次&apos;)</span><br><span class="line"></span><br><span class="line">    test_accuracy = compute_accuracy(bestModule, test_loader, device)</span><br><span class="line"></span><br><span class="line">    print(&apos;best train accuracy is %.3f %%&apos; % (bestA * 100))</span><br><span class="line">    print(&apos;test accuracy is %.3f %%&apos; % (test_accuracy * 100))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    start = time.time()</span><br><span class="line">    compute_gradient_descent(batch_size=batch_size, epoches=epoches)</span><br><span class="line">    end = time.time()</span><br><span class="line">    print(&apos;all train and test need time: %.2f minutes&apos; % ((end - start) / 60.0))</span><br></pre></td></tr></table></figure>
<p>训练<code>500</code>次精度如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">best train accuracy is 99.997 %</span><br><span class="line">test accuracy is 97.959 %</span><br><span class="line">all train and test need time: 71.90 minutes</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/神经网络实现-pytorch/mnist_loss.png" alt></p>
<p><img src="/imgs/神经网络实现-pytorch/mnist_accuracy.png" alt></p>
<h2 id="softmax-log-softmax和NLLLoss-CrossEntropyLoss"><a href="#softmax-log-softmax和NLLLoss-CrossEntropyLoss" class="headerlink" title="softmax/log_softmax和NLLLoss/CrossEntropyLoss"></a>softmax/log_softmax和NLLLoss/CrossEntropyLoss</h2><p><code>pytorch</code>提供了多种<code>softmax</code>评分以及损失函数</p>
<h3 id="评分函数"><a href="#评分函数" class="headerlink" title="评分函数"></a>评分函数</h3><ol>
<li><p><a href="https://pytorch.org/docs/stable/nn.html?highlight=softmax#torch.nn.Softmax" target="_blank" rel="noopener">torch.nn.Softmax</a>：标准的<code>softmax</code>评分函数，在官网中提示了<code>LogSoftmax</code>有更快和更好的数值属性</p>
<script type="math/tex; mode=display">
 \text{Softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}</script><pre><code> This module doesn’t work directly with NLLLoss, which expects the Log to be computed between the Softmax and itself. 
 Use LogSoftmax instead (it’s faster and has better numerical properties).
</code></pre></li>
<li><p><a href="https://pytorch.org/docs/stable/nn.html#logsoftmax" target="_blank" rel="noopener">torch.nn.LogSoftmax</a>：在$Softmax(x)$的基础上添加了对数运算</p>
<script type="math/tex; mode=display">
 \text{LogSoftmax}(x_{i}) = \log\left(\frac{\exp(x_i) }{ \sum_j \exp(x_j)} \right)</script></li>
</ol>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><ol>
<li><p><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss" target="_blank" rel="noopener">torch.nn.CrossEntropyLoss</a>：结合了$nn.LogSoftmax()$和$nn.NLLLoss()$操作</p>
</li>
<li><p><a href="https://pytorch.org/docs/stable/nn.html#nllloss" target="_blank" rel="noopener">torch.nn.NLLLoss</a>：负对数似然损失（<code>negative log likelihood loss</code>）</p>
</li>
</ol>
<h3 id="组合使用"><a href="#组合使用" class="headerlink" title="组合使用"></a>组合使用</h3><p>所以得到隐藏层输出向量后，使用$nn.CrossEntropyLoss$或者$nn.LogSoftmax+nn.NLLLoss$就能够实现损失值的计算，如果想要输出评分值，那么使用$nn.Softmax$</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络实现-numpy</title>
    <url>/posts/ba2ca878.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://www.zhujian.tech/posts/7ca31f7.html#more">神经网络概述</a></p><p><a href="https://www.zhujian.tech/posts/66015d4d.html#more">神经网络推导-批量数据</a></p><p><a href="https://www.zhujian.tech/posts/1dd3ebad.html#more">神经网络推导-矩阵计算</a></p><p>使用<code>numpy</code>实现神经网络模型</p><ul>
<li>使用单层神经网络<code>OneNet</code>实现逻辑或、逻辑与和逻辑非分类</li>
<li>使用<code>2</code>层神经网络<code>TwoNet</code>实现逻辑异或分类</li>
<li>使用<code>3</code>层神经网络<code>ThreeNet</code>实现<code>iris</code>数据集和<code>mnist</code>数据集分类</li>
</ul><a id="more"></a>





<h2 id="使用单层神经网络OneNet实现逻辑或、逻辑与和逻辑非分类"><a href="#使用单层神经网络OneNet实现逻辑或、逻辑与和逻辑非分类" class="headerlink" title="使用单层神经网络OneNet实现逻辑或、逻辑与和逻辑非分类"></a>使用单层神经网络<code>OneNet</code>实现逻辑或、逻辑与和逻辑非分类</h2><p>使用单层神经网络<code>OneNet</code></p>
<ul>
<li>输入层有<code>2</code>个神经元</li>
<li>输出层有<code>1</code>个神经元</li>
<li>评分函数是<code>sigmoid</code></li>
<li>损失函数是交叉熵损失</li>
</ul>
<p><em><code>OneNet</code>就是逻辑回归模型</em></p>
<p><img src="/imgs/神经网络实现-numpy/1-layer-network.png" alt></p>
<ul>
<li>$L=1$</li>
<li>$a^{(0)}\in R^{m\times 2}$</li>
<li>$W^{(1)}\in R^{2\times 1}$</li>
<li>$b^{(1)}\in R^{1\times 2}$</li>
<li>$y\in R^{m\times 1}$，每行数值表示正确类别（0或者1）</li>
</ul>
<p><strong>前向传播过程</strong></p>
<script type="math/tex; mode=display">
z^{(1)}=a^{(0)}\cdot W^{(1)} +b^{(1)} \\
h(z^{(1)})=p(y=1)=sigmoid(z^{(1)})=\frac {1}{1+e^{-z^{(1)}}} \\</script><p>所以分类概率是</p>
<script type="math/tex; mode=display">
probs=[p(y=0), p(y=1)]=[1-h(z^{(1)}), h(z^{(1)})]\\
=[\frac {e^{-z^{(1)}}}{1+e^{-z^{(1)}}}， \frac {1}{1+e^{-z^{(1)}}}] \in R^{m\times 2}</script><p>损失值是</p>
<script type="math/tex; mode=display">
J(z^{(1)})=-\frac {1}{m} 1^{T}\cdot (y* \ln h(z^{(1)})+(1-y)* \ln (1-h(z^{(1)})))</script><p>因为OneNet很特殊（类别不是0就是1），所以损失值可以用下式计算</p>
<script type="math/tex; mode=display">
J(z^{(1)})=-\frac {1}{m} (y\cdot \ln h(z^{(1)})+(1-y)\cdot \ln (1-h(z^{(1)})))</script><p><strong>反向传播过程</strong></p>
<p>计算最终残差$\delta^{(L)}$</p>
<script type="math/tex; mode=display">
dJ=d(-\frac {1}{m} 1^{T}\cdot (y* \ln h(z^{(1)})+(1-y)* \ln (1-h(z^{(1)}))))\\
=d(-\frac {1}{m} 1^{T}\cdot (y* \ln h(z^{(1)})))+d(-\frac {1}{m} 1^{T}\cdot (1-y)* \ln (1-h(z^{(1)})))</script><p>因为</p>
<script type="math/tex; mode=display">
d(-\frac {1}{m} 1^{T}\cdot (y* \ln h(z^{(1)})))=
d(-\frac {1}{m} 1^{T}\cdot (y* (h(z^{(1)})^{-1}\cdot dh(z^{(1)})))\\
=d(-\frac {1}{m} 1^{T}\cdot (y* (h(z^{(1)})^{-1}\cdot h(z^{(1)})\cdot (1-h(z^{(1)})* dz^{(1)}))))\\
=d(-\frac {1}{m} 1^{T}\cdot (y* ((1-h(z^{(1)})* dz^{(1)}))))\\
=d(-\frac {1}{m} y^{T}\cdot ((1-h(z^{(1)})* dz^{(1)})))\\
=d(-\frac {1}{m} y^{T} * (1-h(z^{(1)})^{T}\cdot dz^{(1)}))</script><script type="math/tex; mode=display">
d(-\frac {1}{m} 1^{T}\cdot (1-y)* \ln (1-h(z^{(1)})))=d(-\frac {1}{m} 1^{T}\cdot (1-y)* ((1-h(z^{(1)}))^{-1}\cdot d(1-h(z^{(1)}))))\\
=d(-\frac {1}{m} 1^{T}\cdot (1-y)* ((1-h(z^{(1)}))^{-1}\cdot (-1)\cdot (1-h(z^{(1)}))\cdot h(z^{(1)})* dz^{(1)}))\\
=d(-\frac {1}{m} 1^{T}\cdot (1-y)* ((-1)\cdot h(z^{(1)})* dz^{(1)}))\\
=d(\frac {1}{m} 1^{T}\cdot (1-y)* (h(z^{(1)})* dz^{(1)}))\\
=d(\frac {1}{m} (1-y)^{T}\cdot (h(z^{(1)})* dz^{(1)}))\\
=d(\frac {1}{m} (1-y)^{T}* h(z^{(1)})^{T}\cdot dz^{(1)})</script><p>所以</p>
<script type="math/tex; mode=display">
dJ=d(-\frac {1}{m} y^{T} * (1-h(z^{(1)})^{T}\cdot dz^{(1)}))+
d(\frac {1}{m} (1-y)^{T}* h(z^{(1)})^{T}\cdot dz^{(1)})\\
=d(\frac {1}{m} ((1-y)^{T}* h(z^{(1)})^{T} - y^{T} * (1-h(z^{(1)})^{T})\cdot dz^{(1)}))\\
=d(\frac {1}{m} (h(z^{(1)})^{T}-y^{T}* h(z^{(1)})^{T} - y^{T} + y^{T}* h(z^{(1)})^{T})\cdot dz^{(1)}))\\
=d(\frac {1}{m} (h(z^{(1)})^{T}- y^{T})\cdot dz^{(1)}))</script><script type="math/tex; mode=display">
D_{z^{(1)}}f(z^{(1)})=\frac {1}{m}\cdot (h(z^{(1)})^{T}- y^{T})\\
\bigtriangledown_{z^{(1)}}f(z^{(1)})=\frac {1}{m}\cdot (h(z^{(1)})- y)</script><p>因为<code>OneNet</code>是单层神经网络，所以仅有一个权重矩阵和偏置值</p>
<script type="math/tex; mode=display">
z^{(1)}=a^{(0)}\cdot W^{(1)} +b^{(1)}\\
dz^{(1)}=a^{(0)}\cdot dW^{(1)} + db^{(1)}\\
dJ=d(\frac {1}{m} (h(z^{(1)})^{T}- y^{T})\cdot dz^{(1)}))\\
=d(\frac {1}{m} (h(z^{(1)})^{T}- y^{T})\cdot (a^{(0)}\cdot dW^{(1)} + db^{(1)})))\\
=d(\frac {1}{m} (h(z^{(1)})^{T}- y^{T})\cdot a^{(0)}\cdot dW^{(1)})+d(\frac {1}{m} (h(z^{(1)})^{T}- y^{T})\cdot db^{(1)})\\</script><script type="math/tex; mode=display">
D_{W^{(1)}}f(W^{(1)})=\frac {1}{m}\cdot (h(z^{(1)})^{T}- y^{T})\cdot a^{(0)}\\
\bigtriangledown_{W^{(1)}}f(W^{(1)})=\frac {1}{m}\cdot (a^{(0)})^{T}\cdot (h(z^{(1)})- y)</script><script type="math/tex; mode=display">
D_{b^{(1)}}f(b^{(1)})=\frac {1}{m}\cdot \sum_{i=1}^{m} (h(z_{i}^{(1)})^{T}- y^{T}_{i})\\
\bigtriangledown_{b^{(1)}}f(b^{(1)})=\frac {1}{m}\cdot \sum_{i=1}^{m} (h(z_{i}^{(1)})- y_{i})</script><p><strong>偏置向量需要考虑维数</strong></p>
<p>进行权重更新时添加正则化项</p>
<script type="math/tex; mode=display">
W^{(1)} = W^{(1)} - \alpha\cdot (\nabla_{W^{(1)}} J(W, b)+\lambda \sum W^{(1)})</script><h3 id="numpy实现"><a href="#numpy实现" class="headerlink" title="numpy实现"></a>numpy实现</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-5-17 下午2:54</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 批量大小</span><br><span class="line">N = 4</span><br><span class="line"># 输入维数</span><br><span class="line">D = 2</span><br><span class="line"># 输出类别</span><br><span class="line">K = 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def init_weights(inputs, outputs):</span><br><span class="line">    return 0.01 * np.random.normal(loc=0.0, scale=1.0, size=(inputs, outputs))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class OneNet(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self, w, b):</span><br><span class="line">        self.w = w</span><br><span class="line">        self.b = b</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        前向计算，计算评分函数值</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.m = inputs.shape[0]</span><br><span class="line">        self.a0 = inputs</span><br><span class="line"></span><br><span class="line">        self.z1 = inputs.dot(self.w) + self.b</span><br><span class="line">        self.h = self.sigmoid(self.z1)</span><br><span class="line">        return self.h</span><br><span class="line"></span><br><span class="line">    def backward(self, output):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        反向传播，计算梯度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        delta = (self.h - output) / self.m</span><br><span class="line">        self.dw = self.a0.T.dot(delta)</span><br><span class="line">        self.db = np.sum(delta, axis=0)</span><br><span class="line"></span><br><span class="line">    def update(self, alpha=1e-3, la=1e-3):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        更新梯度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.w = self.w - alpha * (self.dw + la * np.sum(self.w))</span><br><span class="line">        self.b = self.b - alpha * self.db</span><br><span class="line"></span><br><span class="line">    def sigmoid(self, inputs):</span><br><span class="line">        return 1.0 / (1 + np.exp(-1 * inputs))</span><br><span class="line"></span><br><span class="line">    def get_parameters(self):</span><br><span class="line">        return self.w, self.b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_loss(score, y, beta=0.0001):</span><br><span class="line">    loss = -1.0 / score.shape[0] * (y.T.dot(np.log(score + beta)) + (1 - y).T.dot(np.log(1 - score + beta)))</span><br><span class="line">    return loss[0][0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(loss_list, title=&apos;损失图&apos;):</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.ylabel(&apos;损失值&apos;)</span><br><span class="line">    plt.xlabel(&apos;迭代/500次&apos;)</span><br><span class="line">    plt.plot(loss_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    w = init_weights(D, K)</span><br><span class="line">    b = init_weights(K, D)</span><br><span class="line">    net = OneNet(w, b)</span><br><span class="line"></span><br><span class="line">    input_array = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])</span><br><span class="line">    or_array = np.array([[0, 0, 0, 1]]).T</span><br><span class="line">    loss_list = []</span><br><span class="line">    total_loss = 0</span><br><span class="line">    for i in range(200000):</span><br><span class="line">        score = net.forward(input_array)</span><br><span class="line">        total_loss += compute_loss(score, or_array)</span><br><span class="line">        net.backward(or_array)</span><br><span class="line">        net.update()</span><br><span class="line">        if (i % 500) == 499:</span><br><span class="line">            print(&apos;epoch: %d loss: %.4f&apos; % (i + 1, total_loss / 500))</span><br><span class="line">            loss_list.append(total_loss / 500)</span><br><span class="line">            total_loss = 0</span><br><span class="line">    w, b = net.get_parameters()</span><br><span class="line">    print(&apos;weight: &#123;&#125;&apos;.format(w))</span><br><span class="line">    print(&apos;bias: &#123;&#125;&apos;.format(b))</span><br><span class="line"></span><br><span class="line">    print(&apos;输入  输出  预测成绩&apos;)</span><br><span class="line">    score = net.forward(input_array)</span><br><span class="line">    for item in zip(input_array, or_array, score):</span><br><span class="line">        print(item[0], item[1][0], item[2][0])</span><br><span class="line">    draw(loss_list, &apos;逻辑与&apos;)</span><br></pre></td></tr></table></figure>
<h3 id="逻辑与"><a href="#逻辑与" class="headerlink" title="逻辑与"></a>逻辑与</h3><p>输入值与输出值</p>
<ul>
<li>(0,0) - 0</li>
<li>(0,1) - 0</li>
<li>(1,0) - 0</li>
<li>(1,1) - 1</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">input_array = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])</span><br><span class="line">or_array = np.array([[0, 0, 0, 1]]).T</span><br></pre></td></tr></table></figure>
<p>参数如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 批量大小</span><br><span class="line">N = 4</span><br><span class="line"># 输入维数</span><br><span class="line">D = 2</span><br><span class="line"># 输出类别</span><br><span class="line">K = 1</span><br><span class="line"># 学习率</span><br><span class="line">alpha=1e-3</span><br><span class="line"># 正则化强度</span><br><span class="line">la=1e-3</span><br></pre></td></tr></table></figure>
<p>进行<code>2</code>万轮迭代后</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">weight: [[3.58627447 3.58664415]</span><br><span class="line"> [3.58627445 3.58664413]]</span><br><span class="line">bias: [[-5.69865399 -5.69921649]]</span><br><span class="line">输入  输出  预测成绩</span><br><span class="line">[0 0] 0 0.003339284003451103</span><br><span class="line">[0 1] 0 0.1078994052700841</span><br><span class="line">[1 0] 0 0.1078994065762308</span><br><span class="line">[1 1] 1 0.8136486739472225</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/神经网络实现-numpy/logical_and.png" alt></p>
<h3 id="逻辑或"><a href="#逻辑或" class="headerlink" title="逻辑或"></a>逻辑或</h3><p>输入值与输出值</p>
<ul>
<li>(0,0) - 0</li>
<li>(0,1) - 1</li>
<li>(1,0) - 1</li>
<li>(1,1) - 1</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">input_array = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])</span><br><span class="line">or_array = np.array([[0, 1, 1, 1]]).T</span><br></pre></td></tr></table></figure>
<p>参数如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 批量大小</span><br><span class="line">N = 4</span><br><span class="line"># 输入维数</span><br><span class="line">D = 2</span><br><span class="line"># 输出类别</span><br><span class="line">K = 1</span><br><span class="line"># 学习率</span><br><span class="line">alpha=1e-3</span><br><span class="line"># 正则化强度</span><br><span class="line">la=1e-3</span><br></pre></td></tr></table></figure>
<p>进行<code>2</code>万轮迭代后</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">weight: [[4.63629047]</span><br><span class="line"> [4.63636187]]</span><br><span class="line">bias: [[-1.87568775]]</span><br><span class="line">输入  输出  预测成绩</span><br><span class="line">[0 0] 0 0.1328849727549866</span><br><span class="line">[0 1] 1 0.9405133604748699</span><br><span class="line">[1 0] 1 0.9405093656227651</span><br><span class="line">[1 1] 1 0.9993872646847757</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/神经网络实现-numpy/logical_or.png" alt></p>
<h3 id="逻辑非"><a href="#逻辑非" class="headerlink" title="逻辑非"></a>逻辑非</h3><p>输入值与输出值</p>
<ul>
<li>(1) - 0</li>
<li>(0) - 1</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">input_array = np.array([[1], [0]])</span><br><span class="line">or_array = np.array([[0, 1]]).T</span><br></pre></td></tr></table></figure>
<p>参数如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 批量大小</span><br><span class="line">N = 2</span><br><span class="line"># 输入维数</span><br><span class="line">D = 1</span><br><span class="line"># 输出类别</span><br><span class="line">K = 1</span><br><span class="line"># 学习率</span><br><span class="line">alpha=1e-3</span><br><span class="line"># 正则化强度</span><br><span class="line">la=1e-3</span><br></pre></td></tr></table></figure>
<p>进行<code>2</code>万轮迭代后</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">weight: [[-6.79010254]]</span><br><span class="line">bias: [[3.26280938]]</span><br><span class="line">输入  输出  预测成绩</span><br><span class="line">[1] 0 0.02854555463398659</span><br><span class="line">[0] 1 0.9631306816639573</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/神经网络实现-numpy/logical_non.png" alt></p>
<h2 id="使用2层神经网络TwoNet实现逻辑异或分类"><a href="#使用2层神经网络TwoNet实现逻辑异或分类" class="headerlink" title="使用2层神经网络TwoNet实现逻辑异或分类"></a>使用2层神经网络TwoNet实现逻辑异或分类</h2><p>使用<code>2</code>层神经网络<code>TwoNet</code></p>
<ul>
<li>网络层数$L=2$</li>
<li>批量数据$N$</li>
<li>输入层神经元个数$D$</li>
<li>隐藏层神经元个数$H$</li>
<li>输出层神经元个数$K$</li>
<li>激活函数是<code>relu</code></li>
<li>评分函数是<code>softmax</code>评分</li>
<li>损失函数是交叉熵损失平凡</li>
</ul>
<p><img src="/imgs/神经网络实现-numpy/two_layer_network.png" alt></p>
<ul>
<li>$a^{(0)}\in R^{N\times D}$</li>
<li>$W^{(1)}\in R^{D\times H}$</li>
<li>$b^{(1)}\in R^{1\times H}$</li>
<li>$W^{(2)}\in R^{H\times K}$</li>
<li>$b^{(2)}\in R^{1\times K}$</li>
<li>$Y\in R^{N\times K}$，每行仅有正确类别为1，其余为0</li>
</ul>
<p><strong>前向传播过程</strong></p>
<script type="math/tex; mode=display">
z^{(1)}=a^{(0)}\cdot W^{(1)}+b^{(1)} \\
a^{(1)}=relu(z^{(1)}) \\
z^{(2)}=a^{(1)}\cdot W^{(2)}+b^{(2)}</script><p>所以分类概率是</p>
<script type="math/tex; mode=display">
probs=h(z^{(2)})=\frac {exp(z^{(2)})}{exp(z^{(2)})\cdot A\cdot B^{T}}</script><p>其中$A\in R^{K\times 1}，B\in R^{K\times 1}$都是全$1$向量，</p>
<p>损失值是</p>
<script type="math/tex; mode=display">
dataLoss = -\frac {1}{N} 1^{T}\cdot \ln \frac {exp(z^{(2)}* Y\cdot A)}{exp(z^{2})\cdot A}</script><script type="math/tex; mode=display">
regLoss = 0.5\cdot reg\cdot ||W^{(1)}||^{2} + 0.5\cdot reg\cdot ||W^{(2)}||^{2}</script><script type="math/tex; mode=display">
J(z^{(2)})=dataLoss + regLoss</script><p><strong>反向传播过程</strong></p>
<p><strong>输出层输入向量梯度</strong></p>
<script type="math/tex; mode=display">
d(dataloss) = d(-\frac {1}{N} 1^{T}\cdot \ln \frac {exp(z^{(2)}* Y\cdot A)}{exp(z^{2})\cdot A})\\
=tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot dz^{(2)})</script><p>所以</p>
<script type="math/tex; mode=display">
D_{z^{(2)}}f(z^{(2)})=\frac {1}{N} (probs^{T} - Y^{T})\\
\bigtriangledown_{z^{(2)}}f(z^{(2)})=\frac {1}{N} (probs - Y)</script><p><strong>对于输出层权重矩阵、偏置向量以及隐藏层输出向量</strong></p>
<script type="math/tex; mode=display">
z^{(2)}=a^{(1)}\cdot W^{(2)}+b^{(2)}\\
dz^{(2)}=da^{(1)}\cdot W^{(2)} + a^{(1)}\cdot dW^{(2)} + db^{(2)}</script><script type="math/tex; mode=display">
d(dataloss)
=tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot dz^{(2)})\\
=tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot (da^{(1)}\cdot W^{(2)} + a^{(1)}\cdot dW^{(2)} + db^{(2)}))\\
tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot da^{(1)}\cdot W^{(2)}) + tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot a^{(1)}\cdot dW^{(2)}) + tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot db^{(2)}))</script><p>输出层权重矩阵</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot a^{(1)}\cdot dW^{(2)})</script><script type="math/tex; mode=display">
D_{W^{(2)}}f(W^{(2)})=\frac {1}{N} (probs^{T} - Y^{T})\cdot a^{(1)}\\
\bigtriangledown_{W^{(2)}}f(W^{(2)})=\frac {1}{N} (a^{(1)})^{T}\cdot (probs - Y)</script><p>输出层偏置向量</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot db^{(2)}))</script><script type="math/tex; mode=display">
D_{b^{(2)}}f(b^{(2)})=\frac {1}{N} \sum_{i=1}^{N}(probs_{i}^{T} - Y_{i}^{T})\\
\bigtriangledown_{b^{(2)}}f(b^{(2)})=\frac {1}{N} \sum_{i=1}^{N}(probs_{i} - Y_{i})</script><p>隐藏层输出向量</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot da^{(1)}\cdot W^{(2)})
=tr(\frac {1}{N} W^{(2)}\cdot (probs^{T} - Y^{T})\cdot da^{(1)})</script><script type="math/tex; mode=display">
D_{a^{(1)}}f(a^{(1)})=\frac {1}{N} W^{(2)}\cdot (probs^{T} - Y^{T})\\
\bigtriangledown_{a^{(1)}}f(a^{(1)})=\frac {1}{N} (probs - Y)\cdot (W^{(2)})^{T}</script><p><strong>对于隐藏层输入向量</strong></p>
<script type="math/tex; mode=display">
a^{(1)}=relu(z^{(1)})\\
da^{(1)}=1(z^{(1)}\geq 0)* dz^{(1)}</script><script type="math/tex; mode=display">
d(dataloss)
=tr(\frac {1}{N} W^{(2)}\cdot (probs^{T} - Y^{T})\cdot da^{(1)})\\
=tr(\frac {1}{N} (W^{(2)}\cdot (probs^{T} - Y^{T}))\cdot 1(z^{(1)}\geq 0)* dz^{(1)})\\
=tr(\frac {1}{N} (W^{(2)}\cdot (probs^{T} - Y^{T}))* 1(z^{(1)}\geq 0)^{T}\cdot dz^{(1)})</script><script type="math/tex; mode=display">
D_{z^{(1)}}f(z^{(1)})=\frac {1}{N} (W^{(2)}\cdot (probs^{T} - Y^{T}))* 1(z^{(1)}\geq 0)^{T}\\
\bigtriangledown_{z^{(1)}}f(z^{(1)})=\frac {1}{N} ((probs - Y)\cdot (W^{(2)})^{T})* 1(z^{(1)}\geq 0)</script><p><strong>对于隐藏层权重矩阵和偏置值</strong></p>
<script type="math/tex; mode=display">
z^{(1)}=a^{(0)}\cdot W^{(1)}+b^{(1)}\\
dz^{(1)}=da^{(0)}\cdot W^{(1)} + a^{(0)}\cdot dW^{(1)} + db^{(1)}</script><script type="math/tex; mode=display">
d(dataloss)
=tr(\frac {1}{N} (W^{(2)}\cdot (probs^{T} - Y^{T}))* 1(z^{(1)}\geq 0)^{T}\cdot dz^{(1)})\\
=tr(\frac {1}{N} (W^{(2)}\cdot (probs^{T} - Y^{T}))* 1(z^{(1)}\geq 0)^{T}\cdot (da^{(0)}\cdot W^{(1)} + a^{(0)}\cdot dW^{(1)} + db^{(1)}))\\
=tr(\frac {1}{N} (W^{(2)}\cdot (probs^{T} - Y^{T}))* 1(z^{(1)}\geq 0)^{T}\cdot (da^{(0)}\cdot W^{(1)})\\
+tr(\frac {1}{N} (W^{(2)}\cdot (probs^{T} - Y^{T}))* 1(z^{(1)}\geq 0)^{T}\cdot a^{(0)}\cdot dW^{(1)})
+tr(\frac {1}{N} (W^{(2)}\cdot (probs^{T} - Y^{T}))* 1(z^{(1)}\geq 0)^{T}\cdot db^{(1)})</script><p>输出层权重矩阵</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{N} (W^{(2)}\cdot (probs^{T} - Y^{T}))* 1(z^{(1)}\geq 0)^{T}\cdot a^{(0)}\cdot dW^{(1)})</script><script type="math/tex; mode=display">
D_{W^{(1)}}f(W^{(1)})=\frac {1}{N} (W^{(2)}\cdot (probs^{T} - Y^{T}))* 1(z^{(1)}\geq 0)^{T}\cdot a^{(0)}\\
\bigtriangledown_{W^{(1)}}f(W^{(1)})=\frac {1}{N} (a^{(0)})^{T}\cdot (W^{(2)}\cdot (probs^{T} - Y^{T}))* 1(z^{(1)}\geq 0)</script><p>输出层偏置向量</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{N} (W^{(2)}\cdot (probs^{T} - Y^{T}))* 1(z^{(1)}\geq 0)^{T}\cdot db^{(1)})</script><script type="math/tex; mode=display">
D_{b^{(1)}}f(b^{(1)})=\frac {1}{N} \sum_{i=1}^{N}(W^{(2)}\cdot (probs^{T} - Y^{T}))* 1(z^{(1)}\geq 0)^{T}\\
\bigtriangledown_{b^{(1)}}f(b^{(1)})=\frac {1}{N} \sum_{i=1}^{N}((probs - Y)\cdot (W^{(2)})^{T})* 1(z^{(1)}\geq 0)</script><h3 id="numpy实现-1"><a href="#numpy实现-1" class="headerlink" title="numpy实现"></a>numpy实现</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-5-17 下午6:45</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 批量大小</span><br><span class="line">N = 4</span><br><span class="line"># 输入维数</span><br><span class="line">D = 2</span><br><span class="line"># 隐藏层大小</span><br><span class="line">H = 30</span><br><span class="line"># 输出类别</span><br><span class="line">K = 2</span><br><span class="line"></span><br><span class="line"># 学习率</span><br><span class="line">learning_rate = 1e-1</span><br><span class="line"># 正则化强度</span><br><span class="line">lambda_rate = 1e-3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def init_weights(inputs, outputs):</span><br><span class="line">    return 0.01 * np.random.normal(loc=0.0, scale=1.0, size=(inputs, outputs))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class TwoNet(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self, w, b, w2, b2):</span><br><span class="line">        self.w = w</span><br><span class="line">        self.b = b</span><br><span class="line">        self.w2 = w2</span><br><span class="line">        self.b2 = b2</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        前向计算，计算评分函数值</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.N = inputs.shape[0]</span><br><span class="line">        self.a0 = inputs</span><br><span class="line"></span><br><span class="line">        self.z1 = inputs.dot(self.w) + self.b</span><br><span class="line">        self.a1 = np.maximum(0, self.z1)</span><br><span class="line">        self.z2 = self.a1.dot(self.w2) + self.b2</span><br><span class="line">        expscores = np.exp(self.z2)</span><br><span class="line">        self.h = expscores / np.sum(expscores, axis=1, keepdims=True)</span><br><span class="line">        return self.h</span><br><span class="line"></span><br><span class="line">    def backward(self, output):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        反向传播，计算梯度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        delta = self.h</span><br><span class="line">        delta[range(self.N), output] -= 1</span><br><span class="line">        delta /= self.N</span><br><span class="line">        self.dw2 = self.a1.T.dot(delta)</span><br><span class="line">        self.db2 = np.sum(delta, axis=0, keepdims=True)</span><br><span class="line"></span><br><span class="line">        da1 = delta.dot(self.w2.T)</span><br><span class="line">        dz1 = da1</span><br><span class="line">        dz1[self.z1 &lt; 0] = 0</span><br><span class="line"></span><br><span class="line">        self.dw = self.a0.T.dot(dz1)</span><br><span class="line">        self.db = np.sum(dz1, axis=0, keepdims=True)</span><br><span class="line"></span><br><span class="line">    def update(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        更新梯度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.dw2 += lambda_rate * self.w2</span><br><span class="line">        self.dw += lambda_rate * self.w</span><br><span class="line"></span><br><span class="line">        self.w2 = self.w2 - learning_rate * self.dw2</span><br><span class="line">        self.b2 = self.b2 - learning_rate * self.b2</span><br><span class="line"></span><br><span class="line">        self.w = self.w - learning_rate * self.dw</span><br><span class="line">        self.b = self.b - learning_rate * self.db</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_loss(score, y):</span><br><span class="line">    num = score.shape[0]</span><br><span class="line">    data_loss = -1.0 / num * np.sum(np.log(score[range(num), y]))</span><br><span class="line">    # reg_loss = 0.5 * lambda_rate * (np.sum(w ** 2) + np.sum(w2 ** 2))</span><br><span class="line">    return data_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(y, score):</span><br><span class="line">    predict = np.argmax(score, axis=1)</span><br><span class="line">    return np.mean(predict == y), predict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(loss_list, title=&apos;损失图&apos;):</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.ylabel(&apos;损失值&apos;)</span><br><span class="line">    plt.xlabel(&apos;迭代/500次&apos;)</span><br><span class="line">    plt.plot(loss_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    w = init_weights(D, H)</span><br><span class="line">    b = init_weights(1, H)</span><br><span class="line">    w2 = init_weights(H, K)</span><br><span class="line">    b2 = init_weights(1, K)</span><br><span class="line">    net = TwoNet(w, b, w2, b2)</span><br><span class="line"></span><br><span class="line">    input_array = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])</span><br><span class="line">    xor_array = np.array([0, 1, 1, 0])</span><br><span class="line">    loss_list = []</span><br><span class="line">    total_loss = 0</span><br><span class="line">    for i in range(10000):</span><br><span class="line">        score = net.forward(input_array)</span><br><span class="line">        total_loss += compute_loss(score, xor_array)</span><br><span class="line">        net.backward(xor_array)</span><br><span class="line">        net.update()</span><br><span class="line">        if (i % 500) == 499:</span><br><span class="line">            print(&apos;epoch: %d loss: %.4f&apos; % (i + 1, total_loss / 500))</span><br><span class="line">            loss_list.append(total_loss / 500)</span><br><span class="line">            total_loss = 0</span><br><span class="line">    draw(loss_list, &apos;逻辑异或&apos;)</span><br><span class="line"></span><br><span class="line">    w, b = net.get_parameters()</span><br><span class="line">    print(&apos;weight: &#123;&#125;&apos;.format(w))</span><br><span class="line">    print(&apos;bias: &#123;&#125;&apos;.format(b))</span><br><span class="line"></span><br><span class="line">    score = net.forward(input_array)</span><br><span class="line">    res, predict = compute_accuracy(xor_array, score)</span><br><span class="line">    print(&apos;labels: &apos; + str(xor_array))</span><br><span class="line">    print(&apos;predict: &apos; + str(predict))</span><br><span class="line">    print(&apos;training accuracy: %.2f %%&apos; % (res * 100))</span><br></pre></td></tr></table></figure>
<h3 id="逻辑异或"><a href="#逻辑异或" class="headerlink" title="逻辑异或"></a>逻辑异或</h3><p>输入值与输出值</p>
<ul>
<li>(0,0) - 0</li>
<li>(0,1) - 1</li>
<li>(1,0) - 1</li>
<li>(1,1) - 0</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">input_array = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])</span><br><span class="line">xor_array = np.array([0, 1, 1, 0])</span><br></pre></td></tr></table></figure>
<p>参数如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 批量大小</span><br><span class="line">N = 4</span><br><span class="line"># 输入维数</span><br><span class="line">D = 2</span><br><span class="line"># 隐藏层大小</span><br><span class="line">H = 6</span><br><span class="line"># 输出类别</span><br><span class="line">K = 2</span><br><span class="line"></span><br><span class="line"># 学习率</span><br><span class="line">learning_rate = 1e-1</span><br><span class="line"># 正则化强度</span><br><span class="line">lambda_rate = 1e-3</span><br></pre></td></tr></table></figure>
<p>进行<code>1</code>万轮迭代后</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">weight: [[-1.39091559  0.26154732 -0.90273461  1.66258303  1.63181952 -1.61815551]</span><br><span class="line"> [ 1.39121663  0.26156278  0.90284832 -1.66206662  1.63189271 -1.61824032]]</span><br><span class="line">bias: [[ 4.92481313e-05 -2.61570825e-01  8.55319233e-06  8.17393648e-05</span><br><span class="line">  -1.63169400e+00  1.61798312e+00]]</span><br><span class="line">labels: [0 1 1 0]</span><br><span class="line">predict: [0 1 1 0]</span><br><span class="line">training accuracy: 100.00 %</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/神经网络实现-numpy/logical_xor.png" alt></p>
<h2 id="使用3层神经网络ThreeNet实现iris数据集和mnist数据集分类"><a href="#使用3层神经网络ThreeNet实现iris数据集和mnist数据集分类" class="headerlink" title="使用3层神经网络ThreeNet实现iris数据集和mnist数据集分类"></a>使用3层神经网络ThreeNet实现iris数据集和mnist数据集分类</h2><p>使用<code>3</code>层神经网络<code>ThreeNet</code></p>
<ul>
<li>网络层数$L=3$</li>
<li>批量数据$N$</li>
<li>输入层神经元个数$D$</li>
<li>第一个隐藏层神经元个数$H1$</li>
<li>第二个隐藏层神经元个数$H2$</li>
<li>输出层神经元个数$K$</li>
<li>激活函数是<code>relu</code></li>
<li>评分函数是<code>softmax</code>评分</li>
<li>损失函数是交叉熵损失平凡</li>
</ul>
<p><img src="/imgs/神经网络实现-numpy/three_layer_net.png" alt></p>
<ul>
<li>$a^{(0)}\in R^{N\times D}$</li>
<li>$W^{(1)}\in R^{D\times H1}$</li>
<li>$b^{(1)}\in R^{1\times H1}$</li>
<li>$W^{(2)}\in R^{H1\times H2}$</li>
<li>$b^{(2)}\in R^{1\times H2}$</li>
<li>$W^{(3)}\in R^{H2\times K}$</li>
<li>$b^{(3)}\in R^{1\times K}$</li>
<li>$Y\in R^{N\times K}$，每行仅有正确类别为1，其余为0</li>
</ul>
<p><strong>前向传播过程</strong></p>
<script type="math/tex; mode=display">
z^{(1)}=a^{(0)}\cdot W^{(1)}+b^{(1)} \\
a^{(1)}=relu(z^{(1)}) \\
z^{(2)}=a^{(1)}\cdot W^{(2)}+b^{(2)}\\
a^{(2)}=relu(z^{(2)}) \\
z^{(3)}=a^{(2)}\cdot W^{(3)}+b^{(3)}\\</script><p>所以分类概率是</p>
<script type="math/tex; mode=display">
probs=h(z^{(3)})=\frac {exp(z^{(3)})}{exp(z^{(3)})\cdot A\cdot B^{T}}</script><p>其中$A\in R^{K\times 1}，B\in R^{K\times 1}$都是全$1$向量，</p>
<p>损失值是</p>
<script type="math/tex; mode=display">
dataLoss = -\frac {1}{N} 1^{T}\cdot \ln \frac {exp(z^{(3)}* Y\cdot A)}{exp(z^{3})\cdot A}</script><script type="math/tex; mode=display">
regLoss = 0.5\cdot reg\cdot ||W^{(1)}||^{2} + 0.5\cdot reg\cdot ||W^{(2)}||^{2} + 0.5\cdot reg\cdot ||W^{(3)}||^{2}</script><script type="math/tex; mode=display">
J(z^{(2)})=dataLoss + regLoss</script><p><strong>反向传播过程</strong></p>
<p><strong>输出层输入向量梯度</strong></p>
<script type="math/tex; mode=display">
\bigtriangledown_{z^{(3)}}f(z^{(3)})=\frac {1}{N} (probs - Y)</script><p><strong>对于输出层权重矩阵、偏置向量以及第二个隐藏层输出向量</strong></p>
<script type="math/tex; mode=display">
\bigtriangledown_{W^{(3)}}f(W^{(3)})=\frac {1}{N} (a^{(2)})^{T}\cdot (probs - Y)</script><script type="math/tex; mode=display">
\bigtriangledown_{b^{(3)}}f(b^{(3)})=\frac {1}{N} \sum_{i=1}^{N}(probs_{i} - Y_{i})</script><script type="math/tex; mode=display">
\bigtriangledown_{a^{(2)}}f(a^{(2)})=\frac {1}{N} (probs - Y)\cdot (W^{(3)})^{T}</script><p><strong>对于第二个隐藏层输入向量</strong></p>
<script type="math/tex; mode=display">
\bigtriangledown_{z^{(2)}}f(z^{(2)})=\frac {1}{N} ((probs - Y)\cdot (W^{(3)})^{T})* 1(z^{(2)}\geq 0)</script><p><strong>对于第二个隐藏层权重矩阵、偏置向量和第一个隐藏层输出向量</strong></p>
<script type="math/tex; mode=display">
\bigtriangledown_{W^{(2)}}f(W^{(2)})=\frac {1}{N} (a^{(1)})^{T}\cdot ((W^{(3)}\cdot (probs^{T} - Y^{T}))* 1(z^{(2)}\geq 0))</script><script type="math/tex; mode=display">
\bigtriangledown_{b^{(2)}}f(b^{(1)})=\frac {1}{N} \sum_{i=1}^{N}((probs - Y)\cdot (W^{(3)})^{T})* 1(z^{(2)}\geq 0)</script><script type="math/tex; mode=display">
\bigtriangledown_{a^{(1)}}f(a^{(1)})=\frac {1}{N} (((probs - Y)\cdot (W^{(3)})^{T})* 1(z^{(2)}\geq 0))\cdot (W^{(2)})^{T}</script><p><strong>对于第一个隐藏层输入向量</strong></p>
<script type="math/tex; mode=display">
\bigtriangledown_{z^{(2)}}f(z^{(2)})=\frac {1}{N} (((probs - Y)\cdot (W^{(3)})^{T})* 1(z^{(2)}\geq 0)\cdot (W^{(2)})^{T})* 1(z^{(1)}\geq 0)</script><p><strong>对于第一个隐藏层权重矩阵和偏置向量</strong></p>
<script type="math/tex; mode=display">
\bigtriangledown_{W^{(2)}}f(W^{(2)})=\frac {1}{N} (a^{(1)})^{T}\cdot ((((probs - Y)\cdot (W^{(3)})^{T})* 1(z^{(2)}\geq 0)\cdot (W^{(2)})^{T})* 1(z^{(1)}\geq 0))</script><script type="math/tex; mode=display">
\bigtriangledown_{b^{(2)}}f(b^{(1)})=\frac {1}{N} \sum_{i=1}^{N}(((probs - Y)\cdot (W^{(3)})^{T})* 1(z^{(2)}\geq 0)\cdot (W^{(2)})^{T})* 1(z^{(1)}\geq 0)</script><h3 id="numpy实现-2"><a href="#numpy实现-2" class="headerlink" title="numpy实现"></a>numpy实现</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class ThreeNet(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self, w, b, w2, b2, w3, b3):</span><br><span class="line">        self.w = w</span><br><span class="line">        self.b = b</span><br><span class="line">        self.w2 = w2</span><br><span class="line">        self.b2 = b2</span><br><span class="line">        self.w3 = w3</span><br><span class="line">        self.b3 = b3</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        前向计算，计算评分函数值</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.N = inputs.shape[0]</span><br><span class="line">        self.a0 = inputs</span><br><span class="line"></span><br><span class="line">        self.z1 = inputs.dot(self.w) + self.b</span><br><span class="line">        self.a1 = np.maximum(0, self.z1)</span><br><span class="line"></span><br><span class="line">        self.z2 = self.a1.dot(self.w2) + self.b2</span><br><span class="line">        self.a2 = np.maximum(0, self.z2)</span><br><span class="line"></span><br><span class="line">        self.z3 = self.a2.dot(self.w3) + self.b3</span><br><span class="line">        expscores = np.exp(self.z3)</span><br><span class="line">        self.h = expscores / np.sum(expscores, axis=1, keepdims=True)</span><br><span class="line">        return self.h</span><br><span class="line"></span><br><span class="line">    def backward(self, output):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        反向传播，计算梯度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        delta = self.h</span><br><span class="line">        delta[range(self.N), output] -= 1</span><br><span class="line">        delta /= self.N</span><br><span class="line"></span><br><span class="line">        self.dw3 = self.a2.T.dot(delta)</span><br><span class="line">        self.db3 = np.sum(delta, axis=0, keepdims=True)</span><br><span class="line"></span><br><span class="line">        da2 = delta.dot(self.w3.T)</span><br><span class="line">        dz2 = da2</span><br><span class="line">        dz2[self.z2 &lt; 0] = 0</span><br><span class="line"></span><br><span class="line">        self.dw2 = self.a1.T.dot(dz2)</span><br><span class="line">        self.db2 = np.sum(dz2, axis=0, keepdims=True)</span><br><span class="line"></span><br><span class="line">        da1 = dz2.dot(self.w2.T)</span><br><span class="line">        dz1 = da1</span><br><span class="line">        dz1[self.z1 &lt; 0] = 0</span><br><span class="line"></span><br><span class="line">        self.dw = self.a0.T.dot(dz1)</span><br><span class="line">        self.db = np.sum(dz1, axis=0, keepdims=True)</span><br><span class="line"></span><br><span class="line">    def update(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        更新梯度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.dw3 += lambda_rate * self.w3</span><br><span class="line">        self.dw2 += lambda_rate * self.w2</span><br><span class="line">        self.dw += lambda_rate * self.w</span><br><span class="line"></span><br><span class="line">        self.w3 = self.w3 - learning_rate * self.dw3</span><br><span class="line">        self.b3 = self.b3 - learning_rate * self.b3</span><br><span class="line"></span><br><span class="line">        self.w2 = self.w2 - learning_rate * self.dw2</span><br><span class="line">        self.b2 = self.b2 - learning_rate * self.b2</span><br><span class="line"></span><br><span class="line">        self.w = self.w - learning_rate * self.dw</span><br><span class="line">        self.b = self.b - learning_rate * self.db</span><br><span class="line"></span><br><span class="line">    def __copy__(self):</span><br><span class="line">        w = copy.deepcopy(self.w)</span><br><span class="line">        b = copy.deepcopy(self.b)</span><br><span class="line">        w2 = copy.deepcopy(self.w2)</span><br><span class="line">        b2 = copy.deepcopy(self.b2)</span><br><span class="line">        w3 = copy.deepcopy(self.w3)</span><br><span class="line">        b3 = copy.deepcopy(self.b3)</span><br><span class="line"></span><br><span class="line">        net = ThreeNet(w, b, w2, b2, w3, b3)</span><br><span class="line">        return net</span><br></pre></td></tr></table></figure>
<h3 id="iris数据集"><a href="#iris数据集" class="headerlink" title="iris数据集"></a>iris数据集</h3><p>参考：<a href="https://www.zhujian.tech/posts/2626bec3.html#more">softmax回归</a></p>
<p>分类鸢尾（iris）数据集，下载地址：<a href="https://www.kaggle.com/uciml/iris" target="_blank" rel="noopener">iris</a></p>
<p>共<code>4</code>个变量：</p>
<ul>
<li><code>SepalLengthCm</code> - 花萼长度</li>
<li><code>SepalWidthCm</code> - 花萼宽度</li>
<li><code>PetalLengthCm</code> - 花瓣长度</li>
<li><code>PetalWidthCm</code> - 花瓣宽度</li>
</ul>
<p>以及<code>3</code>个类别：</p>
<ul>
<li><code>Iris-setosa</code></li>
<li><code>Iris-versicolor</code></li>
<li><code>Iris-virginica</code></li>
</ul>
<p>网络和训练参数如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 批量大小</span><br><span class="line">N = 120</span><br><span class="line"># 输入维数</span><br><span class="line">D = 4</span><br><span class="line"># 隐藏层大小</span><br><span class="line">H1 = 20</span><br><span class="line">H2 = 20</span><br><span class="line"># 输出类别</span><br><span class="line">K = 3</span><br><span class="line"></span><br><span class="line"># 学习率</span><br><span class="line">learning_rate = 5e-2</span><br><span class="line"># 正则化强度</span><br><span class="line">lambda_rate = 1e-3</span><br></pre></td></tr></table></figure>
<p>完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-5-18 下午2:23</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-5-18 上午11:48</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import copy</span><br><span class="line">from sklearn import utils</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line"># 批量大小</span><br><span class="line">N = 120</span><br><span class="line"># 输入维数</span><br><span class="line">D = 4</span><br><span class="line"># 隐藏层大小</span><br><span class="line">H1 = 20</span><br><span class="line">H2 = 20</span><br><span class="line"># 输出类别</span><br><span class="line">K = 3</span><br><span class="line"></span><br><span class="line"># 学习率</span><br><span class="line">learning_rate = 5e-2</span><br><span class="line"># 正则化强度</span><br><span class="line">lambda_rate = 1e-3</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/iris-species/Iris.csv&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(data_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        data = utils.shuffle(data)</span><br><span class="line"></span><br><span class="line">    species_dict = &#123;</span><br><span class="line">        &apos;Iris-setosa&apos;: 0,</span><br><span class="line">        &apos;Iris-versicolor&apos;: 1,</span><br><span class="line">        &apos;Iris-virginica&apos;: 2</span><br><span class="line">    &#125;</span><br><span class="line">    data[&apos;Species&apos;] = data[&apos;Species&apos;].map(species_dict)</span><br><span class="line"></span><br><span class="line">    data_x = np.array(</span><br><span class="line">        [data[&apos;SepalLengthCm&apos;], data[&apos;SepalWidthCm&apos;], data[&apos;PetalLengthCm&apos;], data[&apos;PetalWidthCm&apos;]]).T</span><br><span class="line">    data_y = data[&apos;Species&apos;]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=False)</span><br><span class="line"></span><br><span class="line">    return x_train, x_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def init_weights(inputs, outputs):</span><br><span class="line">    return 0.01 * np.random.normal(loc=0.0, scale=1.0, size=(inputs, outputs))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ThreeNet(object):</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_loss(score, y):</span><br><span class="line">    num = score.shape[0]</span><br><span class="line">    data_loss = -1.0 / num * np.sum(np.log(score[range(num), y]))</span><br><span class="line">    # reg_loss = 0.5 * lambda_rate * (np.sum(w ** 2) + np.sum(w2 ** 2))</span><br><span class="line">    return data_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(score, y):</span><br><span class="line">    predict = np.argmax(score, axis=1)</span><br><span class="line">    return np.mean(predict == y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(loss_list, title=&apos;损失图&apos;, ylabel=&apos;损失值&apos;, xlabel=&apos;迭代/100次&apos;):</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.ylabel(ylabel)</span><br><span class="line">    plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(loss_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    x_train, x_test, y_train, y_test = load_data(shuffle=True, tsize=0.8)</span><br><span class="line"></span><br><span class="line">    w = init_weights(D, H1)</span><br><span class="line">    b = init_weights(1, H1)</span><br><span class="line">    w2 = init_weights(H1, H2)</span><br><span class="line">    b2 = init_weights(1, H2)</span><br><span class="line">    w3 = init_weights(H2, K)</span><br><span class="line">    b3 = init_weights(1, K)</span><br><span class="line">    net = ThreeNet(w, b, w2, b2, w3, b3)</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    total_loss = 0</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestA = 0</span><br><span class="line">    best_net = None</span><br><span class="line">    for i in range(10000):</span><br><span class="line">        score = net.forward(x_train)</span><br><span class="line">        total_loss += compute_loss(score, y_train)</span><br><span class="line">        net.backward(y_train)</span><br><span class="line">        net.update()</span><br><span class="line"></span><br><span class="line">        if i % 100 == 99:</span><br><span class="line">            avg_loss = total_loss / 100</span><br><span class="line">            print(&apos;epoch: %d loss: %.4f&apos; % (i + 1, avg_loss))</span><br><span class="line">            loss_list.append(avg_loss)</span><br><span class="line">            total_loss = 0</span><br><span class="line"></span><br><span class="line">            # 计算训练数据集检测精度</span><br><span class="line">            accuracy = compute_accuracy(net.forward(x_train), y_train)</span><br><span class="line">            accuracy_list.append(accuracy)</span><br><span class="line">            if accuracy &gt;= bestA:</span><br><span class="line">                bestA = accuracy</span><br><span class="line">                best_net = net.__copy__()</span><br><span class="line"></span><br><span class="line">    draw(loss_list, &apos;iris数据集&apos;)</span><br><span class="line">    draw(accuracy_list, &apos;训练精度&apos;, &apos;检测精度&apos;)</span><br><span class="line"></span><br><span class="line">    test_score = best_net.forward(x_test)</span><br><span class="line">    res = compute_accuracy(test_score, y_test)</span><br><span class="line">    print(&apos;best train accuracy: %.2f %%&apos; % (bestA * 100))</span><br><span class="line">    print(&apos;test accuracy: %.2f %%&apos; % (res * 100))</span><br></pre></td></tr></table></figure>
<p>训练<code>1</code>万次结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">best train accuracy: 98.33 %</span><br><span class="line">test accuracy: 100.00 %</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/神经网络实现-numpy/iris_loss.png" alt></p>
<p><img src="/imgs/神经网络实现-numpy/iris_accuracy.png" alt></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">softmax回归</th>
<th style="text-align:center">神经网络</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">iris</td>
<td style="text-align:center">96.67%</td>
<td style="text-align:center">98.33%</td>
</tr>
</tbody>
</table>
</div>
<h3 id="mnist数据集"><a href="#mnist数据集" class="headerlink" title="mnist数据集"></a>mnist数据集</h3><p>参考：<a href="https://www.zhujian.tech/posts/dd673751.html#more">使用softmax回归进行mnist分类</a></p>
<p><code>mnist</code>数据集是手写数字数据集，共有共有<code>60000</code>张训练图像和<code>10000</code>张测试图像，分别表示数字<code>0-9</code></p>
<p>数据集的下载和解压参考：<a href="https://blog.csdn.net/u012005313/article/details/84453316" target="_blank" rel="noopener">Python MNIST解压</a></p>
<p>网络和训练参数如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 批量大小</span><br><span class="line">batch_size = 256</span><br><span class="line"># 输入维数</span><br><span class="line">D = 784</span><br><span class="line"># 隐藏层大小</span><br><span class="line">H1 = 200</span><br><span class="line">H2 = 80</span><br><span class="line"># 输出类别</span><br><span class="line">K = 10</span><br><span class="line"></span><br><span class="line"># 学习率</span><br><span class="line">learning_rate = 1e-3</span><br><span class="line"># 正则化强度</span><br><span class="line">lambda_rate = 1e-3</span><br></pre></td></tr></table></figure>
<p>完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-5-18 上午11:48</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import copy</span><br><span class="line">import cv2</span><br><span class="line">import os</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line"># 批量大小</span><br><span class="line">batch_size = 256</span><br><span class="line"># 输入维数</span><br><span class="line">D = 784</span><br><span class="line"># 隐藏层大小</span><br><span class="line">H1 = 200</span><br><span class="line">H2 = 80</span><br><span class="line"># 输出类别</span><br><span class="line">K = 10</span><br><span class="line"></span><br><span class="line"># 学习率</span><br><span class="line">learning_rate = 1e-3</span><br><span class="line"># 正则化强度</span><br><span class="line">lambda_rate = 1e-3</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/mnist/&apos;</span><br><span class="line"></span><br><span class="line">cate_list = list(range(10))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(shuffle=True):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载mnist数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    train_dir = os.path.join(data_path, &apos;train&apos;)</span><br><span class="line">    test_dir = os.path.join(data_path, &apos;test&apos;)</span><br><span class="line"></span><br><span class="line">    x_train = []</span><br><span class="line">    x_test = []</span><br><span class="line">    y_train = []</span><br><span class="line">    y_test = []</span><br><span class="line">    train_file_list = []</span><br><span class="line">    for i in cate_list:</span><br><span class="line">        data_dir = os.path.join(train_dir, str(i))</span><br><span class="line">        file_list = os.listdir(data_dir)</span><br><span class="line">        for filename in file_list:</span><br><span class="line">            file_path = os.path.join(data_dir, filename)</span><br><span class="line">            train_file_list.append(file_path)</span><br><span class="line"></span><br><span class="line">        data_dir = os.path.join(test_dir, str(i))</span><br><span class="line">        file_list = os.listdir(data_dir)</span><br><span class="line">        for filename in file_list:</span><br><span class="line">            file_path = os.path.join(data_dir, filename)</span><br><span class="line">            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">            if img is not None:</span><br><span class="line">                h, w = img.shape[:2]</span><br><span class="line">                x_test.append(img.reshape(h * w))</span><br><span class="line">                y_test.append(i)</span><br><span class="line"></span><br><span class="line">    train_file_list = np.array(train_file_list)</span><br><span class="line">    if shuffle:</span><br><span class="line">        np.random.shuffle(train_file_list)</span><br><span class="line"></span><br><span class="line">    for file_path in train_file_list:</span><br><span class="line">        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">        if img is not None:</span><br><span class="line">            h, w = img.shape[:2]</span><br><span class="line">            x_train.append(img.reshape(h * w))</span><br><span class="line">            y_train.append(int(os.path.split(file_path)[0].split(&apos;/&apos;)[-1]))</span><br><span class="line"></span><br><span class="line">    return np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def init_weights(inputs, outputs):</span><br><span class="line">    return 0.01 * np.random.normal(loc=0.0, scale=1.0, size=(inputs, outputs))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ThreeNet(object):</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_loss(score, y):</span><br><span class="line">    num = score.shape[0]</span><br><span class="line">    data_loss = -1.0 / num * np.sum(np.log(score[range(num), y]))</span><br><span class="line">    # reg_loss = 0.5 * lambda_rate * (np.sum(w ** 2) + np.sum(w2 ** 2))</span><br><span class="line">    return data_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(score, y):</span><br><span class="line">    predict = np.argmax(score, axis=1)</span><br><span class="line">    return np.mean(predict == y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(loss_list, title=&apos;损失图&apos;, ylabel=&apos;损失值&apos;, xlabel=&apos;迭代/100次&apos;):</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.ylabel(ylabel)</span><br><span class="line">    plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(loss_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    x_train, x_test, y_train, y_test = load_data(shuffle=True)</span><br><span class="line"></span><br><span class="line">    w = init_weights(D, H1)</span><br><span class="line">    b = init_weights(1, H1)</span><br><span class="line">    w2 = init_weights(H1, H2)</span><br><span class="line">    b2 = init_weights(1, H2)</span><br><span class="line">    w3 = init_weights(H2, K)</span><br><span class="line">    b3 = init_weights(1, K)</span><br><span class="line">    net = ThreeNet(w, b, w2, b2, w3, b3)</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    total_loss = 0</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestA = 0</span><br><span class="line">    best_net = None</span><br><span class="line">    range_list = np.arange(0, x_train.shape[0] - batch_size, step=batch_size)</span><br><span class="line">    for i in range(200):</span><br><span class="line">        for j in range_list:</span><br><span class="line">            data = x_train[j:j + batch_size]</span><br><span class="line">            labels = y_train[j:j + batch_size]</span><br><span class="line"></span><br><span class="line">            score = net.forward(data)</span><br><span class="line">            total_loss += compute_loss(score, labels)</span><br><span class="line">            net.backward(labels)</span><br><span class="line">            net.update()</span><br><span class="line"></span><br><span class="line">            if j == range_list[-1]:</span><br><span class="line">                avg_loss = total_loss / len(range_list)</span><br><span class="line">                print(&apos;epoch: %d loss: %.4f&apos; % (i + 1, avg_loss))</span><br><span class="line">                loss_list.append(avg_loss)</span><br><span class="line">                total_loss = 0</span><br><span class="line"></span><br><span class="line">                # 计算训练数据集检测精度</span><br><span class="line">                score = net.forward(x_train[j:j + batch_size])</span><br><span class="line">                accuracy = compute_accuracy(score, labels)</span><br><span class="line">                accuracy_list.append(accuracy)</span><br><span class="line">                if accuracy &gt;= bestA:</span><br><span class="line">                    bestA = accuracy</span><br><span class="line">                    best_net = net.__copy__()</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;mnist&apos;, xlabel=&apos;迭代/次&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度&apos;, ylabel=&apos;检测精度&apos;, xlabel=&apos;迭代/次&apos;)</span><br><span class="line"></span><br><span class="line">    test_score = best_net.forward(x_test)</span><br><span class="line">    res = compute_accuracy(test_score, y_test)</span><br><span class="line">    print(&apos;best train accuracy: %.2f %%&apos; % (bestA * 100))</span><br><span class="line">    print(&apos;test accuracy: %.2f %%&apos; % (res * 100))</span><br></pre></td></tr></table></figure>
<p>训练<code>200</code>次结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">best train accuracy: 100.00 %</span><br><span class="line">test accuracy: 97.92 %</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/神经网络实现-numpy/mnist_loss.png" alt></p>
<p><img src="/imgs/神经网络实现-numpy/mnist_accuracy.png" alt></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">softmax回归</th>
<th style="text-align:center">神经网络</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">mnist</td>
<td style="text-align:center">92.15%</td>
<td style="text-align:center">97.92%</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>sklearn</tag>
        <tag>pandas</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络推导-矩阵计算</title>
    <url>/posts/1dd3ebad.html</url>
    <content><![CDATA[<p>为了理清如何进行神经网络的前向传播和反向传播的推导，找了很多资料，前向传播比较简单，重点在于如何进行反向传播的梯度计算</p><a id="more"></a>
<p><code>cs231n</code>课程推荐的计算方式是先进行单个元素求导，再逐步泛化到批量数据求梯度，参考</p>
<p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=2ahUKEwiAvpOU85ziAhXFneAKHfsgDzwQFjAAegQIABAC&amp;url=http%3A%2F%2Fcs231n.stanford.edu%2Fhandouts%2Fderivatives.pdf&amp;usg=AOvVaw2olyLQPXL2R8J3UMpk8Zeo" target="_blank" rel="noopener">Derivatives, Backpropagation, and Vectorization - CS231n</a></p>
<p><a href="cs231n.stanford.edu/vecDerivs.pdf">Vector, Matrix, and Tensor Derivatives - CS231n</a></p>
<p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;ved=2ahUKEwiAvpOU85ziAhXFneAKHfsgDzwQFjABegQIBRAC&amp;url=http%3A%2F%2Fcs231n.stanford.edu%2Fslides%2F2017%2Fcs231n_2017_lecture4.pdf&amp;usg=AOvVaw1o70kb0znbYAjhWXntxnlS" target="_blank" rel="noopener">Backpropagation and Neural Networks - CS231n</a></p>
<p>自己也根据参考资料进行2层神经网络逐元素的推导</p>
<p><a href="https://www.zhujian.tech/posts/cb820bb8.html#more">神经网络推导-单个数据</a></p>
<p><a href="https://www.zhujian.tech/posts/66015d4d.html#more">神经网络推导-批量数据</a></p>
<p>最好的方式当然是进行矩阵求导，在网上看了很多博客，比较好的有</p>
<p><a href="https://zhuanlan.zhihu.com/p/24709748" target="_blank" rel="noopener">矩阵求导术（上）</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/32368246" target="_blank" rel="noopener">[矩阵求导]神经网络反向传播梯度计算数学原理</a></p>
<p>神经网络矩阵计算最重要的内容是进行实值标量矩阵的一阶微分以及$Jacobian$矩阵的辨识，参考《矩阵分析与应用》，有以下先导知识</p>
<p><a href="https://www.zhujian.tech/posts/a9bec5e9.html#more">导数、微分和梯度</a></p>
<p><a href="https://www.zhujian.tech/posts/d1deacd1.html#more">矩阵基础</a></p>
<p><a href="https://www.zhujian.tech/posts/29422005.html#more">Jacobian矩阵和梯度矩阵</a></p>
<p><a href="https://www.zhujian.tech/posts/b9ab243b.html#more">实值标量函数一阶微分和Jacobian矩阵辨识</a></p>
<p>使用矩阵微分能够很便捷的实现神经网络反向求导，关键部分是辨识$Jacobian$矩阵，再转换成梯度矩阵</p>
<h2 id="推导一"><a href="#推导一" class="headerlink" title="推导一"></a>推导一</h2><p>文章<a href="https://zhuanlan.zhihu.com/p/32368246" target="_blank" rel="noopener">[矩阵求导]神经网络反向传播梯度计算数学原理</a>给出了一个很好的推导方式，首先给出实现代码，然后使用矩阵计算逐步解释代码</p>
<p><code>PyTorch</code>教程<a href="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html" target="_blank" rel="noopener">Learning PyTorch with Examples</a>给出了一个<code>2</code>层神经网络的<code>numpy</code>实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># N is batch size; D_in is input dimension;</span><br><span class="line"># H is hidden dimension; D_out is output dimension.</span><br><span class="line">N, D_in, H, D_out = 64, 1000, 100, 10</span><br><span class="line"></span><br><span class="line"># Create random input and output data</span><br><span class="line">x = np.random.randn(N, D_in)</span><br><span class="line">y = np.random.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"># Randomly initialize weights</span><br><span class="line">w1 = np.random.randn(D_in, H)</span><br><span class="line">w2 = np.random.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = 1e-6</span><br><span class="line">for t in range(500):</span><br><span class="line">    # Forward pass: compute predicted y</span><br><span class="line">    h = x.dot(w1)</span><br><span class="line">    h_relu = np.maximum(h, 0)</span><br><span class="line">    y_pred = h_relu.dot(w2)</span><br><span class="line"></span><br><span class="line">    # Compute and print loss</span><br><span class="line">    loss = np.square(y_pred - y).sum()</span><br><span class="line">    print(t, loss)</span><br><span class="line"></span><br><span class="line">    # Backprop to compute gradients of w1 and w2 with respect to loss</span><br><span class="line">    grad_y_pred = 2.0 * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.T.dot(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.dot(w2.T)</span><br><span class="line">    grad_h = grad_h_relu.copy()</span><br><span class="line">    grad_h[h &lt; 0] = 0</span><br><span class="line">    grad_w1 = x.T.dot(grad_h)</span><br><span class="line"></span><br><span class="line">    # Update weights</span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>
<p>第一步：定义网络参数</p>
<ul>
<li>批量数据大小$N=64$</li>
<li>输入层神经元个数$D_{in}=1000$</li>
<li>隐藏层神经元个数$H=100$</li>
<li>输出层神经元个数$D_{out}=10$</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># N is batch size; D_in is input dimension;</span><br><span class="line"># H is hidden dimension; D_out is output dimension.</span><br><span class="line">N, D_in, H, D_out = 64, 1000, 100, 10</span><br></pre></td></tr></table></figure>
<p>第二步：初始化数据、权重（<em>该网络没有偏置向量</em>）以及学习率</p>
<ul>
<li>输入数据$x\in R^{N\times D_{in}}$</li>
<li>输出数据$y\in R^{N\times D_{out}}$</li>
<li>隐藏层权重矩阵$w1\in R^{D_{in}\times H}$</li>
<li>输出层权重矩阵$w2\in R^{H\times D_{out}}$</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Create random input and output data</span><br><span class="line">x = np.random.randn(N, D_in)</span><br><span class="line">y = np.random.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"># Randomly initialize weights</span><br><span class="line">w1 = np.random.randn(D_in, H)</span><br><span class="line">w2 = np.random.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = 1e-6</span><br></pre></td></tr></table></figure>
<p>第三步：迭代计算，输入批量数据到神经网络，进行前向传播</p>
<script type="math/tex; mode=display">
h=x\cdot w1\\
h_{relu}=max(0, h)\\
y_{pred}=h_{relu}\cdot w2</script><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Forward pass: compute predicted y</span><br><span class="line">h = x.dot(w1)</span><br><span class="line">h_relu = np.maximum(h, 0)</span><br><span class="line">y_pred = h_relu.dot(w2)</span><br></pre></td></tr></table></figure>
<p>第四步：迭代计算，计算损失函数（<em>误差平方和 - L1范数的平方</em>）</p>
<script type="math/tex; mode=display">
loss=\begin{Vmatrix}
y_{pred}-y
\end{Vmatrix}^{2}</script><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Compute and print loss</span><br><span class="line">loss = np.square(y_pred - y).sum()</span><br><span class="line">print(t, loss)</span><br></pre></td></tr></table></figure>
<p><strong>第五步：迭代计算，反向传播，计算输出层输入向量梯度</strong></p>
<p>设$y_{pred}-y=X$，$X$大小为$N\times D_{out}$，则</p>
<script type="math/tex; mode=display">
loss=\begin{Vmatrix}
X
\end{Vmatrix}^{2}=
(vec(X))^{T}\cdot vec(X)</script><p>对损失函数$loss(y_{pred})$求输出层输入向量的微分</p>
<script type="math/tex; mode=display">
dloss=d(tr(loss))=tr(dloss)=tr(d((vec(X))^{T}\cdot vec(X)
))\\
=tr(d(vec(X)^{T})\cdot vec(X)+vec(X)^{T}\cdot dvec(X))\\
=tr(d(vec(X)^{T})\cdot vec(X))+tr(vec(X)^{T}\cdot dvec(X))\\
=tr((dvec(X))^{T}\cdot vec(X))+tr(vec(X)^{T}\cdot dvec(X))\\
=tr((vec(X))^{T}\cdot dvec(X))+tr(vec(X)^{T}\cdot dvec(X))\\
=tr(2(vec(X))^{T}\cdot dvec(X))\\
=tr(2X^{T}\cdot dX)</script><p>所以Jacobian矩阵为$D_{X}f(X)=2X^{T}$，梯度矩阵为$\bigtriangledown_{X}f(X)=2X=2(y_{pred}-y)$</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grad_y_pred = 2.0 * (y_pred - y)</span><br></pre></td></tr></table></figure>
<p><strong>第六步：迭代计算，反向传播，计算输出层权重向量以及隐藏层输出向量梯度</strong></p>
<script type="math/tex; mode=display">
y_{pred}=h_{relu}\cdot w2
\Rightarrow 
dy_{pred}=dh_{relu}\cdot w2+h_{relu}\cdot dw2</script><script type="math/tex; mode=display">
dloss=tr(2X^{T}\cdot dX)
=tr(2(y_{pred} - y)^{T}\cdot d((y_{pred} - y)))
=tr(2(y_{pred} - y)^{T}\cdot dy_{pred})\\
=tr(2(y_{pred} - y)^{T}\cdot (dh_{relu}\cdot w2+h_{relu}\cdot dw2))\\
=tr(2(y_{pred} - y)^{T}\cdot dh_{relu}\cdot w2)+tr(2(y_{pred} - y)^{T}\cdot h_{relu}\cdot dw2)\\
=tr(w2\cdot 2(y_{pred} - y)^{T}\cdot dh_{relu})+tr(2(y_{pred} - y)^{T}\cdot h_{relu}\cdot dw2)</script><p>输出层权重向量的Jacobian矩阵为$2(y_{pred} - y)^{T}\cdot h_{relu}$，梯度矩阵为$(h_{relu})^{T}\cdot 2(y_{pred} - y)$</p>
<p>隐藏层输出向量的Jacobian矩阵为$w2\cdot 2(y_{pred} - y)^{T}$，梯度矩阵为$2(y_{pred} - y)\cdot (w2)^{T}$</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grad_w2 = h_relu.T.dot(grad_y_pred)</span><br><span class="line">grad_h_relu = grad_y_pred.dot(w2.T)</span><br></pre></td></tr></table></figure>
<p><strong>第七步：迭代计算，反向传播，计算隐藏层输入向量梯度</strong></p>
<script type="math/tex; mode=display">
h_{relu}=max(0, h)
\Rightarrow 
dh_{relu}=\left\{\begin{matrix}
dh & h\geq 0\\ 
0 & h < 0
\end{matrix}\right.
=1(h\geq 0)*dh</script><p>激活函数是逐个元素操作，所以使用Hadamard积</p>
<script type="math/tex; mode=display">
dloss=tr(w2\cdot 2(y_{pred} - y)^{T}\cdot dh_{relu})\\
=tr(w2\cdot 2(y_{pred} - y)^{T}\cdot 1(h\geq 0)* dh)\\
=tr((2(y_{pred} - y)\cdot (w2)^{T})^{T}\cdot 1(h\geq 0)* dh)\\
=tr((2(y_{pred} - y)\cdot (w2)^{T})^{T}* 1(h\geq 0)^{T}\cdot dh)</script><p>所以Jacobian矩阵为$(2(y_{pred} - y)\cdot (w2)^{T})^{T}* 1(h\geq 0)^{T}$，梯度矩阵为</p>
<script type="math/tex; mode=display">
\bigtriangledown_{h}f(h)=1(h\geq 0)\cdot 2(y_{pred} - y)\cdot (w2)^{T}</script><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grad_h = grad_h_relu.copy()</span><br><span class="line">grad_h[h &lt; 0] = 0</span><br></pre></td></tr></table></figure>
<p><strong>第八步：迭代计算，反向传播，计算隐藏层权重向量梯度</strong></p>
<script type="math/tex; mode=display">
h=x\cdot w1
\Rightarrow 
dh=x\cdot dw1</script><script type="math/tex; mode=display">
dloss
=tr((2(y_{pred} - y)\cdot (w2)^{T})^{T}* 1(h\geq 0)^{T}\cdot dh)\\
=tr((2(y_{pred} - y)\cdot (w2)^{T})^{T}* 1(h\geq 0)^{T}\cdot x\cdot dw1)</script><p>所以Jacobian矩阵为$(2(y_{pred} - y)\cdot (w2)^{T})^{T}* 1(h\geq 0)^{T}\cdot x$，梯度矩阵为</p>
<script type="math/tex; mode=display">
\bigtriangledown_{w1}f(w1)=((2(y_{pred} - y)\cdot (w2)^{T})^{T}* 1(h\geq 0)^{T}\cdot x)^{T}\\
=x^{T}\cdot 1(h\geq 0)* 2(y_{pred} - y)\cdot (w2)^{T}</script><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grad_w1 = x.T.dot(grad_h)</span><br></pre></td></tr></table></figure>
<p>第九步：迭代计算，反向传播，更新权重矩阵</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Update weights</span><br><span class="line">w1 -= learning_rate * grad_w1</span><br><span class="line">w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>
<h2 id="推导二"><a href="#推导二" class="headerlink" title="推导二"></a>推导二</h2><p><code>cs231n</code>课程<a href="http://cs231n.github.io/neural-networks-case-study/#net" target="_blank" rel="noopener">Putting it together: Minimal Neural Network Case Study</a>中实现了一个<code>2</code>层神经网络</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">N = 100 # number of points per class</span><br><span class="line">D = 2 # dimensionality</span><br><span class="line">K = 3 # number of classes</span><br><span class="line">X = np.zeros((N*K,D)) # data matrix (each row = single example)</span><br><span class="line">y = np.zeros(N*K, dtype=&apos;uint8&apos;) # class labels</span><br><span class="line">for j in xrange(K):</span><br><span class="line">  ix = range(N*j,N*(j+1))</span><br><span class="line">  r = np.linspace(0.0,1,N) # radius</span><br><span class="line">  t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta</span><br><span class="line">  X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]</span><br><span class="line">  y[ix] = j</span><br><span class="line"></span><br><span class="line"># initialize parameters randomly</span><br><span class="line">h = 100 # size of hidden layer</span><br><span class="line">W = 0.01 * np.random.randn(D,h)</span><br><span class="line">b = np.zeros((1,h))</span><br><span class="line">W2 = 0.01 * np.random.randn(h,K)</span><br><span class="line">b2 = np.zeros((1,K))</span><br><span class="line"></span><br><span class="line"># some hyperparameters</span><br><span class="line">step_size = 1e-0</span><br><span class="line">reg = 1e-3 # regularization strength</span><br><span class="line"></span><br><span class="line"># gradient descent loop</span><br><span class="line">num_examples = X.shape[0]</span><br><span class="line">for i in xrange(10000):</span><br><span class="line">  </span><br><span class="line">  # evaluate class scores, [N x K]</span><br><span class="line">  hidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation</span><br><span class="line">  scores = np.dot(hidden_layer, W2) + b2</span><br><span class="line">  </span><br><span class="line">  # compute the class probabilities</span><br><span class="line">  exp_scores = np.exp(scores)</span><br><span class="line">  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]</span><br><span class="line">  </span><br><span class="line">  # compute the loss: average cross-entropy loss and regularization</span><br><span class="line">  correct_logprobs = -np.log(probs[range(num_examples),y])</span><br><span class="line">  data_loss = np.sum(correct_logprobs)/num_examples</span><br><span class="line">  reg_loss = 0.5*reg*np.sum(W*W) + 0.5*reg*np.sum(W2*W2)</span><br><span class="line">  loss = data_loss + reg_loss</span><br><span class="line">  if i % 1000 == 0:</span><br><span class="line">    print &quot;iteration %d: loss %f&quot; % (i, loss)</span><br><span class="line">  </span><br><span class="line">  # compute the gradient on scores</span><br><span class="line">  dscores = probs</span><br><span class="line">  dscores[range(num_examples),y] -= 1</span><br><span class="line">  dscores /= num_examples</span><br><span class="line">  </span><br><span class="line">  # backpropate the gradient to the parameters</span><br><span class="line">  # first backprop into parameters W2 and b2</span><br><span class="line">  dW2 = np.dot(hidden_layer.T, dscores)</span><br><span class="line">  db2 = np.sum(dscores, axis=0, keepdims=True)</span><br><span class="line">  # next backprop into hidden layer</span><br><span class="line">  dhidden = np.dot(dscores, W2.T)</span><br><span class="line">  # backprop the ReLU non-linearity</span><br><span class="line">  dhidden[hidden_layer &lt;= 0] = 0</span><br><span class="line">  # finally into W,b</span><br><span class="line">  dW = np.dot(X.T, dhidden)</span><br><span class="line">  db = np.sum(dhidden, axis=0, keepdims=True)</span><br><span class="line">  </span><br><span class="line">  # add regularization gradient contribution</span><br><span class="line">  dW2 += reg * W2</span><br><span class="line">  dW += reg * W</span><br><span class="line">  </span><br><span class="line">  # perform a parameter update</span><br><span class="line">  W += -step_size * dW</span><br><span class="line">  b += -step_size * db</span><br><span class="line">  W2 += -step_size * dW2</span><br><span class="line">  b2 += -step_size * db2</span><br></pre></td></tr></table></figure>
<p>第一步：设置批量输入数据和输出数据</p>
<ul>
<li>批量数据大小$N=100$</li>
<li>数据维数$D=2$</li>
<li>类别数$K=3$</li>
<li>输入数据$X\in R^{N\times D}$</li>
<li>输出数据$y\in R^{N\times K}$</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">N = 100 # number of points per class</span><br><span class="line">D = 2 # dimensionality</span><br><span class="line">K = 3 # number of classes</span><br><span class="line">X = np.zeros((N*K,D)) # data matrix (each row = single example)</span><br><span class="line">y = np.zeros(N*K, dtype=&apos;uint8&apos;) # class labels</span><br><span class="line">for j in xrange(K):</span><br><span class="line">  ix = range(N*j,N*(j+1))</span><br><span class="line">  r = np.linspace(0.0,1,N) # radius</span><br><span class="line">  t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta</span><br><span class="line">  X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]</span><br><span class="line">  y[ix] = j</span><br></pre></td></tr></table></figure>
<p>第二步：初始化权重参数</p>
<ul>
<li>隐藏层神经元个数$h=100$</li>
<li>隐藏层权重矩阵$W\in R^{D\times h}$</li>
<li>隐藏层偏置向量$b\in R^{1\times h}$</li>
<li>输出层权重矩阵$W2\in R^{h\times K}$</li>
<li>输出层偏置向量$b2\in R^{1\times K}$</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># initialize parameters randomly</span><br><span class="line">h = 100 # size of hidden layer</span><br><span class="line">W = 0.01 * np.random.randn(D,h)</span><br><span class="line">b = np.zeros((1,h))</span><br><span class="line">W2 = 0.01 * np.random.randn(h,K)</span><br><span class="line">b2 = np.zeros((1,K))</span><br></pre></td></tr></table></figure>
<p>第三步：设置学习率和正则化强度</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># some hyperparameters</span><br><span class="line">step_size = 1e-0</span><br><span class="line">reg = 1e-3 # regularization strength</span><br></pre></td></tr></table></figure>
<p>第四步：迭代计算，输入批量数据到神经网络，进行前向传播</p>
<script type="math/tex; mode=display">
hiddenLayer = max(X\cdot W+b, 0)\\
scores = hiddenLayer\cdot W2+b2</script><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># evaluate class scores, [N x K]</span><br><span class="line">hidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation</span><br><span class="line">scores = np.dot(hidden_layer, W2) + b2</span><br></pre></td></tr></table></figure>
<p>第四步：迭代计算，计算损失值</p>
<script type="math/tex; mode=display">
expScores = exp(scores)\\
probs = \frac {expScores}{expScores\cdot 1}\\
correctLogProbs = -\ln probs_{y}\in R^{N\times 1}\\
dataLoss=\frac {1}{N} 1^{T}\cdot correctLogProbs\\
regLoss=0.5\cdot reg\cdot ||W||^{2}+0.5\cdot reg\cdot ||W2||^{2}\\
loss = dataLoss+regLoss</script><p><em>$1$表示求和向量：$[1,1,…]^{T}$</em></p>
<p><em>$probs_{y}$表示每行正确类别的概率</em></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># compute the class probabilities</span><br><span class="line">exp_scores = np.exp(scores)</span><br><span class="line">probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]</span><br><span class="line"></span><br><span class="line"># compute the loss: average cross-entropy loss and regularization</span><br><span class="line">correct_logprobs = -np.log(probs[range(num_examples),y])</span><br><span class="line">data_loss = np.sum(correct_logprobs)/num_examples</span><br><span class="line">reg_loss = 0.5*reg*np.sum(W*W) + 0.5*reg*np.sum(W2*W2)</span><br><span class="line">loss = data_loss + reg_loss</span><br><span class="line">if i % 1000 == 0:</span><br><span class="line">    print &quot;iteration %d: loss %f&quot; % (i, loss)</span><br></pre></td></tr></table></figure>
<p><strong>第五步：迭代计算，反向传播，计算输出层输入向量梯度</strong></p>
<script type="math/tex; mode=display">
scores_{y}=scores*Y\cdot 1\\
expscores_{y}=exp(scores*Y\cdot 1)\ \ \ \ 
expscores=exp(scores)\ \ \ \ 
expscores_{sum}=exp(scores)\cdot 1\\
probs_{y}=\frac {expscores_{y}}{expscores_{sum}}\ \ \ \ 
probs=\frac {expscores}{expscores_{sum}}</script><script type="math/tex; mode=display">
dataloss=-\frac {1}{N} 1^{T}\cdot \ln (probs_{y})
=-\frac {1}{N} 1^{T}\cdot \ln \frac {expscores_{y}}{expscores_{sum}}\\
=-\frac {1}{N} 1^{T}\cdot (\ln expscores_{y} -\ln expscores_{sum})\\
=-\frac {1}{N} 1^{T}\cdot (scores*Y\cdot 1 -\ln expscores_{sum})</script><script type="math/tex; mode=display">
d(dataloss)=tr(d(-\frac {1}{N} (1^{T}\cdot scores*Y\cdot 1 -1^{T}\cdot \ln expscores_{sum})))\\
=tr(d(-\frac {1}{N} (1^{T}\cdot scores*Y\cdot 1))) - tr(d(-\frac {1}{N} (1^{T}\cdot \ln expscores_{sum})))</script><script type="math/tex; mode=display">
tr(d(-\frac {1}{N} (1^{T}\cdot scores*Y\cdot 1)))=
tr(-\frac {1}{N} (1^{T}\cdot dscores*Y\cdot 1))\\
=tr(-\frac {1}{N} (dscores^{T}\cdot Y))
=tr(-\frac {1}{N} Y^{T}\cdot dscores)</script><script type="math/tex; mode=display">
tr(d(-\frac {1}{N} (1^{T}\cdot \ln expscores_{sum})))
=tr(-\frac {1}{N} (1^{T}\cdot expscores_{sum}^{-1}\cdot dexpscores_{sum}))\\
=tr(-\frac {1}{N} \frac {(1^{T}\cdot dexpscores_{sum})}{expscores_{sum}})
=tr(-\frac {1}{N} \frac {(1^{T}\cdot exp(scores)* dscores\cdot 1)}{expscores_{sum}})\\
=tr(-\frac {1}{N} \frac {exp(scores)^{T}\cdot dscores}{expscores_{sum}})
=tr(-\frac {1}{N} (\frac {exp(scores)}{expscores_{sum}})^{T}\cdot dscores)
=tr(-\frac {1}{N} probs^{T}\cdot dscores)</script><script type="math/tex; mode=display">
\Rightarrow d(dataloss)=
tr(-\frac {1}{N} Y^{T}\cdot dscores)-tr(-\frac {1}{N} probs^{T}\cdot dscores)\\
=tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot dscores)</script><p>所以$Jacobian$矩阵为$D_{scores}f(scores)=probs^{T} - Y^{T}$，梯度矩阵为$\bigtriangledown_{scores}f(scores)=probs - Y$</p>
<ul>
<li>$Y$大小为$N\times K$，每行仅正确类别位置为1，其余为0</li>
<li>$1$是求和向量，$[1,1,…]^{T}$</li>
</ul>
<p>计算<code>softmax</code>分类的交叉熵损失关于输出层输入向量梯度，这一部分想了好久，主要问题是关于矩阵除法和逐元素除法（标量除法）的分别，感觉还是<strong>先对单个数据进行求梯度再泛化比较方便</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># compute the gradient on scores</span><br><span class="line">dscores = probs</span><br><span class="line">dscores[range(num_examples),y] -= 1</span><br><span class="line">dscores /= num_examples</span><br></pre></td></tr></table></figure>
<p><strong>第六步：迭代计算，反向传播，计算输出层权重矩阵、偏置向量以及隐藏层输出向量梯度</strong></p>
<script type="math/tex; mode=display">
scores = hiddenLayer\cdot W2+b2\\
dscores = dhiddenLayer\cdot W2 + hiddenLayer\cdot dW2 + db2</script><script type="math/tex; mode=display">
 d(dataloss)
=tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot dscores)\\
=tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot (dhiddenLayer\cdot W2 + hiddenLayer\cdot dW2 + db2))\\
=tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot dhiddenLayer\cdot W2)\\
+tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot hiddenLayer\cdot dW2)+
tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot db2)</script><p>求输出层权重矩阵梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot hiddenLayer\cdot dW2)</script><script type="math/tex; mode=display">
D_{W2}f(W2)=\frac {1}{N} (probs^{T} - Y^{T})\cdot hiddenLayer\\
\bigtriangledown_{W2}f(W2)=\frac {1}{N} hiddenLayer^{T}\cdot (probs - Y)</script><p>求输出层偏置向量梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{N} \sum_{i=1}^{N}(probs_{i}^{T} - Y_{i}^{T})\cdot db2)</script><script type="math/tex; mode=display">
D_{b2}f(b2)=\frac {1}{N} \sum_{i=1}^{N}(probs_{i}^{T} - Y_{i}^{T})\\
\bigtriangledown_{b2}f(b2)=\frac {1}{N} \sum_{i=1}^{N}(probs_{i} - Y_{i})</script><p><strong>对偏置向量还需要注意维数，求和批量数据的偏置向量梯度</strong></p>
<p>求隐藏层输出向量梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{N} (probs^{T} - Y^{T})\cdot dhiddenLayer\cdot W2)
=tr(\frac {1}{N} W2\cdot (probs^{T} - Y^{T})\cdot dhiddenLayer)</script><script type="math/tex; mode=display">
D_{hiddenLayer}f(hiddenLayer)=\frac {1}{N} W2\cdot (probs^{T} - Y^{T})\\
\bigtriangledown_{hiddenLayer}f(hiddenLayer)=\frac {1}{N} (probs - Y)\cdot (W2)^{T}</script><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># backpropate the gradient to the parameters</span><br><span class="line"># first backprop into parameters W2 and b2</span><br><span class="line">dW2 = np.dot(hidden_layer.T, dscores)</span><br><span class="line">db2 = np.sum(dscores, axis=0, keepdims=True)</span><br><span class="line"># next backprop into hidden layer</span><br><span class="line">dhidden = np.dot(dscores, W2.T)</span><br></pre></td></tr></table></figure>
<p><strong>第七步：迭代计算，反向传播，计算隐藏层输入向量梯度</strong></p>
<script type="math/tex; mode=display">
hiddenLayer_{in}=X\cdot W+b\\
hiddenLayer = max(0, hiddenLayer_{in})\\
dhiddenLayer = 1(hiddenLayer_{in}\geq 0)* dhiddenLayer_{in}</script><script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{N} W2\cdot (probs^{T} - Y^{T})\cdot dhiddenLayer)\\
=tr(\frac {1}{N} W2\cdot (probs^{T} - Y^{T})\cdot 1(hiddenLayer_{in}\geq 0)* dhiddenLayer_{in})\\
=tr(\frac {1}{N} (W2\cdot (probs^{T} - Y^{T}))^{T} * 1(hiddenLayer_{in}\geq 0)^{T}\cdot dhiddenLayer_{in})</script><script type="math/tex; mode=display">
D_{hiddenLayer_{in}}f(hiddenLayer_{in})=\frac {1}{N} (W2\cdot (probs^{T} - Y^{T}))^{T} * 1(hiddenLayer_{in}\geq 0)^{T}\\
\bigtriangledown_{hiddenLayer_{in}}f(hiddenLayer_{in})=\frac {1}{N} ((probs - Y)\cdot (W2)^{T})* 1(hiddenLayer_{in}\geq 0)</script><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># backprop the ReLU non-linearity</span><br><span class="line">dhidden[hidden_layer &lt;= 0] = 0</span><br></pre></td></tr></table></figure>
<p><strong>第七步：迭代计算，反向传播，计算隐藏层权重向量和偏置向量梯度</strong></p>
<script type="math/tex; mode=display">
hiddenLayer_{in}=X\cdot W+b\\
dhiddenLayer_{in}=X\cdot dW + db</script><script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{N} (W2\cdot (probs^{T} - Y^{T}))^{T} * 1(hiddenLayer_{in}\geq 0)^{T}\cdot dhiddenLayer_{in})\\
=tr(\frac {1}{N} (W2\cdot (probs^{T} - Y^{T}))^{T} * 1(hiddenLayer_{in}\geq 0)^{T}\cdot (X\cdot dW + db))</script><p>求隐藏层权重向量梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{N} (W2\cdot (probs^{T} - Y^{T}))^{T} * 1(hiddenLayer_{in}\geq 0)^{T}\cdot X\cdot dW)</script><script type="math/tex; mode=display">
D_{W}f(W)=\frac {1}{N} (W2\cdot (probs^{T} - Y^{T}))^{T} * 1(hiddenLayer_{in}\geq 0)^{T}\cdot X\\
\bigtriangledown_{W}f(W)=\frac {1}{N} X^{T}\cdot ((probs - Y)\cdot (W2)^{T})* 1(hiddenLayer_{in}\geq 0)</script><p>求隐藏层偏置向量梯度</p>
<script type="math/tex; mode=display">
d(dataloss)=tr(\frac {1}{N} \sum_{i=1}^{N}(W2\cdot (probs^{T} - Y^{T}))^{T} * 1(hiddenLayer_{in}\geq 0)^{T}\cdot db)</script><script type="math/tex; mode=display">
D_{W}f(W)=\frac {1}{N} \sum_{i=1}^{N}(W2\cdot (probs^{T} - Y^{T}))^{T} * 1(hiddenLayer_{in}\geq 0)^{T}\\
\bigtriangledown_{W}f(W)=\frac {1}{N} \sum_{i=1}^{N}((probs - Y)\cdot (W2)^{T})* 1(hiddenLayer_{in}\geq 0)</script><p><strong>对偏置向量还需要注意维数，求和批量数据的偏置向量梯度</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># finally into W,b</span><br><span class="line">dW = np.dot(X.T, dhidden)</span><br><span class="line">db = np.sum(dhidden, axis=0, keepdims=True)</span><br></pre></td></tr></table></figure>
<p>第八步：迭代计算，反向传播，计算正则化梯度</p>
<script type="math/tex; mode=display">
regLoss=0.5\cdot reg\cdot ||W||^{2}+0.5\cdot reg\cdot ||W2||^{2}\\
d(regLoss)=reg\cdot W\cdot dW+reg\cdot W2\cdot dW2</script><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># add regularization gradient contribution</span><br><span class="line">dW2 += reg * W2</span><br><span class="line">dW += reg * W</span><br></pre></td></tr></table></figure>
<p>第九步：迭代计算，反向传播，更新权重矩阵和偏置向量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># perform a parameter update</span><br><span class="line">W += -step_size * dW</span><br><span class="line">b += -step_size * db</span><br><span class="line">W2 += -step_size * dW2</span><br><span class="line">b2 += -step_size * db2</span><br></pre></td></tr></table></figure>
<h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><ol>
<li><a href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf" target="_blank" rel="noopener">The Matrix Cookbook - Mathematics</a></li>
<li><a href="https://en.wikipedia.org/wiki/Matrix_calculus" target="_blank" rel="noopener">Matrix calculus</a></li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>实值标量函数一阶微分和Jacobian矩阵辨识</title>
    <url>/posts/b9ab243b.html</url>
    <content><![CDATA[<p>参考：《矩阵分析与应用》第三章 3.2 一阶实矩阵微分与Jacobian矩阵辨识</p><p>神经网络的反向传播可以通过对损失函数进行微分得到各层权重矩阵的梯度</p><a id="more"></a>

<p>其中对损失函数求梯度是实值标量函数一阶微分，其中关键的部分是得到Jacobian矩阵，从而转置获取梯度矩阵</p>
<h2 id="一阶实矩阵微分"><a href="#一阶实矩阵微分" class="headerlink" title="一阶实矩阵微分"></a>一阶实矩阵微分</h2><p>矩阵微分用符号$dX$表示，定义为$dX=[dX_{ij}]_{i=1,j=1}^{m,n}$</p>
<p>实矩阵微分具有两个基本性质</p>
<ol>
<li>转置。矩阵转置的微分等于矩阵微分的转置，既有$d(X^{T})=(dX)^{T}$</li>
<li>线性。$d(\alpha X+\beta Y)=\alpha dX+\beta dY$</li>
</ol>
<h3 id="常用计算公式"><a href="#常用计算公式" class="headerlink" title="常用计算公式"></a>常用计算公式</h3><ol>
<li>常数矩阵的微分矩阵为零矩阵，即$dA=O$</li>
<li>常数$\alpha$与矩阵$X$的乘积的微分矩阵$d(\alpha X)=\alpha dX$</li>
<li>矩阵转置的微分矩阵等于原矩阵的微分矩阵的转置，即$d(X^{T})=(dX)^{T}$</li>
<li>两个矩阵函数的和（差）的微分矩阵为$d(U\pm V)=dU\pm dV$</li>
<li>常数矩阵与矩阵乘积的微分矩阵为$d(AXB)=A(dX)B$</li>
<li>矩阵函数$U=F(X),V=G(X),W=H(X)$乘积的微分矩阵为<script type="math/tex; mode=display">
 d(UV)=(dU)V+U(dV)\\
 d(UVW)=(dU)VW+U(dV)W+UV(dW)</script></li>
<li>矩阵$X$的迹的矩阵微分$d(tr(X))$等于矩阵微分$dX$的迹$tr(dX)$，即<script type="math/tex; mode=display">
 d(tr(X))=tr(dX)</script> 7.1 从而可推导出矩阵函数$F(X)$的迹的矩阵微分为$d(tr(F(X)))=tr(d(F(X)))$</li>
<li>行列式的微分为<script type="math/tex; mode=display">
 d|X|=|X|tr(X^{-1}dX)</script> 8.1 从而可推导出矩阵函数$F(X)$的行列式的微分为$d(|F(X)|)=|F(X)|tr(F^{-1}(X)d(F(X)))$</li>
<li>矩阵函数的<code>Kronecker</code>积的微分矩阵为<script type="math/tex; mode=display">
 d(U\bigotimes V)=(dU)\bigotimes V+U\bigotimes dV</script></li>
<li>矩阵函数的<code>Hadamard</code>积的微分矩阵为<script type="math/tex; mode=display">
d(U* V)=(dU)* V+U* dV</script></li>
<li>向量化函数$vec(X)$的微分矩阵等于$X$的微分矩阵的向量化函数，即<script type="math/tex; mode=display">
d(vec(X))=vec(dX)</script></li>
<li>矩阵对数的微分矩阵为<script type="math/tex; mode=display">
d\log X=X^{-1}dX</script>12.1 从而可推导出矩阵函数$F(X)$的对数的微分矩阵为$d(\log F(X))=F^{-1}(X)d(F(X))$</li>
<li>逆矩阵的微分矩阵为<script type="math/tex; mode=display">
d(X^{-1})=-X^{-1}(dX)X^{-1}</script></li>
</ol>
<h2 id="标量函数的Jacobian矩阵辨识"><a href="#标量函数的Jacobian矩阵辨识" class="headerlink" title="标量函数的Jacobian矩阵辨识"></a>标量函数的Jacobian矩阵辨识</h2><p>多变量函数$f(x_{1},…,x_{m})$在点$(x_{1},…,x_{m})$可微分的充分条件是偏导数$\frac {\partial f}{\partial x_{1}},…,\frac {\partial f}{\partial x_{m}}$均存在，且连续。全微分公式如下：</p>
<script type="math/tex; mode=display">
df(x_{1},...,x_{m})=\frac {\partial f}{\partial x_{1}}dx_{1}+...+\frac {\partial f}{\partial x_{m}}dx_{m}</script><p>若矩阵的标量函数$f(x)$在$m\times n$矩阵点$X$可微分，则$Jacobian$矩阵可直接通过以下公式辨识：</p>
<script type="math/tex; mode=display">
df(x)=tr(Adx)\Leftrightarrow D_{x}f(x)=A\\
df(X)=tr(AdX)\Leftrightarrow D_{X}f(X)=A</script><p>要点如下：</p>
<ol>
<li>标量函数$f(X)$总可以写成迹函数的形式，因为$f(X)=tr(f(X))$</li>
<li>无论$dX$出现在迹函数内的任何位置，总可以通过迹函数的性质$tr[A(dX)B]=tr(BAdX)$，将$dX$写到迹函数的最右端，从而得到迹函数微分矩阵的规范形式</li>
<li>对于$(dX)^{T}$，总可以通过迹函数的性质$tr[A(dX)^{T}B]=tr(A^{T}B^{T}dX)$，写成迹函数微分矩阵的规范形式</li>
</ol>
<p>计算标量函数$f(x)=x^{T}Ax$，$A$是正方常数矩阵，求梯度矩阵</p>
<script type="math/tex; mode=display">
df(x)=d(tr(x^{T}Ax))
=tr[(dx)^{T}Ax+x^{T}Adx]\\
=tr([(dx)^{T}Ax]^{T}+x^{T}Adx)
=tr(x^{T}A^{T}dx+x^{T}Adx)
=tr(x^{T}(A+A^{T})dx)</script><p>所以$Jacobian$矩阵为$x^{T}(A+A^{T})$，梯度矩阵为$(A+A^{T})x$</p>
<p>计算$tr(X^{T}X)$的梯度矩阵</p>
<script type="math/tex; mode=display">
dtr(X^{T}X)=tr(d[X^{T}X])=tr((dX)^{T}X+X^{T}dX)\\
=tr((dX)^{T}X)+tr(X^{T}dX)
=tr(X^{T}dX)+tr(X^{T}dX)
=tr(2X^{T}dX)</script><p>所以$Jacobian$矩阵为$2X^{T}$，梯度矩阵为$2X$</p>
<p>常用的迹函数的微分矩阵及其$Jacobian$矩阵参考<code>《矩阵分析与应用》第3.2章表3.2.1</code></p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title>Jacobian矩阵和梯度矩阵</title>
    <url>/posts/29422005.html</url>
    <content><![CDATA[<p>参考：《矩阵分析与应用》第3章 3.1 Jacobian矩阵与梯度矩阵</p><p>在<code>pytorch</code>的<code>autograd</code>包中，利用<code>Jacobian</code>（雅格比）矩阵进行梯度的计算</p><a id="more"></a>

<p>学习实值标量函数、实值向量函数和实值矩阵函数相对于实向量变元或矩阵变元的偏导</p>
<h2 id="计算符号"><a href="#计算符号" class="headerlink" title="计算符号"></a>计算符号</h2><ul>
<li>实向量变元：$x=[x_{1},…,x_{m}]^T\in R^{m}$</li>
<li>实矩阵变元：$X=[x_{1},…,x_{n}]\in R^{m\times n}$</li>
<li>实值标量函数<ul>
<li>$f(X)\in R$，其变元是$m\times 1$实值向量$x$，记作$f:R^{m}\rightarrow R$</li>
<li>$f(X)\in R$，其变元是$m\times n$实矩阵$X$，记作$f:R^{m\times n}\rightarrow R$</li>
</ul>
</li>
<li>$p$维实列向量函数<ul>
<li>$f(x)\in R^{p}$，其变元是$m\times 1$实值向量$x$，记作$f:R^{m}\rightarrow R^{p}$</li>
<li>$f(X)\in R^{p}$，其变元是$m\times n$实矩阵$X$，记作$f:R^{m}\rightarrow R^{p}$</li>
</ul>
</li>
<li>$p\times q$维实矩阵函数<ul>
<li>$f(x)\in R^{p\times q}$，其变元是$m\times 1$实值向量$x$，记作$f:R^{m}\rightarrow R^{p\times q}$</li>
<li>$f(X)\in R^{p\times q}$，其变元是$m\times n$实矩阵$X$，记作$f:R^{m}\rightarrow R^{p\times q}$</li>
</ul>
</li>
</ul>
<p>实值函数的分类</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">函数类型</th>
<th style="text-align:center">向量变元$x\in R^{m}$</th>
<th>矩阵变元$X\in R^{m\times n}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">标量函数$f\in R$</td>
<td style="text-align:center">$f(x), \ f: R^{m}\rightarrow R$</td>
<td>$f(X), \ f: R^{m\times n}\rightarrow R$</td>
</tr>
<tr>
<td style="text-align:center">向量函数$f\in R^{p}$</td>
<td style="text-align:center">$f(x), \ f: R^{m}\rightarrow R^{p}$</td>
<td>$f(X), \ f: R^{m\times n}\rightarrow R^{p}$</td>
</tr>
<tr>
<td style="text-align:center">矩阵函数$F\in R^{p\times q}$</td>
<td style="text-align:center">$F(x), \ f: R^{m}\rightarrow R^{p\times q}$</td>
<td>$F(X), \ F: R^{m\times n}\rightarrow R^{p\times q}$</td>
</tr>
</tbody>
</table>
</div>
<h2 id="行向量偏导算子和Jacobian矩阵"><a href="#行向量偏导算子和Jacobian矩阵" class="headerlink" title="行向量偏导算子和Jacobian矩阵"></a>行向量偏导算子和Jacobian矩阵</h2><h3 id="实值标量函数"><a href="#实值标量函数" class="headerlink" title="实值标量函数"></a>实值标量函数</h3><p>定义实向量变元$x=[x_{1},…,x_{m}]^T$，$1\times m$行向量偏导算子记为</p>
<script type="math/tex; mode=display">
D_{x}=\frac {\partial }{\partial x^T}
=[\frac {\partial }{\partial x_{1}},...,\frac {\partial }{\partial x_{m}}]</script><p>对于实值标量函数$f(x)$而言，对于$x$的偏导向量是一个$1\times m$行向量</p>
<script type="math/tex; mode=display">
D_{x}f(x)=\frac {\partial f(x)}{\partial x^T}
=[\frac {\partial f(x)}{\partial x_{1}},...,\frac {\partial f(x)}{\partial x_{m}}]</script><p>当变元为实值矩阵$X\in R^{m\times n}$时，其偏导向量有两种表示形式</p>
<script type="math/tex; mode=display">
D_{X}f(X)=\frac {\partial f(X)}{\partial X^T}=
\begin{bmatrix}
\frac {\partial f(X)}{\partial x_{11}} & \dots & \frac {\partial f(X)}{\partial x_{m1}}\\ 
\vdots & \vdots & \vdots\\ 
\frac {\partial f(X)}{\partial x_{1n}} & \vdots & \frac {\partial f(X)}{\partial x_{mn}}
\end{bmatrix}
\in R^{n\times m}</script><p>或者</p>
<script type="math/tex; mode=display">
D_{vecX}f(X)=[\frac {\partial f(X)}{\partial x_{11}},...,\frac {\partial f(X)}{\partial x_{m1}},...,\frac {\partial f(X)}{\partial x_{1n}},...,\frac {\partial f(X)}{\partial x_{mn}}]</script><p>$D_{X}f(X)$称为实值标量函数$f(X)$关于矩阵变元$X$的$Jacobian$矩阵</p>
<p>$D_{vecX}f(X)$称为实值标量函数$f(X)$关于矩阵变元$X$的<strong>行偏导向量</strong></p>
<p>两者之间关系</p>
<script type="math/tex; mode=display">
D_{vecX}f(X)=rvec(D_{X}f(X))=(vec(D_{X}^{T}f(X)))^T</script><p>即实值标量函数$f(X)$的行向量偏导$D_{vecX}f(X)$等于$Jacobian$矩阵的转置$D_{X}^{T}f(X)$的列向量化$vec(D_{X}^{T}f(X)$的转置</p>
<h3 id="实值矩阵函数"><a href="#实值矩阵函数" class="headerlink" title="实值矩阵函数"></a>实值矩阵函数</h3><p>计算实值矩阵函数$F(X)=[f_{kl}]_{k=1,l=1}^{p,q}\in R^{p\times q}$对于矩阵变元$X\in R^{m\times n}$的行偏导矩阵:</p>
<p>先通过列向量化，将$p\times q$矩阵函数$F(X)$转换成$pq\times 1$列向量</p>
<script type="math/tex; mode=display">
vec(F(X))=
[f_{11}(X),...,f_{p1}(X),...,f_{1q}(X),...,f_{pq}(X)]^T\in R^{pq}</script><p>然后，将该列向量对变元$X$的列向量化的转置$(vecX)^T$求偏导，给出$pq\times mn$维$Jacobian$矩阵</p>
<script type="math/tex; mode=display">
D_{X}F(X)=\frac {\partial vec(F(X))}{\partial (vecX)^T}\in R^{pq\times mn}</script><p>具体表达式如下：</p>
<script type="math/tex; mode=display">
D_{X}F(X)=
\begin{bmatrix}
\frac {\partial f_{11}}{\partial (vecX)^T}\\ 
\vdots\\ 
\frac {\partial f_{p1}}{\partial (vecX)^T}\\ 
\vdots\\ 
\frac {\partial f_{1q}}{\partial (vecX)^T}\\ 
\vdots\\ 
\frac {\partial f_{pq}}{\partial (vecX)^T}
\end{bmatrix}=
\begin{bmatrix}
\frac {\partial f_{11}}{\partial x_{11}} & \dots && \frac {\partial f_{11}}{\partial x_{m1}} & \dots & \frac {\partial f_{11}}{\partial x_{1n}} & \dots & \frac {\partial f_{11}}{\partial x_{mn}}\\ 
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\ 
\frac {\partial f_{p1}}{\partial x_{11}} & \dots && \frac {\partial f_{p1}}{\partial x_{m1}} & \dots & \frac {\partial f_{p1}}{\partial x_{1n}} & \dots & \frac {\partial f_{p1}}{\partial x_{mn}}\\ 
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
\frac {\partial f_{1q}}{\partial x_{11}} & \dots && \frac {\partial f_{1q}}{\partial x_{m1}} & \dots & \frac {\partial f_{1q}}{\partial x_{1n}} & \dots & \frac {\partial f_{1q}}{\partial x_{mn}}\\  
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
\frac {\partial f_{pq}}{\partial x_{11}} & \dots && \frac {\partial f_{pq}}{\partial x_{m1}} & \dots & \frac {\partial f_{pq}}{\partial x_{1n}} & \dots & \frac {\partial f_{pq}}{\partial x_{mn}}\\ 
\end{bmatrix}</script><h2 id="列向量偏导算子和梯度矩阵"><a href="#列向量偏导算子和梯度矩阵" class="headerlink" title="列向量偏导算子和梯度矩阵"></a>列向量偏导算子和梯度矩阵</h2><p><strong>采用列向量形式定义的偏导算子称为列向量偏导算子，又称为梯度算子</strong></p>
<h3 id="实值标量函数-1"><a href="#实值标量函数-1" class="headerlink" title="实值标量函数"></a>实值标量函数</h3><p>定义实向量变元$x=[x_{1},…,x_{m}]^T$，$1\times m$行向量偏导算子记为</p>
<script type="math/tex; mode=display">
\bigtriangledown_{x}=\frac {\partial }{\partial x^T}
=[\frac {\partial }{\partial x_{1}},...,\frac {\partial }{\partial x_{m}}]^T</script><p>对于实值标量函数$f(x)$而言，对于$x$的偏导向量$\bigtriangledown_{x}f(x)$是一个$m\times 1$列向量</p>
<script type="math/tex; mode=display">
D_{x}f(x)=\frac {\partial f(x)}{\partial x}
=[\frac {\partial f(x)}{\partial x_{1}},...,\frac {\partial f(x)}{\partial x_{m}}]^T</script><p>将实值矩阵变元$X\in R^{m\times n}$列向量化后，关于矩阵变元$X$的梯度向量为</p>
<script type="math/tex; mode=display">
\bigtriangledown_{vecX}f(X)=\frac {\partial f(X)}{\partial vecX}
=[\frac {\partial f(X)}{\partial x_{11}},...,\frac {\partial f(X)}{\partial x_{m1}},...,\frac {\partial f(X)}{\partial x_{1n}},...,\frac {\partial f(X)}{\partial x_{mn}}]^T</script><p>或者</p>
<script type="math/tex; mode=display">
\bigtriangledown_{X}f(X)=\frac {\partial f(X)}{\partial X}=
\begin{bmatrix}
\frac {\partial f(X)}{\partial x_{11}} & \dots & \frac {\partial f(X)}{\partial x_{1n}}\\ 
\vdots & \vdots & \vdots\\ 
\frac {\partial f(X)}{\partial x_{m1}} & \vdots & \frac {\partial f(X)}{\partial x_{mn}}
\end{bmatrix}</script><p>前者称为实值标量函数$f(X)$关于实值矩阵变元$X$的列向量偏导算子</p>
<p>后者称为实值标量函数$f(X)$关于实值矩阵变元$X$的梯度矩阵</p>
<p><strong>所以实值标量函数$f(X)$的梯度矩阵等于$Jacobian$矩阵的转置</strong></p>
<script type="math/tex; mode=display">
\bigtriangledown_{X}f(X)=D_{X}^T f(X)</script><h3 id="实值矩阵函数-1"><a href="#实值矩阵函数-1" class="headerlink" title="实值矩阵函数"></a>实值矩阵函数</h3><p>计算实值矩阵函数$F(X)\in R^{p\times q}$对于矩阵变元$X\in R^{m\times n}$的梯度矩阵</p>
<p>先通过列向量化，将$p\times q$矩阵函数$F(X)$转换成$pq\times 1$列向量</p>
<script type="math/tex; mode=display">
vec(F(X))=
[f_{11}(X),...,f_{p1}(X),...,f_{1q}(X),...,f_{pq}(X)]^T\in R^{pq}</script><p>然后，将该列向量对变元$X$的列向量化$vecX$求偏导，给出$pq\times mn$维梯度矩阵</p>
<p>具体表达式如下：</p>
<script type="math/tex; mode=display">
\bigtriangledown_{X}F(X)=
\begin{bmatrix}
\frac {\partial f_{11}}{\partial vecX}\\ 
\vdots\\ 
\frac {\partial f_{p1}}{\partial vecX}\\ 
\vdots\\ 
\frac {\partial f_{1q}}{\partial vecX}\\ 
\vdots\\ 
\frac {\partial f_{pq}}{\partial vecX}
\end{bmatrix}=
\begin{bmatrix}
\frac {\partial f_{11}}{\partial x_{11}} & \dots && \frac {\partial f_{11}}{\partial x_{11}} & \dots & \frac {\partial f_{11}}{\partial x_{11}} & \dots & \frac {\partial f_{11}}{\partial x_{11}}\\ 
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\ 
\frac {\partial f_{p1}}{\partial x_{m1}} & \dots && \frac {\partial f_{p1}}{\partial x_{m1}} & \dots & \frac {\partial f_{p1}}{\partial x_{m1}} & \dots & \frac {\partial f_{p1}}{\partial x_{m1}}\\ 
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
\frac {\partial f_{1q}}{\partial x_{1n}} & \dots && \frac {\partial f_{1q}}{\partial x_{1n}} & \dots & \frac {\partial f_{1q}}{\partial x_{1n}} & \dots & \frac {\partial f_{1q}}{\partial x_{1n}}\\  
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
\frac {\partial f_{pq}}{\partial x_{mn}} & \dots && \frac {\partial f_{pq}}{\partial x_{mn}} & \dots & \frac {\partial f_{pq}}{\partial x_{mn}} & \dots & \frac {\partial f_{pq}}{\partial x_{mn}}\\ 
\end{bmatrix}</script><p><strong>所以实值矩阵函数$f(X)$的梯度矩阵等于$Jacobian$矩阵的转置</strong></p>
<script type="math/tex; mode=display">
\bigtriangledown_{X}F(X)=(D_{X} F(X))^T</script><h2 id="偏导和梯度计算"><a href="#偏导和梯度计算" class="headerlink" title="偏导和梯度计算"></a>偏导和梯度计算</h2><p>实值函数对于矩阵变元$X$的梯度计算有如下性质和法则</p>
<ol>
<li>若$f(X)=c$为常数，其中$X\in R^{m\times n}$，则梯度$\frac {\partial c}{\partial X}=O_{m\times n}$（<strong>维数相容原则</strong>）</li>
<li>线性法则。若$f(X)$和$g(X)$分别是矩阵$X$的实值函数，$c_{1}$和$c_{2}$为实常数，那么</li>
</ol>
<script type="math/tex; mode=display">
\frac {\partial [c_{1}f(X)+c_{2}g(X)]}{\partial X}
=c_{1}\frac {\partial f(X)}{\partial X}
+c_{2}\frac {\partial g(X)}{\partial X}</script><ol>
<li>乘积法则。若$f(X), g(X)$和$h(X)$都是矩阵$X$的实值函数，则</li>
</ol>
<script type="math/tex; mode=display">
\frac {\partial [f(X)g(X)]}{\partial X}
=g(X)\frac {\partial f(X)}{\partial X}
+f(X)\frac {\partial g(X)}{\partial X}</script><p>以及</p>
<script type="math/tex; mode=display">
\frac {\partial [f(X)g(X)h(X)]}{\partial X}
=g(X)h(X)\frac {\partial f(X)}{\partial X}
+f(X)h(X)\frac {\partial g(X)}{\partial X}
+f(X)g(X)\frac {\partial h(X)}{\partial X}</script><ol>
<li>商法则。若$g(X)\neq 0$，则</li>
</ol>
<script type="math/tex; mode=display">
\frac {\partial [f(X)/g(X)]}{\partial X}
=\frac {1}{g(X)^2}[g(X)\frac {\partial f(X)}{\partial X}-f(X)\frac {\partial g(X)}{\partial X}]</script><ol>
<li>链式法则。令$X$为$m\times n$矩阵，且$y=f(X)$和$g(y)$分别是以矩阵$X$和标量$y$为变元的实值函数，则</li>
</ol>
<script type="math/tex; mode=display">
\frac {\partial g(f(X))}{\partial X}
=\frac {dg(y)}{dy} \frac {\partial f(X)}{\partial X}</script><h3 id="实值标量函数-2"><a href="#实值标量函数-2" class="headerlink" title="实值标量函数"></a>实值标量函数</h3><p>针对实值标量函数有如下推论</p>
<ol>
<li>实值函数$f(x)=x^{T}Ax$的行偏导向量为$Df(x)=x^{T}(A+A^{T})$，梯度向量为$\bigtriangledown_{X}f(x)=(Df(X))^{T}=(A^{T}+A)x$</li>
<li>实值函数$f(x)=a^{T}XX^{T}b$，其中$X\in R^{m\times n},a,b\in R^{n\times 1}$，$Jacobian$矩阵为$D_{X}f(X)=X^{T}(ba^{T}+ab^{T})$，梯度矩阵为$\bigtriangledown_{X}f(x)=(ab^{T}+ba^{T})X$</li>
<li>实值函数$f(X)=tr(XB)$，其中$X\in R^{m\times n}, b\in R^{n\times m}, tr(BX)=tr(XB)$，所以$Jacobian$矩阵为$D_{X}tr(XB)=D_{X}tr(BX)=B$，梯度矩阵为$\bigtriangledown_{X}tr(XB)=\bigtriangledown_{X}tr(BX)=B^{T}$</li>
</ol>
<p>以推论一为例，假设</p>
<script type="math/tex; mode=display">
x = \begin{bmatrix}
x_{1}\\ 
x_{2}
\end{bmatrix} \ 
A=\begin{bmatrix}
a_{11} & a_{12}\\ 
a_{21} & a_{22}
\end{bmatrix}</script><p>所以</p>
<script type="math/tex; mode=display">
f(x)=x^{T}Ax=
\begin{bmatrix}
x_{1} & x_{2}
\end{bmatrix}
\begin{bmatrix}
a_{11} & a_{12}\\ 
a_{21} & a_{22}
\end{bmatrix}
\begin{bmatrix}
x_{1}\\ 
x_{2}
\end{bmatrix}
=\sum_{k=1}^{2}\sum_{l=1}^{2}a_{kl}x_{k}x_{l}</script><script type="math/tex; mode=display">
=[x_{1}a_{11}+x_{2}a_{21}, x_{1}a_{12}+x_{2}a_{22}]
\begin{bmatrix}
x_{1}\\ 
x_{2}
\end{bmatrix}
=x_{1}a_{11}x_{1}+x_{2}a_{21}x_{1}+x_{1}a_{12}x_{2}+x_{2}a_{22}x_{2}</script><script type="math/tex; mode=display">
Df(X)=\frac {\partial f(x)}{\partial x}=
[x_{1}a_{11}+a_{11}x_{1}+x_{2}a_{21}+a_{12}x_{2}, a_{21}x_{1}+x_{1}a_{12}+x_{2}a_{22}+a_{22}x_{2}]=\\
[x_{1}a_{11}+x_{2}a_{21}, x_{1}a_{12}+x_{2}a_{22}]
+[a_{11}x_{1}+a_{12}x_{2}, a_{21}x_{1}+a_{22}x_{2}]\\
=[x_{1},x_{2}]\begin{bmatrix}
a_{11} & a_{12}\\ 
a_{21} & a_{22}
\end{bmatrix}
+[x_{1},x_{2}]\begin{bmatrix}
a_{11} & a_{21}\\ 
a_{12} & a_{22}
\end{bmatrix}
=x^{T}A+x^{T}A^{T}
=x^{T}(A+A^{T})</script>]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title>矩阵基础</title>
    <url>/posts/d1deacd1.html</url>
    <content><![CDATA[<p>小结矩阵求解过程中的基础知识</p><ul>
<li>标量、向量和矩阵</li>
<li>矩阵乘法/积</li>
<li>转置、共扼、共扼转置</li>
<li>矩阵的迹</li>
<li>向量化和矩阵化</li>
</ul><a id="more"></a>

<h2 id="标量、向量和矩阵"><a href="#标量、向量和矩阵" class="headerlink" title="标量、向量和矩阵"></a>标量、向量和矩阵</h2><p>参考：<a href="https://www.mathsisfun.com/algebra/scalar-vector-matrix.html" target="_blank" rel="noopener">Scalars, Vectors and Matrices</a></p>
<ul>
<li>标量（<code>scalar</code>）是一个数值，仅包含大小（<code>magnitude or size</code>）信息</li>
<li>向量（或称为矢量，<code>vector</code>）是一列数值，同时包含大小（<code>magnitude</code>）和方向（<code>direction</code>）信息</li>
<li>矩阵（<code>matrix）</code>是一个数值数组</li>
</ul>
<p>向量是矩阵的特殊情况（仅有一行或者仅有一列），所以对于矩阵的操作也能应用于向量</p>
<h2 id="矩阵乘法-积"><a href="#矩阵乘法-积" class="headerlink" title="矩阵乘法/积"></a>矩阵乘法/积</h2><p>参考：</p>
<p>《矩阵分析与应用》第一章 1.1.2 矩阵的基本运算</p>
<p>《矩阵分析与应用》第一章 1.9.2 Hadamard积</p>
<p>《矩阵分析与应用》第一章 1.10.1 Kronnecker积及其性质</p>
<p><a href="https://baike.baidu.com/item/%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95" target="_blank" rel="noopener">矩阵乘法</a></p>
<ol>
<li><p>矩阵分别和标量/向量和矩阵的<strong>乘积</strong></p>
<p> 1.1 令$A=[a_{ij}]$是一个$m\times n$矩阵，且$\alpha$是一个标量。乘积$\alpha A$是一个$m\times n$矩阵，定义为$[\alpha A]_{ij}=\alpha a_{ij}$<br> 1.2 $m\times n$矩阵$A=[a_{ij}]$与$r\times 1$向量$x=[x_{1},…,x_{n}]^T$的乘积$Ax$只有当$n=r$时才存在，它是一个$m\times 1$向量，定义为</p>
<script type="math/tex; mode=display">
 [Ax]_{i}=\sum_{j=1}^{n}a_{ij}x_{j}, \ i=1,...,m</script><p> 1.3 $m\times n$矩阵$A=[a_{ij}]$与$r\times s$矩阵$B=[b_{ij}]$的乘积$AB$只有当$n=r$时才存在，它是一个$m\times s$矩阵，定义为</p>
<script type="math/tex; mode=display">
 [AB]_{ij}=\sum_{k=1}^{n}a_{ik}b_{bj}, \ i=1,...,m; \ j=1,...,s</script></li>
<li>矩阵相同位置元素相乘 - <strong>Hadamard积</strong><br> $m\times n$矩阵$A=[a_{ij}]$与$m\times n$矩阵$B=[b_{ij}]$的Hadamard积记作$A*B$，它仍然是一个$m\times n$矩阵，其元素定义为两个矩阵对应元素的乘积<script type="math/tex; mode=display">
 (A*B)_{ij}=a_{ij}b_{ij}</script></li>
<li>Kronecker积<br> 3.1 $m\times n$矩阵$A=[a_{1},…,a_{n}]$和$p\times q$矩阵$B$的<strong>右Kronecker积</strong>记作$A\bigotimes B$，是一个$mp\times nq$矩阵，定义为<script type="math/tex; mode=display">
 A\bigotimes B=[a_{1}B,...,a_{n}B]=[a_{ij}B]_{i=1,j=1}^{m,n}=\begin{bmatrix}
 a_{11}B & a_{12}B & \dots & a_{1n}B\\ 
 a_{21}B & a_{22}B & \dots & a_{2n}B\\ 
 \vdots & \vdots & \vdots & \vdots\\ 
 a_{m1}B & a_{m2}B & \dots & a_{mn}B
 \end{bmatrix}</script> 3.2 $m\times n$矩阵$A=[a_{1},…,a_{n}]$和$p\times q$矩阵$B$的 <strong>(左)Kronecker积</strong> 记作$A\bigotimes B$，是一个$mp\times nq$矩阵，定义为<script type="math/tex; mode=display">
 A\bigotimes B=[a_{1}B,...,a_{n}B]=[a_{ij}B]_{i=1,j=1}^{m,n}=\begin{bmatrix}
 Ab_{11} & Ab_{12} & \dots & Ab_{1q}\\ 
 Ab_{21} & Ab_{22} & \dots & Ab_{2q}\\ 
 \vdots & \vdots & \vdots & \vdots\\ 
 Ab_{m1} & Ab_{m2} & \dots & Ab_{pq}
 \end{bmatrix}</script> 3.3 Kronecker积也称为<strong>直积</strong>（direct product）或者<strong>张量积</strong>（tensor product）通常使用<strong>右Keonecker积</strong>的形式进行书写</li>
</ol>
<h2 id="转置、共扼、共扼转置"><a href="#转置、共扼、共扼转置" class="headerlink" title="转置、共扼、共扼转置"></a>转置、共扼、共扼转置</h2><p>参考：</p>
<p>《矩阵分析与应用》第一章 1.1.2 矩阵的基本运算</p>
<p><a href="https://zh.wikipedia.org/wiki/%E5%85%B1%E8%BD%AD" target="_blank" rel="noopener">共轭</a></p>
<p><a href="https://baike.baidu.com/item/%E8%BD%AC%E7%BD%AE" target="_blank" rel="noopener">转置</a></p>
<p><strong>转置</strong>指矩阵的行列对应互换；<strong>共轭负数</strong>是指实数部分相同而虚数部分互为相反数的两个复数</p>
<p>若$A=[a_{ij}]$是一个$m\times n$矩阵，则</p>
<ul>
<li>$A$的转置记作$A^T$，是一个$n\times m$矩阵，其元素定义为$[A^T]_{ij}=a_{ji}$</li>
<li>$A$的复数共轭 $A^{<em>}$ 仍然是一个 $m\times n$ 矩阵，其元素定义为 $[A^{</em>}]_{ij}=a^{*}_{ij}$</li>
<li>$A$的（复）共轭转置记作$A^{H}$，它是一个$n\times m$矩阵，定义为</li>
</ul>
<script type="math/tex; mode=display">
A^{H}=\begin{bmatrix}
a^{*}_{11} & a^{*}_{21} & \dots & a^{*}_{m1}\\ 
a^{*}_{12} & a^{*}_{22} & \dots & a^{*}_{m2}\\ 
\vdots & \vdots & \vdots & \vdots\\ 
a^{*}_{1n} & a^{*}_{2n} & \dots & a^{*}_{mn}
\end{bmatrix}</script><p><strong>共轭转置又称为Hermitian伴随、Hermitian转置或Hermitian共轭</strong></p>
<p><strong>对称矩阵</strong>：满足$A^T=A$的正方实矩阵</p>
<p><strong>Hermitian矩阵（复共轭对称矩阵）</strong>：满足$A^H=A$的正方复矩阵</p>
<p>共扼转置和转置的关系</p>
<script type="math/tex; mode=display">
A^H=(A^*)^T=(A^T)^*</script><h2 id="矩阵的迹"><a href="#矩阵的迹" class="headerlink" title="矩阵的迹"></a>矩阵的迹</h2><p>参考：《矩阵分析与应用》第一章 1.6.4 矩阵的迹</p>
<p>$n\times n$矩阵$A$的对角元素之和称为$A$的迹（trace），记作$tr(A)$，即有</p>
<script type="math/tex; mode=display">
tr(A)=a_{11}+...+a_{nm}=\sum_{i=1}^{n}a_{ii}</script><p><strong>注意：非正方矩阵无迹的定义</strong></p>
<h3 id="关于迹的等式"><a href="#关于迹的等式" class="headerlink" title="关于迹的等式"></a>关于迹的等式</h3><ol>
<li>若$A$和$B$均为$n\times n$矩阵，则$tr(A\pm B)=tr(A)\pm tr(B)$</li>
<li>若$A$和$B$均为$n\times n$矩阵，并且$c_{1}$和$c_{2}$为常数，则$tr(c_{1}A\pm c_{2}B)=c_{1}tr(A)\pm c_{2}tr(B)$。特别地，若$B=O$，则$tr(cA)=ctr(A)$</li>
<li>矩阵$A$的转置，复数共轭和复共轭转置的迹分别为 $tr(A^{T})=tr(A)，tr(A^{<em>})=[tr(A)]^{</em>}, tr(A^{H})=[tr(A)]^{H}$</li>
<li>若$A\in C^{m\times n}, B\in C^{n\times m}$，则$tr(AB)=tr(BA)$</li>
<li>若$A$是一个$m\times n$矩阵，则$tr(A^H A)=0\Leftrightarrow A=O_{m\times n}（零矩阵）$</li>
<li>$x^{H}Ax=tr(Axx^H)$和$y^H x=tr(xy^H)$</li>
<li>迹等于特征值之和，即$tr(A)=\lambda_{1}+…+\lambda_{n}$</li>
<li>分块矩阵的迹满足<script type="math/tex; mode=display">
 tr\begin{bmatrix}
 A& B\\ 
 C& D
 \end{bmatrix}=tr(A)+tr(D)</script> 其中$A\in C^{m\times m}, B\in C^{m\times n}, C\in C^{n\times m}, D\in C^{n\times n}$</li>
<li>对于任何正整数$k$，有<script type="math/tex; mode=display">
 tr(A^k)=\sum_{i=1}^{n}\lambda _{i}^{k}</script></li>
</ol>
<p>根据迹的等式4进行推理，令$U=A, V=BC$和$U=AB, V=C$，有</p>
<script type="math/tex; mode=display">
tr(ABC)=tr(BCA)=tr(CAB)</script><h3 id="迹和Hadamard积"><a href="#迹和Hadamard积" class="headerlink" title="迹和Hadamard积"></a>迹和Hadamard积</h3><p>另$A,B,C$为$m\times n$矩阵，并且$1=[1,1,…,1]^T$为$n\times 1$求和向量，$D=diag(d_{1},d_{2},…,d_{m})$，其中$d_{i}=\sum_{j=1}^{n}a_{ij}$，则</p>
<script type="math/tex; mode=display">
tr(A^{T}(B*C))=tr((A^{T}*B^{T})C) \\
1^{T}A^{T}(B*C)1=tr(B^{T}DC)</script><p>证明如下，设</p>
<script type="math/tex; mode=display">
A=\begin{bmatrix}
a_{1} & a_{2} 
\end{bmatrix} \ 
B=\begin{bmatrix}
b_{1} & b_{2} 
\end{bmatrix} \ 
C=\begin{bmatrix}
c_{1} & c_{2} 
\end{bmatrix} \ 
D=\begin{bmatrix}
a_{1} & 0\\
0 & a_{2} 
\end{bmatrix}</script><p>所以</p>
<script type="math/tex; mode=display">
A^{T}(B*C)=
\begin{bmatrix}
a_{1}\\
a_{2} 
\end{bmatrix}
(\begin{bmatrix}
b_{1} & b_{2} 
\end{bmatrix}
*
\begin{bmatrix}
c_{1} & c_{2} 
\end{bmatrix})
=\begin{bmatrix}
a_{1}\\
a_{2} 
\end{bmatrix}
\begin{bmatrix}
b_{1}c_{1} & b_{2}c_{2} 
\end{bmatrix}
=\begin{bmatrix}
a_{1}b_{1}c_{1} & a_{1}b_{2}c_{2}\\
a_{2}b_{1}c_{1} & a_{2}b_{2}c_{2}
\end{bmatrix}</script><script type="math/tex; mode=display">
(A^{T}*B^{T})C=
(
\begin{bmatrix}
a_{1}\\
a_{2} 
\end{bmatrix}
*
\begin{bmatrix}
b_{1}\\
b_{2} 
\end{bmatrix}
)
\begin{bmatrix}
c_{1} & c_{2} 
\end{bmatrix}
=\begin{bmatrix}
a_{1}b_{1}\\
a_{2}b_{2}
\end{bmatrix}
\begin{bmatrix}
c_{1} & c_{2} 
\end{bmatrix}
=\begin{bmatrix}
a_{1}b_{1}c_{1} & a_{1}b_{1}c_{2}\\
a_{2}b_{2}c_{1} & a_{2}b_{2}c_{2}
\end{bmatrix}</script><script type="math/tex; mode=display">
\Rightarrow tr(A^{T}(B*C))=tr((A^{T}*B^{T})C)=a_{1}b_{1}c_{1}+a_{2}b_{2}c_{2}</script><script type="math/tex; mode=display">
1^{T}A^{T}(B*C)1=
1^{T}
\begin{bmatrix}
a_{1}\\
a_{2} 
\end{bmatrix}
(\begin{bmatrix}
b_{1} & b_{2} 
\end{bmatrix}
*\begin{bmatrix}
c_{1} & c_{2} 
\end{bmatrix})1
=1^{T}
\begin{bmatrix}
a_{1}\\
a_{2} 
\end{bmatrix}
\begin{bmatrix}
b_{1}c_{1} & b_{2}c_{2} 
\end{bmatrix}1\\
=(a_{1}+a_{2})
\begin{bmatrix}
b_{1}c_{1} & b_{2}c_{2} 
\end{bmatrix}1
=(a_{1}+a_{2})(b_{1}c_{1}+b_{2}c_{2})</script><script type="math/tex; mode=display">
tr(B^{T}DC)
=tr(
\begin{bmatrix}
b_{1}\\
b_{2} 
\end{bmatrix}
(a_{1}+a_{2})
\begin{bmatrix}
c_{1} & c_{2} 
\end{bmatrix}
)
=tr(
(a_{1}+a_{2})
\begin{bmatrix}
b_{1}\\
b_{2} 
\end{bmatrix}
\begin{bmatrix}
c_{1} & c_{2} 
\end{bmatrix}
)\\
=tr(
(a_{1}+a_{2})
\begin{bmatrix}
b_{1}c_{1} & b_{1}c_{2}\\
b_{2}c_{2} & b_{2}c_{2}
\end{bmatrix})
=(a_{1}+a_{2})(b_{1}c_{1}+b_{2}c_{2})</script><script type="math/tex; mode=display">
\Rightarrow 1^{T}A^{T}(B*C)1=tr(B^{T}DC)=(a_{1}+a_{2})(b_{1}c_{1}+b_{2}c_{2})</script><p>对于公式二而言，其矩阵大小变化如下：</p>
<script type="math/tex; mode=display">
R^{1\times n}\cdot R^{n\times m}\cdot (R^{m\times n}* R^{m\times n})\cdot R^{n\times 1}=R^{1}</script><p>所以只要满足结果为$R^{1}$，公式二可以变形如下：</p>
<p>假设$B/C$大小为$R^{n\times 1}$</p>
<script type="math/tex; mode=display">
1^{T}\cdot (B* C)=B^{T}\cdot C</script><h2 id="向量化和矩阵化"><a href="#向量化和矩阵化" class="headerlink" title="向量化和矩阵化"></a>向量化和矩阵化</h2><p>参考：《矩阵分析与应用》第一章 1.11.1 矩阵的向量化与向量的矩阵化</p>
<h3 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h3><ul>
<li>列向量化：矩阵$A\in R^{m\times n}$的向量化（vectorization）vec(A)是一个线性变换，它将矩阵$A=[a_{ij}]$的元素按列堆栈（column stacking），排列成一个$mn\times 1$向量</li>
</ul>
<script type="math/tex; mode=display">
vec(A)=[a_{11},...,a_{m1},...,a_{1n},...,a_{mn}]^T</script><ul>
<li>行向量化：按行堆栈（stack the rows）</li>
</ul>
<script type="math/tex; mode=display">
rvec(A)=[a_{11},...,a_{1n},...,a_{m1},...,a_{mn}]</script><p><strong>注意：默认矩阵向量化指的是列向量化</strong></p>
<p>行向量化和列向量化的关系：</p>
<script type="math/tex; mode=display">
rvec(A)=(vec(A^T))^T \\
vec(A^T)=(rvec(A^T))^T</script><p>存在一个$mn\times mn$置换矩阵，可以将一个矩阵的向量化$vec(A)$变换为其转置矩阵的向量化$vec(A^T)$，称为<strong>交换矩阵（communication matrix）</strong>，记作$K_{mn}$，定义为</p>
<script type="math/tex; mode=display">
K_{mn}vec(A)=vec(A^T)</script><p>同样存在一个将转置矩阵的向量化$vec(A^T)$变换为原矩阵的向量化$vec(A)$的交换矩阵，记作$K_{nm}$，定义为</p>
<script type="math/tex; mode=display">
K_{nm}vec(A^T)=vec(A)</script><h3 id="矩阵化"><a href="#矩阵化" class="headerlink" title="矩阵化"></a>矩阵化</h3><p>一个$mn\times 1$向量$a=[a_{1},…,a_{mn}]^T$转换为一个$m\times n$矩阵$A$的运算称为矩阵化（matrixing, maxicization），用符号$unvec_{m,n}(a)$表示，定义为</p>
<script type="math/tex; mode=display">
A_{m\times n}=unvec_{m,n}(a)=\begin{bmatrix}
a_{1} & a_{m+1} & \dots & a_{m(n-1)+1}\\ 
a_{2} & a_{m+2} & \dots & a_{m(n-1)+2}\\ 
\vdots & \vdots & \vdots & \vdots\\ 
a_{m} & a_{2m} & \dots & a_{mn}
\end{bmatrix}</script><script type="math/tex; mode=display">
A_{ij}=a_{i+(j-1)m},\ i=1,...,m;j=1,...,n</script><p>同样的，符号$unrvec_{m,n}(b)$记作行向量的矩阵化</p>
<script type="math/tex; mode=display">
B_{m\times n}
=unvec_{m,n}(b)
=\begin{bmatrix}
b_{1} & b_{m+1} & \dots & b_{m(n-1)+1}\\ 
b_{2} & b_{m+2} & \dots & b_{m(n-1)+2}\\ 
\vdots & \vdots & \vdots & \vdots\\ 
b_{m} & b_{2m} & \dots & b_{mn}
\end{bmatrix}</script><script type="math/tex; mode=display">
B_{ij}=a_{j+(i-1)n},\ i=1,...,m;j=1,...,n</script>]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title>导数、微分和梯度</title>
    <url>/posts/a9bec5e9.html</url>
    <content><![CDATA[<p>参考：</p><p>《高等数学》导数与微分</p><p>《高等数学》多元函数微分学</p><p>最近推导神经网络的前向传播和反向传播过程，经常会遇到有关导数、微分和梯度的内容，对它们的概念进行一次小结</p><a id="more"></a>



<ul>
<li>导数</li>
<li>微分</li>
<li>偏导数</li>
<li>全微分</li>
<li>方向导数</li>
<li>梯度</li>
</ul>
<h2 id="导数"><a href="#导数" class="headerlink" title="导数"></a>导数</h2><p>设函数$y=f(x)$在点$x_{0}$处的某个邻域$U(x_{0}, \delta)$内有定义，当自变量$x$在$x^{0}$处取得增量$\Delta x$（点$x+\Delta x$仍在该邻域内）时，相应地，函数$y=f(x)$取得增量$\Delta y=f(x_{0}+\Delta x)-f(x_{0})$，如果极限</p>
<script type="math/tex; mode=display">
\lim_{\Delta x\to 0}\frac {\Delta y}{\Delta x}=
\lim_{\Delta x\to 0}\frac {\Delta f(x_{0}+\Delta x)-f(x_{0})}{\Delta x}</script><p>存在，则称函数$y=f(x)$在点$x_{0}$处可导，并称这个极限值为函数$y=f(x)$在点$x_{0}$处的导数，记为</p>
<script type="math/tex; mode=display">
{y}'|_{x=x_{0}},\ f'(x_{0}),\ \frac {dy}{dx}|_{x=x_{0}}\ 或\ \frac {df(x)}{dx}|_{x=x_{0}}</script><p>即</p>
<script type="math/tex; mode=display">
f'(x_{0})=
\lim_{\Delta x\to 0}\frac {\Delta y}{\Delta x}=
\lim_{\Delta x\to 0}\frac {\Delta f(x_{0}+\Delta x)-f(x_{0})}{\Delta x}</script><p>函数$f(x)$在点$x_{0}$处可导有时也说成$f(x)$在点$x_{0}$具有导数或导数存在</p>
<p>如果极限不存在，则说$y=f(x)$在点$x_{0}$处不可导</p>
<h3 id="不可导情形"><a href="#不可导情形" class="headerlink" title="不可导情形"></a>不可导情形</h3><ol>
<li>当$\Delta x\to 0$时，$\frac {\Delta y}{\Delta x}$没有稳定的变化趋势</li>
<li>$\lim_{\Delta x\to 0}\frac {\Delta y}{\Delta x}=\infty $，此时也说导数为无穷大</li>
</ol>
<h3 id="左导数和右导数"><a href="#左导数和右导数" class="headerlink" title="左导数和右导数"></a>左导数和右导数</h3><p>设函数$y=f(x)$在点$x_{0}$的某个右邻域$[x_{0},x_{0}+\delta)$内有定义，如果极限</p>
<script type="math/tex; mode=display">
\lim_{\Delta x\to 0^{+}}\frac {\Delta f(x_{0}+\Delta x)-f(x_{0})}{\Delta x}\ 或\ 
\lim_{x\to x_{0}^{+}}\frac {f(x)-f(x_{0})}{x-x_{0}}</script><p>存在，则称此极限为函数$f(x)$在点$x_{0}$处的<strong>右导数</strong>，记作$f’_{+}(x_{0})</p>
<p>设函数$y=f(x)$在点$x_{0}$的某个右邻域$[x_{0},x_{0}+\delta)$内有定义，如果极限</p>
<script type="math/tex; mode=display">
\lim_{\Delta x\to 0^{-}}\frac {\Delta f(x_{0}+\Delta x)-f(x_{0})}{\Delta x}\ 或\ 
\lim_{x\to x_{0}^{-}}\frac {f(x)-f(x_{0})}{x-x_{0}}</script><p>存在，则称此极限为函数$f(x)$在点$x_{0}$处的<strong>左导数</strong>，记作$f’_{-}(x_{0})$</p>
<p>函数$y=f(x)$在点$x_{0}$处可导的<strong>充分必要条件</strong>是左导数$f’_{-}(x_{0})$和右导数$f’_{+}(x_{0})$都存在且相等</p>
<h3 id="可导性和连续性"><a href="#可导性和连续性" class="headerlink" title="可导性和连续性"></a>可导性和连续性</h3><p>函数连续只是函数可导的必要条件，但不是充分条件，所以如果函数在某点不连续，则函数在该点必不可导</p>
<p><strong>所以可导必连续，连续不一定可导，不连续一定不可导</strong></p>
<h3 id="四则运算法则"><a href="#四则运算法则" class="headerlink" title="四则运算法则"></a>四则运算法则</h3><ul>
<li>$[u(x)+v(x)]’=u’(x)\pm v’(x)$</li>
<li>$[u(x)v(x)]’=u’(x)v(x)+u(x)v’(x)$</li>
<li>$[\frac {u(x)}{v(x)}]’=\frac {u’(x)v(x)-u(x)v’(x)}{v^{2}(x)}$</li>
</ul>
<h2 id="微分"><a href="#微分" class="headerlink" title="微分"></a>微分</h2><p>设函数$y=f(x)$在某个区间内有定义，$x_{0}$及$x_{0}+\Delta x$在这个区间内，如果函数的增量$\Delta y=f(x_{0}+\Delta x)-f(x_{0})$可表示为</p>
<script type="math/tex; mode=display">
\Delta y=A\Delta x+o(\Delta x)</script><p>其中$A$是与$\Delta x$无关的常数，$o(\Delta x)$是比$\Delta x$高阶的无穷小，则称函数$y=f(x)$在点$x_{0}$可微，称$A\Delta x$为函数$y=f(x)$在点$x_{0}$相应于自变量增量$\Delta x$的微分，记作$dy|_{x=x_{0}}$或$df(x)|_{x=x_{0}}$，即</p>
<script type="math/tex; mode=display">
dy|_{x=x_{0}}=A\Delta x</script><h3 id="可微与可导"><a href="#可微与可导" class="headerlink" title="可微与可导"></a>可微与可导</h3><p>函数$y=f(x)$在点$x_{0}$处可微的充要条件是$f(x)$在点$x_{0}$处可导，且</p>
<script type="math/tex; mode=display">
dy|_{x=x_{0}}=f'(x_{0})\Delta x</script><p><strong>所以可微必可导，可导必可微，二者等价</strong></p>
<h2 id="偏导数"><a href="#偏导数" class="headerlink" title="偏导数"></a>偏导数</h2><p>设函数$z=f(x,y)$在点$(x_{0},y_{0})$的某一邻域内有定义，当$y$固定在$y_{0}$，而$x$在$x_{0}$处有增量$\Delta x$时，相应地函数有增量</p>
<script type="math/tex; mode=display">
f(x_{0}+\Delta x, y)-f(x_{0},y_{0})</script><p>如果</p>
<script type="math/tex; mode=display">
\lim_{\Delta x\to 0}\frac {f(x_{0}+\Delta x, y_{0})-f(x_{0},y_{0})}{\Delta x}</script><p>存在，则称此极限为函数$z=f(x,y)$在点$(x_{0},y_{0})$处对$x$的偏导数，记为</p>
<script type="math/tex; mode=display">
\frac{\partial z}{\partial x}|_{x=x_{0},y=y_{0}}, \ 
\frac{\partial f}{\partial x}|_{x=x_{0},y=y_{0}}, \ 
z_{x}|_{x=x_{0},y=y_{0}}, \ 或\ f_{x}(x_{0},y_{0})</script><p>类似地，函数$z=f(x,y)$在点$(x_{0},y_{0})$处对$y$的偏导数定义为</p>
<script type="math/tex; mode=display">
\lim_{\Delta y\to 0}\frac {f(x_{0}, y_{0}+\Delta y)-f(x_{0},y_{0})}{\Delta y}</script><p>记为</p>
<script type="math/tex; mode=display">
\frac{\partial z}{\partial y}|_{x=x_{0},y=y_{0}}, \ 
\frac{\partial f}{\partial y}|_{x=x_{0},y=y_{0}}, \ 
z_{y}|_{x=x_{0},y=y_{0}}, \ 或\ f_{y}(x_{0},y_{0})</script><p><strong>由偏导数的定义可知，求偏导数本质上是求一元函数的导数，函数对某一个变量求偏导数时，只需要把其余的自变量看成常数，因此一元函数微分法的求导法则全部适用于多元函数的偏导数</strong></p>
<h2 id="全微分"><a href="#全微分" class="headerlink" title="全微分"></a>全微分</h2><p>设二元函数$z=f(x,y)$在点$(x,y)$的某领域内有定义且偏导数$f_{x}(x,y), f_{y}(x,y)$存在，当变量$x,y$分别有增量$\Delta x, \Delta y$时，由一元函数增量与微分的关系，得</p>
<script type="math/tex; mode=display">
f(x+\Delta x,y)-f(x,y)\approx f_{x}(x,y)\Delta x \\
f(x,y+\Delta y)-f(x,y)\approx f_{y}(x,y)\Delta y</script><p>其中</p>
<script type="math/tex; mode=display">
f(x+\Delta x,y)-f(x,y), \ f(x,y+\Delta y)-f(x,y)</script><p>分别成为二元函数对$x$和对$y$的<strong>偏增量</strong>，而</p>
<script type="math/tex; mode=display">
f_{x}(x,y)\Delta x, \ f_{y}(x,y)\Delta y</script><p>分别称为二元函数对$x$和对$y$的<strong>偏微分</strong>，将</p>
<script type="math/tex; mode=display">
\Delta z=f(x+\Delta x,y+\Delta y)-f(x,y)</script><p>称为函数$f(x,y)$在点$(x,y)$处的<strong>全增量</strong></p>
<p>若函数$z=f(x,y)$在点$(x,y)$处的全增量可以表示为</p>
<script type="math/tex; mode=display">
\Delta z=f(x+\Delta x,y+\Delta y)-f(x,y)
=A\Delta x+B\Delta y+o(\rho )</script><p>其中，$A,B$不依赖于$\Delta x,\Delta y$，只与$x,y$有关，$\rho=\sqrt{(\Delta x)^{2}+(\Delta y)^{2}}$，$o(\rho )$是当$\rho \to 0$时比$\rho $高阶的无穷小量，则称函数$z=f(x,y)$在点$(x,y)$处<strong>可微</strong>，而称$A\Delta x+B\Delta y$为函数$z=f(x,y)$在点$(x,y)$处的<strong>全微分</strong>，记作</p>
<script type="math/tex; mode=display">
dz = A\Delta x+B\Delta y</script><h3 id="全微分、偏导数与连续性"><a href="#全微分、偏导数与连续性" class="headerlink" title="全微分、偏导数与连续性"></a>全微分、偏导数与连续性</h3><p>如果函数$z=f(x,y)$在点$(x,y)$处可微，则函数在该点连续</p>
<p><strong>所以连续是可微的必要条件，可微必连续</strong></p>
<p>如果函数$z=f(x,y)$在点$(x,y)$处的两个偏导数$\frac{\partial z}{\partial x}, \frac{\partial z}{\partial y}$存在且连续，则函数在该点可微</p>
<p><strong>所以偏导数存在且连续是可微的充分条件，可微必存在偏导数</strong></p>
<p><strong>偏导数和连续性没有关系</strong></p>
<h2 id="方向导数"><a href="#方向导数" class="headerlink" title="方向导数"></a>方向导数</h2><p>设函数$z=f(x,y)$在$P_{0}(x_{0},y_{0})$的某一领域$U(P_{0})$内有定义，自$P_{0}(x_{0},y_{0})$点引射线$l$，在$l$上任取一点$P(x_{0}+\Delta x,y_{0}+\Delta y),P\in U(P_{0})$</p>
<p>若$P$沿$l$趋近于$P_{0}$时，即当</p>
<script type="math/tex; mode=display">
\rho =\sqrt{(\Delta x)^2+(\Delta y)^2} \to 0</script><p>时，极限</p>
<script type="math/tex; mode=display">
\lim_{\rho \to o^{+}}\frac {f(x_{0}+\Delta x,y_{0}+\Delta y)-f(x_{0},y_{0})}{\rho}</script><p>存在，则称此极限为函数$f(x,y)$在点$P_{0}$处沿方向$l$的<strong>方向导数</strong>，记作$\frac{\partial f}{\partial l}|_{x=x_{0},y=y_{0}}$，即</p>
<script type="math/tex; mode=display">
\frac{\partial f}{\partial l}|_{x=x_{0},y=y_{0}}=
\lim_{\rho \to o^{+}}\frac {f(x_{0}+\Delta x,y_{0}+\Delta y)-f(x_{0},y_{0})}{\rho}</script><h3 id="方向导数和偏导数"><a href="#方向导数和偏导数" class="headerlink" title="方向导数和偏导数"></a>方向导数和偏导数</h3><p>如果函数$z=f(x,y)$在点$P_{0}(x_{0},y_{0})$的偏导数存在，则<strong>偏导数就是函数沿坐标轴正向的方向导数</strong></p>
<h2 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h2><p>设函数$z=f(x,y)$在平面区域$D$内具有一阶<strong>连续偏导数</strong>，则对于每一点$P_{0}(x_{0},y_{0})\in D$都可确定一个向量</p>
<script type="math/tex; mode=display">
f_{x}(x_{0},y_{0})i + f_{y}(x_{0},y_{0})j</script><p>该向量称为函数$z=f(x,y)$在点$P_{0}(x_{0},y_{0})$的梯度，记作$grad f(x_{0},y_{0})$或$\bigtriangledown f(x_{0},y_{0})$，即</p>
<script type="math/tex; mode=display">
grad f(x_{0},y_{0})=
f_{x}(x_{0},y_{0})i + f_{y}(x_{0},y_{0})j=
\{f_{x}(x_{0},y_{0}), f_{y}(x_{0},y_{0})\}</script><h3 id="梯度和方向导数"><a href="#梯度和方向导数" class="headerlink" title="梯度和方向导数"></a>梯度和方向导数</h3><p>设$e_{l}=\{\cos \alpha,\cos \beta\}$是与方向$l$同方向的单位向量，则由方向导数的计算公式得</p>
<script type="math/tex; mode=display">
\frac{\partial f}{\partial l}|_{x=x_{0},y=y_{0}}=
f_{x}(x_{0},y_{0})\cos \alpha+f_{y}(x_{0},y_{0})\cos \beta=
\{f_{x}(x_{0},y_{0}),f_{y}(x_{0},y_{0})\}\cdot \{ \cos \alpha, \cos \beta \}\\=
grad f(x_{0},y_{0})\cdot e_{l}=
|grad f(x_{0},y_{0})|\cos \theta</script><p>当$\theta = 0$，即方向$e_{l}$与梯度$grad f(x_{0},y_{0})$的方向相同时，方向导数$\frac{\partial f}{\partial l}|_{x=x_{0},y=y_{0}}=$取得最大值，也就是函数$f(x,y)$增加得最快，这个最大值就是梯度$grad f(x_{0},y_{0})$的模，即$|grad f(x_{0},y_{0})|$</p>
<p><strong>所以梯度向量的方向是函数在该点的方向导数取得最大值的方向，梯度向量的模就是方向导数的最大值</strong></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ol>
<li><p>一元还是多元</p>
<p> 导数和微分是一元函数定义</p>
<p> 偏导数、全微分、方向导数和梯度是多元函数定义</p>
</li>
<li><p>导数、微分和连续性关系</p>
<p> 导数和微分等价，可导必可微，可微必可导</p>
<p> 连续性是导数的必要关系，可导必连续，不连续必不可导</p>
<p> <img src="../imgs/导数、微分和梯度/math_relation1.PNG" alt></p>
</li>
<li><p>偏导数、全微分和连续性关系</p>
<p> 偏导数、全微分和连续性没有等价关系</p>
<p> 连续性和偏导数存在是可微的充分条件</p>
<p> 连续性是可微的必要条件，可微必连续</p>
<p> 偏导数是可微的必要条件，可微必可偏导</p>
<p> 连续性和偏导数没有关系</p>
<p> <img src="../imgs/导数、微分和梯度/math_relation2.PNG" alt></p>
</li>
<li><p>全微分、方向导数和梯度</p>
<p> 参考：</p>
<p> <a href="https://blog.csdn.net/czmacd/article/details/81178650" target="_blank" rel="noopener">导数、微分、偏导数、全微分、方向导数、梯度的定义与关系</a></p>
<p> <a href="https://www.zhihu.com/question/63660102/answer/259769616" target="_blank" rel="noopener">梯度与全微分的关系是什么？梯度方向上的增量是全微分么？</a></p>
<p> 全微分存在是方向导数存在的充分条件，全微分存在则方向导数存在</p>
<p> 梯度方向是方向导数取得最大变化的方向，梯度模就是最大变化值</p>
</li>
</ol>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络推导-批量数据</title>
    <url>/posts/66015d4d.html</url>
    <content><![CDATA[<p>参考：<a href="https://www.zhujian.tech/posts/cb820bb8.html">神经网络推导-单个数据</a></p><p>输入批量数据到神经网络，进行前向传播和反向传播的推导</p><h2 id="TestNet网络"><a href="#TestNet网络" class="headerlink" title="TestNet网络"></a>TestNet网络</h2><p><code>TestNet</code>是一个<code>2</code>层神经网络，结构如下：</p><a id="more"></a>


<ul>
<li>输入层有<code>3</code>个神经元</li>
<li>隐藏层有<code>4</code>个神经元</li>
<li>输出层有<code>2</code>个神经元</li>
</ul>
<p><img src="/imgs/神经网络推导-批量数据/test_net.png" alt></p>
<ul>
<li>激活函数为<code>relu</code>函数</li>
<li>评分函数为<code>softmax</code>回归</li>
<li>代价函数为交叉熵损失</li>
</ul>
<h3 id="网络符号定义"><a href="#网络符号定义" class="headerlink" title="网络符号定义"></a>网络符号定义</h3><p>规范神经网络的计算符号</p>
<p>关于神经元和层数</p>
<ul>
<li>$L$表示网络层数（不计入输入层）<ul>
<li>$L=2$，其中输入层是第<code>0</code>层，隐藏层是第<code>1</code>层，输出层是第<code>2</code>层</li>
</ul>
</li>
<li>$n^{(l)}$表示第$l$层的神经元个数（不包括偏置神经元）<ul>
<li>$n^{(0)}=3$，表示输入层神经元个数为<code>3</code></li>
<li>$n^{(1)}=4$，表示隐藏层神经元个数为<code>4</code></li>
<li>$n^{(2)}=2$，表示输出层神经元个数为<code>2</code></li>
</ul>
</li>
</ul>
<p>关于权重矩阵和偏置值</p>
<ul>
<li>$W^{(l)}$表示第$l-1$层到第$l$层的<strong>权重矩阵</strong>，矩阵行数为第$l-1$层的神经元个数，列数为第$l$层神经元个数<ul>
<li>$W^{(1)}$表示输入层到隐藏层的权重矩阵，大小为$R^{3\times 4}$</li>
<li>$W^{(2)}$表示隐藏层到输出层的权重矩阵，大小为$R^{4\times 2}$</li>
</ul>
</li>
<li>$W^{(l)}_{i,j}$表示第$l-1$层第$i$个神经元到第$l$第$j$个神经元的权值<ul>
<li>$i$的取值范围是$[1,n^{(l-1)}]$</li>
<li>$j$的取值范围是$[1, n^{(l)}]$</li>
</ul>
</li>
<li>$W^{(l)}_{i}$表示第$l-1$层第$i$个神经元对应的权重向量，大小为$n^{(l)}$</li>
<li>$W^{(l)}_{,j}$表示第$l$层第$j$个神经元对应的权重向量，大小为$n^{(l-1)}$</li>
<li>$b^{(l)}$表示第$l$层的<strong>偏置向量</strong><ul>
<li>$b^{(1)}$表示输入层到隐藏层的偏置向量，大小为$R^{1\times 4}$</li>
<li>$b^{(2)}$表示隐藏层到输出层的偏置向量，大小为$R^{1\times 2}$</li>
</ul>
</li>
<li>$b^{(l)}_{i}$表示第$l$层第$i$个神经元的偏置值<ul>
<li>$b^{(1)}_{2}$表示第$1$层隐藏层第$2$个神经元的偏置值</li>
</ul>
</li>
</ul>
<p>关于神经元输入向量和输出向量</p>
<ul>
<li>$a^{(l)}$表示第$l$层<strong>输出向量</strong>，$a^{(l)}=[a^{(l)}_{1},a^{(l)}_{2},…,a^{(l)}_{m}]^{T}$<ul>
<li>$a^{(0)}$表示输入层输出向量，大小为$R^{m\times 3}$</li>
<li>$a^{(1)}$表示隐藏层输出向量，大小为$R^{m\times 4}$</li>
<li>$a^{(2)}$表示输出层输出向量，大小为$R^{m\times 2}$</li>
</ul>
</li>
<li><p>$a^{(l)}_{i}$表示第$l$层第$i$个单元的输出值，其是输入向量经过激活计算后的值</p>
<ul>
<li>$a^{(1)}_{3}$表示隐含层第$3$个神经元的输入值，$a^{(1)}_{3}=g(z^{(1)}_{3})$</li>
</ul>
</li>
<li><p>$z^{(l)}$表示第$l$层<strong>输入向量</strong>，$z^{(l)}=[z^{(l)}_{1},z^{(l)}_{2},…,z^{(l)}_{m}]^{T}$</p>
<ul>
<li>$z^{(1)}$表示隐藏层的输入向量，大小为$R^{m\times 4}$</li>
<li>$z^{(2)}$表示输出层的输入向量，大小为$R^{m\times 2}$</li>
</ul>
</li>
<li>$z^{(l)}_{i,j}$表示第$l$层第$j$个单元的输入值，其是上一层输出向量第$i$个数据和该层第$j$个神经元权重向量的加权累加和    <ul>
<li>$z^{(1)}_{1,2}$表示隐藏层第$2$个神经元的输入值，$z^{(1)}_{1,2}=b^{(2)}_{2}+a^{(0)}_{1,1}\cdot W^{(1)}_{1,2}+a^{(0)}_{1,2}\cdot W^{(1)}_{2,2}+a^{(0)}_{1,3}\cdot W^{(1)}_{3,2}$</li>
</ul>
</li>
</ul>
<p>关于神经元激活函数</p>
<ul>
<li>$g()$表示激活函数操作</li>
</ul>
<p>关于评分函数和损失函数</p>
<ul>
<li>$h()$表示评分函数操作</li>
<li>$J()$表示代价函数操作</li>
</ul>
<p><strong>神经元执行步骤</strong></p>
<p>神经元操作分为<code>2</code>步计算：</p>
<ol>
<li>输入向量$z^{(l)}$=前一层神经元输出向量$a^{(l-1)}$与权重矩阵$W^{(l)}$的加权累加和+偏置向量</li>
</ol>
<script type="math/tex; mode=display">
z^{(l)}_{i,j}=a^{(l-1)}_{i}\cdot W^{(l)}_{,j} + b^{(l)}_{j} \Rightarrow 
z^{(l)}=a^{(l-1)}\cdot W^{(l)} + b^{(l)}</script><ol>
<li>输出向量$a^{(l)}$=对输入向量$z^{(l)}$进行激活函数操作</li>
</ol>
<script type="math/tex; mode=display">
a^{(l)}_{i}=g(z_{i}^{(l)})
\Rightarrow 
a^{(l)}=g(z^{(l)})</script><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>对输入层</p>
<script type="math/tex; mode=display">
a^{(0)}
=\begin{bmatrix}
a^{(0)}_{1}\\ 
\vdots\\ 
a^{(0)}_{m}
\end{bmatrix}
=\begin{bmatrix}
a^{(0)}_{1,1} & a^{(0)}_{1,2} & a^{(0)}_{1,3}\\ 
\vdots & \vdots & \vdots\\ 
a^{(0)}_{m,1} & a^{(0)}_{m,2} & a^{(0)}_{m,3}
\end{bmatrix}\in R^{m\times 3}</script><p>对隐藏层</p>
<script type="math/tex; mode=display">
W^{(1)}
=\begin{bmatrix}
W^{(1)}_{1,1} & W^{(1)}_{1,2} & W^{(1)}_{1,3} & W^{(1)}_{1,4}\\ 
W^{(1)}_{2,1} & W^{(1)}_{2,2} & W^{(1)}_{2,3} & W^{(1)}_{2,4}\\ 
W^{(1)}_{3,1} & W^{(1)}_{3,2} & W^{(1)}_{3,3} & W^{(1)}_{3,4}
\end{bmatrix}
\in R^{3\times 4}</script><script type="math/tex; mode=display">
b^{(1)}=[[b^{(1)}_{1},b^{(1)}_{2},b^{(1)}_{3},b^{(1)}_{4}]]\in R^{1\times 4}</script><script type="math/tex; mode=display">
z^{(1)}
=\begin{bmatrix}
z^{(0)}_{1,1} & z^{(0)}_{1,2} & z^{(0)}_{1,3} & z^{(0)}_{1,4}\\ 
\vdots & \vdots & \vdots & \vdots\\ 
z^{(0)}_{m,1} & z^{(0)}_{m,2} & z^{(0)}_{m,3} & z^{(0)}_{m,4}
\end{bmatrix}\in R^{m\times 4}</script><script type="math/tex; mode=display">
a^{(1)}
=\begin{bmatrix}
a^{(0)}_{1,1} & a^{(0)}_{1,2} & a^{(0)}_{1,3} & a^{(0)}_{1,4}\\ 
\vdots & \vdots & \vdots & \vdots\\ 
a^{(0)}_{m,1} & a^{(0)}_{m,2} & a^{(0)}_{m,3} & a^{(0)}_{m,4}
\end{bmatrix}\in R^{m\times 4}</script><p>对输出层</p>
<script type="math/tex; mode=display">
W^{(2)}
=\begin{bmatrix}
W^{(2)}_{1,1} & W^{(2)}_{1,2}\\
W^{(2)}_{2,1} & W^{(2)}_{2,2}\\ 
W^{(2)}_{3,1} & W^{(2)}_{3,2}\\
W^{(2)}_{4,1} & W^{(2)}_{4,2}
\end{bmatrix}
\in R^{4\times 2}</script><script type="math/tex; mode=display">
b^{(2)}=[[b^{(2)}_{1},b^{(2)}_{2}]]\in R^{1\times 2}</script><script type="math/tex; mode=display">
z^{(2)}
=\begin{bmatrix}
z^{(2)}_{1,1} & z^{(0)}_{1,2}\\ 
\vdots & \vdots\\ 
z^{(2)}_{m,1} & z^{(0)}_{m,2}
\end{bmatrix}\in R^{m\times 2}</script><p>评分值</p>
<script type="math/tex; mode=display">
h(z^{(2)})
=\begin{bmatrix}
p(y_{1}=1) & p(y_{1}=2)\\ 
\vdots & \vdots\\ 
p(y_{m}=1) & p(y_{m}=2)
\end{bmatrix}\in R^{m\times 2}</script><p>损失值</p>
<script type="math/tex; mode=display">
J(z^{(2)})=(-1)\sum_{i=1}^{m} \sum_{j=1}^{2}\cdot 1(y_{m,j}=1)\ln p(y_{m,j}=1)\in R^{1}</script><h2 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h2><p>输入层到隐藏层计算</p>
<script type="math/tex; mode=display">
z^{(1)}_{i,1}=a^{(0)}_{i}\cdot W^{(1)}_{,1}+b^{(1)}_{1}
=a^{(0)}_{i,1}\cdot W^{(1)}_{1,1} 
+a^{(0)}_{i,2}\cdot W^{(1)}_{2,1} 
+a^{(0)}_{i,3}\cdot W^{(1)}_{3,1} 
+b^{(1)}_{1,1}</script><script type="math/tex; mode=display">
z^{(1)}_{i,2}=a^{(0)}_{i}\cdot W^{(1)}_{,2}+b^{(1)}_{2}
=a^{(0)}_{i,1}\cdot W^{(1)}_{1,2} 
+a^{(0)}_{i,2}\cdot W^{(1)}_{2,2} 
+a^{(0)}_{i,3}\cdot W^{(1)}_{3,2} 
+b^{(1)}_{1,2}</script><script type="math/tex; mode=display">
z^{(1)}_{i,3}=a^{(0)}_{i}\cdot W^{(1)}_{,3}+b^{(1)}_{3}
=a^{(0)}_{i,1}\cdot W^{(1)}_{1,3} 
+a^{(0)}_{i,2}\cdot W^{(1)}_{2,3} 
+a^{(0)}_{i,3}\cdot W^{(1)}_{3,3} 
+b^{(1)}_{1,3}</script><script type="math/tex; mode=display">
z^{(1)}_{i,4}=a^{(0)}_{i}\cdot W^{(1)}_{,4}+b^{(1)}_{4}
=a^{(0)}_{i,1}\cdot W^{(1)}_{1,4} 
+a^{(0)}_{i,2}\cdot W^{(1)}_{2,4} 
+a^{(0)}_{i,3}\cdot W^{(1)}_{3,4} 
+b^{(1)}_{1,4}</script><script type="math/tex; mode=display">
\Rightarrow z^{(1)}_{i}
=[z^{(1)}_{i,1},z^{(1)}_{i,2},z^{(1)}_{i,3},z^{(1)}_{i,4}]
=a^{(0)}_{i}\cdot W^{(1)}+b^{(1)}</script><script type="math/tex; mode=display">
\Rightarrow z^{(1)}
=a^{(0)}\cdot W^{(1)}+b^{(1)}</script><p>隐藏层输入向量到输出向量</p>
<script type="math/tex; mode=display">
a^{(1)}_{i,1}=relu(z^{(1)}_{i,1}) \\
a^{(1)}_{i,2}=relu(z^{(1)}_{i,2}) \\
a^{(1)}_{i,3}=relu(z^{(1)}_{i,3}) \\
a^{(1)}_{i,4}=relu(z^{(1)}_{i,4})</script><script type="math/tex; mode=display">
\Rightarrow 
a^{(1)}_{i}=[a^{(1)}_{i,1},a^{(1)}_{i,2},a^{(1)}_{i,3},a^{(1)}_{i,4}]
=relu(z^{(1)}_{i})</script><script type="math/tex; mode=display">
\Rightarrow 
a^{(1)}=relu(z^{(1)})</script><p>隐藏层到输出层计算</p>
<script type="math/tex; mode=display">
z^{(2)}_{i,1}=a^{(1)}_{i}\cdot W^{(2)}_{,1}+b^{(2)}_{1,1}
=a^{(1)}_{i,1}\cdot W^{(2)}_{1,1}
+a^{(1)}_{i,2}\cdot W^{(2)}_{2,1}
+a^{(1)}_{i,3}\cdot W^{(2)}_{3,1}
+a^{(1)}_{i,4}\cdot W^{(2)}_{4,1}
+b^{(2)}_{1,1}</script><script type="math/tex; mode=display">
z^{(2)}_{i,2}=a^{(1)}_{i}\cdot W^{(2)}_{,2}+b^{(2)}_{1,2}
=a^{(1)}_{i,1}\cdot W^{(2)}_{1,2}
+a^{(1)}_{i,2}\cdot W^{(2)}_{2,2}
+a^{(1)}_{i,3}\cdot W^{(2)}_{3,2}
+a^{(1)}_{i,4}\cdot W^{(2)}_{4,2}
+b^{(2)}_{1,2}</script><script type="math/tex; mode=display">
\Rightarrow z^{(2)}_{i}
=[z^{(2)}_{i,1},z^{(2)}_{i,2}]
=a^{(1)}_{i}\cdot W^{(2)}+b^{(2)}</script><script type="math/tex; mode=display">
\Rightarrow z^{(2)}
=a^{(1)}\cdot W^{(2)}+b^{(2)}</script><p>评分操作</p>
<script type="math/tex; mode=display">
p(y_{i}=1)=\frac {exp(z^{(2)}_{i,1})}{\sum exp(z^{(2)}_{i})} \\
p(y_{i}=2)=\frac {exp(z^{(2)}_{i,2})}{\sum exp(z^{(2)}_{i})}</script><script type="math/tex; mode=display">
\Rightarrow h(z^{(2)}_{i})
=[p(y_{i}=1),p(y_{i}=2)]
=[\frac {exp(z^{(2)}_{i,1})}{\sum exp(z^{(2)}_{i})}, \frac {exp(z^{(2)}_{i,2})}{\sum exp(z^{(2)}_{i})}]</script><script type="math/tex; mode=display">
\Rightarrow h(z^{(2)})
=\begin{bmatrix}
p(y_{1}=1) & p(y_{1}=2) \\ 
\vdots & \vdots\\ 
p(y_{m}=1) & p(y_{m}=2)
\end{bmatrix}</script><p>损失值</p>
<script type="math/tex; mode=display">
J(z^{(2)})=(-1)\sum_{i=1}^{m} \sum_{j=1}^{2}\cdot 1(y_{m,j}=1)\ln p(y_{m,j}=1)</script><h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p>计算输出层输入向量梯度</p>
<script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(2)}_{i,1}}=
(-1)\cdot \frac {1(y_{i}=1)}{p(y_{i}=1)}\cdot \frac {\partial p(y_{i}=1)}{\partial z^{(2)}_{i,1}}
+(-1)\cdot \frac {1(y_{i}=2)}{p(y_{i}=2)}\cdot \frac {\partial p(y_{i}=2)}{\partial z^{(2)}_{i,1}}</script><script type="math/tex; mode=display">
\frac {\partial p(y_{i}=1)}{\partial z^{(2)}_{i,1}}
=\frac {exp(z^{(2)}_{i,1})\cdot \sum exp(z^{(2)}_{i})-exp(z^{(2)}_{i,1})\cdot exp(z^{(2)}_{i,1})}{(\sum exp(z^{(2)}_{i}))^2}
=\frac {exp(z^{(2)}_{i,1})}{\sum exp(z^{(2)}_{i})}
-(\frac {exp(z^{(2)}_{i,1})}{\sum exp(z^{(2)}_{i})})^2
=p(y_{i}=1)-(p(y_{i}=1))^2</script><script type="math/tex; mode=display">
\frac {\partial p(y_{i}=2)}{\partial z^{(2)}_{i,1}}
=\frac {-exp(z^{(2)}_{i,2})\cdot exp(z^{(2)}_{i,1})}{(\sum exp(z^{(2)}_{i}))^2}
=(-1)\cdot \frac {exp(z^{(2)}_{i,1})}{\sum exp(z^{(2)}_{i})}\cdot \frac {exp(z^{(2)}_{i,2})}{\sum exp(z^{(2)}_{i})}
=(-1)\cdot p(y_{i}=1)p(y_{i}=2)</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial z^{(2)}_{i,1}}
=(-1)\cdot \frac {1(y_{i}=1)}{p(y_{i}=1)}\cdot (p(y_{i}=1)-(p(y_{i}=1))^2)
+(-1)\cdot \frac {1(y_{i}=2)}{p(y_{i}=2)}\cdot (-1)\cdot p(y_{i}=1)p(y_{i}=2) \\
=(-1)\cdot 1(y_{i}=1)\cdot (1-p(y_{i}=1))
+1(y_{i}=2)\cdot p(y_{i}=1)
=p(y_{i}=1)-1(y_{i}=1)</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial z^{(2)}_{i,2}}
=p(y_{i}=2)-1(y_{i}=2)</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial z^{(2)}_{i}}
=[p(y_{i}=1)-1(y_{i}=1), p(y_{i}=2)-1(y_{i}=2)]</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial z^{(2)}}
=\begin{bmatrix}
p(y_{1}=1)-1(y_{1}=1) & p(y_{1}=2)-1(y_{1}=2)\\ 
\vdots & \vdots\\ 
p(y_{m}=1)-1(y_{m}=1) & p(y_{m}=2)-1(y_{m}=2)
\end{bmatrix}</script><p>计算输出层权重向量梯度</p>
<script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{1,1}}
=\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(2)}_{i,1}}\cdot \frac {\partial z^{(2)}_{i,1}}{\partial W^{(2)}_{1,1}}
=\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=1)-1(y_{i}=1))\cdot a^{(1)}_{i,1})</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{2,1}}
=\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(2)}_{i,1}}\cdot \frac {\partial z^{(2)}_{i,1}}{\partial W^{(2)}_{2,1}}
=\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=1)-1(y_{i}=1))\cdot a^{(1)}_{i,2})</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{3,1}}
=\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(2)}_{i,1}}\cdot \frac {\partial z^{(2)}_{i,1}}{\partial W^{(2)}_{3,1}}
=\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=1)-1(y_{i}=1))\cdot a^{(1)}_{i,3})</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{4,1}}
=\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(2)}_{i,1}}\cdot \frac {\partial z^{(2)}_{i,1}}{\partial W^{(2)}_{4,1}}
=\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=1)-1(y_{i}=1))\cdot a^{(1)}_{i,4})</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{1,2}}
=\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(2)}_{i,2}}\cdot \frac {\partial z^{(2)}_{2}}{\partial W^{(2)}_{1,2}}
=\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=2)-1(y_{i}=2))\cdot a^{(1)}_{i,1})</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{2,2}}
=\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(2)}_{i,2}}\cdot \frac {\partial z^{(2)}_{2}}{\partial W^{(2)}_{2,2}}
=\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=2)-1(y_{i}=2))\cdot a^{(1)}_{i,2})</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{3,2}}
=\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(2)}_{i,2}}\cdot \frac {\partial z^{(2)}_{2}}{\partial W^{(2)}_{3,2}}
=\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=2)-1(y_{i}=2))\cdot a^{(1)}_{i,3})</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{4,2}}
=\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(2)}_{i,2}}\cdot \frac {\partial z^{(2)}_{2}}{\partial W^{(2)}_{4,2}}
=\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=2)-1(y_{i}=2))\cdot a^{(1)}_{i,4})</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial W^{(2)}}
=\begin{bmatrix}
\frac {\partial J}{\partial W^{(2)}_{1,1}} & \frac {\partial J}{\partial W^{(2)}_{1,2}}\\
\frac {\partial J}{\partial W^{(2)}_{2,1}} & \frac {\partial J}{\partial W^{(2)}_{2,2}}\\ 
\frac {\partial J}{\partial W^{(2)}_{3,1}} & \frac {\partial J}{\partial W^{(2)}_{3,2}}\\
\frac {\partial J}{\partial W^{(2)}_{4,1}} & \frac {\partial J}{\partial W^{(2)}_{4,2}}
\end{bmatrix}</script><script type="math/tex; mode=display">
=\begin{bmatrix}
\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=1)-1(y_{i}=1))\cdot a^{(1)}_{i,1}) & \frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=1)-1(y_{i}=1))\cdot a^{(1)}_{i,2})\\ 
\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=1)-1(y_{i}=1))\cdot a^{(1)}_{i,3}) & \frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=1)-1(y_{i}=1))\cdot a^{(1)}_{i,4})\\
\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=2)-1(y_{i}=2))\cdot a^{(1)}_{i,1}) & \frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=2)-1(y_{i}=2))\cdot a^{(1)}_{i,2})\\ 
\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=2)-1(y_{i}=2))\cdot a^{(1)}_{i,3}) & \frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=2)-1(y_{i}=2))\cdot a^{(1)}_{i,4})
\end{bmatrix}</script><script type="math/tex; mode=display">
=\frac {1}{m}\sum_{i=1}^{m}
\begin{bmatrix}
a^{(1)}_{i,1}\\ 
a^{(1)}_{i,2}\\ 
a^{(1)}_{i,3}\\ 
a^{(1)}_{i,4}
\end{bmatrix} 
\begin{bmatrix}
p(y_{i}=1)-1(y_{i}=1) & p(y_{i}=2)-1(y_{i}=2)
\end{bmatrix}\\
=\frac {1}{m}\sum_{i=1}^{m} ((a^{(1)}_{i})^{T}\cdot \frac {\partial J}{\partial z^{(2)}_{i}}) 
=\frac {1}{m} (a^{(1)})^{T}\cdot \frac {\partial J}{\partial z^{(2)}}
=\frac {1}{m}\sum_{i=1}^{m} (R^{4\times m}\cdot R^{m\times 2})
=R^{4\times 2}</script><p>计算隐藏层输出向量梯度</p>
<script type="math/tex; mode=display">
\frac {\partial J}{\partial a^{(1)}_{i,1}}
=\frac {\partial J}{\partial z^{(2)}_{i,1}}\cdot \frac {\partial z^{(2)}_{i,1}}{\partial a^{(1)}_{i,1}}
+\frac {\partial J}{\partial z^{(2)}_{i,2}}\cdot \frac {\partial z^{(2)}_{i,2}}{\partial a^{(1)}_{i,1}}
=(p(y_{i}=1)-1(y_{i}=1))\cdot W^{(2)}_{1,1}
+(p(y_{i}=2)-1(y_{i}=2))\cdot W^{(2)}_{1,2}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial a^{(1)}_{i,2}}
=\frac {\partial J}{\partial z^{(2)}_{i,1}}\cdot \frac {\partial z^{(2)}_{i,1}}{\partial a^{(1)}_{i,2}}
+\frac {\partial J}{\partial z^{(2)}_{i,2}}\cdot \frac {\partial z^{(2)}_{i,2}}{\partial a^{(1)}_{i,2}}
=(p(y_{i}=1)-1(y_{i}=1))\cdot W^{(2)}_{2,1}
+(p(y_{i}=2)-1(y_{i}=2))\cdot W^{(2)}_{2,2}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial a^{(1)}_{i,3}}
=\frac {\partial J}{\partial z^{(2)}_{i,1}}\cdot \frac {\partial z^{(2)}_{i,1}}{\partial a^{(1)}_{i,3}}
+\frac {\partial J}{\partial z^{(2)}_{i,2}}\cdot \frac {\partial z^{(2)}_{i,2}}{\partial a^{(1)}_{i,3}}
=(p(y_{i}=1)-1(y_{i}=1))\cdot W^{(2)}_{3,1}
+(p(y_{i}=2)-1(y_{i}=2))\cdot W^{(2)}_{3,2}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial a^{(1)}_{i,4}}
=\frac {\partial J}{\partial z^{(2)}_{i,1}}\cdot \frac {\partial z^{(2)}_{i,1}}{\partial a^{(1)}_{i,4}}
+\frac {\partial J}{\partial z^{(2)}_{i,2}}\cdot \frac {\partial z^{(2)}_{i,2}}{\partial a^{(1)}_{i,4}}
=(p(y_{i}=1)-1(y_{i}=1))\cdot W^{(2)}_{4,1}
+(p(y_{i}=2)-1(y_{i}=2))\cdot W^{(2)}_{4,2}</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial a^{(1)}_{i}}
=\begin{bmatrix}
p(y_{i}=1)-1(y_{i}=1) & p(y_{i}=2)-1(y_{i}=2)
\end{bmatrix}
\begin{bmatrix}
W^{(2)}_{1,1} & W^{(2)}_{2,1} & W^{(2)}_{3,1} & W^{(2)}_{4,1}\\ 
W^{(2)}_{1,2} & W^{(2)}_{2,2} & W^{(2)}_{3,2} & W^{(2)}_{4,2}
\end{bmatrix} \\
=\frac {\partial J}{\partial z^{(2)}_{i}}\cdot (W^{(2)})^T
=R^{1\times 2}\cdot R^{2\times 4}
=R^{1\times 4}</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial a^{(1)}}
=\begin{bmatrix}
p(y_{1}=1)-1(y_{1}=1) & p(y_{1}=2)-1(y_{1}=2)\\ 
\vdots & \vdots\\ 
p(y_{m}=1)-1(y_{m}=1) & p(y_{m}=2)-1(y_{m}=2)
\end{bmatrix}
\begin{bmatrix}
W^{(2)}_{1,1} & W^{(2)}_{2,1} & W^{(2)}_{3,1} & W^{(2)}_{4,1}\\ 
W^{(2)}_{1,2} & W^{(2)}_{2,2} & W^{(2)}_{3,2} & W^{(2)}_{4,2}
\end{bmatrix} \\
=\frac {\partial J}{\partial z^{(2)}}\cdot (W^{(2)})^T
=R^{m\times 2}\cdot R^{2\times 4}
=R^{m\times 4}</script><p>计算隐藏层输入向量的梯度</p>
<script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(1)}_{i,1}}
=\frac {\partial J}{\partial a^{(1)}_{i,1}}\cdot \frac {\partial a^{(1)}_{i,1}}{\partial z^{(1)}_{i,1}}
=((p(y_{i}=1)-1(y_{i}=1))\cdot W^{(2)}_{1,1}
+(p(y=2)-1(y=2))\cdot W^{(2)}_{1,2})\cdot 1(z^{(1)}_{i,1}\geq 0)</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(1)}_{i,2}}
=\frac {\partial J}{\partial a^{(1)}_{i,2}}\cdot \frac {\partial a^{(1)}_{i,2}}{\partial z^{(1)}_{i,2}}
=((p(y_{i}=1)-1(y_{i}=1))\cdot W^{(2)}_{2,1}
+(p(y_{i}=2)-1(y_{i}=2))\cdot W^{(2)}_{2,2})\cdot 1(z^{(1)}_{i,2}\geq 0)</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(1)}_{i,3}}
=\frac {\partial J}{\partial a^{(1)}_{i,3}}\cdot \frac {\partial a^{(1)}_{i,3}}{\partial z^{(1)}_{i,3}}
=((p(y_{i}=1)-1(y_{i}=1))\cdot W^{(2)}_{3,1}
+(p(y_{i}=2)-1(y_{i}=2))\cdot W^{(2)}_{3,2})\cdot 1(z^{(1)}_{i,3}\geq 0)</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(1)}_{i,4}}
=\frac {\partial J}{\partial a^{(1)}_{i,4}}\cdot \frac {\partial a^{(1)}_{i,4}}{\partial z^{(1)}_{i,4}}
=((p(y_{i}=1)-1(y_{i}=1))\cdot W^{(2)}_{4,1}
+(p(y_{i}=2)-1(y_{i}=2))\cdot W^{(2)}_{4,2})\cdot 1(z^{(1)}_{i,4}\geq 0)</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial z^{(1)}_{i}}
=(\begin{bmatrix}
p(y_{i}=1)-1(y_{i}=1) & p(y_{i}=2)-1(y_{i}=2)
\end{bmatrix}
\begin{bmatrix}
W^{(2)}_{1,1} & W^{(2)}_{2,1} & W^{(2)}_{3,1} & W^{(2)}_{4,1}\\ 
W^{(2)}_{1,2} & W^{(2)}_{2,2} & W^{(2)}_{3,2} & W^{(2)}_{4,2}
\end{bmatrix})
*\begin{bmatrix}
\frac {\partial a^{(1)}_{i,1}}{\partial z^{(1)}_{i,1}}&
\frac {\partial a^{(1)}_{i,2}}{\partial z^{(1)}_{i,2}}& 
\frac {\partial a^{(1)}_{i,3}}{\partial z^{(1)}_{i,3}}& 
\frac {\partial a^{(1)}_{i,4}}{\partial z^{(1)}_{i,4}}
\end{bmatrix}\\
=(R^{1\times 2}\cdot R^{2\times 4})* R^{1\times 4}
=R^{1\times 4}</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial z^{(1)}_{i}}
=(\begin{bmatrix}
p(y_{i}=1)-1(y_{i}=1) & p(y_{i}=2)-1(y_{i}=2)
\end{bmatrix}
\begin{bmatrix}
W^{(2)}_{1,1} & W^{(2)}_{2,1} & W^{(2)}_{3,1} & W^{(2)}_{4,1}\\ 
W^{(2)}_{1,2} & W^{(2)}_{2,2} & W^{(2)}_{3,2} & W^{(2)}_{4,2}
\end{bmatrix})
*
\begin{bmatrix}
1(z^{(1)}_{i,1}\geq 0) & 1(z^{(1)}_{i,2}\geq 0) & 1(z^{(1)}_{i,3}\geq 0) & 1(z^{(1)}_{i,4}\geq 0)
\end{bmatrix}\\
=(R^{1\times 2}\cdot R^{2\times 4})\ast  R^{1\times 4}
=R^{1\times 4}</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial z^{(1)}}
=(\begin{bmatrix}
p(y_{1}=1)-1(y_{1}=1) & p(y_{1}=2)-1(y_{1}=2)\\ 
\vdots & \vdots\\ 
p(y_{m}=1)-1(y_{m}=1) & p(y_{m}=2)-1(y_{m}=2)
\end{bmatrix}
\begin{bmatrix}
W^{(2)}_{1,1} & W^{(2)}_{2,1} & W^{(2)}_{3,1} & W^{(2)}_{4,1}\\ 
W^{(2)}_{1,2} & W^{(2)}_{2,2} & W^{(2)}_{3,2} & W^{(2)}_{4,2}
\end{bmatrix})
*
\begin{bmatrix}
1(z^{(1)}_{1,1}\geq 0) & 1(z^{(1)}_{1,2}\geq 0) & 1(z^{(1)}_{1,3}\geq 0) & 1(z^{(1)}_{1,4}\geq 0)\\
\vdots & \vdots\\ 
1(z^{(1)}_{m,1}\geq 0) & 1(z^{(1)}_{m,2}\geq 0) & 1(z^{(1)}_{m,3}\geq 0) & 1(z^{(1)}_{m,4}\geq 0)
\end{bmatrix}\\
=\frac {\partial J}{\partial a^{(1)}} * 1(z^{(1)}\geq 0)
=(R^{m\times 2}\cdot R^{2\times 4})\ast R^{m\times 4}
=R^{m\times 4}</script><p>计算隐藏层权重向量的梯度</p>
<script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(1)}_{1,1}}
=\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,1}}\cdot
\frac {\partial z^{(1)}_{i,1}}{\partial W^{(1)}_{1,1}}
=\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=1)-1(y_{i}=1))\cdot W^{(2)}_{1,1}
+(p(y_{i}=2)-1(y_{i}=2))\cdot W^{(2)}_{1,2})\cdot 1(z^{(1)}_{i,1}\geq 0)\cdot a^{(0)}_{i,1}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(1)}_{1,2}}
=\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,2}}\cdot
\frac {\partial z^{(1)}_{i,2}}{\partial W^{(1)}_{1,2}}
=\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=1)-1(y_{i}=1))\cdot W^{(2)}_{2,1}
+(p(y_{i}=2)-1(y_{i}=2))\cdot W^{(2)}_{2,2})\cdot 1(z^{(1)}_{i,2}\geq 0)\cdot a^{(0)}_{i,1}</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial W^{(1)}_{k,l}}
=\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,l}}\cdot
\frac {\partial z^{(1)}_{i,l}}{\partial W^{(1)}_{k,l}}
=\frac {1}{m}\sum_{i=1}^{m} ((p(y_{i}=1)-1(y_{i}=1))\cdot W^{(2)}_{l,1}
+(p(y_{i}=2)-1(y_{i}=2))\cdot W^{(2)}_{l,2})\cdot 1(z^{(1)}_{i,l}\geq 0)\cdot a^{(0)}_{i,k}</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial W^{(1)}}
=\begin{bmatrix}
\frac {\partial J}{\partial W^{(1)}_{1,1}} & \frac {\partial J}{\partial W^{(1)}_{1,2}} & \frac {\partial J}{\partial W^{(1)}_{1,3}}  & \frac {\partial J}{\partial W^{(1)}_{1,4}}\\ 
\frac {\partial J}{\partial W^{(1)}_{2,1}} & \frac {\partial J}{\partial W^{(1)}_{2,2}} & \frac {\partial J}{\partial W^{(1)}_{2,3}}  & \frac {\partial J}{\partial W^{(1)}_{2,4}}\\ 
\frac {\partial J}{\partial W^{(1)}_{3,1}} & \frac {\partial J}{\partial W^{(1)}_{3,2}} & \frac {\partial J}{\partial W^{(1)}_{3,3}}  & \frac {\partial J}{\partial W^{(1)}_{3,4}}
\end{bmatrix}\\
=\begin{bmatrix}
\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,1}}\cdot \frac {\partial z^{(1)}_{i,1}}{\partial W^{(1)}_{1,1}} 
& \frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,2}}\cdot \frac {\partial z^{(1)}_{i,2}}{\partial W^{(1)}_{1,2}} 
& \frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,3}}\cdot \frac {\partial z^{(1)}_{i,3}}{\partial W^{(1)}_{1,3}}  
& \frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,4}}\cdot \frac {\partial z^{(1)}_{i,4}}{\partial W^{(1)}_{1,4}}\\ 
\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,1}}\cdot \frac {\partial z^{(1)}_{i,1}}{\partial W^{(1)}_{2,1}} 
& \frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,2}}\cdot \frac {\partial z^{(1)}_{i,2}}{\partial W^{(1)}_{2,2}} 
& \frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,3}}\cdot \frac {\partial z^{(1)}_{i,3}}{\partial W^{(1)}_{2,3}}  
& \frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,4}}\cdot \frac {\partial z^{(1)}_{i,4}}{\partial W^{(1)}_{2,4}}\\ 
\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,1}}\cdot \frac {\partial z^{(1)}_{i,1}}{\partial W^{(1)}_{3,1}} 
& \frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,2}}\cdot \frac {\partial z^{(1)}_{i,2}}{\partial W^{(1)}_{3,2}} 
& \frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,3}}\cdot \frac {\partial z^{(1)}_{i,3}}{\partial W^{(1)}_{3,3}}  
& \frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i,4}}\cdot \frac {\partial z^{(1)}_{i,4}}{\partial W^{(1)}_{3,4}}
\end{bmatrix}\\
=\frac {1}{m}\sum_{i=1}^{m} \begin{bmatrix}
\frac {\partial J}{\partial z^{(1)}_{i,1}}\cdot \frac {\partial z^{(1)}_{i,1}}{\partial W^{(1)}_{1,1}} 
& \frac {\partial J}{\partial z^{(1)}_{i,2}}\cdot \frac {\partial z^{(1)}_{i,2}}{\partial W^{(1)}_{1,2}} 
& \frac {\partial J}{\partial z^{(1)}_{i,3}}\cdot \frac {\partial z^{(1)}_{i,3}}{\partial W^{(1)}_{1,3}}  
& \frac {\partial J}{\partial z^{(1)}_{i,4}}\cdot \frac {\partial z^{(1)}_{i,4}}{\partial W^{(1)}_{1,4}}\\ 
\frac {\partial J}{\partial z^{(1)}_{i,1}}\cdot \frac {\partial z^{(1)}_{i,1}}{\partial W^{(1)}_{2,1}} 
& \frac {\partial J}{\partial z^{(1)}_{i,2}}\cdot \frac {\partial z^{(1)}_{i,2}}{\partial W^{(1)}_{2,2}} 
& \frac {\partial J}{\partial z^{(1)}_{i,3}}\cdot \frac {\partial z^{(1)}_{i,3}}{\partial W^{(1)}_{2,3}}  
& \frac {\partial J}{\partial z^{(1)}_{i,4}}\cdot \frac {\partial z^{(1)}_{i,4}}{\partial W^{(1)}_{2,4}}\\ 
\frac {\partial J}{\partial z^{(1)}_{i,1}}\cdot \frac {\partial z^{(1)}_{i,1}}{\partial W^{(1)}_{3,1}} 
& \frac {\partial J}{\partial z^{(1)}_{i,2}}\cdot \frac {\partial z^{(1)}_{i,2}}{\partial W^{(1)}_{3,2}} 
&  \frac {\partial J}{\partial z^{(1)}_{i,3}}\cdot \frac {\partial z^{(1)}_{i,3}}{\partial W^{(1)}_{3,3}}  
& \frac {\partial J}{\partial z^{(1)}_{i,4}}\cdot \frac {\partial z^{(1)}_{i,4}}{\partial W^{(1)}_{3,4}}
\end{bmatrix}\\
=\frac {1}{m}\sum_{i=1}^{m} \begin{bmatrix}
\frac {\partial J}{\partial z^{(1)}_{i,1}}\cdot a^{(0)}_{i,1} 
& \frac {\partial J}{\partial z^{(1)}_{i,2}}\cdot a^{(0)}_{i,1}
& \frac {\partial J}{\partial z^{(1)}_{i,3}}\cdot a^{(0)}_{i,1}
& \frac {\partial J}{\partial z^{(1)}_{i,4}}\cdot a^{(0)}_{i,1}\\ 
\frac {\partial J}{\partial z^{(1)}_{i,1}}\cdot a^{(0)}_{i,2}
& \frac {\partial J}{\partial z^{(1)}_{i,2}}\cdot a^{(0)}_{i,2}
& \frac {\partial J}{\partial z^{(1)}_{i,3}}\cdot a^{(0)}_{i,2}
& \frac {\partial J}{\partial z^{(1)}_{i,4}}\cdot a^{(0)}_{i,2}\\ 
\frac {\partial J}{\partial z^{(1)}_{i,1}}\cdot a^{(0)}_{i,3}
& \frac {\partial J}{\partial z^{(1)}_{i,2}}\cdot a^{(0)}_{i,3}
&  \frac {\partial J}{\partial z^{(1)}_{i,3}}\cdot a^{(0)}_{i,3}
& \frac {\partial J}{\partial z^{(1)}_{i,4}}\cdot a^{(0)}_{i,3}
\end{bmatrix}\\
=\frac {1}{m}\sum_{i=1}^{m} 
\begin{bmatrix}
a^{(0)}_{i,1}\\
a^{(0)}_{i,2}\\
a^{(0)}_{i,3}
\end{bmatrix}
\begin{bmatrix}
\frac {\partial J}{\partial z^{(1)}_{i,1}} 
& \frac {\partial J}{\partial z^{(1)}_{i,2}}
& \frac {\partial J}{\partial z^{(1)}_{i,3}}
& \frac {\partial J}{\partial z^{(1)}_{i,4}} 
\end{bmatrix}
=\frac {1}{m}\sum_{i=1}^{m} (a^{(0)}_{i})^T\cdot \frac {\partial J}{\partial z^{(1)}_{i}}
=\frac {1}{m} (a^{(0)})^T\cdot \frac {\partial J}{\partial z^{(1)}}
=R^{3\times m}\cdot R^{m\times 4}
=R^{3\times 4}</script><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><code>TestNet</code>网络的前向操作如下：</p>
<script type="math/tex; mode=display">
z^{(1)}
=a^{(0)}\cdot W^{(1)}+b^{(1)}</script><script type="math/tex; mode=display">
a^{(1)}=relu(z^{(1)})</script><script type="math/tex; mode=display">
z^{(2)}
=a^{(1)}\cdot W^{(2)}+b^{(2)}</script><script type="math/tex; mode=display">
h(z^{(2)})
=\begin{bmatrix}
p(y_{1}=1) & p(y_{1}=2) \\ 
\vdots & \vdots\\ 
p(y_{m}=1) & p(y_{m}=2)
\end{bmatrix}</script><script type="math/tex; mode=display">
J(z^{(2)})=(-1)\sum_{i=1}^{m} \sum_{j=1}^{2}\cdot 1(y_{m,j}=1)\ln p(y_{m,j}=1)</script><p>反向传播如下：</p>
<script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(2)}}
=\begin{bmatrix}
p(y_{1}=1)-1(y_{1}=1) & p(y_{1}=2)-1(y_{1}=2)\\ 
\vdots & \vdots\\ 
p(y_{m}=1)-1(y_{m}=1) & p(y_{m}=2)-1(y_{m}=2)
\end{bmatrix}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}}
=\frac {1}{m} (a^{(1)})^{T}\cdot \frac {\partial J}{\partial z^{(2)}}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial b^{(2)}}
=\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(2)}_{i}}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial a^{(1)}}
=\frac {\partial J}{\partial z^{(2)}}\cdot (W^{(2)})^T</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(1)}}
=\frac {\partial J}{\partial a^{(1)}} * 1(z^{(1)}\geq 0)</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(1)}}
=\frac {1}{m} (a^{(0)})^T\cdot \frac {\partial J}{\partial z^{(1)}}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial b^{(1)}}
=\frac {1}{m}\sum_{i=1}^{m} \frac {\partial J}{\partial z^{(1)}_{i}}</script><p>假设批量数据大小为$m$，数据维数为$D$，网络层数为$L$（$1,2,…,l,…,L$），输出类别为$C$</p>
<p>参考<a href="http://ufldl.stanford.edu/wiki/index.php/%E5%8F%8D%E5%90%91%E4%BC%A0%E5%AF%BC%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">反向传导算法</a>和<a href="https://zhuanlan.zhihu.com/p/22473137" target="_blank" rel="noopener">神经网络反向传播的数学原理</a>，设每层输入向量为残差$\delta^{(l)}=\frac{\partial J(W, b)}{\partial z^{(l)}}$，用于表示该层对最终输出值的残差造成的影响；而最终输出值的残差$\delta^{(L)}$就是损失函数对输出层输入向量的梯度</p>
<p>前向传播执行步骤</p>
<ol>
<li><p>层与层之间的操作就是输出向量和权值矩阵的加权求和以及对输入向量的函数激活（<em>以relu为例</em>）</p>
<script type="math/tex; mode=display">
 z^{(l)} = a^{(l-1)}\cdot W^{(l)}+b^{(l)} \\
 a^{(l)} = relu(z^{(l)})</script></li>
<li><p>输出层输出结果后，进行评分函数的计算，得到最终的计算结果（<em>以softmax分类为例</em>）</p>
<script type="math/tex; mode=display">
 h(z^{(L)})
 =\begin{bmatrix}
 p(y_{1}=1) & \dots & p(y_{1}=C) \\ 
 \vdots & \vdots & \vdots\\ 
 p(y_{m}=1) & \dots & p(y_{m}=C)
 \end{bmatrix}
 =\begin{bmatrix}
 \frac {exp(z^{(2)}_{1,1})}{\sum exp(z^{(2)}_{1})} & \dots & \frac {exp(z^{(2)}_{1,C})}{\sum exp(z^{(2)}_{1})} \\ 
 \vdots & \vdots & \vdots\\ 
 \frac {exp(z^{(2)}_{m,1})}{\sum exp(z^{(2)}_{m})} & \dots & \frac {exp(z^{(2)}_{m,C})}{\sum exp(z^{(2)}_{m})}
 \end{bmatrix}</script></li>
<li><p>损失函数根据计算结果判断最终损失值（<em>以交叉熵损失为例</em>）</p>
<script type="math/tex; mode=display">
 J(z^{(L)})=(-1)\sum_{i=1}^{m} \sum_{j=1}^{2}\cdot 1(y_{m,j}=1)\ln p(y_{m,j}=1)</script></li>
</ol>
<p>反向传播执行步骤</p>
<ol>
<li><p>计算损失函数对于输出层输入向量的梯度(最终层残差)</p>
<script type="math/tex; mode=display">
 \delta^{(L)}=
 \frac {\partial J}{\partial z^{(L)}}
 =\begin{bmatrix}
 p(y_{1}=1)-1(y_{1}=1) & \dots & p(y_{1}=C)-1(y_{1}=C)\\ 
 \vdots & \vdots & \vdots\\ 
 p(y_{m}=1)-1(y_{m}=1) & \dots & p(y_{m}=C)-1(y_{m}=C)
 \end{bmatrix}</script></li>
<li><p>计算中间隐藏层的残差值（$L-1,L-2,…1$）</p>
<script type="math/tex; mode=display">
 \delta^{(l)}=
 \frac{\varphi J}{\varphi z^{(l)}}
 =(\frac{\varphi J}{\varphi z^{(l+1)}}\cdot \frac{\varphi z^{(l+1)}}{\varphi a^{(l)}})
 *\frac{\varphi a^{(l)}}{\varphi z^{(l)}}
 =(\delta^{(l+1)}\cdot (W^{(l+1)})^{T})
 *1(z^{(l)}\geq 0)</script></li>
<li><p>完成所有的可学习参数（权值矩阵和偏置向量）的梯度计算</p>
<script type="math/tex; mode=display">
 \nabla_{W^{(l)}} J(W, b)= \frac {1}{m} (a^{(l-1)})^{T}\cdot \delta^{(l)}\\
 \nabla_{b^{(l)}} J(W, b)= \frac {1}{m}\sum_{i=1}^{m} \delta^{(l)}_{i}</script></li>
<li><p>更新权值矩阵和偏置向量</p>
<script type="math/tex; mode=display">
 W^{(l)}=W^{(l)}-\alpha\left[\nabla W^{(l)}+\lambda W^{(l)}\right] \\
 b^{(l)}=b^{(l)}-\alpha \nabla b^{(l)}</script></li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>深度学习</category>
        <category>数学</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>线性代数</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络推导-单个数据</title>
    <url>/posts/cb820bb8.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://www.zhujian.tech/posts/7ca31f7.html#more">神经网络概述</a></p><p><a href="http://ufldl.stanford.edu/wiki/index.php/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" target="_blank" rel="noopener">神经网络</a></p><p>输入单个数据到神经网络，进行前向传播和反向传播的推导</p><h2 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h2><ol>
<li>链式法则</li>
<li>雅可比矩阵</li>
</ol><a id="more"></a>




<h3 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h3><p>参考：<a href="https://baike.baidu.com/item/%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99" target="_blank" rel="noopener">链式法则</a></p>
<p>反向传播（<code>backpropagatation</code>）的目的是进行可学习参数（<code>learnable parameters</code>）的更新，其实现方式是利用链式法则（<code>chain rule</code>）进行梯度计算</p>
<p><code>cs231n</code>的<a href="http://cs231n.github.io/optimization-2/" target="_blank" rel="noopener">Backpropagation, Intuitions </a>给出了生动的关于链式求导的学习示例</p>
<h4 id="简单函数求导"><a href="#简单函数求导" class="headerlink" title="简单函数求导"></a>简单函数求导</h4><p>对于简单函数而言，其导数计算方式很简单。比如</p>
<script type="math/tex; mode=display">
f(x,y)=x\pm y \Rightarrow \frac{d f}{d x}=1 \ \  \frac{d f}{d y}=\pm 1  \\
f(x)=ax \Rightarrow \frac{d f}{d x}=a \\
f(x)=\frac {1}{x} \Rightarrow \frac{d f}{d x}=\frac {-1}{x^2} \\
f(x)=e^{x} \Rightarrow \frac{d f}{d x}=e^{x} \\
f(x,y)=max(x,y) \Rightarrow \frac{d f}{d x}=\mathbb{1}(x>=y) \ \ \frac{d f}{d y}=\mathbb{1}(y>=x)</script><h4 id="复合函数求导"><a href="#复合函数求导" class="headerlink" title="复合函数求导"></a>复合函数求导</h4><p>对于复合函数而言，直接计算导数很复杂，但它可以拆分为多个简单函数，然后逐一进行计算</p>
<p>以函数$f(x_{1},x_{2})$为例，其实现公式如下：</p>
<script type="math/tex; mode=display">
f(x_{1},x_{2})=\frac{1}{1+e^{-(w_{0}+w_{1}\cdot x_{1}+w_{2}\cdot x_{2})}}</script><p>其中函数可拆分成如下形式：</p>
<script type="math/tex; mode=display">
\sigma (x)=\frac {1}{1+e^{-x}} \\
p(x)= w\cdot x\\</script><p>对$\sigma (x)$和$p(x)$求导如下：</p>
<script type="math/tex; mode=display">
\frac{d \sigma}{d x} = \frac {-1}{(1+e^{-x})^2}\cdot (-e^{-x}) = \sigma (x)(1-\sigma (x)) \\
\frac{d p}{d x} = w</script><p>所以函数$f(x_{1},x_{2})$求导如下：</p>
<script type="math/tex; mode=display">
\frac{d f}{d x_{1}}=\frac{d \sigma}{d p}\cdot \frac{d p}{d x_{1}}=f(x_{1},x_{2})\cdot (1-f(x_{1},x_{2}))\cdot w_{1} \\
\frac{d f}{d x_{2}}=\frac{d \sigma}{d p}\cdot \frac{d p}{d x_{2}}=f (x_{1},x_{2})\cdot (1-f (x_{1},x_{2}))\cdot w_{2}</script><p><em>可以用相同的方式对权重$w_{1},w_{2}$求导</em></p>
<p><strong>所以链式法则指的是将复合函数拆分为一个个简单函数，通过组合简单函数的导数得到复合函数的导数，最后组成梯度进行权值更新</strong></p>
<h3 id="雅可比矩阵"><a href="#雅可比矩阵" class="headerlink" title="雅可比矩阵"></a>雅可比矩阵</h3><p>假设函数从$R^{n}$映射到$R^{m}$，其雅可比（Jacobian）矩阵就是从$R^{n}$到$R^{m}$的线性映射</p>
<p>如果函数由$m$个实函数组成：$y_{1}(x_{1},…,x_{n}),…,y_{m}(x_{1},…,x_{n})$，则其偏导数（如果存在）可以组成一个$m$行$n$列的雅可比矩阵</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}{\frac{\partial y_{1}}{\partial x_{1}}} & {\cdots} & {\frac{\partial y_{1}}{\partial x_{n}}} \\ {\vdots} & {\ddots} & {\vdots} \\ {\frac{\partial y_{m}}{\partial x_{1}}} & {\cdots} & {\frac{\partial y_{m}}{\partial x_{n}}}\end{array}\right]</script><p>其大小为$m\times n$</p>
<p><strong>在神经网络中每次计算的输入输出结果都是向量或矩阵，所以其偏导数均可以组成Jacobian矩阵</strong></p>
<p>比如函数$f’(z^{l})$表示输出向量$a^{(l)}$对输入向量$z^{(l)}$求导，就是一个雅可比矩阵</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}{\frac{\partial a^{(l)}_{1}}{\partial z^{(l)}_{1}}} & {\cdots} & {\frac{\partial a^{(1)}_{1}}{\partial z^{(l)}_{n}}} \\ {\vdots} & {\ddots} & {\vdots} \\ {\frac{\partial a^{(l)}_{m}}{\partial z^{(l)}_{1}}} & {\cdots} & {\frac{\partial a^{(l)}_{m}}{\partial z^{(l)}_{n}}}\end{array}\right]</script><p>其大小为$n^{(l)}\times n^{(l)}$</p>
<h2 id="网络符号定义"><a href="#网络符号定义" class="headerlink" title="网络符号定义"></a>网络符号定义</h2><p>规范神经网络的计算符号</p>
<p>关于神经元和层数</p>
<ul>
<li>$L$表示网络层数（不计入输入层）<ul>
<li>$L=2$，其中输入层是第<code>0</code>层，隐藏层是第<code>1</code>层，输出层是第<code>2</code>层</li>
</ul>
</li>
<li>$n^{(l)}$表示第$l$层的神经元个数（不包括偏置神经元）<ul>
<li>$n^{(0)}=3$，表示输入层神经元个数为<code>3</code></li>
<li>$n^{(1)}=4$，表示隐藏层神经元个数为<code>4</code></li>
<li>$n^{(2)}=2$，表示输出层神经元个数为<code>2</code></li>
</ul>
</li>
</ul>
<p>关于权重矩阵和偏置值</p>
<ul>
<li>$W^{(l)}$表示第$l-1$层到第$l$层的<strong>权重矩阵</strong>，矩阵行数为第$l$层的神经元个数，列数为第$l-1$层神经元个数<ul>
<li>$W^{(1)}$表示输入层到隐藏层的权重矩阵，大小为$R^{4\times 3}$</li>
<li>$W^{(2)}$表示隐藏层到输出层的权重矩阵，大小为$R^{2\times 4}$</li>
</ul>
</li>
<li>$W^{(l)}_{i,j}$表示第$l$层第$i$个神经元到第$l-1$第$j$个神经元的权值<ul>
<li>$i$的取值范围是$[1,n^{(l)}]$</li>
<li>$j$的取值范围是$[1, n^{(l-1)}]$</li>
</ul>
</li>
<li>$W^{(l)}_{i}$表示第$l$层第$i$个神经元对应的权重向量，大小为$n^{(l-1)}$</li>
<li>$W^{(l)}_{,j}$表示第$l-1$层第$j$个神经元对应的权重向量，大小为$n^{(l)}$</li>
<li>$b^{(l)}$表示第$l$层的<strong>偏置向量</strong><ul>
<li>$b^{(1)}$表示输入层到隐藏层的偏置向量，大小为$R^{4\times 1}$</li>
<li>$b^{(2)}$表示隐藏层到输出层的偏置向量，大小为$R^{2\times 1}$</li>
</ul>
</li>
<li>$b^{(l)}_{i}$表示第$l$层第$i$个神经元的偏置值<ul>
<li>$b^{(1)}_{2}$表示第$1$层隐藏层第$2$个神经元的偏置值</li>
</ul>
</li>
</ul>
<p>关于神经元输入向量和输出向量</p>
<ul>
<li>$a^{(l)}$表示第$l$层<strong>输出向量</strong>，$a^{(l)}=[a^{(l)}_{1},a^{(l)}_{2},…,a^{(l)}_{n^{l}}]^{T}$<ul>
<li>$a^{(0)}$表示输入层输出向量，大小为$R^{3\times 1}$</li>
<li>$a^{(1)}$表示隐藏层输出向量，大小为$R^{4\times 1}$</li>
<li>$a^{(2)}$表示输出层输出向量，大小为$R^{2\times 1}$</li>
</ul>
</li>
<li><p>$a^{(l)}_{i}$表示第$l$层第$i$个单元的输出值，其是输入向量经过激活计算后的值</p>
<ul>
<li>$a^{(1)}_{3}$表示隐含层第$3$个神经元的输入值，$a^{(1)}_{3}=g(z^{(1)}_{3})$</li>
</ul>
</li>
<li><p>$z^{(l)}$表示第$l$层<strong>输入向量</strong>，$z^{(l)}=[z^{(l)}_{1},z^{(l)}_{2},…,z^{(l)}_{n^{l}}]^{T}$</p>
<ul>
<li>$z^{(1)}$表示隐藏层的输入向量，大小为$R^{4\times 1}$</li>
<li>$z^{(2)}$表示输出层的输入向量，大小为$R^{2\times 1}$</li>
</ul>
</li>
<li>$z^{(l)}_{i}$表示第$l$层第$i$个单元的输入值，其是上一层输出向量和该层第$i$个神经元权重向量的加权累加和    <ul>
<li>$z^{(1)}_{1}$表示隐藏层第$1$个神经元的输入值，$z^{(1)}_{1}=b^{(1)}_{1}+W^{(1)}_{1,1}\cdot a^{(0)}_{1}+W^{(1)}_{1,2}\cdot a^{(0)}_{2}+W^{(1)}_{1,3}\cdot a^{(0)}_{3}$</li>
</ul>
</li>
</ul>
<p>关于神经元激活函数</p>
<ul>
<li>$g()$表示激活函数操作</li>
</ul>
<p>关于评分函数和损失函数</p>
<ul>
<li>$h()$表示评分函数操作</li>
<li>$J()$表示代价函数操作</li>
</ul>
<p><strong>神经元执行步骤</strong></p>
<p>神经元操作分为<code>2</code>步计算：</p>
<ol>
<li>输入向量$z^{(l)}$=前一层神经元输出向量$a^{(l-1)}$与权重矩阵$W^{(l)}$的加权累加和+偏置向量</li>
</ol>
<script type="math/tex; mode=display">
z^{(l)}_{j}=W^{(l)}_{i,j}\cdot a^{(l-1)}_{i} + b^{(l)}_{j} \Rightarrow 
z^{(l)}=W^{(l)}\cdot a^{(l-1)} + b^{(l)}</script><ol>
<li>输出向量$a^{(l)}$=对输入向量$z^{(l)}$进行激活函数操作</li>
</ol>
<script type="math/tex; mode=display">
a^{(l)}_{i}=g(z_{i}^{(l)})
\Rightarrow 
a^{(l)}=g(z^{(l)})</script><h2 id="TestNet网络"><a href="#TestNet网络" class="headerlink" title="TestNet网络"></a>TestNet网络</h2><p><code>TestNet</code>是一个<code>2</code>层神经网络，结构如下：</p>
<ul>
<li>输入层有<code>3</code>个神经元</li>
<li>隐藏层有<code>4</code>个神经元</li>
<li>输出层有<code>2</code>个神经元</li>
</ul>
<p><img src="/imgs/神经网络推导-单个数据/test_net.png" alt></p>
<ul>
<li>激活函数为<code>relu</code>函数</li>
<li>评分函数为<code>softmax</code>回归</li>
<li>代价函数为交叉熵损失</li>
</ul>
<p>对输入层</p>
<script type="math/tex; mode=display">
a^{(0)}=
\begin{bmatrix}
a^{(0)}_{1}\\ 
a^{(0)}_{2}\\ 
a^{(0)}_{3}
\end{bmatrix}
\in R^{3\times 1}</script><p>对隐藏层</p>
<script type="math/tex; mode=display">
W^{(1)}
=\begin{bmatrix}
W^{(1)}_{1,1} & W^{(1)}_{1,2} & W^{(1)}_{1,3}\\ 
W^{(1)}_{2,1} & W^{(1)}_{2,2} & W^{(1)}_{2,3}\\ 
W^{(1)}_{3,1} & W^{(1)}_{3,2} & W^{(1)}_{3,3}\\ 
W^{(1)}_{4,1} & W^{(1)}_{4,2} & W^{(1)}_{4,3}
\end{bmatrix}
\in R^{4\times 3}</script><script type="math/tex; mode=display">
b^{(1)}=
\begin{bmatrix}
b^{(1)}_{1}\\ 
b^{(1)}_{2}\\ 
b^{(1)}_{3}\\
b^{(1)}_{4}
\end{bmatrix}
\in R^{4\times 1}</script><script type="math/tex; mode=display">
z^{(1)}=
\begin{bmatrix}
z^{(1)}_{1}\\ 
z^{(1)}_{2}\\ 
z^{(1)}_{3}\\
z^{(1)}_{4}
\end{bmatrix}
\in R^{4\times 1}</script><script type="math/tex; mode=display">
a^{(1)}=
\begin{bmatrix}
a^{(1)}_{1}\\ 
a^{(1)}_{2}\\ 
a^{(1)}_{3}\\
a^{(1)}_{4}
\end{bmatrix}
\in R^{4\times 1}</script><p>对输出层</p>
<script type="math/tex; mode=display">
W^{(2)}
=\begin{bmatrix}
W^{(2)}_{1,1} & W^{(2)}_{1,2} & W^{(2)}_{1,3} & W^{(2)}_{1,4}\\ 
W^{(2)}_{2,1} & W^{(2)}_{2,2} & W^{(2)}_{2,3} & W^{(2)}_{2,4}
\end{bmatrix}
\in R^{2\times 4}</script><script type="math/tex; mode=display">
b^{(2)}=
\begin{bmatrix}
b^{(2)}_{1}\\ 
b^{(2)}_{2}
\end{bmatrix}
\in R^{4\times 1}</script><script type="math/tex; mode=display">
z^{(2)}=
\begin{bmatrix}
z^{(2)}_{1}\\ 
z^{(2)}_{2}
\end{bmatrix}
\in R^{4\times 1}</script><p>评分值</p>
<script type="math/tex; mode=display">
h(z^{(2)})
=\begin{bmatrix}
p(y=1)\\ 
p(y=2)
\end{bmatrix}
\in R^{2\times 1}</script><p>损失值</p>
<script type="math/tex; mode=display">
J(z^{(2)})=(-1)\cdot 1(y=1)\ln p(y=1)+(-1)\cdot 1(y=2)\ln p(y=2)\in R^{1}</script><h2 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h2><ul>
<li>对于输入层神经元，其得到输入数据后直接输出到下一层，并没有进行权值操作和激活函数操作，所以严格意义上讲输入层不是真正的神经元</li>
<li>对于输出层神经元，其得到输入数据，进行加权求和后直接输出进行评分函数计算，没有进行激活函数操作</li>
</ul>
<p>输入层到隐藏层计算</p>
<script type="math/tex; mode=display">
z^{(1)}_{1}=W^{(1)}_{1}\cdot a^{(0)}+b^{(1)}_{1}
=W^{(1)}_{1,1}\cdot a^{(0)}_{1}
+W^{(1)}_{1,2}\cdot a^{(0)}_{2}
+W^{(1)}_{1,3}\cdot a^{(0)}_{3}
+b^{(1)}_{1}</script><script type="math/tex; mode=display">
z^{(1)}_{2}=W^{(1)}_{2}\cdot a^{(0)}+b^{(1)}_{2}
=W^{(1)}_{2,1}\cdot a^{(0)}_{1}
+W^{(1)}_{2,2}\cdot a^{(0)}_{2}
+W^{(1)}_{2,3}\cdot a^{(0)}_{3}
+b^{(1)}_{2}</script><script type="math/tex; mode=display">
z^{(1)}_{3}=W^{(1)}_{3}\cdot a^{(0)}+b^{(1)}_{3}
=W^{(1)}_{3,1}\cdot a^{(0)}_{1}
+W^{(1)}_{3,2}\cdot a^{(0)}_{2}
+W^{(1)}_{3,3}\cdot a^{(0)}_{3}
+b^{(1)}_{3}</script><script type="math/tex; mode=display">
z^{(1)}_{4}=W^{(1)}_{4}\cdot a^{(0)}+b^{(1)}_{4}
=W^{(1)}_{4,1}\cdot a^{(0)}_{1}
+W^{(1)}_{4,2}\cdot a^{(0)}_{2}
+W^{(1)}_{4,3}\cdot a^{(0)}_{3}
+b^{(1)}_{4}</script><script type="math/tex; mode=display">
\Rightarrow z^{(1)}
=[z^{(1)}_{1},z^{(1)}_{2},z^{(1)}_{3},z^{(1)}_{4}]^{T}
=W^{(1)}\cdot a^{(0)}+b^{(1)}</script><p>隐藏层输入向量到输出向量</p>
<script type="math/tex; mode=display">
a^{(1)}_{1}=relu(z^{(1)}_{1}) \\
a^{(1)}_{2}=relu(z^{(1)}_{2}) \\
a^{(1)}_{3}=relu(z^{(1)}_{3}) \\
a^{(1)}_{4}=relu(z^{(1)}_{4})</script><script type="math/tex; mode=display">
\Rightarrow 
a^{(1)}=[a^{(1)}_{1},a^{(1)}_{2},a^{(1)}_{3},a^{(1)}_{4}]^{T}
=relu(z^{(1)})</script><p>隐藏层到输出层计算</p>
<script type="math/tex; mode=display">
z^{(2)}_{1}=W^{(2)}_{1}\cdot a^{(1)}+b^{(2)}_{1}
=W^{(2)}_{1,1}\cdot a^{(1)}_{1}
+W^{(2)}_{1,2}\cdot a^{(1)}_{2}
+W^{(2)}_{1,3}\cdot a^{(1)}_{3}
+W^{(2)}_{1,4}\cdot a^{(1)}_{4}
+b^{(2)}_{1}</script><script type="math/tex; mode=display">
z^{(2)}_{2}=W^{(2)}_{2}\cdot a^{(1)}+b^{(2)}_{2}
=W^{(2)}_{2,1}\cdot a^{(1)}_{1}
+W^{(2)}_{2,2}\cdot a^{(1)}_{2}
+W^{(2)}_{2,3}\cdot a^{(1)}_{3}
+W^{(2)}_{2,4}\cdot a^{(1)}_{4}
+b^{(2)}_{2}</script><script type="math/tex; mode=display">
\Rightarrow z^{(2)}
=[z^{(2)}_{1},z^{(2)}_{2}]^{T}
=W^{(2)}\cdot a^{(1)}+b^{(2)}</script><p>评分操作</p>
<script type="math/tex; mode=display">
p(y=1)=\frac {exp(z^{(2)}_{1})}{\sum exp(z^{(2)})} \ \ 
p(y=2)=\frac {exp(z^{(2)}_{2})}{\sum exp(z^{(2)})}</script><script type="math/tex; mode=display">
\Rightarrow h(z^{(2)})
=[p(y=1),p(y=2)]^{T}
=[\frac {exp(z^{(2)}_{1})}{\sum exp(z^{(2)})}, \frac {exp(z^{(2)}_{2})}{\sum exp(z^{(2)})}]^{T}</script><p>损失值</p>
<script type="math/tex; mode=display">
J(z^{(2)})=(-1)\cdot 1(y=1)\ln p(y=1)+(-1)\cdot 1(y=2)\ln p(y=2)</script><h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p>计算输出层输入向量梯度</p>
<script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(2)}_{1}}=
(-1)\cdot \frac {1(y=1)}{p(y=1)}\cdot \frac {\partial p(y=1)}{\partial z^{(2)}_{1}}
+(-1)\cdot \frac {1(y=2)}{p(y=2)}\cdot \frac {\partial p(y=2)}{\partial z^{(2)}_{1}}</script><script type="math/tex; mode=display">
\frac {\partial p(y=1)}{\partial z^{(2)}_{1}}
=\frac {exp(z^{(2)}_{1})\cdot \sum exp(z^{(2)})-exp(z^{(2)}_{1})\cdot exp(z^{(2)}_{1})}{(\sum exp(z^{(2)}))^{2}}
=\frac {exp(z^{(2)}_{1})}{\sum exp(z^{(2)})}
-(\frac {exp(z^{(2)}_{1})}{\sum exp(z^{(2)})})^2
=p(y=1)-(p(y=1))^2</script><script type="math/tex; mode=display">
\frac {\partial p(y=2)}{\partial z^{(2)}_{1}}
=\frac {-exp(z^{(2)}_{2})\cdot exp(z^{(2)}_{1})}{(\sum exp(z^{(2)}))^2}
=(-1)\cdot \frac {exp(z^{(2)}_{1})}{\sum exp(z^{(2)})}\cdot \frac {exp(z^{(2)}_{2})}{\sum exp(z^{(2)})}
=(-1)\cdot p(y=1)p(y=2)</script><script type="math/tex; mode=display">
\Rightarrow 
\frac {\partial J}{\partial z^{(2)}_{1}}
=(-1)\cdot \frac {1(y=1)}{p(y=1)}\cdot (p(y=1)-(p(y=1))^2)
+(-1)\cdot \frac {1(y=2)}{p(y=2)}\cdot (-1)\cdot p(y=1)p(y=2) \\
=(-1)\cdot 1(y=1)\cdot (1-p(y=1))
+1(y=2)\cdot p(y=1)
=p(y=1)-1(y=1)</script><script type="math/tex; mode=display">
\Rightarrow
\frac {\partial J}{\partial z^{(2)}_{2}}
=p(y=2)-1(y=2)</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial z^{(2)}}
=[p(y=1)-1(y=1), p(y=2)-1(y=2)]^{T}</script><p>计算输出层权重向量梯度</p>
<script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{1,1}}
=\frac {\partial J}{\partial z^{(2)}_{1}}\cdot \frac {\partial z^{(2)}_{1}}{\partial W^{(2)}_{1,1}}
=(p(y=1)-1(y=1))\cdot a^{(1)}_{1}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{1,2}}
=\frac {\partial J}{\partial z^{(2)}_{1}}\cdot \frac {\partial z^{(2)}_{1}}{\partial W^{(2)}_{1,2}}
=(p(y=1)-1(y=1))\cdot a^{(1)}_{2}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{1,3}}
=\frac {\partial J}{\partial z^{(2)}_{1}}\cdot \frac {\partial z^{(2)}_{1}}{\partial W^{(2)}_{1,3}}
=(p(y=1)-1(y=1))\cdot a^{(1)}_{3}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{1,4}}
=\frac {\partial J}{\partial z^{(2)}_{1}}\cdot \frac {\partial z^{(2)}_{1}}{\partial W^{(2)}_{1,4}}
=(p(y=1)-1(y=1))\cdot a^{(1)}_{4}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{2,1}}
=\frac {\partial J}{\partial z^{(2)}_{2}}\cdot \frac {\partial z^{(2)}_{2}}{\partial W^{(2)}_{2,1}}
=(p(y=2)-1(y=2))\cdot a^{(1)}_{1}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{2,2}}
=\frac {\partial J}{\partial z^{(2)}_{2}}\cdot \frac {\partial z^{(2)}_{2}}{\partial W^{(2)}_{2,2}}
=(p(y=2)-1(y=2))\cdot a^{(1)}_{2}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{2,3}}
=\frac {\partial J}{\partial z^{(2)}_{2}}\cdot \frac {\partial z^{(2)}_{2}}{\partial W^{(2)}_{2,3}}
=(p(y=2)-1(y=2))\cdot a^{(1)}_{3}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}_{2,4}}
=\frac {\partial J}{\partial z^{(2)}_{2}}\cdot \frac {\partial z^{(2)}_{2}}{\partial W^{(2)}_{2,4}}
=(p(y=2)-1(y=2))\cdot a^{(1)}_{4}</script><script type="math/tex; mode=display">
\Rightarrow 
\frac {\partial J}{\partial W^{(2)}}
=\begin{bmatrix}
\frac {\partial J}{\partial W^{(2)}_{1,1}} & \frac {\partial J}{\partial W^{(2)}_{1,2}} & \frac {\partial J}{\partial W^{(2)}_{1,3}} & \frac {\partial J}{\partial W^{(2)}_{1,4}}\\ 
\frac {\partial J}{\partial W^{(2)}_{2,1}} & \frac {\partial J}{\partial W^{(2)}_{2,2}} & \frac {\partial J}{\partial W^{(2)}_{2,3}} & \frac {\partial J}{\partial W^{(2)}_{2,4}}
\end{bmatrix}</script><script type="math/tex; mode=display">
=\begin{bmatrix}
(p(y=1)-1(y=1))\cdot a^{(1)}_{1} & (p(y=1)-1(y=1))\cdot a^{(1)}_{2} & (p(y=1)-1(y=1))\cdot a^{(1)}_{3} & (p(y=1)-1(y=1))\cdot a^{(1)}_{4}\\ 
(p(y=2)-1(y=2))\cdot a^{(1)}_{1} & (p(y=2)-1(y=2))\cdot a^{(1)}_{2} & (p(y=2)-1(y=2))\cdot a^{(1)}_{3} & (p(y=2)-1(y=2))\cdot a^{(1)}_{4}
\end{bmatrix}</script><script type="math/tex; mode=display">
=\begin{bmatrix}
p(y=1)-1(y=1)\\ 
p(y=2)-1(y=2)
\end{bmatrix} 
\begin{bmatrix}
a^{(1)}_{1}\\ 
a^{(1)}_{2}\\ 
a^{(1)}_{3}\\ 
a^{(1)}_{4}
\end{bmatrix}
=R^{2\times 1}\cdot R^{1\times 4}
=R^{2\times 4}</script><p>计算隐藏层输出向量梯度</p>
<script type="math/tex; mode=display">
\frac {\partial J}{\partial a^{(1)}_{1}}
=\frac {\partial J}{\partial z^{(2)}_{1}}\cdot \frac {\partial z^{(2)}_{1}}{\partial a^{(1)}_{1}}
+\frac {\partial J}{\partial z^{(2)}_{2}}\cdot \frac {\partial z^{(2)}_{2}}{\partial a^{(1)}_{1}}
=(p(y=1)-1(y=1))\cdot W^{(2)}_{1,1}
+(p(y=2)-1(y=2))\cdot W^{(2)}_{2,1}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial a^{(1)}_{2}}
=\frac {\partial J}{\partial z^{(2)}_{1}}\cdot \frac {\partial z^{(2)}_{1}}{\partial a^{(1)}_{2}}
+\frac {\partial J}{\partial z^{(2)}_{2}}\cdot \frac {\partial z^{(2)}_{2}}{\partial a^{(1)}_{2}}
=(p(y=1)-1(y=1))\cdot W^{(2)}_{1,2}
+(p(y=2)-1(y=2))\cdot W^{(2)}_{2,2}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial a^{(1)}_{3}}
=\frac {\partial J}{\partial z^{(2)}_{1}}\cdot \frac {\partial z^{(2)}_{1}}{\partial a^{(1)}_{3}}
+\frac {\partial J}{\partial z^{(2)}_{2}}\cdot \frac {\partial z^{(2)}_{2}}{\partial a^{(1)}_{3}}
=(p(y=1)-1(y=1))\cdot W^{(2)}_{1,3}
+(p(y=2)-1(y=2))\cdot W^{(2)}_{2,3}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial a^{(1)}_{4}}
=\frac {\partial J}{\partial z^{(2)}_{1}}\cdot \frac {\partial z^{(2)}_{1}}{\partial a^{(1)}_{4}}
+\frac {\partial J}{\partial z^{(2)}_{2}}\cdot \frac {\partial z^{(2)}_{2}}{\partial a^{(1)}_{4}}
=(p(y=1)-1(y=1))\cdot W^{(2)}_{1,4}
+(p(y=2)-1(y=2))\cdot W^{(2)}_{2,4}</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial a^{(1)}}
=\begin{bmatrix}
W^{(2)}_{1,1} & W^{(2)}_{2,1}\\ 
W^{(2)}_{1,2} & W^{(2)}_{2,2}\\ 
W^{(2)}_{1,3} & W^{(2)}_{2,3}\\ 
W^{(2)}_{1,4} & W^{(2)}_{2,4}
\end{bmatrix}
\begin{bmatrix}
p(y=1)-1(y=1)\\ 
p(y=2)-1(y=2)
\end{bmatrix}
=R^{4\times 2}\cdot R^{2\times 1}
=R^{4\times 1}</script><p>计算隐藏层输入向量的梯度</p>
<script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(1)}_{1}}
=\frac {\partial J}{\partial a^{(1)}_{1}}\cdot \frac {\partial a^{(1)}_{1}}{\partial z^{(1)}_{1}}
=((p(y=1)-1(y=1))\cdot W^{(2)}_{1,1}
+(p(y=2)-1(y=2))\cdot W^{(2)}_{2,1})\cdot 1(z^{(1)}_{1}\geq 0)</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(1)}_{2}}
=\frac {\partial J}{\partial a^{(1)}_{2}}\cdot \frac {\partial a^{(1)}_{2}}{\partial z^{(1)}_{2}}
=((p(y=1)-1(y=1))\cdot W^{(2)}_{1,2}
+(p(y=2)-1(y=2))\cdot W^{(2)}_{2,2})\cdot 1(z^{(1)}_{2}\geq 0)</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(1)}_{3}}
=\frac {\partial J}{\partial a^{(1)}_{3}}\cdot \frac {\partial a^{(1)}_{3}}{\partial z^{(1)}_{3}}
=((p(y=1)-1(y=1))\cdot W^{(2)}_{1,3}
+(p(y=2)-1(y=2))\cdot W^{(2)}_{2,3})\cdot 1(z^{(1)}_{3}\geq 0)</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(1)}_{4}}
=\frac {\partial J}{\partial a^{(1)}_{4}}\cdot \frac {\partial a^{(1)}_{4}}{\partial z^{(1)}_{4}}
=((p(y=1)-1(y=1))\cdot W^{(2)}_{1,4}
+(p(y=2)-1(y=2))\cdot W^{(2)}_{2,4})\cdot 1(z^{(1)}_{4}\geq 0)</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial z^{(1)}}
=\frac {\partial J}{\partial a^{(1)}}\cdot \frac {\partial a^{(1)}}{\partial z^{(1)}}
=(
\begin{bmatrix}
W^{(2)}_{1,1} & W^{(2)}_{2,1}\\ 
W^{(2)}_{1,2} & W^{(2)}_{2,2}\\ 
W^{(2)}_{1,3} & W^{(2)}_{2,3}\\ 
W^{(2)}_{1,4} & W^{(2)}_{2,4}
\end{bmatrix}
\begin{bmatrix}
p(y=1)-1(y=1)\\ 
p(y=2)-1(y=2)
\end{bmatrix}
)
*\begin{bmatrix}
1(z^{(1)}_{1}\geq 0) \\ 
1(z^{(1)}_{2}\geq 0) \\ 
1(z^{(1)}_{3}\geq 0) \\ 
1(z^{(1)}_{4}\geq 0)
\end{bmatrix}
=(R^{4\times 2}\cdot R^{2\times 1})* R^{4\times 1}
=R^{4\times 1}</script><p>计算隐藏层权重向量的梯度</p>
<script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(1)}_{1,1}}
=\frac {\partial J}{\partial z^{(1)}_{1}}\cdot
\frac {\partial z^{(1)}_{1}}{\partial W^{(1)}_{1,1}}
=((p(y=1)-1(y=1))\cdot W^{(2)}_{1,1}
+(p(y=2)-1(y=2))\cdot W^{(2)}_{2,1})\cdot 1(z^{(1)}_{1}\geq 0)\cdot a^{(0)}_{1}</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial W^{(1)}_{i,j}}
=\frac {\partial J}{\partial z^{(1)}_{i}}\cdot
\frac {\partial z^{(1)}_{i}}{\partial W^{(1)}_{i,j}}
=((p(y=1)-1(y=1))\cdot W^{(2)}_{1,i}
+(p(y=2)-1(y=2))\cdot W^{(2)}_{2,i})\cdot 1(z^{(1)}_{i}\geq 0)\cdot a^{(0)}_{j}</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial W^{(1)}_{i,:}}
=((p(y=1)-1(y=1))\cdot W^{(2)}_{1,i}
+(p(y=2)-1(y=2))\cdot W^{(2)}_{2,i})\cdot 1(z^{(1)}_{i}\geq 0)\cdot a^{(0)}</script><script type="math/tex; mode=display">
\Rightarrow \frac {\partial J}{\partial W^{(1)}}
=\frac {\partial J}{\partial z^{(1)}_{1}}\cdot (a^{(0)})^{T}
=R^{4\times 1}\cdot R^{1\times 3}
=R^{4\times 3}</script><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><code>TestNet</code>网络的前向操作如下：</p>
<script type="math/tex; mode=display">
z^{(1)}
=W^{(1)}\cdot a^{(0)}+b^{(1)}</script><script type="math/tex; mode=display">
a^{(1)}
=g(z^{(1)})</script><script type="math/tex; mode=display">
z^{(2)}
=W^{(2)}\cdot a^{(1)}+b^{(2)}</script><script type="math/tex; mode=display">
h(z^{(2)})
=[p(y=1),p(y=2)]^{T}
=[\frac {exp(z^{(2)}_{1})}{\sum exp(z^{(2)})}, \frac {exp(z^{(2)}_{2})}{\sum exp(z^{(2)})}]^{T}</script><script type="math/tex; mode=display">
J(z^{(2)})=(-1)\cdot 1(y=1)\ln p(y=1)+(-1)\cdot 1(y=2)\ln p(y=2)</script><p>反向传播如下：</p>
<script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(2)}}
=[p(y=1)-1(y=1), p(y=2)-1(y=2)]^{T}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(2)}}
=\frac {\partial J}{\partial z^{(2)}}\cdot a^{(1)}
=\begin{bmatrix}
p(y=1)-1(y=1)\\ 
p(y=2)-1(y=2)
\end{bmatrix} 
\begin{bmatrix}
a^{(1)}_{1}\\ 
a^{(1)}_{2}\\ 
a^{(1)}_{3}\\ 
a^{(1)}_{4}
\end{bmatrix}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial a^{(1)}}
=(W^{(2)})^{T}\cdot \frac {\partial J}{\partial z^{(2)}}
=\begin{bmatrix}
W^{(2)}_{1,1} & W^{(2)}_{2,1}\\ 
W^{(2)}_{1,2} & W^{(2)}_{2,2}\\ 
W^{(2)}_{1,3} & W^{(2)}_{2,3}\\ 
W^{(2)}_{1,4} & W^{(2)}_{2,4}
\end{bmatrix}
\begin{bmatrix}
p(y=1)-1(y=1)\\ 
p(y=2)-1(y=2)
\end{bmatrix}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial z^{(1)}}
=\frac {\partial J}{\partial a^{(1)}}*1(z^{(1)}\geq 0)
=(
\begin{bmatrix}
W^{(2)}_{1,1} & W^{(2)}_{2,1}\\ 
W^{(2)}_{1,2} & W^{(2)}_{2,2}\\ 
W^{(2)}_{1,3} & W^{(2)}_{2,3}\\ 
W^{(2)}_{1,4} & W^{(2)}_{2,4}
\end{bmatrix}
\begin{bmatrix}
p(y=1)-1(y=1)\\ 
p(y=2)-1(y=2)
\end{bmatrix}
)
*\begin{bmatrix}
1(z^{(1)}_{1}\geq 0) \\ 
1(z^{(1)}_{2}\geq 0) \\ 
1(z^{(1)}_{3}\geq 0) \\ 
1(z^{(1)}_{4}\geq 0)
\end{bmatrix}</script><script type="math/tex; mode=display">
\frac {\partial J}{\partial W^{(1)}}
=\frac {\partial J}{\partial z^{(1)}_{1}}\cdot (a^{(0)})^{T}</script><p>参考<a href="http://ufldl.stanford.edu/wiki/index.php/%E5%8F%8D%E5%90%91%E4%BC%A0%E5%AF%BC%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">反向传导算法</a>和<a href="https://zhuanlan.zhihu.com/p/22473137" target="_blank" rel="noopener">神经网络反向传播的数学原理</a>，设每层输入向量为残差$\delta^{(l)}=\frac{\partial J(W, b)}{\partial z^{(l)}}$，用于表示该层对最终输出值的残差造成的影响；而最终输出值的残差$\delta^{(L)}$就是损失函数对输出层输入向量的梯度</p>
<p>前向传播执行步骤</p>
<ol>
<li><p>层与层之间的操作就是输出向量和权值矩阵的加权求和以及对输入向量的函数激活</p>
<script type="math/tex; mode=display">
 z^{(l)} = W^{(l)}\cdot a^{(l-1)}+b^{(l)} \\
 a^{(l)} = g(z^{(l)})</script></li>
<li><p>输出层输出结果后，进行评分函数的计算，得到最终的计算结果（<em>以softmax分类为例</em>）</p>
<script type="math/tex; mode=display">
 h(z^{(2)})
 =[p(y=1),...,p(y=n^{(L)})]^{T}
 =[\frac {exp(z^{(2)}_{1})}{\sum exp(z^{(2)})}, ...,\frac {exp(z^{(2)}_{n^{(L)}})}{\sum exp(z^{(2)})}]^{T}</script></li>
<li><p>损失函数根据计算结果判断最终损失值（<em>以交叉熵损失为例</em>）</p>
<script type="math/tex; mode=display">
 J(z^{(L)})=(-1)\cdot 1(y=1)\ln p(y=1)+...+(-1)\cdot 1(y=n^{(L)})\ln p(y=n^{(L)})</script></li>
</ol>
<p>反向传播执行步骤</p>
<ol>
<li><p>计算损失函数对于输出层输入向量的梯度(最终层残差)</p>
<script type="math/tex; mode=display">
 \delta^{(L)}=
 \frac{\varphi J}{\varphi z^{(L)}}
 =[p(y=1)-1(y=1), ..., p(y=n^{(L)})-1(y=n^{(L)})]^{T}</script></li>
<li><p>计算中间隐藏层的残差值（$L-1,L-2,…1$）</p>
<script type="math/tex; mode=display">
 \delta^{(l)}=
 \frac{\varphi J}{\varphi z^{(l)}}
 =(\frac{\varphi J}{\varphi z^{(l+1)}}\cdot \frac{\varphi z^{(l+1)}}{\varphi a^{(l)}})
 *\frac{\varphi a^{(l)}}{\varphi z^{(l)}}
 =((W^{(l+1)})^{T}\cdot \delta^{(l+1)})
 *\frac{\varphi a^{(l)}}{\varphi z^{(l)}}</script></li>
<li><p>完成所有的可学习参数（权值矩阵和偏置向量）的梯度计算</p>
<script type="math/tex; mode=display">
 \nabla_{W^{(l)}} J(W, b)= \delta^{(l)}\cdot a^{(l-1)}\\
 \nabla_{b^{(l)}} J(W, b)= \delta^{(l)}</script></li>
<li><p>更新权值矩阵和偏置向量</p>
<script type="math/tex; mode=display">
 W^{(l)}=W^{(l)}-\alpha\left[\nabla W^{(l)}+\lambda W^{(l)}\right] \\
 b^{(l)}=b^{(l)}-\alpha \nabla b^{(l)}</script></li>
</ol>
<h4 id="初始化数据的必要性"><a href="#初始化数据的必要性" class="headerlink" title="初始化数据的必要性"></a>初始化数据的必要性</h4><p>梯度与输入数据<strong>呈正相关</strong>，权值更新公式如下：</p>
<script type="math/tex; mode=display">
W^{(l)}_{i,j} = W^{(l)}_{i,j} - \alpha \cdot \frac{\varphi J}{\varphi W^{(l)}_{i,j}}</script><p><strong>如果输入数据放大<code>1000</code>倍，那么梯度至少放大<code>1000</code>倍，这时需要极小的$\alpha$才能平衡每次更新的大小，所以初始化数据很有必要</strong></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>深度学习</category>
        <category>数学</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>线性代数</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>激活函数</title>
    <url>/posts/f86c970.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://www.zhujian.tech/posts/7ca31f7.html#more">神经网络概述</a></p><p><a href="http://simtalk.cn/2016/09/08/Neural-Network/" target="_blank" rel="noopener">Neural Network</a></p><p><a href="https://blog.csdn.net/mao_xiao_feng/article/details/53242235" target="_blank" rel="noopener">【深度学习】论文导读：ELU激活函数的提出（FAST AND ACCURATE DEEP NETWORK LEARNING BY EXPONENTIAL LINEAR UNITS (ELUS)）</a></p><a id="more"></a>



<p><a href="https://www.cnblogs.com/XDU-Lakers/p/10557496.html" target="_blank" rel="noopener">深度学习中几种常见的激活函数理解与总结</a></p>
<p>介绍激活函数及其特性</p>
<ul>
<li>Sigmoid</li>
<li>Tanh</li>
<li>ReLU</li>
<li>Leaky ReLU</li>
<li>Maxout</li>
</ul>
<h2 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a><code>Sigmoid</code></h2><p><code>Sigmoid</code>函数是最早出现的激活函数，估计是因为逻辑回归模型的缘故</p>
<p>它能够将输入数据压缩到<code>[0,1]</code>之间，值越小，越接近于<code>0</code>；值越大，越接近于<code>1</code>。数学公式如下：</p>
<script type="math/tex; mode=display">
\sigma (x)=\frac{1}{1+e^{-x}}</script><script type="math/tex; mode=display">
\frac {\varphi  \sigma (x)}{\varphi x}=
\frac{-1}{(1+e^{-x})^2}\cdot e^{-x} \cdot (-1)=
\frac{1}{1+e^{-x}}\cdot \frac{e^{-x}}{1+e^{-x}}= 
\sigma (x)\cdot (1-\sigma (x))</script><p>目前基本不使用<code>Sigmoid</code>作为激活函数，主要有两个缺陷</p>
<ol>
<li>当激活值处于饱和（<code>saturate</code>）状态（接近<code>0</code>或<code>1</code>），此时得到的梯度几乎为<code>0</code>（<em>如下图所示</em>），也就是说无法在反向传播过程中对权重进行有效更新，网络也将停止学习。所以初始化权重值不能过大，否则会导致激活函数饱和</li>
<li>因为<code>Sigmoid</code>的取值范围是<code>[0,1]</code>，所以其输出不是零中心（<code>zero-centered</code>）。如果输入的数据总是正值，会导致计算得到的梯度值变为全正或全负（<em>依赖于线性运算的表达式$f$</em>）。非零中心会导致权重更新时呈$Z$字形下降，这个问题可以通过初始化权重时平衡正负值来减轻影响</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def sigmoid(x):</span><br><span class="line">    return 1.0 / (1 + np.exp(-1 * x))</span><br><span class="line"></span><br><span class="line">def dsigmoid(x):</span><br><span class="line">    return sigmoid(x) * (1 - sigmoid(x))</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/激活函数/sigmoid.png" alt></p>
<h2 id="Tanh"><a href="#Tanh" class="headerlink" title="Tanh"></a><code>Tanh</code></h2><p><code>Tanh</code>（全局正切）函数在<code>Sigmoid</code>函数的基础上进一步发展，其将取值压缩在<code>[-1,1]</code>之间，值越小，越接近于<code>-1</code>；值越大，越接近于<code>1</code>。数学公式如下：</p>
<script type="math/tex; mode=display">
tanh(x) = \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}=\frac{1-e^{-2x}}{1+e^{-2x}}=\frac{2-(1+e^{-2x})}{1+e^{-2x}}=2\sigma (2x)+1</script><script type="math/tex; mode=display">
\frac {\varphi  tanh(x)}{\varphi x}=
\frac {v(x)'\cdot u(x)-v(x)\cdot u(x)'}{u(x)^2}</script><p>其中</p>
<script type="math/tex; mode=display">
v(x)=e^{x}-e^{-x}
\Rightarrow {v(x)}'= e^{x}+e^{-x} \\
u(x)=e^{x}+e^{-x}
\Rightarrow {u(x)}'= e^{x}-e^{-x}</script><p>所以</p>
<script type="math/tex; mode=display">
\frac {\varphi  tanh(x)}{\varphi x}=\frac {u(x)^2-v(x)^2}{u(x)^2}=
1-(tanh(x))^2</script><p>根据公式可知，$tanh$函数是$sigmoid$函数的扩展，它解决了输出零中心的问题</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def tanh(x):</span><br><span class="line">    x1 = np.exp(x)</span><br><span class="line">    x2 = np.exp(-1 * x)</span><br><span class="line">    return (x1 - x2) / (x1 + x2)</span><br><span class="line">    # return 2 * sigmoid(2 * x) + 1</span><br><span class="line"></span><br><span class="line">def dtanh(x):</span><br><span class="line">    return 1 - tanh(x) ** 2</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/激活函数/tanh.png" alt></p>
<h2 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a><code>ReLU</code></h2><p><code>ReLU</code>(<code>Rectified Linear Unit</code>，整流线性单元)激活函数是因为在<a href="http://xueshu.baidu.com/usercenter/paper/show?paperid=bfdf67dfdf8cea0c47038f63e91b9df1&amp;site=xueshu_se" target="_blank" rel="noopener">AlexNet网络</a>中的使用而得到了推广。当输入小于<code>0</code>时，输出为<code>0</code>；否则，输入为输出值。其数学公式如下：</p>
<script type="math/tex; mode=display">
f(x)=\max (0,x)</script><script type="math/tex; mode=display">
\frac {\varphi  f(x)}{\varphi x}=
\left\{\begin{matrix}
0, x<0\\ 
1, x\geq 0
\end{matrix}\right.
=1(x\geq 0)</script><p>优势如下：</p>
<ol>
<li>计算高效。达到同样训练误差率的时间，使用<code>ReLU</code>能够比<code>tanh</code>快<code>6</code>倍</li>
<li>实现简单。相比于<code>sigmoid/tanh</code>需要指数运算，<code>ReLU</code>仅是线性阈值操作</li>
</ol>
<p>缺陷如下：</p>
<ol>
<li>输出值没有零中心</li>
<li>当输入值小于<code>0</code>时，梯度消失，权值不再更新</li>
</ol>
<p>如果步长（<code>learning rate</code>，学习率）设置过大，有可能导致梯度更新后，神经元线性计算结果永远小于<code>0</code>，无法再次更新权值，也就是说这个神经元在训练过程中<em>死亡</em>了，所以需要合理设置步长大小</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def relu(x):</span><br><span class="line">    return np.array(list(map(lambda x: x if x &gt; 0 else 0, x)))</span><br><span class="line"></span><br><span class="line">def drelu(x):</span><br><span class="line">    return x &gt;= 0</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/激活函数/relu.png" alt></p>
<h2 id="Leaky-ReLU"><a href="#Leaky-ReLU" class="headerlink" title="Leaky ReLU"></a><code>Leaky ReLU</code></h2><p><code>Leaky ReLU</code>试图解决<code>ReLU</code>单侧梯度消失的问题，其实现公式如下：</p>
<script type="math/tex; mode=display">
f(x)=I (x<0)(ax)+I (x>=0)(x)</script><script type="math/tex; mode=display">
\frac {\varphi  f(x)}{\varphi x}=
\left\{\begin{matrix}
a, x<0\\ 
1, x\geq 0
\end{matrix}\right.</script><p>其中$a$是一个超参数，通常是一个很小的常数（比如$0.01$），这样当输入值小于$0$时仍旧能够进行权重更新</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def leaky_relu(x, a=0.01):</span><br><span class="line">    return np.array(list(map(lambda x: x if x &gt; 0 else a * x, x)))</span><br><span class="line"></span><br><span class="line">def dleaky_relu(x, a=0.01):</span><br><span class="line">    return np.array(list(map(lambda x: 1 if x &gt; 0 else a, x)))</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/激活函数/leaky_relu.png" alt></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>推荐使用顺序：<code>ReLU &gt; Leaky ReLU &gt; Tanh &gt; Sigmoid</code></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>最优化</category>
        <category>数学</category>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>微积分</tag>
        <tag>激活函数</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络概述</title>
    <url>/posts/7ca31f7.html</url>
    <content><![CDATA[<p>参考：<a href="http://cs231n.github.io/neural-networks-1/" target="_blank" rel="noopener">Neural Networks Part 1: Setting up the Architecture </a></p><a id="more"></a>
<p>神经网络是卷积神经网络的基础，其包含的层架构、激活函数、反向传播、正则化等等内容都可以应用于卷积神经网络</p>
<h2 id="生物神经元"><a href="#生物神经元" class="headerlink" title="生物神经元"></a>生物神经元</h2><p>神经网络是因为生物神经系统的研究而得到启发的，人脑基本的计算单位是神经元（<code>neuron</code>）</p>
<p>简单的神经元实现如下：通过树突（<code>dendrity</code>）接收信号，经过细胞体（<code>cell body</code>）处理后再通过轴突（<code>axon</code>）传输到其他神经元</p>
<p>数学建模如下：每个树突会有一个权重值$w$，接受到信号$x$后会进行乘法交互$w\cdot x$，所有的信号会在细胞体中求和$\sum w\cdot x$，如果总和达到某一阈值，就通过轴突向外发送信号</p>
<p><img src="/imgs/神经网络概述/neuron.png" alt></p>
<script type="math/tex; mode=display">
y=f(\sum w_{i}\cdot x_{i})</script><p><em>把阈值函数称为激活函数（<code>activate function</code>）</em></p>
<p><em>逻辑回归就是一个典型的单神经元架构，其输入一组向量，经过线性计算后再通过<code>sigmoid</code>函数输出</em></p>
<p><em>每个神经元都可以设置一个偏置值（<code>bias</code>）</em></p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p>单个神经元能够实现二元分类问题，组合多个神经元就能够实现多元分类</p>
<h3 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h3><p>神经网络以层的结构组织神经元，每一层可以有多个神经元，每个神经元都与前一层所有神经元全部连接，同层神经元互不连接，所以神经网络层的类型称为全连接层（<code>fully-connected layer</code>）</p>
<p>输入层神经元得到输入数据后，直接传送给下一层神经元，没有经过激活函数处理</p>
<p>输出层神经元得到输出，进行线性计算后<strong>不经过激活函数处理</strong>，直接向外发送，进行评分函数或损失函数处理</p>
<p><em><code>softmax</code>回归就是一个单层神经网络模型</em></p>
<h3 id="命名规范"><a href="#命名规范" class="headerlink" title="命名规范"></a>命名规范</h3><ol>
<li>神经网络（<code>neural network</code>）也被称为人工神经网络（<code>artifical neural networks, ANN</code>），或者称为多层感知器（<code>multi-layer perceptrons, MLP</code>）；神经元（<code>neuron</code>）也被称为单元（<code>unit</code>）</li>
<li>神经网络把第一层称为输入层（<code>input layer</code>），把最后一层称为输出层（<code>output layer</code>），把中间层称为隐藏层（<code>hidden layer</code>）</li>
<li>通常不把输入层计入网络层数，也就是说一个单层神经网络指的是没有隐藏层的神经网络（输入层直接连接输出层）</li>
</ol>
<p>单层神经网络和<code>2</code>层神经网络如下所示</p>
<p><img src="/imgs/神经网络概述/1-layer-network.png" alt></p>
<p><img src="/imgs/神经网络概述/2-layer-network.png" alt></p>
<h3 id="网络大小评判"><a href="#网络大小评判" class="headerlink" title="网络大小评判"></a>网络大小评判</h3><p>通常使用神经元个数和可学习参数（权重值+偏置值）个数来评判神经网络大小</p>
<p><strong>注意：不包括输入层</strong></p>
<ul>
<li>在上图单层神经网络中，神经元个数是$3$，权重个数是$5\times 3=15$，偏置值个数是$3$，所以可学习参数（learnable parameter）是$18$个</li>
<li>在上图2层神经网络中，神经元个数是$4+2=6$，权重个数是$3\times 4+4\times 2=20$个，偏置值是$4+2=6$个，所以可学习参数是$26$个</li>
</ul>
<h3 id="拟合能力"><a href="#拟合能力" class="headerlink" title="拟合能力"></a>拟合能力</h3><p>参考：<a href="http://cs231n.github.io/neural-networks-1/" target="_blank" rel="noopener">Representational power</a></p>
<p>参考<a href="http://www.dartmouth.edu/~gvc/Cybenko_MCSS.pdf" target="_blank" rel="noopener">Approximation by Superpositions of Sigmoidal Function</a>和<a href="http://neuralnetworksanddeeplearning.com/chap4.html" target="_blank" rel="noopener">A visual proof that neural nets can compute any function</a>，至少一个隐藏层的神经网络是一个通用逼近器（<code>universal approximator</code>），它能够近似（<code>approximate</code>）任何连续函数（<code>continuous function</code>），即给定任何连续函数$f(x)$和误差$\epsilon&gt;0$，存在一个神经网络$g(x)$，对$\forall x,有|f(x)-g(x)|&lt;\epsilon$</p>
<h4 id="网络深度与拟合能力"><a href="#网络深度与拟合能力" class="headerlink" title="网络深度与拟合能力"></a>网络深度与拟合能力</h4><p>理论上单层隐藏层神经网络就能够近似所有的连续函数，但是更深的神经网络在实践中能够实现更好的分类结果</p>
<p>参考文章<a href="https://blog.csdn.net/ybdesire/article/details/78837688" target="_blank" rel="noopener">深层神经网络与浅层神经网络的区别</a></p>
<p>作者给出两个解释是</p>
<ol>
<li>在设计单层隐藏层神经网络模型时是否能够提供足够多的神经元</li>
<li>如果目标是拟合非连续函数</li>
</ol>
<p>在<code>cs231n</code>课程中，推荐使用3层神经网络，它能够比<code>2</code>层神经网络性能更优，但是更深的神经网络（<code>4/5/6</code>层）没有更多的帮助，并提供了一个<a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html" target="_blank" rel="noopener">JS Demo</a>进行验证</p>
<h3 id="激活函数作用"><a href="#激活函数作用" class="headerlink" title="激活函数作用"></a>激活函数作用</h3><p>参考：</p>
<p><a href="https://blog.csdn.net/program_developer/article/details/78704224" target="_blank" rel="noopener">神经网络激活函数的作用是什么？</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1010097" target="_blank" rel="noopener">理解激活函数在神经网络模型构建中的作用</a></p>
<p><a href="https://www.zhihu.com/question/29021768" target="_blank" rel="noopener">请问人工神经网络中的activation function的作用具体是什么？为什么ReLu要好过于tanh和sigmoid function?</a></p>
<p>在神经网络中，激活函数得到前一层输出向量和权重的加权求和向量后进行非线性组合，<strong>其目的是为神经网络添加非线性因素，提高网络表达能力，解决线性模型不能解决的非线性问题</strong></p>
<ul>
<li><strong>数值上表现</strong>：挤压输入向量，比如<code>sigmoid</code>输出范围<code>[0,1]</code>，<code>tanh</code>输出范围<code>[-1,1]</code>，<code>ReLU</code>输出范围<code>[0,x]</code></li>
<li><strong>空间上表现</strong>：扭曲分类决策面，产生非线性决策面</li>
</ul>
<h3 id="权重向量和偏置值"><a href="#权重向量和偏置值" class="headerlink" title="权重向量和偏置值"></a>权重向量和偏置值</h3><p>参考：<a href="https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks" target="_blank" rel="noopener">Role of Bias in Neural Networks</a></p>
<p>每个神经元都包含一个权重向量和一个偏置值（输入层除外），<strong>权重向量的作用是决定分类决策面的方向，偏置值的作用是确定分类决策面的位置</strong></p>
<p>对单个神经元而言，其表达公式如下：</p>
<script type="math/tex; mode=display">
output = g(w\cdot x+b)</script><p>其中$output$是输出向量，$g()$是激活函数，$w$是权重向量，$x$是输入向量，$b$是偏置值。以二维坐标轴为例</p>
<ul>
<li><p>如果仅有权重向量，其分类决策面一定要经过零点，所以<strong>偏置值的作用就是帮助决策面在坐标轴上左右移动，确定分类位置</strong></p>
</li>
<li><p>如果仅有偏置值，其分类决策面仅是一条水平线，所以<strong>权重向量的作用就是扭曲决策面，确定分类方向</strong></p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-5-4 上午10:19</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def sigmoid(x):</span><br><span class="line">    return 1.0 / (1 + np.exp(-1 * x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    x = np.linspace(-10, 10)</span><br><span class="line">    y = sigmoid(x)</span><br><span class="line">    y2 = sigmoid(x + 3)</span><br><span class="line">    y3 = sigmoid(x - 3)</span><br><span class="line">    y4 = sigmoid(3)</span><br><span class="line">    y5 = sigmoid(-3)</span><br><span class="line"></span><br><span class="line">    plt.plot(x, y, label=&apos;没有偏置值&apos;)</span><br><span class="line">    plt.plot(x, y2, label=&apos;添加偏置值3&apos;)</span><br><span class="line">    plt.plot(x, y3, label=&apos;添加偏置值-3&apos;)</span><br><span class="line">    plt.hlines(y4, -10, 10, label=&apos;仅有偏置值3&apos;)</span><br><span class="line">    plt.hlines(y5, -10, 10, label=&apos;仅有偏置值-3&apos;)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/神经网络概述/weight_bias.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>深度学习</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>使用softmax回归进行mnist分类</title>
    <url>/posts/dd673751.html</url>
    <content><![CDATA[<p>参考：<a href="https://www.jiqizhixin.com/articles/2019-03-15-17" target="_blank" rel="noopener">PyTorch进阶之路（三）：使用logistic回归实现图像分类</a></p><p><code>MNIST</code>是手写数字数据库，共有<code>60000</code>张训练图像和<code>10000</code>张测试图像，分别表示数字<code>0-9</code></p><a id="more"></a>

<p>利用<code>softmax</code>回归模型进行<code>mnist</code>分类</p>
<h2 id="numpy实现"><a href="#numpy实现" class="headerlink" title="numpy实现"></a><code>numpy</code>实现</h2><p>首先需要进行数据库下载和解压，参考<a href="https://blog.csdn.net/u012005313/article/details/84453316" target="_blank" rel="noopener">Python MNIST解压</a></p>
<p>加载数据集并将训练数据打乱</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def load_data(shuffle=True):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载mnist数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    train_dir = os.path.join(data_path, &apos;train&apos;)</span><br><span class="line">    test_dir = os.path.join(data_path, &apos;test&apos;)</span><br><span class="line"></span><br><span class="line">    x_train = []</span><br><span class="line">    x_test = []</span><br><span class="line">    y_train = []</span><br><span class="line">    y_test = []</span><br><span class="line">    train_file_list = []</span><br><span class="line">    for i in cate_list:</span><br><span class="line">        data_dir = os.path.join(train_dir, str(i))</span><br><span class="line">        file_list = os.listdir(data_dir)</span><br><span class="line">        for filename in file_list:</span><br><span class="line">            file_path = os.path.join(data_dir, filename)</span><br><span class="line">            train_file_list.append(file_path)</span><br><span class="line"></span><br><span class="line">        data_dir = os.path.join(test_dir, str(i))</span><br><span class="line">        file_list = os.listdir(data_dir)</span><br><span class="line">        for filename in file_list:</span><br><span class="line">            file_path = os.path.join(data_dir, filename)</span><br><span class="line">            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">            if img is not None:</span><br><span class="line">                h, w = img.shape[:2]</span><br><span class="line">                x_test.append(img.reshape(h * w))</span><br><span class="line">                y_test.append(i)</span><br><span class="line"></span><br><span class="line">    train_file_list = np.array(train_file_list)</span><br><span class="line">    if shuffle:</span><br><span class="line">        np.random.shuffle(train_file_list)</span><br><span class="line"></span><br><span class="line">    for file_path in train_file_list:</span><br><span class="line">        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">        if img is not None:</span><br><span class="line">            h, w = img.shape[:2]</span><br><span class="line">            x_train.append(img.reshape(h * w))</span><br><span class="line">            y_train.append(int(os.path.split(file_path)[0].split(&apos;/&apos;)[-1]))</span><br><span class="line"></span><br><span class="line">    df = pd.DataFrame(y_train)</span><br><span class="line">    df.columns = [&apos;label&apos;]</span><br><span class="line">    y_train_indicator = pd.get_dummies(df.label)</span><br><span class="line"></span><br><span class="line">    return np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test), y_train_indicator.values</span><br></pre></td></tr></table></figure>
<p>对数据集进行预处理，压缩到<code>[-1,1]</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 计算均值，进行图像预处理</span><br><span class="line">mu = np.mean(x_train, axis=0)</span><br><span class="line">x_train = (x_train - mu) / 255</span><br><span class="line">x_test = (x_test - mu) / 255</span><br></pre></td></tr></table></figure>
<p><code>softmax</code>回归<code>numpy</code>实现参考<a href="https://www.zhujian.tech/posts/2626bec3.html#more">softmax回归</a></p>
<p>完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-4-29 上午10:00</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import pandas as pd</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/mnist/&apos;</span><br><span class="line"></span><br><span class="line">cate_list = list(range(10))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(shuffle=True):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载mnist数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    train_dir = os.path.join(data_path, &apos;train&apos;)</span><br><span class="line">    test_dir = os.path.join(data_path, &apos;test&apos;)</span><br><span class="line"></span><br><span class="line">    x_train = []</span><br><span class="line">    x_test = []</span><br><span class="line">    y_train = []</span><br><span class="line">    y_test = []</span><br><span class="line">    train_file_list = []</span><br><span class="line">    for i in cate_list:</span><br><span class="line">        data_dir = os.path.join(train_dir, str(i))</span><br><span class="line">        file_list = os.listdir(data_dir)</span><br><span class="line">        for filename in file_list:</span><br><span class="line">            file_path = os.path.join(data_dir, filename)</span><br><span class="line">            train_file_list.append(file_path)</span><br><span class="line"></span><br><span class="line">        data_dir = os.path.join(test_dir, str(i))</span><br><span class="line">        file_list = os.listdir(data_dir)</span><br><span class="line">        for filename in file_list:</span><br><span class="line">            file_path = os.path.join(data_dir, filename)</span><br><span class="line">            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">            if img is not None:</span><br><span class="line">                h, w = img.shape[:2]</span><br><span class="line">                x_test.append(img.reshape(h * w))</span><br><span class="line">                y_test.append(i)</span><br><span class="line"></span><br><span class="line">    train_file_list = np.array(train_file_list)</span><br><span class="line">    if shuffle:</span><br><span class="line">        np.random.shuffle(train_file_list)</span><br><span class="line"></span><br><span class="line">    for file_path in train_file_list:</span><br><span class="line">        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">        if img is not None:</span><br><span class="line">            h, w = img.shape[:2]</span><br><span class="line">            x_train.append(img.reshape(h * w))</span><br><span class="line">            y_train.append(int(os.path.split(file_path)[0].split(&apos;/&apos;)[-1]))</span><br><span class="line"></span><br><span class="line">    df = pd.DataFrame(y_train)</span><br><span class="line">    df.columns = [&apos;label&apos;]</span><br><span class="line">    y_train_indicator = pd.get_dummies(df.label)</span><br><span class="line"></span><br><span class="line">    return np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test), y_train_indicator.values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def linear(x, w):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    线性操作</span><br><span class="line">    :param x: 大小为(m,n+1)</span><br><span class="line">    :param w: 大小为(n+1,k)</span><br><span class="line">    :return: 大小为(m,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return x.dot(w)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def softmax(x):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    softmax归一化计算</span><br><span class="line">    :param x: 大小为(m, k)</span><br><span class="line">    :return: 大小为(m, k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x -= np.atleast_2d(np.max(x, axis=1)).T</span><br><span class="line">    exps = np.exp(x)</span><br><span class="line">    return exps / np.atleast_2d(np.sum(exps, axis=1)).T</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_scores(X, W):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param X: 大小为(m,n+1)</span><br><span class="line">    :param W: 大小为(n+1,k)</span><br><span class="line">    :return: (m,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return softmax(linear(X, W))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_loss(scores, indicator, W, la=2e-4):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算损失值</span><br><span class="line">    :param scores: 大小为(m, k)</span><br><span class="line">    :param indicator: 大小为(m, k)</span><br><span class="line">    :param W: (n+1, k)</span><br><span class="line">    :return: (1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    cost = -1 / scores.shape[0] * np.sum(np.log(scores) * indicator)</span><br><span class="line">    reg = la / 2 * np.sum(W ** 2)</span><br><span class="line">    return cost + reg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient(scores, indicator, x, W, la=2e-4):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算梯度</span><br><span class="line">    :param scores: 大小为(m,k)</span><br><span class="line">    :param indicator: 大小为(m,k)</span><br><span class="line">    :param x: 大小为(m,n+1)</span><br><span class="line">    :param W: (n+1, k)</span><br><span class="line">    :return: (n+1,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return -1 / scores.shape[0] * x.T.dot((indicator - scores)) + la * W</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(scores, Y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param scores: (m,k)</span><br><span class="line">    :param Y: (m,1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    res = np.dstack((np.argmax(scores, axis=1), Y.squeeze())).squeeze()</span><br><span class="line"></span><br><span class="line">    return len(list(filter(lambda x: x[0] == x[1], res[:]))) / len(res)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(res_list, title=None, xlabel=None):</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    if xlabel is not None:</span><br><span class="line">        plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(res_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient_descent(batch_size=8, epoches=2000, alpha=2e-4):</span><br><span class="line">    x_train, x_test, y_train, y_test, y_train_indicator = load_data(shuffle=True)</span><br><span class="line"></span><br><span class="line">    m, n = x_train.shape[:2]</span><br><span class="line">    k = y_train_indicator.shape[1]</span><br><span class="line"></span><br><span class="line">    # 计算均值，进行图像预处理</span><br><span class="line">    mu = np.mean(x_train, axis=0)</span><br><span class="line">    x_train = (x_train - mu) / 255</span><br><span class="line">    x_test = (x_test - mu) / 255</span><br><span class="line"></span><br><span class="line">    # 初始化权重(n+1,k)</span><br><span class="line">    W = 0.01 * np.random.normal(loc=0.0, scale=1.0, size=(n + 1, k))</span><br><span class="line">    x_train = np.insert(x_train, 0, np.ones(m), axis=1)</span><br><span class="line">    x_test = np.insert(x_test, 0, np.ones(x_test.shape[0]), axis=1)</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestW = None</span><br><span class="line">    bestA = 0</span><br><span class="line">    range_list = np.arange(0, m - batch_size, step=batch_size)</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j in range_list:</span><br><span class="line">            data = x_train[j:j + batch_size]</span><br><span class="line">            labels = y_train_indicator[j:j + batch_size]</span><br><span class="line"></span><br><span class="line">            # 计算分类概率</span><br><span class="line">            scores = np.atleast_2d(compute_scores(data, W))</span><br><span class="line">            # 更新梯度</span><br><span class="line">            tempW = W - alpha * compute_gradient(scores, labels, data, W)</span><br><span class="line">            W = tempW</span><br><span class="line"></span><br><span class="line">            if j == range_list[-1]:</span><br><span class="line">                loss = compute_loss(scores, labels, W)</span><br><span class="line">                print(loss)</span><br><span class="line">                loss_list.append(loss)</span><br><span class="line"></span><br><span class="line">                accuracy = compute_accuracy(compute_scores(x_train, W), y_train)</span><br><span class="line">                print(&apos;epoch: %d accuracy is %.2f %%&apos; % (i + 1, accuracy * 100))</span><br><span class="line">                accuracy_list.append(accuracy)</span><br><span class="line">                if accuracy &gt;= bestA:</span><br><span class="line">                    bestA = accuracy</span><br><span class="line">                    bestW = W.copy()</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度&apos;)</span><br><span class="line"></span><br><span class="line">    test_accuracy = compute_accuracy(compute_scores(x_test, bestW), y_test)</span><br><span class="line">    print(&apos;best train accuracy is %.2f %%&apos; % (bestA * 100))</span><br><span class="line">    print(&apos;test accuracy is %.2f %%&apos; % (test_accuracy * 100))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    compute_gradient_descent(batch_size=128, epoches=10000)</span><br></pre></td></tr></table></figure>
<p>批量大小为<code>128</code>，学习率为<code>2e-4</code>，共训练<code>1</code>万次，结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">best train accuracy is 92.33 %</span><br><span class="line">test accuracy is 92.15 %</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/使用softmax回归进行mnist分类/numpy_softmax_mnist_loss.png" alt></p>
<p><img src="/imgs/使用softmax回归进行mnist分类/numpy_softmax_mnist_accuracy.png" alt></p>
<h2 id="pytorch实现-cpu训练"><a href="#pytorch实现-cpu训练" class="headerlink" title="pytorch实现 - cpu训练"></a><code>pytorch</code>实现 - <code>cpu</code>训练</h2><p><code>pytorch</code>提供了类<a href="https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=imagefolder#torchvision.datasets.ImageFolder" target="_blank" rel="noopener">torchvision.datasets.ImageFolder</a>用于自动加载排列如下的数据集：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root/dog/xxx.png</span><br><span class="line">root/dog/xxy.png</span><br><span class="line">root/dog/xxz.png</span><br><span class="line"></span><br><span class="line">root/cat/123.png</span><br><span class="line">root/cat/nsdf3.png</span><br><span class="line">root/cat/asd932_.png</span><br></pre></td></tr></table></figure>
<p><code>pytorch</code>也提供了类<a href="https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transform" target="_blank" rel="noopener">torchvision.transforms</a>用于数据格式转换以及数据处理</p>
<p>默认<code>ImageFolder</code>读取得到的是彩色<code>PIL Image</code>格式图像，需要转换成灰度<code>Tensor</code>格式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.Grayscale(),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p><strong>使用<code>ToTensor</code>进行<code>PIL Image</code>或<code>numpy.ndarray</code>格式图像转换，从通道（<code>H, W, C</code>）、取值（<code>0,255</code>）转换为通道（<code>C, H, W</code>）、取值（<code>0,1</code>）</strong></p>
<p>最后将数据集载入<code>pytorch</code>提供的<code>DataLoader</code>，用于批量处理和数据打乱</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def load_data(batch_size=128, shuffle=True):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    train_dir = os.path.join(data_path, &apos;train&apos;)</span><br><span class="line">    test_dir = os.path.join(data_path, &apos;test&apos;)</span><br><span class="line"></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Grayscale(),</span><br><span class="line">        transforms.ToTensor()</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    train_data_set = ImageFolder(train_dir, transform=transform)</span><br><span class="line">    test_data_set = ImageFolder(test_dir, transform=transform)</span><br><span class="line"></span><br><span class="line">    return DataLoader(train_data_set, batch_size=batch_size, shuffle=shuffle), DataLoader(test_data_set,</span><br><span class="line">                                                                                          batch_size=batch_size,</span><br><span class="line">                                                                                          shuffle=shuffle)</span><br></pre></td></tr></table></figure>
<p>完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-4-28 下午7:55</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from torchvision.datasets import ImageFolder</span><br><span class="line">import os</span><br><span class="line">import time</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/mnist/&apos;</span><br><span class="line"></span><br><span class="line">cate_list = list(range(10))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(batch_size=128, shuffle=True):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    train_dir = os.path.join(data_path, &apos;train&apos;)</span><br><span class="line">    test_dir = os.path.join(data_path, &apos;test&apos;)</span><br><span class="line"></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Grayscale(),</span><br><span class="line">        transforms.ToTensor()</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    train_data_set = ImageFolder(train_dir, transform=transform)</span><br><span class="line">    test_data_set = ImageFolder(test_dir, transform=transform)</span><br><span class="line"></span><br><span class="line">    return DataLoader(train_data_set, batch_size=batch_size, shuffle=shuffle), DataLoader(test_data_set,</span><br><span class="line">                                                                                          batch_size=batch_size,</span><br><span class="line">                                                                                          shuffle=shuffle)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(module, dataLoader):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param module: 计算模型</span><br><span class="line">    :param dataLoader: 数据加载器</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    accuracy = 0</span><br><span class="line">    for i, items in enumerate(dataLoader, 0):</span><br><span class="line">        data, labels = items</span><br><span class="line">        data = data.reshape((data.size()[0], -1))</span><br><span class="line">        scores = module.forward(data)</span><br><span class="line"></span><br><span class="line">        predictions = torch.argmax(scores, dim=1)</span><br><span class="line">        res = (predictions == labels.squeeze())</span><br><span class="line">        accuracy += 1.0 * torch.sum(res).item() / scores.size()[0]</span><br><span class="line">    return accuracy / dataLoader.__len__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(res_list, title=None, xlabel=None):</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    if xlabel is not None:</span><br><span class="line">        plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(res_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class SoftmaxModule(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, inputs, outputs):</span><br><span class="line">        super(SoftmaxModule, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(inputs, outputs)</span><br><span class="line">        self.softmax = nn.LogSoftmax()</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        x = self.linear.forward(input)</span><br><span class="line">        x = self.softmax.forward(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def getParameter(self):</span><br><span class="line">        return self.linear.weight, self.linear.bias</span><br><span class="line"></span><br><span class="line">    def setParameter(self, weight, bias):</span><br><span class="line">        self.linear.weight = nn.Parameter(weight)</span><br><span class="line">        self.linear.bias = nn.Parameter(bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient_descent(batch_size=8, epoches=2000, alpha=2e-4):</span><br><span class="line">    train_loader, test_loader = load_data(batch_size=batch_size, shuffle=True)</span><br><span class="line"></span><br><span class="line">    n = 784</span><br><span class="line">    k = 10</span><br><span class="line"></span><br><span class="line">    # softmax模型</span><br><span class="line">    module = SoftmaxModule(n, k)</span><br><span class="line">    # 损失函数</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    # 优化器</span><br><span class="line">    optimizer = optim.SGD(module.parameters(), lr=alpha)</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestW = None</span><br><span class="line">    bestB = None</span><br><span class="line">    bestA = 0</span><br><span class="line"></span><br><span class="line">    batch_len = train_loader.__len__()</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        start = time.time()</span><br><span class="line">        for j, items in enumerate(train_loader, 0):</span><br><span class="line">            data, labels = items</span><br><span class="line">            data = data.reshape((data.size()[0], -1))</span><br><span class="line"></span><br><span class="line">            scores = module.forward(data)</span><br><span class="line">            loss = criterion(scores, labels.squeeze())</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            # 反向传播</span><br><span class="line">            loss.backward()</span><br><span class="line">            # 梯度更新</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            if j == (batch_len - 1):</span><br><span class="line">                loss_list.append(loss.item())</span><br><span class="line">        end = time.time()</span><br><span class="line">        print(&apos;epoch： %d time: %.2f s&apos; % (i + 1, end - start))</span><br><span class="line">        if i % 20 == 19:  # 每个20次进行一次检测</span><br><span class="line">            start = time.time()</span><br><span class="line">            accuracy = compute_accuracy(module, train_loader)</span><br><span class="line">            accuracy_list.append(accuracy)</span><br><span class="line">            if accuracy &gt;= bestA:</span><br><span class="line">                bestA = accuracy</span><br><span class="line">                bestW, bestB = module.getParameter()</span><br><span class="line">            end = time.time()</span><br><span class="line">            print(&apos;epoch: %d time: %.2f s accuracy: %.3f %%&apos; % (i + 1, end - start, accuracy * 100))</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度/20次&apos;)</span><br><span class="line"></span><br><span class="line">    module.setParameter(bestW, bestB)</span><br><span class="line">    test_accuracy = compute_accuracy(module, test_loader)</span><br><span class="line"></span><br><span class="line">    print(&apos;best train accuracy is %.3f %%&apos; % (bestA * 100))</span><br><span class="line">    print(&apos;test accuracy is %.3f %%&apos; % (test_accuracy * 100))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    start = time.time()</span><br><span class="line">    compute_gradient_descent(batch_size=128, epoches=200)</span><br><span class="line">    end = time.time()</span><br><span class="line">    print(&apos;all train and test need time: %.2f minutes&apos; % ((end - start) / 60.0))</span><br></pre></td></tr></table></figure>
<p>使用<code>8</code>核<code>CPU</code>（<code>Intel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz</code>）训练<code>200</code>次，需要<code>54.97</code>分钟，训练和测试精度如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">best train accuracy is 87.474 %</span><br><span class="line">test accuracy is 88.301 %</span><br><span class="line">all train and test need time: 54.97 minutes</span><br></pre></td></tr></table></figure>
<h2 id="pytorch实现-gpu训练"><a href="#pytorch实现-gpu训练" class="headerlink" title="pytorch实现 - gpu训练"></a><code>pytorch</code>实现 - <code>gpu</code>训练</h2><p><code>pytorch</code>提供了<code>gpu</code>相关代码，用于加速训练过程</p>
<p>首先判断当前设备是否保存gpu</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br></pre></td></tr></table></figure>
<p>然后使用<code>to</code>函数将模型、损失函数、数据和标签转入<code>gpu</code>进行训练</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># softmax模型</span><br><span class="line">module = SoftmaxModule(n, k).to(device=device)</span><br><span class="line"># 损失函数</span><br><span class="line">criterion = nn.CrossEntropyLoss().to(device=device)</span><br><span class="line">...</span><br><span class="line">data, labels = data.to(device=device), labels.to(device=device)</span><br></pre></td></tr></table></figure>
<p>完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-4-29 下午3:48</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from torchvision.datasets import ImageFolder</span><br><span class="line">import os</span><br><span class="line">import time</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/mnist/&apos;</span><br><span class="line"></span><br><span class="line">cate_list = list(range(10))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(batch_size=128, shuffle=True):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    train_dir = os.path.join(data_path, &apos;train&apos;)</span><br><span class="line">    test_dir = os.path.join(data_path, &apos;test&apos;)</span><br><span class="line"></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Grayscale(),</span><br><span class="line">        transforms.ToTensor()</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    train_data_set = ImageFolder(train_dir, transform=transform)</span><br><span class="line">    test_data_set = ImageFolder(test_dir, transform=transform)</span><br><span class="line"></span><br><span class="line">    return DataLoader(train_data_set, batch_size=batch_size, shuffle=shuffle), DataLoader(test_data_set,</span><br><span class="line">                                                                                          batch_size=batch_size,</span><br><span class="line">                                                                                          shuffle=shuffle)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(module, dataLoader, device=torch.device(&apos;cpu&apos;)):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param module: 计算模型</span><br><span class="line">    :param dataLoader: 数据加载器</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    accuracy = 0</span><br><span class="line">    for i, items in enumerate(dataLoader, 0):</span><br><span class="line">        data, labels = items</span><br><span class="line">        data = data.reshape((data.size()[0], -1))</span><br><span class="line">        data, labels = data.to(device=device), labels.to(device=device)</span><br><span class="line"></span><br><span class="line">        scores = module.forward(data)</span><br><span class="line">        predictions = torch.argmax(scores, dim=1)</span><br><span class="line">        res = (predictions == labels.squeeze())</span><br><span class="line">        accuracy += 1.0 * torch.sum(res).item() / scores.size()[0]</span><br><span class="line">    return accuracy / dataLoader.__len__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(res_list, title=None, xlabel=None):</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    if xlabel is not None:</span><br><span class="line">        plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(res_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class SoftmaxModule(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, inputs, outputs):</span><br><span class="line">        super(SoftmaxModule, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(inputs, outputs)</span><br><span class="line">        self.softmax = nn.LogSoftmax()</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        x = self.linear.forward(input)</span><br><span class="line">        x = self.softmax.forward(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def getParameter(self):</span><br><span class="line">        return self.linear.weight, self.linear.bias</span><br><span class="line"></span><br><span class="line">    def setParameter(self, weight, bias):</span><br><span class="line">        self.linear.weight = nn.Parameter(weight)</span><br><span class="line">        self.linear.bias = nn.Parameter(bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient_descent(batch_size=8, epoches=2000, alpha=2e-4):</span><br><span class="line">    train_loader, test_loader = load_data(batch_size=batch_size, shuffle=True)</span><br><span class="line"></span><br><span class="line">    n = 784</span><br><span class="line">    k = 10</span><br><span class="line"></span><br><span class="line">    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line"></span><br><span class="line">    # softmax模型</span><br><span class="line">    module = SoftmaxModule(n, k).to(device=device)</span><br><span class="line">    # 损失函数</span><br><span class="line">    criterion = nn.CrossEntropyLoss().to(device=device)</span><br><span class="line">    # 优化器</span><br><span class="line">    optimizer = optim.SGD(module.parameters(), lr=alpha)</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestW = None</span><br><span class="line">    bestB = None</span><br><span class="line">    bestA = 0</span><br><span class="line"></span><br><span class="line">    batch_len = train_loader.__len__()</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        start = time.time()</span><br><span class="line">        for j, items in enumerate(train_loader, 0):</span><br><span class="line">            data, labels = items</span><br><span class="line">            data = data.reshape((data.size()[0], -1))</span><br><span class="line">            data, labels = data.to(device=device), labels.to(device=device)</span><br><span class="line"></span><br><span class="line">            scores = module.forward(data)</span><br><span class="line">            loss = criterion(scores, labels.squeeze())</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            # 反向传播</span><br><span class="line">            loss.backward()</span><br><span class="line">            # 梯度更新</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            if j == (batch_len - 1):</span><br><span class="line">                loss_list.append(loss.item())</span><br><span class="line">        end = time.time()</span><br><span class="line">        print(&apos;epoch： %d time: %.2f s&apos; % (i + 1, end - start))</span><br><span class="line">        if i % 20 == 19:  # 每个20次进行一次检测</span><br><span class="line">            start = time.time()</span><br><span class="line">            accuracy = compute_accuracy(module, train_loader, device)</span><br><span class="line">            accuracy_list.append(accuracy)</span><br><span class="line">            if accuracy &gt;= bestA:</span><br><span class="line">                bestA = accuracy</span><br><span class="line">                bestW, bestB = module.getParameter()</span><br><span class="line">            end = time.time()</span><br><span class="line">            print(&apos;epoch: %d time: %.2f s accuracy: %.3f %%&apos; % (i + 1, end - start, accuracy * 100))</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度/20次&apos;)</span><br><span class="line"></span><br><span class="line">    module.setParameter(bestW, bestB)</span><br><span class="line">    test_accuracy = compute_accuracy(module, test_loader, device)</span><br><span class="line"></span><br><span class="line">    print(&apos;best train accuracy is %.3f %%&apos; % (bestA * 100))</span><br><span class="line">    print(&apos;test accuracy is %.3f %%&apos; % (test_accuracy * 100))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    start = time.time()</span><br><span class="line">    compute_gradient_descent(batch_size=128, epoches=200)</span><br><span class="line">    end = time.time()</span><br><span class="line">    print(&apos;all train and test need time: %.2f minutes&apos; % ((end - start) / 60.0))</span><br></pre></td></tr></table></figure>
<p>使用<code>GeForce GTX 1080</code>训练<code>200</code>次，需要<code>29.88</code>分钟，训练和测试精度如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">best train accuracy is 87.442 %</span><br><span class="line">test accuracy is 88.439 %</span><br><span class="line">all train and test need time: 29.88 minutes</span><br></pre></td></tr></table></figure>
<h2 id="使用torchvision内置mnist"><a href="#使用torchvision内置mnist" class="headerlink" title="使用torchvision内置mnist"></a>使用<code>torchvision</code>内置<code>mnist</code></h2><p><code>torchvision</code>模块中包含了许多常用数据集的加载类，其中就包括了<a href="https://pytorch.org/docs/stable/torchvision/datasets.html#mnist" target="_blank" rel="noopener">MNIST</a></p>
<p>类<code>torchvision.datasets.MNIST</code>能够实现<code>MNIST</code>数据集的下载，保存和处理</p>
<p>实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from torchvision import transforms</span><br><span class="line">from torchvision import datasets</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line"></span><br><span class="line">def load_data(batch_size=128, shuffle=False):</span><br><span class="line">    data_dir = &apos;../data/mnist/&apos;</span><br><span class="line"></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Grayscale(),</span><br><span class="line">        transforms.ToTensor()</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    train_data_set = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)</span><br><span class="line">    test_data_set = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)</span><br><span class="line"></span><br><span class="line">    train_loader = DataLoader(train_data_set, batch_size=batch_size, shuffle=shuffle)</span><br><span class="line">    test_loader = DataLoader(test_data_set, batch_size=batch_size, shuffle=shuffle)</span><br><span class="line">    return train_loader, test_loader</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>pandas</tag>
        <tag>softmax</tag>
      </tags>
  </entry>
  <entry>
    <title>从numpy到pytorch实现softmax回归</title>
    <url>/posts/1c195604.html</url>
    <content><![CDATA[<p>使用<code>pytorch</code>实现<code>softmax</code>回归，首先使用基本数学运算函数实现，然后逐步使用各种封装函数和优化包进行替换</p><a id="more"></a>
<p>超参数如下：</p>
<ul>
<li>batch_size = 8</li>
<li>lambda = 2e-4</li>
<li>alpha = 2e-4</li>
</ul>
<p>使用数据库</p>
<ul>
<li><a href="https://www.kaggle.com/uciml/iris" target="_blank" rel="noopener">Iris Species</a></li>
</ul>
<h2 id="numpy实现"><a href="#numpy实现" class="headerlink" title="numpy实现"></a><code>numpy</code>实现</h2><p>参考<a href="https://www.zhujian.tech/posts/2626bec3.html#more">softmax回归</a></p>
<h2 id="pytorch实现-基本数学运算函数"><a href="#pytorch实现-基本数学运算函数" class="headerlink" title="pytorch实现 - 基本数学运算函数"></a><code>pytorch</code>实现 - 基本数学运算函数</h2><p>先利用<code>numpy</code>获取<code>iris</code>数据，再转换<code>为torch.Tensor</code>结构</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x_train, x_test, y_train, y_test, y_train_indicator = load_data()</span><br><span class="line"></span><br><span class="line">x_train = torch.FloatTensor(x_train)</span><br><span class="line">x_test = torch.FloatTensor(x_test)</span><br><span class="line">y_train = torch.LongTensor(y_train)</span><br><span class="line">y_test = torch.LongTensor(y_test)</span><br><span class="line">y_train_indicator = torch.FloatTensor(y_train_indicator)</span><br></pre></td></tr></table></figure>
<p>初始化权重，生成标准正态分布随机数组</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def init_weights(inputs, outputs, requires_grad=False):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    初始化权重</span><br><span class="line">    使用torch.randn生成标准正态分布</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    w = 0.01 * torch.randn(inputs, outputs, requires_grad=requires_grad, dtype=torch.float)</span><br><span class="line">    b = 0.01 * torch.randn(1, requires_grad=requires_grad, dtype=torch.float)</span><br><span class="line">    return w, b</span><br></pre></td></tr></table></figure>
<p>执行线性运算和<code>softmax</code>运算</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def linear(x, w, b):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    线性操作</span><br><span class="line">    :param x: 大小为(m,n)</span><br><span class="line">    :param w: 大小为(k,n)</span><br><span class="line">    :return: 大小为(m,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return x.mm(w) + b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def softmax(x):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    softmax归一化计算</span><br><span class="line">    :param x: 大小为(m, k)</span><br><span class="line">    :return: 大小为(m, k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x -= torch.unsqueeze(torch.max(x, 1)[0], 1)</span><br><span class="line">    exps = torch.exp(x)</span><br><span class="line">    return exps / torch.unsqueeze(torch.sum(exps, dim=1), 1)</span><br></pre></td></tr></table></figure>
<p>计算预测结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def compute_scores(W, b, X):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param X: 大小为(m,n)</span><br><span class="line">    :param W: 大小为(k,n)</span><br><span class="line">    :param b: 1</span><br><span class="line">    :return: (m,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return softmax(linear(X, W, b))</span><br></pre></td></tr></table></figure>
<p>计算损失值和梯度值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def compute_loss(scores, indicator, W, b, la=2e-4):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算损失值</span><br><span class="line">    :param scores: 大小为(m, n)</span><br><span class="line">    :param indicator: 大小为(m, n)</span><br><span class="line">    :param W: (n, k)</span><br><span class="line">    :return: (m,1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    loss = -1 / scores.size()[0] * torch.sum(torch.log(scores) * indicator)</span><br><span class="line">    reg = la / 2 * (torch.sum(W ** 2) + b ** 2)</span><br><span class="line"></span><br><span class="line">    return (loss + reg).item()</span><br><span class="line"></span><br><span class="line">def compute_gradient(indicator, scores, x, W, la=2e-4):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算梯度</span><br><span class="line">    :param indicator: 大小为(m,k)</span><br><span class="line">    :param scores: 大小为(m,k)</span><br><span class="line">    :param x: 大小为(m,n)</span><br><span class="line">    :param W: (n, k)</span><br><span class="line">    :return: (n,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    dloss = -1 / scores.size()[0] * x.t().mm(torch.sub(indicator, scores))</span><br><span class="line">    dreg = la * W</span><br><span class="line">    return dloss + dreg</span><br></pre></td></tr></table></figure>
<p>最后计算精度</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def compute_accuracy(scores, Y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param scores: (m,k)</span><br><span class="line">    :param Y: (m,1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    predictions = torch.argmax(scores, dim=1)</span><br><span class="line">    res = (predictions == Y.squeeze())</span><br><span class="line">    return 1.0 * torch.sum(res).item() / scores.size()[0]</span><br></pre></td></tr></table></figure>
<p>完整代码如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-4-27 下午3:05</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn import utils</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/iris-species/Iris.csv&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(data_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        data = utils.shuffle(data)</span><br><span class="line"></span><br><span class="line">    # 示性函数</span><br><span class="line">    pd_indicator = pd.get_dummies(data[&apos;Species&apos;])</span><br><span class="line">    indicator = np.array(</span><br><span class="line">        [pd_indicator[&apos;Iris-setosa&apos;], pd_indicator[&apos;Iris-versicolor&apos;], pd_indicator[&apos;Iris-virginica&apos;]]).T</span><br><span class="line"></span><br><span class="line">    species_dict = &#123;</span><br><span class="line">        &apos;Iris-setosa&apos;: 0,</span><br><span class="line">        &apos;Iris-versicolor&apos;: 1,</span><br><span class="line">        &apos;Iris-virginica&apos;: 2</span><br><span class="line">    &#125;</span><br><span class="line">    data[&apos;Species&apos;] = data[&apos;Species&apos;].map(species_dict)</span><br><span class="line"></span><br><span class="line">    data_x = np.array(</span><br><span class="line">        [data[&apos;SepalLengthCm&apos;], data[&apos;SepalWidthCm&apos;], data[&apos;PetalLengthCm&apos;], data[&apos;PetalWidthCm&apos;]]).T</span><br><span class="line">    data_y = data[&apos;Species&apos;]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=False)</span><br><span class="line"></span><br><span class="line">    y_train = np.atleast_2d(y_train).T</span><br><span class="line">    y_test = np.atleast_2d(y_test).T</span><br><span class="line"></span><br><span class="line">    y_train_indicator = np.atleast_2d(indicator[:y_train.shape[0]])</span><br><span class="line"></span><br><span class="line">    return torch.from_numpy(x_train).float(), torch.from_numpy(x_test).float(), torch.from_numpy(</span><br><span class="line">        y_train), torch.from_numpy(y_test), torch.from_numpy(y_train_indicator).float()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def linear(x, w):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    线性操作</span><br><span class="line">    :param x: 大小为(m,n+1)</span><br><span class="line">    :param w: 大小为(n+1,k)</span><br><span class="line">    :return: 大小为(m,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return x.mm(w)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def softmax(x):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    softmax归一化计算</span><br><span class="line">    :param x: 大小为(m, k)</span><br><span class="line">    :return: 大小为(m, k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x -= torch.unsqueeze(torch.max(x, 1)[0], 1)</span><br><span class="line">    exps = torch.exp(x)</span><br><span class="line">    return exps / torch.unsqueeze(torch.sum(exps, dim=1), 1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_scores(X, W):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param X: 大小为(m,n)</span><br><span class="line">    :param W: 大小为(k,n)</span><br><span class="line">    :return: (m,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return softmax(linear(X, W))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_loss(scores, indicator, W, la=2e-4):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算损失值</span><br><span class="line">    :param scores: 大小为(m, k)</span><br><span class="line">    :param indicator: 大小为(m, k)</span><br><span class="line">    :param W: (n+1, k)</span><br><span class="line">    :return: (1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    loss = -1 / scores.size()[0] * torch.sum(torch.log(scores) * indicator)</span><br><span class="line">    reg = la / 2 * torch.sum(W ** 2)</span><br><span class="line"></span><br><span class="line">    return (loss + reg).item()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient(indicator, scores, x, W, la=2e-4):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算梯度</span><br><span class="line">    :param indicator: 大小为(m,k)</span><br><span class="line">    :param scores: 大小为(m,k)</span><br><span class="line">    :param x: 大小为(m,n+1)</span><br><span class="line">    :param W: (n+1, k)</span><br><span class="line">    :return: (n+1,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    dloss = -1 / scores.size()[0] * x.t().mm(torch.sub(indicator, scores))</span><br><span class="line">    dreg = la * W</span><br><span class="line">    return dloss + dreg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(scores, Y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param scores: (m,k)</span><br><span class="line">    :param Y: (m,1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    predictions = torch.argmax(scores, dim=1)</span><br><span class="line">    res = (predictions == Y.squeeze())</span><br><span class="line">    return 1.0 * torch.sum(res).item() / scores.size()[0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(res_list, title=None, xlabel=None):</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    if xlabel is not None:</span><br><span class="line">        plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(res_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient_descent(batch_size=8, epoches=2000, alpha=2e-4):</span><br><span class="line">    x_train, x_test, y_train, y_test, y_train_indicator = load_data()</span><br><span class="line"></span><br><span class="line">    m, n = x_train.size()[:2]</span><br><span class="line">    k = 3</span><br><span class="line">    # print(m, n, k)</span><br><span class="line"></span><br><span class="line">    W = 0.01 * torch.randn(n + 1, k, requires_grad=False, dtype=torch.float)</span><br><span class="line">    # print(w)</span><br><span class="line">    # 插入一列</span><br><span class="line">    x_train = torch.from_numpy(np.insert(x_train.numpy(), 0, np.ones(m), axis=1))</span><br><span class="line">    x_test = torch.from_numpy(np.insert(x_test.numpy(), 0, np.ones(x_test.size()[0]), axis=1))</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestW = None</span><br><span class="line">    bestA = 0</span><br><span class="line">    range_list = list(range(0, m - batch_size, batch_size))</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j in range_list:</span><br><span class="line">            data = x_train[j:j + batch_size]</span><br><span class="line">            labels = y_train_indicator[j:j + batch_size]</span><br><span class="line"></span><br><span class="line">            scores = compute_scores(data, W)</span><br><span class="line">            tempW = W - alpha * compute_gradient(labels, scores, data, W)</span><br><span class="line">            W = tempW</span><br><span class="line"></span><br><span class="line">            if j == range_list[-1]:</span><br><span class="line">                loss = compute_loss(scores, labels, W)</span><br><span class="line">                loss_list.append(loss)</span><br><span class="line"></span><br><span class="line">                accuracy = compute_accuracy(compute_scores(x_train, W), y_train)</span><br><span class="line">                accuracy_list.append(accuracy)</span><br><span class="line">                if accuracy &gt;= bestA:</span><br><span class="line">                    bestA = accuracy</span><br><span class="line">                    bestW = W.clone()</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度&apos;)</span><br><span class="line"></span><br><span class="line">    print(bestA)</span><br><span class="line">    print(compute_accuracy(compute_scores(x_test, bestW), y_test))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    compute_gradient_descent(batch_size=8, epoches=100000)</span><br></pre></td></tr></table></figure>
<p>测试结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 测试集精度</span><br><span class="line">0.975</span><br><span class="line"># 验证集精度</span><br><span class="line">1.0</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_basic_softmax_loss.png" alt></p>
<p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_basic_softmax_accuracy.png" alt></p>
<h2 id="pytorch实现-使用nn包优化softmax回归模型和损失函数"><a href="#pytorch实现-使用nn包优化softmax回归模型和损失函数" class="headerlink" title="pytorch实现 - 使用nn包优化softmax回归模型和损失函数"></a><code>pytorch</code>实现 - 使用<code>nn</code>包优化<code>softmax</code>回归模型和损失函数</h2><p><code>pytorch</code>在包<code>nn</code>中提供了大量算法和损失函数实现，并且能够自动计算梯度</p>
<p>使用线性模型和<code>softmax</code>回归模型</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># softmax回归模型和权重</span><br><span class="line">linearModel = nn.Linear(n, k)</span><br><span class="line">softmaxModel = nn.LogSoftmax()</span><br><span class="line">w = linearModel.weight</span><br><span class="line">b = linearModel.bias</span><br><span class="line"></span><br><span class="line">scores = softmaxModel.forward(linearModel.forward(data))</span><br></pre></td></tr></table></figure>
<p>使用交叉熵损失类计算损失和计算梯度</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 损失函数</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">loss = criterion(scores, labels.squeeze())</span><br><span class="line"># 反向传播</span><br><span class="line">loss.backward()</span><br><span class="line"># 梯度更新</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    w -= w.grad * alpha</span><br><span class="line">    w.grad.zero_()</span><br><span class="line">    b -= b.grad * alpha</span><br><span class="line">    b.grad.zero_()</span><br></pre></td></tr></table></figure>
<p>完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn import utils</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/iris-species/Iris.csv&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(data_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        data = utils.shuffle(data)</span><br><span class="line"></span><br><span class="line">    # 示性函数</span><br><span class="line">    pd_indicator = pd.get_dummies(data[&apos;Species&apos;])</span><br><span class="line">    indicator = np.array(</span><br><span class="line">        [pd_indicator[&apos;Iris-setosa&apos;], pd_indicator[&apos;Iris-versicolor&apos;], pd_indicator[&apos;Iris-virginica&apos;]]).T</span><br><span class="line"></span><br><span class="line">    species_dict = &#123;</span><br><span class="line">        &apos;Iris-setosa&apos;: 0,</span><br><span class="line">        &apos;Iris-versicolor&apos;: 1,</span><br><span class="line">        &apos;Iris-virginica&apos;: 2</span><br><span class="line">    &#125;</span><br><span class="line">    data[&apos;Species&apos;] = data[&apos;Species&apos;].map(species_dict)</span><br><span class="line"></span><br><span class="line">    data_x = np.array(</span><br><span class="line">        [data[&apos;SepalLengthCm&apos;], data[&apos;SepalWidthCm&apos;], data[&apos;PetalLengthCm&apos;], data[&apos;PetalWidthCm&apos;]]).T</span><br><span class="line">    data_y = data[&apos;Species&apos;]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=False)</span><br><span class="line"></span><br><span class="line">    y_train = np.atleast_2d(y_train).T</span><br><span class="line">    y_test = np.atleast_2d(y_test).T</span><br><span class="line"></span><br><span class="line">    y_train_indicator = np.atleast_2d(indicator[:y_train.shape[0]])</span><br><span class="line"></span><br><span class="line">    return torch.from_numpy(x_train).float(), torch.from_numpy(x_test).float(), torch.from_numpy(</span><br><span class="line">        y_train), torch.from_numpy(y_test), torch.from_numpy(y_train_indicator).float()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(scores, Y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param scores: (m,k)</span><br><span class="line">    :param Y: (m,1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    predictions = torch.argmax(scores, dim=1)</span><br><span class="line">    res = (predictions == Y.squeeze())</span><br><span class="line">    return 1.0 * torch.sum(res).item() / scores.size()[0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(res_list, title=None, xlabel=None):</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    if xlabel is not None:</span><br><span class="line">        plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(res_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient_descent(batch_size=8, epoches=2000, alpha=2e-4):</span><br><span class="line">    x_train, x_test, y_train, y_test, y_train_indicator = load_data()</span><br><span class="line"></span><br><span class="line">    m, n = x_train.size()[:2]</span><br><span class="line">    k = 3</span><br><span class="line">    # print(m, n, k)</span><br><span class="line"></span><br><span class="line">    # softmax回归模型和权重</span><br><span class="line">    linearModel = nn.Linear(n, k)</span><br><span class="line">    softmaxModel = nn.LogSoftmax()</span><br><span class="line">    w = linearModel.weight</span><br><span class="line">    b = linearModel.bias</span><br><span class="line">    # 损失函数</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestW = None</span><br><span class="line">    bestB = None</span><br><span class="line">    bestA = 0</span><br><span class="line">    range_list = list(range(0, m - batch_size, batch_size))</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j in range_list:</span><br><span class="line">            data = x_train[j:j + batch_size]</span><br><span class="line">            labels = y_train[j:j + batch_size]</span><br><span class="line"></span><br><span class="line">            scores = softmaxModel.forward(linearModel.forward(data))</span><br><span class="line">            loss = criterion(scores, labels.squeeze())</span><br><span class="line">            # 反向传播</span><br><span class="line">            loss.backward()</span><br><span class="line">            # 梯度更新</span><br><span class="line">            with torch.no_grad():</span><br><span class="line">                w -= w.grad * alpha</span><br><span class="line">                w.grad.zero_()</span><br><span class="line">                b -= b.grad * alpha</span><br><span class="line">                b.grad.zero_()</span><br><span class="line"></span><br><span class="line">            if j == range_list[-1]:</span><br><span class="line">                loss_list.append(loss.item())</span><br><span class="line"></span><br><span class="line">                accuracy = compute_accuracy(softmaxModel(linearModel(x_train)), y_train)</span><br><span class="line">                accuracy_list.append(accuracy)</span><br><span class="line">                if accuracy &gt;= bestA:</span><br><span class="line">                    bestA = accuracy</span><br><span class="line">                    bestW = w.clone()</span><br><span class="line">                    bestB = b.clone()</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度&apos;)</span><br><span class="line"></span><br><span class="line">    linearModel.weight = nn.Parameter(bestW)</span><br><span class="line">    linearModel.bias = nn.Parameter(bestB)</span><br><span class="line">    print(bestA)</span><br><span class="line">    print(compute_accuracy(softmaxModel.forward(linearModel.forward(x_test)), y_test))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    compute_gradient_descent(batch_size=8, epoches=50000)</span><br></pre></td></tr></table></figure>
<p>测试结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 测试集精度</span><br><span class="line">0.9833333333333333</span><br><span class="line"># 验证集精度</span><br><span class="line">1.0</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_advanced_softmax_loss.png" alt></p>
<p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_advanced_softmax_accuracy.png" alt></p>
<h2 id="pytorch实现-使用优化器和自定义softmax实现类"><a href="#pytorch实现-使用优化器和自定义softmax实现类" class="headerlink" title="pytorch实现 - 使用优化器和自定义softmax实现类"></a><code>pytorch</code>实现 - 使用优化器和自定义<code>softmax</code>实现类</h2><p>自定义类，实现<code>softmax</code>运算以及参数设置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class SoftmaxModule(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, inputs, outputs):</span><br><span class="line">        super(SoftmaxModule, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(inputs, outputs)</span><br><span class="line">        self.softmax = nn.LogSoftmax()</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        x = self.linear.forward(input)</span><br><span class="line">        x = self.softmax.forward(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def getParameter(self):</span><br><span class="line">        return self.linear.weight, self.linear.bias</span><br><span class="line"></span><br><span class="line">    def setParameter(self, weight, bias):</span><br><span class="line">        self.linear.weight = nn.Parameter(weight)</span><br><span class="line">        self.linear.bias = nn.Parameter(bias)</span><br></pre></td></tr></table></figure>
<p><code>pytorch</code>提供了优化器包<code>torch.optim</code>来辅助进行梯度更新</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 优化器</span><br><span class="line">optimizer = optim.SGD(module.parameters(), lr=alpha)</span><br><span class="line"></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"># 反向传播</span><br><span class="line">loss.backward()</span><br><span class="line"># 梯度更新</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure>
<p>更新代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class SoftmaxModule(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, inputs, outputs):</span><br><span class="line">        super(SoftmaxModule, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(inputs, outputs)</span><br><span class="line">        self.softmax = nn.LogSoftmax()</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        x = self.linear.forward(input)</span><br><span class="line">        x = self.softmax.forward(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def getParameter(self):</span><br><span class="line">        return self.linear.weight, self.linear.bias</span><br><span class="line"></span><br><span class="line">    def setParameter(self, weight, bias):</span><br><span class="line">        self.linear.weight = nn.Parameter(weight)</span><br><span class="line">        self.linear.bias = nn.Parameter(bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient_descent(batch_size=8, epoches=2000, alpha=2e-4):</span><br><span class="line">    x_train, x_test, y_train, y_test, y_train_indicator = load_data()</span><br><span class="line"></span><br><span class="line">    m, n = x_train.size()[:2]</span><br><span class="line">    k = 3</span><br><span class="line">    # print(m, n, k)</span><br><span class="line"></span><br><span class="line">    # softmax模型</span><br><span class="line">    module = SoftmaxModule(n, k)</span><br><span class="line">    # 损失函数</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    # 优化器</span><br><span class="line">    optimizer = optim.SGD(module.parameters(), lr=alpha)</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestW = None</span><br><span class="line">    bestB = None</span><br><span class="line">    bestA = 0</span><br><span class="line">    range_list = list(range(0, m - batch_size, batch_size))</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j in range_list:</span><br><span class="line">            data = x_train[j:j + batch_size]</span><br><span class="line">            labels = y_train[j:j + batch_size]</span><br><span class="line"></span><br><span class="line">            scores = module.forward(data)</span><br><span class="line">            loss = criterion(scores, labels.squeeze())</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            # 反向传播</span><br><span class="line">            loss.backward()</span><br><span class="line">            # 梯度更新</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            if j == range_list[-1]:</span><br><span class="line">                loss_list.append(loss.item())</span><br><span class="line"></span><br><span class="line">                accuracy = compute_accuracy(module.forward(x_train), y_train)</span><br><span class="line">                accuracy_list.append(accuracy)</span><br><span class="line">                if accuracy &gt;= bestA:</span><br><span class="line">                    bestA = accuracy</span><br><span class="line">                    bestW, bestB = module.getParameter()</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度&apos;)</span><br><span class="line"></span><br><span class="line">    module.setParameter(bestW, bestB)</span><br><span class="line">    print(bestA)</span><br><span class="line">    print(compute_accuracy(module.forward(x_test), y_test))</span><br></pre></td></tr></table></figure>
<p>测试结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 测试集精度</span><br><span class="line">0.975</span><br><span class="line"># 验证集精度</span><br><span class="line">1.0</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_advanced_softmax_loss_v2.png" alt></p>
<p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_advanced_softmax_accuracy_v2.png" alt></p>
<h2 id="pytorch实现-使用TensorDataset和DataLoader简化批量数据操作"><a href="#pytorch实现-使用TensorDataset和DataLoader简化批量数据操作" class="headerlink" title="pytorch实现 - 使用TensorDataset和DataLoader简化批量数据操作"></a><code>pytorch</code>实现 - 使用<code>TensorDataset</code>和<code>DataLoader</code>简化批量数据操作</h2><p><code>pytorch.util.data</code>包提供了类<code>TensorDataset</code>和<code>DataLoader</code>，用于批量加载数据</p>
<p><code>TensorDataset</code>是一个数据集包装类；<code>DataLoader</code>是一个数据加载类，能够实现批量采样、数据打乱</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 包装数据集和标记</span><br><span class="line">dataset = TensorDataset(x_train, y_train)</span><br><span class="line"># 加载包装类，设置批量和打乱数据</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)</span><br><span class="line"># 获取批量数据个数</span><br><span class="line">batch_len = dataloader.__len__()</span><br><span class="line"># 依次获取批量数据</span><br><span class="line">for j, items in enumerate(dataloader, 0):</span><br><span class="line">    data, labels = items</span><br></pre></td></tr></table></figure>
<p>完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from torch.utils.data import TensorDataset</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn import utils</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/iris-species/Iris.csv&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(data_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        data = utils.shuffle(data)</span><br><span class="line"></span><br><span class="line">    species_dict = &#123;</span><br><span class="line">        &apos;Iris-setosa&apos;: 0,</span><br><span class="line">        &apos;Iris-versicolor&apos;: 1,</span><br><span class="line">        &apos;Iris-virginica&apos;: 2</span><br><span class="line">    &#125;</span><br><span class="line">    data[&apos;Species&apos;] = data[&apos;Species&apos;].map(species_dict)</span><br><span class="line"></span><br><span class="line">    data_x = np.array(</span><br><span class="line">        [data[&apos;SepalLengthCm&apos;], data[&apos;SepalWidthCm&apos;], data[&apos;PetalLengthCm&apos;], data[&apos;PetalWidthCm&apos;]]).T</span><br><span class="line">    data_y = data[&apos;Species&apos;]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=False)</span><br><span class="line"></span><br><span class="line">    y_train = np.atleast_2d(y_train).T</span><br><span class="line">    y_test = np.atleast_2d(y_test).T</span><br><span class="line"></span><br><span class="line">    return torch.from_numpy(x_train).float(), torch.from_numpy(x_test).float(), torch.from_numpy(</span><br><span class="line">        y_train), torch.from_numpy(y_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(scores, Y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param scores: (m,k)</span><br><span class="line">    :param Y: (m,1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    predictions = torch.argmax(scores, dim=1)</span><br><span class="line">    res = (predictions == Y.squeeze())</span><br><span class="line">    return 1.0 * torch.sum(res).item() / scores.size()[0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(res_list, title=None, xlabel=None):</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    if xlabel is not None:</span><br><span class="line">        plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(res_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class SoftmaxModule(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, inputs, outputs):</span><br><span class="line">        super(SoftmaxModule, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(inputs, outputs)</span><br><span class="line">        self.softmax = nn.LogSoftmax()</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        x = self.linear.forward(input)</span><br><span class="line">        x = self.softmax.forward(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def getParameter(self):</span><br><span class="line">        return self.linear.weight, self.linear.bias</span><br><span class="line"></span><br><span class="line">    def setParameter(self, weight, bias):</span><br><span class="line">        self.linear.weight = nn.Parameter(weight)</span><br><span class="line">        self.linear.bias = nn.Parameter(bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient_descent(batch_size=8, epoches=2000, alpha=2e-4):</span><br><span class="line">    x_train, x_test, y_train, y_test = load_data()</span><br><span class="line"></span><br><span class="line">    m, n = x_train.size()[:2]</span><br><span class="line">    k = 3</span><br><span class="line">    # print(m, n, k)</span><br><span class="line"></span><br><span class="line">    # softmax模型</span><br><span class="line">    module = SoftmaxModule(n, k)</span><br><span class="line">    # 损失函数</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    # 优化器</span><br><span class="line">    optimizer = optim.SGD(module.parameters(), lr=alpha)</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestW = None</span><br><span class="line">    bestB = None</span><br><span class="line">    bestA = 0</span><br><span class="line"></span><br><span class="line">    dataset = TensorDataset(x_train, y_train)</span><br><span class="line">    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)</span><br><span class="line">    batch_len = dataloader.__len__()</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j, items in enumerate(dataloader, 0):</span><br><span class="line">            data, labels = items</span><br><span class="line"></span><br><span class="line">            scores = module.forward(data)</span><br><span class="line">            loss = criterion(scores, labels.squeeze())</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            # 反向传播</span><br><span class="line">            loss.backward()</span><br><span class="line">            # 梯度更新</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            if j == (batch_len - 1):</span><br><span class="line">                loss_list.append(loss.item())</span><br><span class="line">                accuracy = compute_accuracy(module.forward(x_train), y_train)</span><br><span class="line">                accuracy_list.append(accuracy)</span><br><span class="line">                if accuracy &gt;= bestA:</span><br><span class="line">                    bestA = accuracy</span><br><span class="line">                    bestW, bestB = module.getParameter()</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度&apos;)</span><br><span class="line"></span><br><span class="line">    module.setParameter(bestW, bestB)</span><br><span class="line">    print(bestA)</span><br><span class="line">    print(compute_accuracy(module.forward(x_test), y_test))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    compute_gradient_descent(batch_size=8, epoches=50000)</span><br></pre></td></tr></table></figure>
<p>测试结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 测试集精度</span><br><span class="line">0.975</span><br><span class="line"># 验证集精度</span><br><span class="line">1.0</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_advanced_softmax_loss_v3.png" alt></p>
<p><img src="/imgs/从numpy到pytorch实现softmax回归/pytorch_advanced_softmax_accuracy_v3.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>sklearn</tag>
        <tag>pandas</tag>
        <tag>softmax</tag>
      </tags>
  </entry>
  <entry>
    <title>softmax回归</title>
    <url>/posts/2626bec3.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92" target="_blank" rel="noopener">Softmax回归</a></p><p><code>softmax</code>回归常用于多分类问题，其输出可直接看成对类别的预测概率</p><p>假设对<code>k</code>类标签（<code>[1, 2, ..., k]</code>）进行分类，那么经过<code>softmax</code>回归计算后，输出一个<code>k</code>维向量，向量中每个值都代表对一个类别的预测概率</p><a id="more"></a>



<p>下面先以单个输入数据为例，进行评分函数、损失函数的计算和求导，然后扩展到多个输入数据同步计算</p>
<h2 id="对数函数操作"><a href="#对数函数操作" class="headerlink" title="对数函数操作"></a>对数函数操作</h2><p>对数求和</p>
<script type="math/tex; mode=display">
log_{a}^{x}+log_{a}^{y} = log_{a}^{xy}</script><p>对数求差</p>
<script type="math/tex; mode=display">
log_{a}^{x}-log_{a}^{y} = log_{a}^{\frac{x}{y}}</script><p>指数乘法</p>
<script type="math/tex; mode=display">
e^{x}\cdot e^{y} = e^{x+y}</script><h2 id="求导公式"><a href="#求导公式" class="headerlink" title="求导公式"></a>求导公式</h2><p>若函数$u(x),v(x)均可导$，那么</p>
<script type="math/tex; mode=display">
\left(\frac{u(x)}{v(x)}\right)^{\prime}=\frac{u^{\prime}(x) v(x)-v^{\prime}(x) u(x)}{v^{2}(x)}</script><h2 id="单个输入数据进行softmax回归计算"><a href="#单个输入数据进行softmax回归计算" class="headerlink" title="单个输入数据进行softmax回归计算"></a>单个输入数据进行<code>softmax</code>回归计算</h2><h3 id="评分函数"><a href="#评分函数" class="headerlink" title="评分函数"></a>评分函数</h3><p>假设使用<code>softmax</code>回归分类数据$x$，共$k$个标签，首先进行线性回归操作</p>
<script type="math/tex; mode=display">
z_{\theta}(x)=\theta^T\cdot x
=\begin{bmatrix}
\theta_{1}^T\\ 
\theta_{2}^T\\ 
...\\ 
\theta_{k}^T
\end{bmatrix}\cdot x
=\begin{bmatrix}
\theta_{1}^T\cdot x\\ 
\theta_{2}^T\cdot x\\ 
...\\ 
\theta_{k}^T\cdot x
\end{bmatrix}</script><p>其中输入数据$x$大小为$(n+1)\times 1$，$\theta$大小为$(n+1)\times k$，$n$表示权重数量，$m$表示训练数据个数，$k$表示类别标签数量</p>
<p>输出结果$z$大小为$k\times 1$，然后对计算结果进行归一化操作，使得输出值能够表示类别概率，如下所示</p>
<script type="math/tex; mode=display">
h_{\theta}\left(x\right)=\left[ \begin{array}{c}{p\left(y=1 | x ; \theta\right)} \\ {p\left(y=2 | x ; \theta\right)} \\ {\vdots} \\ {p\left(y=k | x ; \theta\right)}\end{array}\right]
=\frac{1}{\sum_{j=1}^{k} e^{\theta_{j}^{T} x}} \left[ \begin{array}{c}{e^{\theta_{1}^{T} x}} \\ {e^{\theta_{2}^{T} x}} \\ {\vdots} \\ {e^{\theta_{k}^{T} x}}\end{array}\right]</script><p>其中$\theta_{1}、\theta_{2},…,\theta_{k}$的大小为$(n+1)\times 1$，输出结果是一个$k\times 1$大小向量，每列表示$k$类标签的预测概率</p>
<p>所以对于输入数据$x$而言，其属于标签$j$的概率是</p>
<script type="math/tex; mode=display">
p\left(y=j | x; \theta\right)=\frac{e^{\theta_{j}^{T} x}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x}}</script><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>利用交叉熵损失（<code>cross entropy loss</code>）作为<code>softmax</code>回归的损失函数，用于计算训练数据对应的真正标签的损失值</p>
<script type="math/tex; mode=display">
J(\theta)
= (-1)\cdot \sum_{j=1}^{k} 1\left\{y=j\right\} \ln p\left(y=j | x; \theta\right)
= (-1)\cdot \sum_{j=1}^{k} 1\left\{y=j\right\} \ln \frac{e^{\theta_{j}^{T} x}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x}}</script><p>其中函数$1\{\cdot\}$是一个示性函数（<code>indicator function</code>），其取值规则为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1&#123;a true statement&#125; = 1, and 1&#123;a false statement&#125; = 0</span><br></pre></td></tr></table></figure>
<p>也就是示性函数输入为<code>True</code>时，输出为<code>1</code>；否则，输出为<code>0</code></p>
<p>对权重向量$\theta_{s}$进行求导：</p>
<script type="math/tex; mode=display">
\frac{\varphi J(\theta)}{\varphi \theta_{s}}
=(-1)\cdot \frac{\varphi }{\varphi \theta_{s}}
\left[ \\
\sum_{j=1,j\neq s}^{k} 1\left\{y=j \right\} \ln p\left(y=j | x; \theta\right)
+1\left\{y=s \right\} \ln p\left(y=s | x; \theta\right) \\
\right]</script><script type="math/tex; mode=display">
=(-1)\cdot \sum_{j=1,j\neq s}^{k} 1\left\{y=j \right\} \frac{1}{p\left(y=j | x; \theta\right)}\frac{\varphi p\left(y=j | x; \theta\right)}{\varphi \theta_{s}}
+(-1)\cdot 1\left\{y=s \right\} \frac{1}{p\left(y=s | x; \theta\right)}\frac{\varphi p\left(y=s | x; \theta\right)}{\varphi \theta_{s}}</script><p>分为两种情况</p>
<ul>
<li>当计算结果正好由$\theta_{s}$计算得到，此时线性运算为$z=\theta_{s}^{T} x$，计算结果为$p\left(y=s | x; \theta\right)=\frac{e^{\theta_{s}^{T} x}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x}}$，求导如下</li>
</ul>
<script type="math/tex; mode=display">
\frac{\varphi p\left(y=s | x; \theta\right)}{\varphi \theta_{s}}
=\frac{u^{\prime}(x) v(x)-v^{\prime}(x) u(x)}{v^{2}(x)}</script><p>其中</p>
<script type="math/tex; mode=display">
u(x) = e^{\theta_{s}^{T} x}, v(x)=\sum_{l=1}^{k} e^{\theta_{l}^{T} x}</script><p>所以</p>
<script type="math/tex; mode=display">
\frac{\varphi u(x)}{\varphi \theta_s} = e^{\theta_{s}^{T} x}\cdot x=u(x)\cdot x,
\frac{\varphi v(x)}{\varphi \theta_s} = e^{\theta_{s}^{T} x}\cdot x=u(x)\cdot x \\
\frac{\varphi p\left(y=s | x; \theta\right)}{\varphi \theta_{s}} = p\left(y=s | x; \theta\right)\cdot x-p\left(y=s | x; \theta\right)^2\cdot x</script><ul>
<li>当计算结果不是由$\theta_{s}$计算得到，此时线性运算为$z=\theta_{j}^{T} x, j\neq s$，计算结果为$p\left(y=j | x; \theta\right)=\frac{e^{\theta_{j}^{T} x}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x}}$</li>
</ul>
<script type="math/tex; mode=display">
\frac{\varphi p\left(y=j | x; \theta\right)}{\varphi \theta_{s}}
=\frac{u^{\prime}(x) v(x)-v^{\prime}(x) u(x)}{v^{2}(x)}</script><p>其中</p>
<script type="math/tex; mode=display">
u(x) = e^{\theta_{j}^{T} x}, v(x)=\sum_{l=1}^{k} e^{\theta_{l}^{T} x}</script><p>所以</p>
<script type="math/tex; mode=display">
\frac{\varphi u(x)}{\varphi \theta_s} = e^{\theta_{j}^{T} x}\cdot x=0,
\frac{\varphi v(x)}{\varphi \theta_s} = e^{\theta_{s}^{T} x}\cdot x \\
\frac{\varphi p\left(y=s | x; \theta\right)}{\varphi \theta_{s}} = -p\left(y=s | x; \theta\right)p\left(y=j | x; \theta\right)\cdot x</script><p>综合上述两种情况可知，求导结果为</p>
<script type="math/tex; mode=display">
\frac{\varphi J(\theta)}{\varphi \theta_{s}}
=(-1)\cdot \sum_{j=1,j\neq s}^{k} 1\left\{y=j \right\} \frac{1}{p\left(y=j | x; \theta\right)}\frac{\varphi p\left(y=j | x; \theta\right)}{\varphi \theta_{s}}
+(-1)\cdot 1\left\{y=s \right\} \frac{1}{p\left(y=s | x; \theta\right)}\frac{\varphi p\left(y=s | x; \theta\right)}{\varphi \theta_{s}} \\
=(-1)\cdot \sum_{j=1,j\neq s}^{k} 1\left\{y=j \right\} \frac{1}{p\left(y=j | x; \theta\right)})\cdot (-1)\cdot p\left(y=s | x; \theta\right)p\left(y=j | x; \theta\right)\cdot x + (-1)\cdot 1\left\{y=s \right\} \frac{1}{p\left(y=s | x; \theta\right)}\left[p\left(y=s | x; \theta\right)\cdot x-p\left(y=s | x; \theta\right)^2\cdot x\right] \\
=(-1)\cdot \sum_{j=1,j\neq s}^{k} 1\left\{y=j \right\}\cdot (-1)\cdot p\left(y=s | x; \theta\right)\cdot x + (-1)\cdot 1\left\{y=s \right\} \left[x-p\left(y=s | x; \theta\right)\cdot x\right] \\
=(-1)\cdot 1\left\{y=s \right\} x - (-1)\cdot \sum_{j=1}^{k} 1\left\{y=j \right\} p\left(y=s | x; \theta\right)\cdot x</script><p>因为$\sum_{j=1}^{k} 1\left\{y=j \right\}=1$，所以最终结果为</p>
<script type="math/tex; mode=display">
\frac{\varphi J(\theta)}{\varphi \theta_{s}}
=(-1)\cdot \left[ 1\left\{y=s \right\} - p\left(y=s | x; \theta\right) \right]\cdot x</script><h2 id="批量数据进行softmax回归计算"><a href="#批量数据进行softmax回归计算" class="headerlink" title="批量数据进行softmax回归计算"></a>批量数据进行softmax回归计算</h2><p>上面实现了单个数据进行类别概率和损失函数的计算以及求导，进一步推导到批量数据进行操作</p>
<h3 id="评分函数-1"><a href="#评分函数-1" class="headerlink" title="评分函数"></a>评分函数</h3><p>假设使用softmax回归分类数据$x$，共$k$个标签，首先进行线性回归操作</p>
<script type="math/tex; mode=display">
z_{\theta}(x_{i})=\theta^T\cdot x_{i}
=\begin{bmatrix}
\theta_{1}^T\\ 
\theta_{2}^T\\ 
...\\ 
\theta_{k}^T
\end{bmatrix}\cdot x_{i}
=\begin{bmatrix}
\theta_{1}^T\cdot x_{i}\\ 
\theta_{2}^T\cdot x_{i}\\ 
...\\ 
\theta_{k}^T\cdot x_{i}
\end{bmatrix}</script><p>其中输入数据$x$大小为$(n+1)\times m$，$\theta$大小为$(n+1)\times k$，$n$表示权重数量，$m$表示训练数据个数，$k$表示类别标签数量</p>
<p>输出结果$z$大小为$k\times m$，然后对计算结果进行归一化操作，使得输出值能够表示类别概率，如下所示</p>
<script type="math/tex; mode=display">
h_{\theta}\left(x_{i}\right)=\left[ \begin{array}{c}{p\left(y=1 | x_{i} ; \theta\right)} \\ 
{p\left(y=2 | x_{i} ; \theta\right)} \\ 
{\vdots} \\
{p\left(y=k | x_{i} ; \theta\right)}\end{array}\right]
=\frac{1}{\sum_{j=1}^{k} e^{\theta_{j}^{T} x}} \left[ \begin{array}{c}{e^{\theta_{1}^{T} x_{i}}} \\ 
{e^{\theta_{2}^{T} x_{i}}} \\
 {\vdots} \\ 
 {e^{\theta_{k}^{T} x_{i}}}\end{array}\right]</script><p>其中$\theta_{1}、\theta_{2},…,\theta_{k}$的大小为$(n+1)\times 1$，输出结果是一个$k\times m$大小向量，每列表示$k$类标签的预测概率</p>
<p>所以对于输入数据$x_{i}$而言，其属于标签$j$的概率是</p>
<script type="math/tex; mode=display">
p\left(y_{i}=j | x_{i}; \theta\right)=\frac{e^{\theta_{j}^{T} x_{i}}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x_{i}}}</script><h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><p>利用交叉熵损失（cross entropy loss）作为softmax回归的代价函数，用于计算训练数据对应的真正标签的损失值</p>
<script type="math/tex; mode=display">
J(\theta)
= (-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m} \sum_{j=1}^{k} 1\left\{y_{i}=j\right\} \ln p\left(y_{i}=j | x_{i}; \theta\right)
= (-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m} \sum_{j=1}^{k} 1\left\{y_{i}=j\right\} \ln \frac{e^{\theta_{j}^{T} x_{i}}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x_{i}}}</script><p>其中函数$1\{\cdot\}$是一个示性函数（indicator function），其取值规则为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1&#123;a true statement&#125; = 1, and 1&#123;a false statement&#125; = 0</span><br></pre></td></tr></table></figure>
<p>也就是示性函数输入为True时，输出为1；否则，输出为0</p>
<p>对权重向量$\theta_{s}$进行求导：</p>
<script type="math/tex; mode=display">
\frac{\varphi J(\theta)}{\varphi \theta_{s}}
=(-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m}\cdot \frac{\varphi }{\varphi \theta_{s}}
\left[ \sum_{j=1,j\neq s}^{k} 1\left\{y_{i}=j \right\} \ln p\left(y_{i}=j | x_{i}; \theta\right)+1\left\{y_{i}=s \right\} \ln p\left(y_{i}=s | x_{i}; \theta\right) \right]</script><script type="math/tex; mode=display">
=(-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m}\cdot \sum_{j=1,j\neq s}^{k} 1\left\{y_{i}=j \right\} \frac{1}{p\left(y_{i}=j | x_{i}; \theta\right)}\frac{\varphi p\left(y_{i}=j | x_{i}; \theta\right)}{\varphi \theta_{s}}
+(-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m}\cdot 1\left\{y_{i}=s \right\} \frac{1}{p\left(y_{i}=s | x_{i}; \theta\right)}\frac{\varphi p\left(y_{i}=s | x_{i}; \theta\right)}{\varphi \theta_{s}}</script><p>分为两种情况</p>
<ul>
<li>当计算结果正好由$\theta_{s}$计算得到，此时线性运算为$z=\theta_{s}^{T} x_{i}$，计算结果为$p\left(y_{i}=s | x_{i}; \theta\right)=\frac{e^{\theta_{s}^{T} x_{i}}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x_{i}}}$，求导如下</li>
</ul>
<script type="math/tex; mode=display">
\frac{\varphi p\left(y_{i}=s | x_{i}; \theta\right)}{\varphi \theta_{s}}
=\frac{u^{\prime}(x) v(x)-v^{\prime}(x) u(x)}{v^{2}(x)}</script><p>其中</p>
<script type="math/tex; mode=display">
u(x) = e^{\theta_{s}^{T} x}, v(x)=\sum_{l=1}^{k} e^{\theta_{l}^{T} x}</script><p>所以</p>
<script type="math/tex; mode=display">
\frac{\varphi u(x)}{\varphi \theta_s} = e^{\theta_{s}^{T} x}\cdot x=u(x)\cdot x,
\frac{\varphi v(x)}{\varphi \theta_s} = e^{\theta_{s}^{T} x}\cdot x=u(x)\cdot x \\
\frac{\varphi p\left(y=s | x_{i}; \theta\right)}{\varphi \theta_{s}} = p\left(y=s | x_{i}; \theta\right)\cdot x_{i}-p\left(y=s | x_{i}; \theta\right)^2\cdot x_{i}</script><ul>
<li>当计算结果不是由$\theta_{s}$计算得到，此时线性运算为$z=\theta_{j}^{T} x_{i}, j\neq s$，计算结果为$p\left(y_{i}=j | x_{i}; \theta\right)=\frac{e^{\theta_{j}^{T} x_{i}}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x_{i}}}$</li>
</ul>
<script type="math/tex; mode=display">
\frac{\varphi p\left(y_{i}=j | x_{i}; \theta\right)}{\varphi \theta_{s}}
=\frac{u^{\prime}(x) v(x)-v^{\prime}(x) u(x)}{v^{2}(x)}</script><p>其中</p>
<script type="math/tex; mode=display">
u(x) = e^{\theta_{j}^{T} x}, v(x)=\sum_{l=1}^{k} e^{\theta_{l}^{T} x}</script><p>所以</p>
<script type="math/tex; mode=display">
\frac{\varphi u(x)}{\varphi \theta_s} = e^{\theta_{j}^{T} x}\cdot x=0,
\frac{\varphi v(x)}{\varphi \theta_s} = e^{\theta_{s}^{T} x}\cdot x \\
\frac{\varphi p\left(y_{i}=s | x_{i}; \theta\right)}{\varphi \theta_{s}} = -p\left(y_{i}=s | x_{i}; \theta\right)p\left(y_{i}=j | x_{i}; \theta\right)\cdot x_{i}</script><p>综合上述两种情况可知，求导结果为</p>
<script type="math/tex; mode=display">
\frac{\varphi J(\theta)}{\varphi \theta_{s}}
=(-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m}\cdot \sum_{j=1,j\neq s}^{k} 1\left\{y_{i}=j \right\} \frac{1}{p\left(y_{i}=j | x_{i}; \theta\right)}\frac{\varphi p\left(y_{i}=j | x_{i}; \theta\right)}{\varphi \theta_{s}}
+(-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m}\cdot 1\left\{y_{i}=s \right\} \frac{1}{p\left(y_{i}=s | x_{i}; \theta\right)}\frac{\varphi p\left(y_{i}=s | x_{i}; \theta\right)}{\varphi \theta_{s}} \\
=(-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m}\cdot \sum_{j=1,j\neq s}^{k} 1\left\{y_{i}=j \right\} \frac{1}{p\left(y_{i}=j | x_{i}; \theta\right)})\cdot (-1)\cdot p\left(y_{i}=s | x_{i}; \theta\right)p\left(y_{i}=j | x_{i}; \theta\right)\cdot x_{i} + (-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m}\cdot 1\left\{y_{i}=s \right\} \frac{1}{p\left(y_{i}=s | x_{i}; \theta\right)}\left[p\left(y_{i}=s | x_{i}; \theta\right)\cdot x_{i}-p\left(y_{i}=s | x_{i}; \theta\right)^2\cdot x_{i}\right] \\
=(-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m}\cdot \sum_{j=1,j\neq s}^{k} 1\left\{y_{i}=j \right\}\cdot (-1)\cdot p\left(y_{i}=s | x_{i}; \theta\right)\cdot x_{i} + (-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m}\cdot 1\left\{y_{i}=s \right\} \left[x_{i}-p\left(y_{i}=s | x_{i}; \theta\right)\cdot x_{i}\right] \\
=(-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m}\cdot 1\left\{y_{i}=s \right\} x_{i} - (-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m}\cdot \sum_{j=1}^{k} 1\left\{y_{i}=j \right\} p\left(y_{i}=s | x_{i}; \theta\right)\cdot x_{i}</script><p>因为$\sum_{j=1}^{k} 1\left\{y_{i}=j \right\}=1$，所以最终结果为</p>
<script type="math/tex; mode=display">
\frac{\varphi J(\theta)}{\varphi \theta_{s}}
=(-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m}\cdot \left[ 1\left\{y_{i}=s \right\} - p\left(y_{i}=s | x_{i}; \theta\right) \right]\cdot x_{i}</script><h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>权重$W$大小为$(n+1)\times k$，输入数据集大小为$m\times (n+1)$，输出数据集大小为$m\times k$</p>
<p>矩阵求导如下：</p>
<script type="math/tex; mode=display">
\frac{\varphi J(\theta)}{\varphi \theta}
=\frac{1}{m}\cdot \sum_{i=1}^{m}\cdot 
\begin{bmatrix}
(-1)\cdot\left[ 1\left\{y=1 \right\} - p\left(y=1 | x; \theta\right) \right]\cdot x\\ 
(-1)\cdot\left[ 1\left\{y=2 \right\} - p\left(y=2 | x; \theta\right) \right]\cdot x\\ 
...\\ 
(-1)\cdot\left[ 1\left\{y=k \right\} - p\left(y=k | x; \theta\right) \right]\cdot x
\end{bmatrix}
=(-1)\cdot \frac{1}{m}\cdot X_{m\times n+1}^T \cdot (I_{m\times k} - Y_{m\times k})</script><p>参考：</p>
<p><a href="https://www.kaggle.com/saksham219/softmax-regression-for-iris-classification" target="_blank" rel="noopener">Softmax regression for Iris classification</a></p>
<p><a href="https://math.stackexchange.com/questions/945871/derivative-of-softmax-loss-function" target="_blank" rel="noopener">Derivative of Softmax loss function</a></p>
<p>上述计算的是输入单个数据时的评分、损失和求导，所以使用随机梯度下降法进行权重更新，分类</p>
<h2 id="参数冗余和权重衰减"><a href="#参数冗余和权重衰减" class="headerlink" title="参数冗余和权重衰减"></a>参数冗余和权重衰减</h2><p><code>softmax</code>回归存在参数冗余现象，即对参数向量$\theta_{j}$减去向量$\varphi $不改变预测结果。证明如下：</p>
<script type="math/tex; mode=display">
\begin{aligned} p\left(y^{(i)}=j | x^{(i)} ; \theta\right) &=\frac{e^{\left(\theta_{j}-\psi\right)^{T} x^{(i)}}}{\sum_{l=1}^{k} e^{\left(\theta_{l}-\psi\right)^{T} x^{(i)}}} \\ &=\frac{e^{\theta_{j}^{T} x^{(i)}} e^{-\psi^{T} x^{(i)}}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x^{(i)}} e^{-\psi^{T} x^{(i)}}} \\ &=\frac{e^{\theta_{j}^{T} x^{(i)}}}{\sum_{l=1}^{k} e^{\theta_{t}^{T} x^{(i)}}} \end{aligned}</script><p>假设$(\theta_{1},\theta_{2},…,\theta_{k})$能得到$j(\theta)$的极小值点，那么$(\theta_{1}-\varphi,\theta_{2}-\varphi,…,\theta_{k}-\varphi)$同样能得到相同的极小值点</p>
<p>与此同时，因为损失函数是凸函数，局部最小值就是全局最小值，所以会导致权重在参数过大情况下就停止收敛，影响模型泛化能力</p>
<p><strong>在代价函数中加入权重衰减，能够避免过度参数化，得到泛化性能更强的模型</strong></p>
<p>在代价函数中加入<code>L2</code>正则化项，如下所示：</p>
<script type="math/tex; mode=display">
J(\theta)
= (-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m} \sum_{j=1}^{k} 1\left\{y_{i}=j\right\} \ln p\left(y_{i}=j | x_{i}; \theta\right) + \frac{\lambda}{2} \sum_{i=1}^{k} \sum_{j=0}^{n} \theta_{i j}^{2}
= (-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m} \sum_{j=1}^{k} 1\left\{y_{i}=j\right\} \ln \frac{e^{\theta_{j}^{T} x_{i}}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x_{i}}} + \frac{\lambda}{2} \sum_{i=1}^{k} \sum_{j=0}^{n} \theta_{i j}^{2}</script><p>求导结果如下：</p>
<script type="math/tex; mode=display">
\frac{\varphi J(\theta)}{\varphi \theta_{s}}
=(-1)\cdot \frac{1}{m}\cdot \sum_{i=1}^{m}\cdot \left[ 1\left\{y_{i}=s \right\} - p\left(y_{i}=s | x_{i}; \theta\right) \right]\cdot x_{i}+ \lambda \theta_{j}</script><p>代价实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def compute_loss(scores, indicator, W):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算损失值</span><br><span class="line">    :param scores: 大小为(m, n)</span><br><span class="line">    :param indicator: 大小为(m, n)</span><br><span class="line">    :param W: (n, k)</span><br><span class="line">    :return: (m,1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return -1 * np.sum(np.log(scores) * indicator, axis=1) + 0.001/2*np.sum(W**2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient(indicator, scores, x, W):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算梯度</span><br><span class="line">    :param indicator: 大小为(m,k)</span><br><span class="line">    :param scores: 大小为(m,k)</span><br><span class="line">    :param x: 大小为(m,n)</span><br><span class="line">    :param W: (n, k)</span><br><span class="line">    :return: (n,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return -1 * x.T.dot((indicator - scores)) + 0.001*W</span><br></pre></td></tr></table></figure>
<h2 id="鸢尾数据集"><a href="#鸢尾数据集" class="headerlink" title="鸢尾数据集"></a>鸢尾数据集</h2><p>使用鸢尾（iris）数据集，参考<a href="https://www.kaggle.com/uciml/iris" target="_blank" rel="noopener">Iris Species</a></p>
<p>共<code>4</code>个变量：</p>
<ul>
<li><code>SepalLengthCm</code> - 花萼长度</li>
<li><code>SepalWidthCm</code> - 花萼宽度</li>
<li><code>PetalLengthCm</code> - 花瓣长度</li>
<li><code>PetalWidthCm</code> - 花瓣宽度</li>
</ul>
<p>以及<code>3</code>个类别：</p>
<ul>
<li><code>Iris-setosa</code></li>
<li><code>Iris-versicolor</code></li>
<li><code>Iris-virginica</code></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def load_data(shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(data_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line">    # print(data.columns)</span><br><span class="line"></span><br><span class="line">    draw_data(data.values, data.columns)</span><br><span class="line"></span><br><span class="line">def draw_data(data, columns):</span><br><span class="line">    data_a = data[:50, 1:5]</span><br><span class="line">    data_b = data[50:100, 1:5]</span><br><span class="line">    data_c = data[100:150, 1:5]</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(1)</span><br><span class="line">    plt.scatter(data_a[:, 0], data_a[:, 1], c=&apos;b&apos;, marker=&apos;8&apos;)</span><br><span class="line">    plt.scatter(data_b[:, 0], data_b[:, 1], c=&apos;r&apos;, marker=&apos;s&apos;)</span><br><span class="line">    plt.scatter(data_c[:, 0], data_c[:, 1], c=&apos;y&apos;, marker=&apos;*&apos;)</span><br><span class="line">    plt.xlabel(columns[1])</span><br><span class="line">    plt.ylabel(columns[2])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(2)</span><br><span class="line">    plt.scatter(data_a[:, 2], data_a[:, 3], c=&apos;b&apos;, marker=&apos;8&apos;)</span><br><span class="line">    plt.scatter(data_b[:, 2], data_b[:, 3], c=&apos;r&apos;, marker=&apos;s&apos;)</span><br><span class="line">    plt.scatter(data_c[:, 2], data_c[:, 3], c=&apos;y&apos;, marker=&apos;*&apos;)</span><br><span class="line">    plt.xlabel(columns[3])</span><br><span class="line">    plt.ylabel(columns[4])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    # 验证是否有重复数据</span><br><span class="line">    # for i in range(data_b.shape[0]):</span><br><span class="line">    #     res = list(filter(lambda x: x[0] == data_b[i][0] and x[1] == data_b[i][1], data_c[:, :2]))</span><br><span class="line">    #     if len(res) != 0:</span><br><span class="line">    #         res2 = list(filter(lambda x: x[2] == data_b[i][2] and x[3] == data_b[i][3], data_c[:, 2:4]))</span><br><span class="line">    #         if len(res2) != 0:</span><br><span class="line">    #             print(b[i])</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/softmax回归/iris_petal.png" alt></p>
<p><img src="/imgs/softmax回归/iris_sepal.png" alt></p>
<h2 id="numpy实现"><a href="#numpy实现" class="headerlink" title="numpy实现"></a>numpy实现</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-4-25 上午10:30</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn import utils</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/iris-species/Iris.csv&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(shuffle=True, tsize=0.8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载iris数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = pd.read_csv(data_path, header=0, delimiter=&apos;,&apos;)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        data = utils.shuffle(data)</span><br><span class="line"></span><br><span class="line">    # 示性函数</span><br><span class="line">    pd_indicator = pd.get_dummies(data[&apos;Species&apos;])</span><br><span class="line">    indicator = np.array(</span><br><span class="line">        [pd_indicator[&apos;Iris-setosa&apos;], pd_indicator[&apos;Iris-versicolor&apos;], pd_indicator[&apos;Iris-virginica&apos;]]).T</span><br><span class="line"></span><br><span class="line">    species_dict = &#123;</span><br><span class="line">        &apos;Iris-setosa&apos;: 0,</span><br><span class="line">        &apos;Iris-versicolor&apos;: 1,</span><br><span class="line">        &apos;Iris-virginica&apos;: 2</span><br><span class="line">    &#125;</span><br><span class="line">    data[&apos;Species&apos;] = data[&apos;Species&apos;].map(species_dict)</span><br><span class="line"></span><br><span class="line">    data_x = np.array(</span><br><span class="line">        [data[&apos;SepalLengthCm&apos;], data[&apos;SepalWidthCm&apos;], data[&apos;PetalLengthCm&apos;], data[&apos;PetalWidthCm&apos;]]).T</span><br><span class="line">    data_y = data[&apos;Species&apos;]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=False)</span><br><span class="line"></span><br><span class="line">    y_train = np.atleast_2d(y_train).T</span><br><span class="line">    y_test = np.atleast_2d(y_test).T</span><br><span class="line"></span><br><span class="line">    y_train_indicator = np.atleast_2d(indicator[:y_train.shape[0]])</span><br><span class="line">    y_test_indicator = indicator[y_train.shape[0]:]</span><br><span class="line"></span><br><span class="line">    return x_train, x_test, y_train, y_test, y_train_indicator, y_test_indicator</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def linear(x, w):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    线性操作</span><br><span class="line">    :param x: 大小为(m,n+1)</span><br><span class="line">    :param w: 大小为(n+1,k)</span><br><span class="line">    :return: 大小为(m,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return x.dot(w)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def softmax(x):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    softmax归一化计算</span><br><span class="line">    :param x: 大小为(m, k)</span><br><span class="line">    :return: 大小为(m, k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x -= np.atleast_2d(np.max(x, axis=1)).T</span><br><span class="line">    exps = np.exp(x)</span><br><span class="line">    return exps / np.atleast_2d(np.sum(exps, axis=1)).T</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_scores(X, W):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param X: 大小为(m,n+1)</span><br><span class="line">    :param W: 大小为(n+1,k)</span><br><span class="line">    :return: (m,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return softmax(linear(X, W))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_loss(scores, indicator, W, la=2e-4):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算损失值</span><br><span class="line">    :param scores: 大小为(m, k)</span><br><span class="line">    :param indicator: 大小为(m, k)</span><br><span class="line">    :param W: (n+1, k)</span><br><span class="line">    :return: (1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    cost = -1 / scores.shape[0] * np.sum(np.log(scores) * indicator)</span><br><span class="line">    reg = la / 2 * np.sum(W ** 2)</span><br><span class="line">    return cost + reg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient(scores, indicator, x, W, la=2e-4):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算梯度</span><br><span class="line">    :param scores: 大小为(m,k)</span><br><span class="line">    :param indicator: 大小为(m,k)</span><br><span class="line">    :param x: 大小为(m,n+1)</span><br><span class="line">    :param W: (n+1, k)</span><br><span class="line">    :return: (n+1,k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return -1 / scores.shape[0] * x.T.dot((indicator - scores)) + la * W</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_accuracy(scores, Y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算精度</span><br><span class="line">    :param scores: (m,k)</span><br><span class="line">    :param Y: (m,1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    res = np.dstack((np.argmax(scores, axis=1), Y.squeeze())).squeeze()</span><br><span class="line"></span><br><span class="line">    return len(list(filter(lambda x: x[0] == x[1], res[:]))) / len(res)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(res_list, title=None, xlabel=None):</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    if xlabel is not None:</span><br><span class="line">        plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(res_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient_descent(batch_size=8, epoches=2000, alpha=2e-4):</span><br><span class="line">    x_train, x_test, y_train, y_test, y_train_indicator, y_test_indicator = load_data()</span><br><span class="line"></span><br><span class="line">    m, n = x_train.shape[:2]</span><br><span class="line">    k = y_train_indicator.shape[1]</span><br><span class="line">    # 初始化权重(n+1,k)</span><br><span class="line">    W = 0.01 * np.random.normal(loc=0.0, scale=1.0, size=(n + 1, k))</span><br><span class="line">    x_train = np.insert(x_train, 0, np.ones(m), axis=1)</span><br><span class="line">    x_test = np.insert(x_test, 0, np.ones(x_test.shape[0]), axis=1)</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    bestW = None</span><br><span class="line">    bestA = 0</span><br><span class="line">    range_list = np.arange(0, x_train.shape[0] - batch_size, step=batch_size)</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j in range_list:</span><br><span class="line">            data = x_train[j:j + batch_size]</span><br><span class="line">            labels = y_train_indicator[j:j + batch_size]</span><br><span class="line"></span><br><span class="line">            # 计算分类概率</span><br><span class="line">            scores = np.atleast_2d(compute_scores(data, W))</span><br><span class="line">            # 更新梯度</span><br><span class="line">            tempW = W - alpha * compute_gradient(scores, labels, data, W)</span><br><span class="line">            W = tempW</span><br><span class="line"></span><br><span class="line">            if j == range_list[-1]:</span><br><span class="line">                loss = compute_loss(scores, labels, W)</span><br><span class="line">                loss_list.append(loss)</span><br><span class="line"></span><br><span class="line">                accuracy = compute_accuracy(compute_scores(x_train, W), y_train)</span><br><span class="line">                accuracy_list.append(accuracy)</span><br><span class="line">                if accuracy &gt;= bestA:</span><br><span class="line">                    bestA = accuracy</span><br><span class="line">                    bestW = W.copy()</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练精度&apos;)</span><br><span class="line"></span><br><span class="line">    print(bestA)</span><br><span class="line">    print(compute_accuracy(compute_scores(x_test, bestW), y_test))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    compute_gradient_descent(batch_size=8, epoches=100000)</span><br></pre></td></tr></table></figure>
<p>训练10万次的最好训练结果以及对应的测试结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 测试集精度</span><br><span class="line">0.9916666666666667</span><br><span class="line"># 验证集精度</span><br><span class="line">0.9666666666666667</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/softmax回归/numpy_softmax_loss.png" alt></p>
<p><img src="/imgs/softmax回归/numpy_softmax_accuracy.png" alt></p>
<h3 id="指数计算-数值稳定性考虑"><a href="#指数计算-数值稳定性考虑" class="headerlink" title="指数计算 - 数值稳定性考虑"></a>指数计算 - 数值稳定性考虑</h3><p>参考：<a href="http://cs231n.github.io/linear-classify/" target="_blank" rel="noopener">Practical issues: Numeric stability.</a></p>
<p>在<code>softmax</code>回归中，需要利用指数函数$e^x$对线性操作的结果进行归一化，这有可能会造成数值溢出，常用的做法是对分数上下同乘以一个常数$C$</p>
<script type="math/tex; mode=display">
\frac{e^{f_{i_{i}}}}{\sum_{j} e^{f_{j}}}=\frac{C e^{f_{y_{i}}}}{C \sum_{j} e^{f_{j}}}=\frac{e^{f_{i_{i}}+\log C}}{\sum_{j} e^{f_{j}+\log C}}</script><p>这个操作不改变结果，如果取值$C$为线性操作结果最大值负数$\log C=-\max _{j} f_{j}$，就能够将向量$f$的取值范围降低，最大值为$0$，避免数值不稳定</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def softmax(x):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    softmax归一化计算</span><br><span class="line">    :param x: 大小为(m, k)</span><br><span class="line">    :return: 大小为(m, k)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x -= np.atleast_2d(np.max(x, axis=1)).T</span><br><span class="line">    exps = np.exp(x)</span><br><span class="line">    return exps / np.atleast_2d(np.sum(exps, axis=1)).T</span><br></pre></td></tr></table></figure>
<h2 id="softmax回归和logistic回归"><a href="#softmax回归和logistic回归" class="headerlink" title="softmax回归和logistic回归"></a>softmax回归和logistic回归</h2><p><code>softmax</code>回归是<code>logistic</code>回归在多分类任务上的扩展，将$k=2$时，<code>softmax</code>回归模型可转换成<code>logistic</code>回归模型</p>
<script type="math/tex; mode=display">
h_{\theta}(x)=\frac{1}{e^{\theta_{1}^{T} x}+e^{\theta_{2}^{T} x^{(i)}}} \left[ \begin{array}{c}{e^{\theta_{1}^{T} x}} \\ {e^{\theta_{2}^{T} x}}\end{array}\right] 
=\frac{1}{e^{\vec{0}^{T} x}+e^{(\theta_{2}-\theta_{1})^{T} x^{(i)}}} \left[ \begin{array}{c}{e^{\vec{0}^{T} x}} \\ {e^{(\theta_{2}-\theta_{1})^{T} x}}\end{array}\right] \\
=\frac{1}{1+e^{(\theta_{2}-\theta_{1})^{T} x^{(i)}}} \left[ \begin{array}{c}{1} \\ {e^{(\theta_{2}-\theta_{1})^{T} x}}\end{array}\right]
= \left[ \begin{array}{c}{\frac{1}{1+e^{(\theta_{2}-\theta_{1})^{T} x^{(i)}}}} \\ {\frac{e^{(\theta_{2}-\theta_{1})^{T} x}}{1+e^{(\theta_{2}-\theta_{1})^{T} x^{(i)}}}}\end{array}\right]
=\left[ \begin{array}{c}{\frac{1}{1+e^{(\theta_{2}-\theta_{1})^{T} x^{(i)}}}} \\ {1- \frac{1}{1+e^{(\theta_{2}-\theta_{1})^{T} x^{(i)}}}}\end{array}\right]</script><p>针对多分类任务，可以选择<code>softmax</code>回归模型进行多分类，也可以选择<code>logistic</code>回归模型进行若干个二分类</p>
<p>区别在于选择的类别是否<strong>互斥</strong>，如果类别互斥，使用<code>softmax</code>回归分类更为合适；如果类别不互斥，使用<code>logistic</code>回归分类更为合适</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>数学</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>微积分</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>sklearn</tag>
        <tag>pandas</tag>
        <tag>softmax</tag>
      </tags>
  </entry>
  <entry>
    <title>成绩函数、目标函数、代价函数和损失函数</title>
    <url>/posts/5d2f01d1.html</url>
    <content><![CDATA[<p>参考：<a href="https://aboveintelligent.com/deep-learning-basics-the-score-function-cross-entropy-d6cc20c9f972" target="_blank" rel="noopener">Deep Learning Basics: The Score Function &amp; Cross Entropy</a></p><a id="more"></a>
<p>成绩函数（<code>score function</code>）、目标函数（<code>objective functio</code>n）、代价函数（<code>cost function</code>）和损失函数（<code>loss function</code>）这四个术语经常出现在机器学习和深度学习的各类算法中</p>
<h2 id="目标函数、代价函数和损失函数"><a href="#目标函数、代价函数和损失函数" class="headerlink" title="目标函数、代价函数和损失函数"></a>目标函数、代价函数和损失函数</h2><p>参考：</p>
<p><a href="https://stats.stackexchange.com/questions/73221/what-is-a-loss-function-in-decision-theory#comment142380_73221" target="_blank" rel="noopener">What is a loss function in decision theory?</a></p>
<p><a href="https://stats.stackexchange.com/questions/179026/objective-function-cost-function-loss-function-are-they-the-same-thing" target="_blank" rel="noopener">Objective function, cost function, loss function: are they the same thing?</a></p>
<p><a href="https://www.quora.com/What-is-the-difference-between-a-cost-function-and-a-loss-function-in-machine-learning" target="_blank" rel="noopener">What is the difference between a cost function and a loss function in machine learning?</a></p>
<p><a href="https://www.zhihu.com/question/52398145" target="_blank" rel="noopener">机器学习中的目标函数、损失函数、代价函数有什么区别？</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/41679108" target="_blank" rel="noopener">CS231n笔记|3 损失函数和最优化</a></p>
<p>目标函数指的是最优化经验风险和结构风险的函数（最大值/最小值优化）。经验风险指的是针对训练数据的损失值，在深度学习中指的是数据损失（<code>data loss</code>）；结构风险指的是针对模型复杂度的损失值，在深度学习中指的是正则化损失（<code>regularization loss</code>）。</p>
<p>损失函数和代价函数指的是最小值优化函数，<code>Andrew Ng</code>在机器学习课程<a href="https://www.coursera.org/learn/neural-networks-deep-learning/lecture/yWaRd/logistic-regression-cost-function" target="_blank" rel="noopener"> Logistic Regression Cost Function - deeplearning.ai | Coursera</a>中给出一个解释如下：</p>
<ul>
<li><p>损失函数用于评判单个训练数据计算结果的好坏</p>
</li>
<li><p>代价函数用于评判整个训练数据计算结果的好坏</p>
</li>
</ul>
<p>目标函数可以看成损失函数或代价函数的泛化形式，在深度学习中，获取最优的分类结果需要<strong>最小化</strong>损失函数或者代价函数值</p>
<h2 id="关联"><a href="#关联" class="headerlink" title="关联"></a>关联</h2><p>参考：<a href="https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit" target="_blank" rel="noopener">CS231n课程笔记翻译：线性分类笔记（上）</a></p>
<p>理清每个术语的概念以及联系，以分类算法为例，假设有一组训练数据$X$，大小为$m\times n$，$m$表示数据个数，$n$表示单个数据维数。$X$中的每个数据都有一个类别，保存为$Y$，大小为$m\times 1$</p>
<p>想要实现一个算法$F$，输入$X$中的数据就能够输出$Y$中相对应的类别，并且希望能够进一步泛化，输入和$X$相同类型的数据也能够输出正确的类别</p>
<p>通常实现方法是设置一个函数$S$，输入数据后输出一组评分，每个评分表示属于某一个标签的可能性，选取最大的评分值作为输入数据所属类别</p>
<p><strong>$S$就是成绩函数，又称为评分函数，其目的是原始数据到类别的映射</strong></p>
<p>那么怎么来计算$S$的好坏呢？可以设置另一个函数$O$，用来计算$S$输出的评分值和正确类别（<em>将类别数值化</em>）之间的差距</p>
<p><strong>$O$就是目标函数，其目的是量化预测分类结果和真实结果之间的的距离</strong></p>
<p>函数$O$的结果越小，表明函数$S$的结果越好，也就是分类效果越好</p>
<p>目标函数的计算包括两部分，一是针对计算结果的评判，二是针对算法复杂度的评判</p>
<p>针对计算结果的评判，就是数据损失，表示<strong>损失函数或者代价函数</strong>；针对算法复杂度的评判，就是正则化损失</p>
<script type="math/tex; mode=display">
O(\theta) = L(\theta)+\Omega(\theta)
=\frac{1}{N} \sum_{j=1}^{N}loss(y_{j},f(x_{j}))+\lambda R(W)</script>]]></content>
      <categories>
        <category>算法</category>
        <category>深度学习</category>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>正则化</title>
    <url>/posts/ce0afb50.html</url>
    <content><![CDATA[<p><a href="http://cs231n.github.io/neural-networks-2/#init" target="_blank" rel="noopener">Setting up the data and the model</a></p><p><a href="https://www.zhihu.com/question/20924039" target="_blank" rel="noopener">机器学习中常常提到的正则化到底是什么意思？</a></p><a id="more"></a>

<h2 id="泰勒公式"><a href="#泰勒公式" class="headerlink" title="泰勒公式"></a>泰勒公式</h2><p>参考：<a href="https://zh.wikipedia.org/wiki/%E6%B3%B0%E5%8B%92%E5%85%AC%E5%BC%8F" target="_blank" rel="noopener">泰勒公式</a></p>
<p>设$n$是一个正整数，如果定义一个包含$a$的区间上的函数$f$在$a$点处$n+1$次可导，那么对于区间上的任意x，都有：</p>
<script type="math/tex; mode=display">
f(x)=f(a)+\frac{f^{\prime}(a)}{1 !}(x-a)+\frac{f^{(2)}(a)}{2 !}(x-a)^{2}+\cdots+\frac{f^{(n)}(a)}{n !}(x-a)^{n}+R_{n}(x)</script><p>其中的多项式称为函数在$a$点处的<strong>泰勒展开式</strong>，剩余的$R_{n}(x)$是泰勒展开式的余项，是$(x-a)^{n}$的高阶无穷小</p>
<h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h2><p>范数（<code>norm</code>）常被用于度量某个向量空间（或矩阵）中的每个向量的长度或大小。通用计算公式如下：</p>
<script type="math/tex; mode=display">
\|x\|_{p}=\left(\sum_{i}\left|x_{i}\right|^{p}\right)^{1 / p}</script><p>常用的范数包括<code>L0/L1/L2</code>范数</p>
<ul>
<li>0-范数，计算向量中非零元素的个数</li>
<li>1-范数，又称为<code>L1</code>范数，计算向量中各元素绝对值之和</li>
</ul>
<script type="math/tex; mode=display">
\left \| X \right \| = \left | X \right | = \left | x_{1} \right |+\left |x_{2}  \right |+...+\left | x_{n} \right |</script><ul>
<li>2-范数，又称为<code>L2</code>范数，计算向量中各元素之间距离（欧式距离）之和</li>
</ul>
<script type="math/tex; mode=display">
\left \| X \right \|_{2} = \sqrt{x_{1}^{2}+x_{2}^{2}+...+x_{n}^{2}}</script><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>在深度学习或机器学习中，一方面要提高算法泛化能力，另一方面要避免算法过拟合</p>
<p><strong>正则化（<code>regularization</code>）指的是最小化算法结构风险，其目的就是为了防止算法过拟合，提高泛化能力</strong></p>
<p>常用的方法包括</p>
<ul>
<li>权重惩罚（<code>weight penalty</code>）</li>
<li>提前停止策略（<code>early stopping</code>）</li>
<li>随机失活（<code>dropout</code>）</li>
<li>最大值上限（<code>max-upper constraint</code>）</li>
</ul>
<h3 id="权重惩罚"><a href="#权重惩罚" class="headerlink" title="权重惩罚"></a>权重惩罚</h3><p>参考：</p>
<p><a href="https://blog.csdn.net/zouxy09/article/details/24971995" target="_blank" rel="noopener">机器学习中的范数规则化之（一）L0、L1与L2范数</a></p>
<p><a href="https://www.kaggle.com/residentmario/l1-norms-versus-l2-norms" target="_blank" rel="noopener">L1 Norms versus L2 Norms</a></p>
<p><a href="https://www.zhihu.com/question/26485586" target="_blank" rel="noopener">l1正则与l2正则的特点是什么，各有什么优势？</a></p>
<p>根据泰勒公式可知，如果函数足够光滑的话，可以用泰勒展开式近似。对于非线性函数而言，可以替换成如下形式</p>
<script type="math/tex; mode=display">
h(x;\theta) 
=w_{0}+w_{1}\cdot x+w_{2}\cdot x^{2}+...+w_{n}\cdot x^{n}</script><p>参数$\theta=(w_{0},w_{1},…,w_{n})$，一次项是$w_{1}\cdot x$，$x$次数高于2的项统称为高次项</p>
<p>一方面算法增加高次项能够提高拟合能力；另一方面高次项的系数变化对整个算法的影响更大，过高的系数会导致算法过拟合</p>
<p>为了防止算法过拟合，需要在损失函数中加上正则化项，常用的有<code>L1/L2</code>正则化</p>
<p><code>L1</code>正则化使用<code>L1</code>范数加上超参数$\lambda$作为正则化项，目标函数实现如下：</p>
<script type="math/tex; mode=display">
obj(x;\theta) = loss(x;\theta)+\lambda \left \| \theta \right \|
=loss(x;\theta)+\lambda \left | \theta \right |</script><p>求导如下：</p>
<script type="math/tex; mode=display">
\frac{\varphi O}{\varphi w_{i}}=\frac{\varphi L}{\varphi w_{i}}+\lambda</script><p><code>L2</code>正则化使用<code>L2</code>范数（<em>通常去除开根号</em>）加上超参数$\lambda$作为正则化项，目标函数实现如下：</p>
<script type="math/tex; mode=display">
obj(x;\theta) = loss(x;\theta)+\frac{1}{2} \lambda \left \| \theta \right \|_{2}
=loss(x;\theta)+\frac{1}{2} \lambda \theta^{2}</script><p>求导如下</p>
<script type="math/tex; mode=display">
\frac{\varphi O}{\varphi w_{i}}=\frac{\varphi L}{\varphi w_{i}}+\lambda w_{i}</script><p>从导函数可知，使用<code>L1</code>范数作为正则化项会导致训练后的权重向量变得稀疏（<code>sparse</code>），即某些权重非常接近于<code>0</code>，因为每次梯度更新都会减去一个固定大小正则化梯度；使用<code>L2</code>范数作为正则化项会导致训练后的权重向量变得平均（<code>diffuse</code>），因为在梯度更新过程中，权重值越大，其减去的梯度也会更大</p>
<p><strong>使用<code>L1</code>范数更有利于特征选择，使用<code>L2</code>范数能够抑制大权值对网络的影响，充分利用所有权重向量。在实践过程中，通常使用<code>L2</code>范数作为正则化项</strong></p>
<p><em>不需要惩罚$w_{0}$，因为它没有和输入数据进行乘法交互，不会放大拟合能力。在实际使用中，惩罚$w_{0}$几乎不会导致性能显著下降</em></p>
<h3 id="提前停止"><a href="#提前停止" class="headerlink" title="提前停止"></a>提前停止</h3><p>提前停止是一个训练策略，最开始训练过程中，训练集和验证集的错误率都在下降，但训练多轮之后，模型可能会开始进一步学习噪声，此时训练集的错误率在下降但是验证集的错误率会提高。在这种情况下可以中止训练，通过调整超参数来防止模型过拟合</p>
<h3 id="随机失活"><a href="#随机失活" class="headerlink" title="随机失活"></a>随机失活</h3><p>针对网络结构模型，通过在训练过程中随机移除网络中的某些节点，能够防止网络的过拟合，提高泛化能力</p>
<p>随机失活的优势如下：</p>
<ol>
<li>防止节点之间权重依赖性，提高节点自适应能力</li>
<li>实践证明，组合多个网络的模型能够有效提高泛化能力，随机失活操作相当于同时训练多个稀疏网络</li>
</ol>
<h3 id="最大值上限"><a href="#最大值上限" class="headerlink" title="最大值上限"></a>最大值上限</h3><p>最大值上限（<code>max-upper constraint</code>），也称为最大范数限制（<code>max-norm constraint</code>）用于避免权重过大，防止权重爆炸</p>
<p>设置一个最大值$c$（<em>通常设置为3或4，可通过验证集测试</em>），计算每个神经元的权重向量$\overrightarrow{w}$的L-2范数（平方和），如果$||\overrightarrow{w}||_{2} &gt; c$，就缩放权重向量到$||\overrightarrow{w}||_{2} = c$</p>
<script type="math/tex; mode=display">
w = \frac {w}{\sqrt{\sum (w^{2})}}\cdot c</script>]]></content>
      <categories>
        <category>算法</category>
        <category>最优化</category>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>正则化</tag>
        <tag>权重惩罚</tag>
      </tags>
  </entry>
  <entry>
    <title>从numpy到pytorch实现逻辑回归</title>
    <url>/posts/730913b9.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://cloud.tencent.com/developer/article/1072473" target="_blank" rel="noopener">Pytorch实现Logistic回归二分类</a></p><p><a href="https://www.pytorchtutorial.com/pytorch-simple-classifier/" target="_blank" rel="noopener">PyTorch 入门之五分钟实现简单二分类器</a></p><p>逻辑回归常用于二元分类任务，其使用交叉熵损失进行梯度计算，实现步骤如下：</p><a id="more"></a>



<ol>
<li>加载、打乱、标准化训练和测试数据</li>
<li>设计分类器、损失函数和梯度更新函数</li>
<li>用训练数据计算目标函数和精度</li>
<li>用训练数据计算损失函数和梯度，并更新梯度</li>
<li>重复<code>3-4</code>步，直到精度达到要求或达到指定迭代次数</li>
<li>用测试数据计算目标函数和精度</li>
</ol>
<p>使用<code>numpy</code>和<code>pytorch</code>分别实现小批量梯度下降的<code>2</code>分类逻辑回归</p>
<p>关键参数：</p>
<ul>
<li>批量大小：<code>128</code></li>
<li>迭代次数：<code>50000</code></li>
<li>学习步长：<code>0.0001</code></li>
</ul>
<h2 id="测试数据"><a href="#测试数据" class="headerlink" title="测试数据"></a>测试数据</h2><p>使用<code>numeric</code>类型的德国信用数据，其包含<code>24</code>个变量和一个<code>2</code>类标签 - <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/" target="_blank" rel="noopener">german.data-numeric</a></p>
<h2 id="numpy实现"><a href="#numpy实现" class="headerlink" title="numpy实现"></a><code>numpy</code>实现</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/german.data-numeric&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(tsize=0.8, shuffle=True):</span><br><span class="line">    data_list = pd.read_csv(data_path, header=None, sep=&apos;\s+&apos;)</span><br><span class="line"></span><br><span class="line">    data_array = data_list.values</span><br><span class="line">    height, width = data_array.shape[:2]</span><br><span class="line">    data_x = data_array[:, :(width - 1)]</span><br><span class="line">    data_y = data_array[:, (width - 1)]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    y_train = np.atleast_2d(np.array(list(map(lambda x: 1 if x == 2 else 0, y_train)))).T</span><br><span class="line">    y_test = np.atleast_2d(np.array(list(map(lambda x: 1 if x == 2 else 0, y_test)))).T</span><br><span class="line"></span><br><span class="line">    return x_train, y_train, x_test, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def init_weights(inputs):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    初始化权重，符合标准正态分布</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return np.atleast_2d(np.random.uniform(size=inputs)).T</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def sigmoid(x):</span><br><span class="line">    return 1 / (1 + np.exp(-1 * x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def logistic_regression(w, x):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    w大小为(n+1)x1</span><br><span class="line">    x大小为mx(n+1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    z = x.dot(w)</span><br><span class="line">    return sigmoid(z)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_loss(w, x, y, isBatch=True):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    w大小为(n+1)x1</span><br><span class="line">    x大小为mx(n+1)</span><br><span class="line">    y大小为mx1</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    lr_value = logistic_regression(w, x)</span><br><span class="line">    if isBatch:</span><br><span class="line">        n = y.shape[0]</span><br><span class="line">        res = -1.0 / n * (y.T.dot(np.log(lr_value)) + (1 - y.T).dot(np.log(1 - lr_value)))</span><br><span class="line">        return res[0][0]</span><br><span class="line">    else:</span><br><span class="line">        res = -1.0 * (y * (np.log(lr_value)) + (1 - y) * (np.log(1 - lr_value)))</span><br><span class="line">        return res[0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient(w, x, y, isBatch=True):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    梯度计算</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    lr_value = logistic_regression(w, x)</span><br><span class="line">    if isBatch:</span><br><span class="line">        n = y.shape[0]</span><br><span class="line">        return 1.0 / n * x.T.dot(lr_value - y)</span><br><span class="line">    else:</span><br><span class="line">        return np.atleast_2d(1.0 * x.T * (lr_value - y)).T</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_predict_accuracy(predictions, y):</span><br><span class="line">    results = predictions &gt; 0.5</span><br><span class="line">    res = len(list(filter(lambda x: x[0] == x[1], np.dstack((results, y))[:, 0]))) / len(results)</span><br><span class="line">    return res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(res_list, title=None, xlabel=None):</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    if xlabel is not None:</span><br><span class="line">        plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(res_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # 加载训练和测试数据</span><br><span class="line">    # train_data, train_label, test_data, test_label = load_german_numeric(tsize=0.85, shuffle=False)</span><br><span class="line">    train_data, train_label, test_data, test_label = load_data()</span><br><span class="line"></span><br><span class="line">    # 根据训练数据计算均值和标准差</span><br><span class="line">    mu = np.mean(train_data, axis=0)</span><br><span class="line">    std = np.std(train_data, axis=0)</span><br><span class="line"></span><br><span class="line">    # 标准化训练和测试数据</span><br><span class="line">    train_data = (train_data - mu) / std</span><br><span class="line">    test_data = (test_data - mu) / std</span><br><span class="line"></span><br><span class="line">    # 添加偏置值</span><br><span class="line">    train_data = np.insert(train_data, 0, np.ones(train_data.shape[0]), axis=1)</span><br><span class="line">    test_data = np.insert(test_data, 0, np.ones(test_data.shape[0]), axis=1)</span><br><span class="line"></span><br><span class="line">    # 定义步长、权重和偏置值</span><br><span class="line">    lr = 0.0001</span><br><span class="line">    w = init_weights(train_data.shape[1])</span><br><span class="line"></span><br><span class="line">    # 计算目标函数/损失函数以及梯度更新</span><br><span class="line">    epoches = 50000</span><br><span class="line">    batch_size = 128</span><br><span class="line">    num = train_label.shape[0]</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    loss = 0</span><br><span class="line">    best_accuracy = 0</span><br><span class="line">    best_w = None</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        loss = 0</span><br><span class="line">        train_num = 0</span><br><span class="line">        for j in range(0, num, batch_size):</span><br><span class="line">            loss += compute_loss(w, train_data[j:j + batch_size], train_label[j:j + batch_size], isBatch=True)</span><br><span class="line">            train_num += 1</span><br><span class="line">            # 计算梯度</span><br><span class="line">            gradient = compute_gradient(w, train_data[j:j + batch_size], train_label[j:j + batch_size], isBatch=True)</span><br><span class="line">            # 权重更新</span><br><span class="line">            tempW = w - lr * gradient</span><br><span class="line">            w = tempW</span><br><span class="line">        # 计算损失值</span><br><span class="line">        loss_list.append(loss / train_num)</span><br><span class="line"></span><br><span class="line">        # 计算精度</span><br><span class="line">        accuracy = compute_predict_accuracy(logistic_regression(w, train_data), train_label)</span><br><span class="line">        accuracy_list.append(accuracy)</span><br><span class="line"></span><br><span class="line">        if accuracy &gt; best_accuracy:</span><br><span class="line">            best_accuracy = accuracy</span><br><span class="line">            best_w = w.copy()</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练集检测精度&apos;)</span><br><span class="line">    print(&apos;train accuracy: %.3f&apos; % (max(accuracy_list)))</span><br><span class="line"></span><br><span class="line">    test_accuracy = compute_predict_accuracy(logistic_regression(best_w, test_data), test_label)</span><br><span class="line">    print(&apos;test accuracy: %.3f&apos; % (test_accuracy))</span><br></pre></td></tr></table></figure>
<p>训练和测试精度：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">train accuracy: 0.784</span><br><span class="line">test accuracy: 0.765</span><br></pre></td></tr></table></figure>
<p>训练损失图和精度图</p>
<p><img src="/imgs/从numpy到pytorch实现逻辑回归/numpy_loss.png" alt></p>
<p><img src="/imgs/从numpy到pytorch实现逻辑回归/numpy_accu.png" alt></p>
<h2 id="pytorch实现"><a href="#pytorch实现" class="headerlink" title="pytorch实现"></a><code>pytorch</code>实现</h2><p>获取数据，转换成<code>pytorch.Tensor</code>数据格式，并进行数据标准化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def load_data(tsize=0.8, shuffle=True):</span><br><span class="line">    data_list = pd.read_csv(data_path, header=None, sep=&apos;\s+&apos;)</span><br><span class="line"></span><br><span class="line">    data_array = data_list.values</span><br><span class="line">    height, width = data_array.shape[:2]</span><br><span class="line">    data_x = data_array[:, :(width - 1)]</span><br><span class="line">    data_y = data_array[:, (width - 1)]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    y_train = np.atleast_2d(np.array(list(map(lambda x: 1 if x == 2 else 0, y_train)))).T</span><br><span class="line">    y_test = np.atleast_2d(np.array(list(map(lambda x: 1 if x == 2 else 0, y_test)))).T</span><br><span class="line"></span><br><span class="line">    return torch.FloatTensor(x_train), torch.LongTensor(y_train), torch.FloatTensor(x_test), torch.LongTensor(y_test)</span><br><span class="line"></span><br><span class="line">train_data, train_label, test_data, test_label = load_data(tsize=0.8, shuffle=True)</span><br><span class="line"></span><br><span class="line"># 标准化数据</span><br><span class="line">mu = torch.mean(train_data)</span><br><span class="line">std = torch.std(train_data)</span><br><span class="line"></span><br><span class="line">train_data = (train_data - mu) / std</span><br><span class="line">test_data = (test_data - mu) / std</span><br></pre></td></tr></table></figure>
<p>使用<code>torch.utils.data.TensorDataSet</code>加载数据和标签，使用<code>torch.utils.data.DataLoader</code>进行数据分片和打乱</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">batch_size = 16</span><br><span class="line">data_ts = TensorDataset(train_data, train_label)</span><br><span class="line">data_loader = DataLoader(data_ts, batch_size=batch_size, shuffle=True)</span><br></pre></td></tr></table></figure>
<p>使用<code>torch.nn.Linear</code>进行线性运算，使用<code>torch.nn.Sigmoid</code>进行<code>sigmoid</code>运算</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">linear_model = nn.Linear(train_data.size()[1], 2)</span><br><span class="line">sigmoid_model = nn.Sigmoid()</span><br></pre></td></tr></table></figure>
<p>使用<code>torch.nn.CrossEntropyLoss</code>进行交叉熵损失计算，使用<code>torch.optim.SGD</code>进行小批量梯度下降</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(linear_model.parameters(), lr=0.01)</span><br></pre></td></tr></table></figure>
<p>完整代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from torch.utils.data import TensorDataset</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/german.data-numeric&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(tsize=0.8, shuffle=True):</span><br><span class="line">    data_list = pd.read_csv(data_path, header=None, sep=&apos;\s+&apos;)</span><br><span class="line"></span><br><span class="line">    data_array = data_list.values</span><br><span class="line">    height, width = data_array.shape[:2]</span><br><span class="line">    data_x = data_array[:, :(width - 1)]</span><br><span class="line">    data_y = data_array[:, (width - 1)]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    y_train = np.atleast_2d(np.array(list(map(lambda x: 1 if x == 2 else 0, y_train)))).T</span><br><span class="line">    y_test = np.atleast_2d(np.array(list(map(lambda x: 1 if x == 2 else 0, y_test)))).T</span><br><span class="line"></span><br><span class="line">    return torch.FloatTensor(x_train), torch.LongTensor(y_train), torch.FloatTensor(x_test), torch.LongTensor(y_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_predict_accuracy(predictions, y):</span><br><span class="line">    results = torch.max(predictions, 1)[1]</span><br><span class="line">    res = len(list(filter(lambda x: x[0] == x[1], torch.t(torch.stack((results, y.squeeze())))))) / len(results)</span><br><span class="line">    return res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(res_list):</span><br><span class="line">    plt.plot(res_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    train_data, train_label, test_data, test_label = load_data(tsize=0.8, shuffle=True)</span><br><span class="line"></span><br><span class="line">    # 标准化数据</span><br><span class="line">    mu = torch.mean(train_data)</span><br><span class="line">    std = torch.std(train_data)</span><br><span class="line"></span><br><span class="line">    train_data = (train_data - mu) / std</span><br><span class="line">    test_data = (test_data - mu) / std</span><br><span class="line"></span><br><span class="line">    batch_size = 128</span><br><span class="line">    data_ts = TensorDataset(train_data, train_label)</span><br><span class="line">    data_loader = DataLoader(data_ts, batch_size=batch_size, shuffle=True)</span><br><span class="line"></span><br><span class="line">    # 设计分类器</span><br><span class="line">    linear_model = nn.Linear(train_data.size()[1], 2)</span><br><span class="line">    sigmoid_model = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    # 损失函数</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    # 优化器</span><br><span class="line">    optimizer = optim.SGD(linear_model.parameters(), lr=0.00001)</span><br><span class="line"></span><br><span class="line">    epoches = 50000</span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    best_accuracy = 0</span><br><span class="line">    w = None</span><br><span class="line">    b = None</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        data = None</span><br><span class="line">        labels = None</span><br><span class="line">        outputs = None</span><br><span class="line">        for j, items in enumerate(data_loader, 0):</span><br><span class="line">            # 获取数据</span><br><span class="line">            data, labels = items</span><br><span class="line">            # 计算目标函数</span><br><span class="line">            outputs = sigmoid_model(linear_model(data))</span><br><span class="line">            # 计算损失值</span><br><span class="line">            loss = criterion(outputs, labels.squeeze().long())</span><br><span class="line">            # 保存损失值</span><br><span class="line">            loss_list.append(loss.item())</span><br><span class="line">            # 清空梯度</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            # 计算梯度</span><br><span class="line">            loss.backward()</span><br><span class="line">            # 更新梯度</span><br><span class="line">            optimizer.step()</span><br><span class="line">        # 计算精度</span><br><span class="line">        accuracy = compute_predict_accuracy(outputs, labels)</span><br><span class="line">        accuracy_list.append(accuracy)</span><br><span class="line">        if accuracy &gt;= best_accuracy:</span><br><span class="line">            w, b = linear_model.weight, linear_model.bias</span><br><span class="line">            best_accuracy = accuracy</span><br><span class="line"></span><br><span class="line">    draw(loss_list)</span><br><span class="line">    draw(accuracy_list)</span><br><span class="line">    print(&apos;train accuracy: %.3f&apos; % (max(accuracy_list)))</span><br><span class="line"></span><br><span class="line">    test_accuracy = compute_predict_accuracy(torch.sigmoid(torch.matmul(test_data, torch.t(w)) + b), test_label)</span><br><span class="line">    print(&apos;test accuracy: %.3f&apos; % (test_accuracy))</span><br></pre></td></tr></table></figure>
<p>训练和测试精度：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">train accuracy: 1.000</span><br><span class="line">test accuracy: 0.710</span><br></pre></td></tr></table></figure>
<p>训练损失图和精度图</p>
<p><img src="/imgs/从numpy到pytorch实现逻辑回归/pytorch_loss.png" alt></p>
<p><img src="/imgs/从numpy到pytorch实现逻辑回归/pytorch_accu.png" alt></p>
<h2 id="创建分类器类"><a href="#创建分类器类" class="headerlink" title="创建分类器类"></a>创建分类器类</h2><p>可以创建分类器类来进行前向操作和预测（逻辑回归操作中仅线性操作需要权重计算，所以前向操作中可以仅执行线性回归，在预测操作中执行完整操作）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class LrModule(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, input_size):</span><br><span class="line">        super(LrModule, self).__init__()</span><br><span class="line">        self.fc = nn.Linear(input_size, 2)</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        return F.sigmoid(self.fc(inputs))</span><br><span class="line"></span><br><span class="line">    def get_weights(self):</span><br><span class="line">        return self.fc.weight, self.fc.bias</span><br></pre></td></tr></table></figure>
<p>实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">    # 设计分类器</span><br><span class="line">    model = LrModule(train_data.size()[1])</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br><span class="line">        for j, items in enumerate(data_loader, 0):</span><br><span class="line">            # 获取数据</span><br><span class="line">            data, labels = items</span><br><span class="line">            # 计算目标函数</span><br><span class="line">            outputs = model.forward(data)</span><br><span class="line">            ...</span><br><span class="line">            ...</span><br><span class="line">        # 计算精度</span><br><span class="line">        accuracy = compute_predict_accuracy(outputs, labels)</span><br><span class="line">        accuracy_list.append(accuracy)</span><br><span class="line">        if accuracy &gt;= best_accuracy:</span><br><span class="line">            w, b = model.get_weights()</span><br><span class="line">            best_accuracy = accuracy</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>训练和测试精度：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">train accuracy: 0.969</span><br><span class="line">test accuracy: 0.720</span><br></pre></td></tr></table></figure>
<p>训练损失图和精度图</p>
<p><img src="/imgs/从numpy到pytorch实现逻辑回归/pytorch_loss_v2.png" alt></p>
<p><img src="/imgs/从numpy到pytorch实现逻辑回归/pytorch_accu_v2.png" alt></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><code>pytorch</code>使用到的类库如下所示</p>
<p><img src="/imgs/从numpy到pytorch实现逻辑回归/torch-class.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>sklearn</tag>
        <tag>pandas</tag>
        <tag>逻辑回归</tag>
      </tags>
  </entry>
  <entry>
    <title>逻辑回归</title>
    <url>/posts/9f2d3388.html</url>
    <content><![CDATA[<p>参考：</p><p>《机器学习基础 原理、算法与实践》第3章</p><p><a href="https://www.kaggle.com/emilyhorsman/basic-logistic-regression-with-numpy" target="_blank" rel="noopener">Basic Logistic Regression With NumPy</a></p><a id="more"></a>


<p><a href="https://www.kaggle.com/mtax687/logistic-regression-using-numpy" target="_blank" rel="noopener">Logistic Regression using Numpy</a></p>
<p>逻辑回归（<code>logistic regression</code>）是分类算法，常用于二元分类</p>
<h2 id="基本求导公式"><a href="#基本求导公式" class="headerlink" title="基本求导公式"></a>基本求导公式</h2><p>参考：<a href="https://baike.baidu.com/item/%E5%AF%BC%E6%95%B0%E8%A1%A8/10889755" target="_blank" rel="noopener">导数表</a></p>
<p>对数函数求导</p>
<script type="math/tex; mode=display">
y=log_{a}^{x} \Rightarrow {y}'=\frac{1}{xln(a)} \Rightarrow {ln(x)}'=\frac{1}{x}</script><p>幂函数求导</p>
<script type="math/tex; mode=display">
y=\frac{1}{x^{n}} \Rightarrow {y}'=-\frac{n}{x^{n+1}}</script><p>指数函数求导</p>
<script type="math/tex; mode=display">
y=n^x \Rightarrow {y}'=n^x \cdot ln(n) \Rightarrow {(e^x)}'=e^x</script><h2 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h2><p><code>sigmoid</code>函数简称为<code>S</code>型函数，也称为<code>logistic</code>函数，公式如下：</p>
<script type="math/tex; mode=display">
g(z)=\frac{1}{1+e^{-z}}</script><p><em>$e^{-z}$常写为$exp(-z)$</em>，求导如下</p>
<script type="math/tex; mode=display">
\frac{\varphi }{\varphi z}g(z)=\frac{-1}{(1+e^{-z})^2}\cdot {(e^{-z})}' = \frac{-e^{-z}}{(1+e^{-z})^2}\cdot {(-z)}' =  \frac{e^{-z}}{(1+e^{-z})^2}</script><script type="math/tex; mode=display">
=\frac{1}{1+e^{-z}}\cdot \frac{e^{-z}}{1+e^{-z}}
=\frac{1}{1+e^{-z}}\cdot (1-\frac{1}{1+e^{-z}})
=g(z)\cdot (1-g(z))</script><p>其实现特性如下：</p>
<ul>
<li>当输入值大于<code>0</code>时，输出趋近于<code>1</code></li>
<li>当输入值小于<code>0</code>时，输出趋近于<code>-1</code></li>
<li>当输入值等于<code>0</code>时，输出为<code>0.5</code></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def sigmoid(x):</span><br><span class="line">    return 1 / (1 + np.exp(-1 * x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw_sigmoid():</span><br><span class="line">    x = np.linspace(-10, 10)</span><br><span class="line">    y = sigmoid(np.array(x))</span><br><span class="line"></span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    draw_sigmoid()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/逻辑回归/sigmoid.png" alt></p>
<h2 id="负对数似然代价函数"><a href="#负对数似然代价函数" class="headerlink" title="负对数似然代价函数"></a>负对数似然代价函数</h2><p>负对数似然代价函数计算公式如下</p>
<script type="math/tex; mode=display">
cost(h(x;\theta),y)=\left\{\begin{matrix}
-ln(h(x;\theta)),y=1
\\ 
-ln(1-h(x;\theta)),y=0
\end{matrix}\right.</script><p>分两种情况</p>
<ol>
<li>判定计算结果是否为<code>1</code>。当计算结果为<code>1</code>时，代价为<code>0</code>，否则代价随$h(x;\theta)$减少而增大</li>
<li>判定计算结果是否为<code>0</code>。当计算结果为<code>0</code>时，代价为<code>0</code>，否则代价随$h(x;\theta)$增大而增大</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">def cost(x):</span><br><span class="line">    y1 = -1 * np.log(x)</span><br><span class="line">    y2 = -1 * np.log(1 - x)</span><br><span class="line">    return y1, y2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw_cost():</span><br><span class="line">    x = np.linspace(0, 1)</span><br><span class="line">    y1, y2 = cost(x)</span><br><span class="line"></span><br><span class="line">    plt.plot(x, y1)</span><br><span class="line">    plt.plot(x, y2)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    draw_cost()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/逻辑回归/cost.png" alt></p>
<h2 id="交叉熵损失函数"><a href="#交叉熵损失函数" class="headerlink" title="交叉熵损失函数"></a>交叉熵损失函数</h2><p>在二元分类中，结果<code>y</code>取值为<code>0</code>或<code>1</code>，将负对数似然代价函数的两种情况合并在一起得到交叉熵损失函数（<code>cross entropy loss function</code>）</p>
<script type="math/tex; mode=display">
loss(h(x;\theta),y)=-yln(h(x;\theta))-(1-y)ln(1-h(x;\theta))</script><h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><p>逻辑回归的实现就是线性回归加上<code>sigmoid</code>操作，其线性操作如下：</p>
<script type="math/tex; mode=display">
z_{\theta}(x)=\theta^T\cdot x=\theta_{0}\cdot x_{0}+\theta_{1}\cdot x_{1}+...+\theta_{n}\cdot x_{n}</script><p>逻辑回归模型实现公式如下：</p>
<script type="math/tex; mode=display">
h(x;\theta)=g(z_{\theta}(x))=g(\theta^T\cdot x)=\frac{1}{1+e^{-\theta^T\cdot x}}</script><p>对逻辑回归模型求导如下：</p>
<script type="math/tex; mode=display">
\frac{\varphi }{\varphi \theta_{i}}h(x;\theta)={h(\theta^T\cdot x)}'={g(\theta^T\cdot x)}'
=g(\theta^T\cdot x)\cdot (1-g(\theta^T\cdot x))\cdot {(\theta^T\cdot x)}'</script><script type="math/tex; mode=display">
=g(\theta^T\cdot x)\cdot (1-g(\theta^T\cdot x))\cdot x_{i}
=h(x;\theta)\cdot (1-h(x;\theta))\cdot x_{i}</script><p>逻辑回归利用<code>sigmoid</code>函数进行二元分类，首先对输入数据进行线性运算$\theta^T\cdot x$，再将结果输入<code>sigmoid</code>函数，压缩到$[0,1]$范围内，输出结果作为判别概率，表示输出结果为1的可能性，即$h(x;\theta)=P(y=1|x;\theta)$，相对应的输出结果为0的概率为$P(y=0|x;\theta)=1-h(x;\theta)$</p>
<p>逻辑回归利用交叉熵损失函数作为二元分类损失函数，公式如下：</p>
<script type="math/tex; mode=display">
J(\theta)=-\frac{1}{N}
\sum_{j=1}^{N}
\begin{bmatrix}
 y_{j}ln(h(x_{j};\theta))+(1-y_{j})ln(1-h(x_{j};\theta))
\end{bmatrix}</script><p>矩阵运算如下：</p>
<script type="math/tex; mode=display">
\Rightarrow 
J(\theta)=
-\frac{1}{N} (Y^T\cdot ln(g(X\cdot \theta))+(1-Y^T)\cdot ln(1-g(X\cdot \theta))</script><p>其中$X$大小为$m\times (n+1)$，$\theta$大小为$(n+1)\times 1$，$Y$大小为$m\times 1$，$m$表示样本数量，$n$表示权重数量</p>
<h2 id="测试数据"><a href="#测试数据" class="headerlink" title="测试数据"></a>测试数据</h2><p>使用<code>numeric</code>类型的德国信用数据，其包含<code>24</code>个变量和一个<code>2</code>类标签 - <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/" target="_blank" rel="noopener">german.data-numeric</a></p>
<h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>参考：<a href="https://www.cnblogs.com/zhongmiaozhimen/p/6155093.html" target="_blank" rel="noopener">第三周：逻辑回归代价函数求导过程</a></p>
<p>使用批量训练数据进行梯度计算，对损失函数求导如下：</p>
<script type="math/tex; mode=display">
\frac{\varphi }{\varphi \theta_{i}}J(\theta)=
-\frac{1}{N}
\sum_{j=1}^{N}
\begin{bmatrix}
 y_{j}ln(h(x_{j};\theta))+(1-y_{j})ln(1-h(x_{j};\theta))
\end{bmatrix}'</script><script type="math/tex; mode=display">
=-\frac{1}{N}
\sum_{j=1}^{N}
\begin{bmatrix}
 y_{j}\frac{1}{h(x_{j};\theta)}\cdot {h(\theta^T\cdot x)}'+(1-y_{j})\frac{1}{1-h(x_{j};\theta)}\cdot {(1-h(\theta^T\cdot x))}'
\end{bmatrix}</script><script type="math/tex; mode=display">
=-\frac{1}{N}
\sum_{j=1}^{N}
\begin{bmatrix}
 y_{j}\frac{1}{h(x_{j};\theta)}\cdot h(x_{j};\theta)\cdot (1-h(x_{j};\theta))\cdot x_{j,i}+(1-y_{j})\frac{1}{1-h(x_{j};\theta)}\cdot -h(x_{j};\theta)\cdot (1-h(x_{j};\theta))\cdot x_{j,i}
 \end{bmatrix}</script><script type="math/tex; mode=display">
=-\frac{1}{N}
\sum_{j=1}^{N}
\begin{bmatrix}
 y_{j}\cdot (1-h(x_{j};\theta))\cdot x_{j,i} - (1-y_{j})\cdot h(x_{j};\theta)\cdot x_{j,i}
 \end{bmatrix}</script><script type="math/tex; mode=display">
=-\frac{1}{N}
\sum_{j=1}^{N}
\begin{bmatrix}
 y_{j}\cdot x_{j,i} -  h(x_{j};\theta)\cdot x_{j,i}
 \end{bmatrix}
=\frac{1}{N}
\sum_{j=1}^{N}
\begin{bmatrix}
 (h(x_{j};\theta)-y_{j})\cdot x_{j,i}
 \end{bmatrix}</script><p>其中$x_{j,i}$表示第$j$行第$i$列，矩阵运算如下：</p>
<script type="math/tex; mode=display">
\Rightarrow 
\frac{\varphi }{\varphi \theta}J(\theta)=
\frac{1}{N} X^T\cdot (g(X\cdot \theta)-Y)</script><p>其中$X$大小为$m\times (n+1)$，$\theta$大小为$(n+1)\times 1$，$Y$大小为$m\times 1$，$m$表示样本数量，$n$表示权重数量</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-4-18 上午9:22</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">data_path = &apos;../data/german.data-numeric&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data(tsize=0.8, shuffle=True):</span><br><span class="line">    data_list = pd.read_csv(data_path, header=None, sep=&apos;\s+&apos;)</span><br><span class="line"></span><br><span class="line">    data_array = data_list.values</span><br><span class="line">    height, width = data_array.shape[:2]</span><br><span class="line">    data_x = data_array[:, :(width - 1)]</span><br><span class="line">    data_y = data_array[:, (width - 1)]</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, train_size=tsize, test_size=(1 - tsize),</span><br><span class="line">                                                        shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    y_train = np.atleast_2d(np.array(list(map(lambda x: 1 if x == 2 else 0, y_train)))).T</span><br><span class="line">    y_test = np.atleast_2d(np.array(list(map(lambda x: 1 if x == 2 else 0, y_test)))).T</span><br><span class="line"></span><br><span class="line">    return x_train, y_train, x_test, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def init_weights(inputs):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    初始化权重，符合标准正态分布</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return np.atleast_2d(np.random.uniform(size=inputs)).T</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def sigmoid(x):</span><br><span class="line">    return 1 / (1 + np.exp(-1 * x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def logistic_regression(w, x):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    w大小为(n+1)x1</span><br><span class="line">    x大小为mx(n+1)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    z = x.dot(w)</span><br><span class="line">    return sigmoid(z)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_loss(w, x, y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    w大小为(n+1)x1</span><br><span class="line">    x大小为mx(n+1)</span><br><span class="line">    y大小为mx1</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    lr_value = logistic_regression(w, x)</span><br><span class="line">    n = y.shape[0]</span><br><span class="line">    res = -1.0 / n * (y.T.dot(np.log(lr_value)) + (1 - y.T).dot(np.log(1 - lr_value)))</span><br><span class="line">    return res[0][0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient(w, x, y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    梯度计算</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    n = y.shape[0]</span><br><span class="line">    lr_value = logistic_regression(w, x)</span><br><span class="line">    return 1.0 / n * x.T.dot(lr_value - y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_predict_accuracy(predictions, y):</span><br><span class="line">    results = predictions &gt; 0.5</span><br><span class="line">    res = len(list(filter(lambda x: x[0] == x[1], np.dstack((results, y))[:, 0]))) / len(results)</span><br><span class="line">    return res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw(res_list, title=None, xlabel=None, ylabel=None):</span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    if xlabel is not None:</span><br><span class="line">        plt.xlabel(xlabel)</span><br><span class="line">    plt.plot(res_list)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # 加载训练和测试数据</span><br><span class="line">    # train_data, train_label, test_data, test_label = load_german_numeric(tsize=0.85, shuffle=False)</span><br><span class="line">    train_data, train_label, test_data, test_label = load_data()</span><br><span class="line"></span><br><span class="line">    # 根据训练数据计算均值和标准差</span><br><span class="line">    mu = np.mean(train_data, axis=0)</span><br><span class="line">    std = np.std(train_data, axis=0)</span><br><span class="line"></span><br><span class="line">    # 标准化训练和测试数据</span><br><span class="line">    train_data = (train_data - mu) / std</span><br><span class="line">    test_data = (test_data - mu) / std</span><br><span class="line"></span><br><span class="line">    # 添加偏置值</span><br><span class="line">    train_data = np.insert(train_data, 0, np.ones(train_data.shape[0]), axis=1)</span><br><span class="line">    test_data = np.insert(test_data, 0, np.ones(test_data.shape[0]), axis=1)</span><br><span class="line"></span><br><span class="line">    # 定义步长、权重和偏置值</span><br><span class="line">    lr = 0.01</span><br><span class="line">    w = init_weights(train_data.shape[1])</span><br><span class="line"></span><br><span class="line">    # 计算目标函数/损失函数以及梯度更新</span><br><span class="line">    epoches = 20000</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    loss = 0</span><br><span class="line">    best_accuracy = 0</span><br><span class="line">    best_w = None</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        loss += compute_loss(w, train_data, train_label)</span><br><span class="line">        # 计算梯度</span><br><span class="line">        gradient = compute_gradient(w, train_data, train_label)</span><br><span class="line">        # 权重更新</span><br><span class="line">        tempW = w - lr * gradient</span><br><span class="line">        w = tempW</span><br><span class="line"></span><br><span class="line">        if i % 50 == 49:</span><br><span class="line">            # 每个50次记录一次</span><br><span class="line">            # 计算精度</span><br><span class="line">            accuracy = compute_predict_accuracy(logistic_regression(w, train_data), train_label)</span><br><span class="line">            accuracy_list.append(accuracy)</span><br><span class="line"></span><br><span class="line">            if accuracy &gt; best_accuracy:</span><br><span class="line">                best_accuracy = accuracy</span><br><span class="line">                best_w = w.copy()</span><br><span class="line">            # 计算损失</span><br><span class="line">            loss_list.append(loss / 50)</span><br><span class="line">            loss = 0</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值/50&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练集检测精度/50&apos;)</span><br><span class="line">    print(max(accuracy_list))</span><br><span class="line">    print(compute_predict_accuracy(logistic_regression(best_w, test_data), test_label))</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/逻辑回归/lr_batch_loss.png" alt></p>
<p><img src="/imgs/逻辑回归/lr_batch_accu.png" alt></p>
<p>随机梯度下降实现如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&apos;ignore&apos;)</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">def compute_loss(w, x, y, isBatch=True):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    w大小为(n+1)x1</span><br><span class="line">    x大小为mx(n+1)</span><br><span class="line">    y大小为mx1</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    lr_value = logistic_regression(w, x)</span><br><span class="line">    if isBatch:</span><br><span class="line">        n = y.shape[0]</span><br><span class="line">        res = -1.0 / n * (y.T.dot(np.log(lr_value)) + (1 - y.T).dot(np.log(1 - lr_value)))</span><br><span class="line">        return res[0][0]</span><br><span class="line">    else:</span><br><span class="line">        res = -1.0 * (y * (np.log(lr_value)) + (1 - y) * (np.log(1 - lr_value)))</span><br><span class="line">        return res[0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_gradient(w, x, y, isBatch=True):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    梯度计算</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    lr_value = logistic_regression(w, x)</span><br><span class="line">    if isBatch:</span><br><span class="line">        n = y.shape[0]</span><br><span class="line">        return 1.0 / n * x.T.dot(lr_value - y)</span><br><span class="line">    else:</span><br><span class="line">        return np.atleast_2d(1.0 * x.T * (lr_value - y)).T</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br><span class="line">    # 计算目标函数/损失函数以及梯度更新</span><br><span class="line">    epoches = 20</span><br><span class="line">    num = train_label.shape[0]</span><br><span class="line"></span><br><span class="line">    loss_list = []</span><br><span class="line">    accuracy_list = []</span><br><span class="line">    loss = 0</span><br><span class="line">    best_accuracy = 0</span><br><span class="line">    best_w = None</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j in range(num):</span><br><span class="line">            loss += compute_loss(w, train_data[j], train_label[j], isBatch=False)</span><br><span class="line">            # 计算梯度</span><br><span class="line">            gradient = compute_gradient(w, train_data[j], train_label[j], isBatch=False)</span><br><span class="line">            # 权重更新</span><br><span class="line">            tempW = w - lr * gradient</span><br><span class="line">            w = tempW</span><br><span class="line"></span><br><span class="line">            if j % 50 == 49:</span><br><span class="line">                # 每个50次记录一次</span><br><span class="line">                # 计算精度</span><br><span class="line">                accuracy = compute_predict_accuracy(logistic_regression(w, train_data), train_label)</span><br><span class="line">                accuracy_list.append(accuracy)</span><br><span class="line"></span><br><span class="line">                if accuracy &gt; best_accuracy:</span><br><span class="line">                    best_accuracy = accuracy</span><br><span class="line">                    best_w = w.copy()</span><br><span class="line">                # 计算损失</span><br><span class="line">                loss_list.append(loss / 50)</span><br><span class="line">                loss = 0</span><br><span class="line"></span><br><span class="line">    draw(loss_list, title=&apos;损失值/50&apos;)</span><br><span class="line">    draw(accuracy_list, title=&apos;训练集检测精度/50&apos;)</span><br><span class="line">    print(max(accuracy_list))</span><br><span class="line">    print(compute_predict_accuracy(logistic_regression(best_w, test_data), test_label))</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/逻辑回归/lr_stochastic_loss.png" alt></p>
<p><img src="/imgs/逻辑回归/lr_stochastic_accu.png" alt></p>
<p>小批量梯度下降结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 计算目标函数/损失函数以及梯度更新</span><br><span class="line">epoches = 200</span><br><span class="line">batch_size = 128</span><br><span class="line">num = train_label.shape[0]</span><br><span class="line"></span><br><span class="line">loss_list = []</span><br><span class="line">accuracy_list = []</span><br><span class="line">loss = 0</span><br><span class="line">best_accuracy = 0</span><br><span class="line">best_w = None</span><br><span class="line">for i in range(epoches):</span><br><span class="line">    for j in range(0, num, 16):</span><br><span class="line">        loss_list.append(compute_loss(w, train_data[j:j + batch_size], train_label[j:j + batch_size], isBatch=True))</span><br><span class="line">        # 计算梯度</span><br><span class="line">        gradient = compute_gradient(w, train_data[j:j + batch_size], train_label[j:j + batch_size], isBatch=True)</span><br><span class="line">        # 权重更新</span><br><span class="line">        tempW = w - lr * gradient</span><br><span class="line">        w = tempW</span><br><span class="line"></span><br><span class="line">        # 每个小批次记录一次</span><br><span class="line">        # 计算精度</span><br><span class="line">        accuracy = compute_predict_accuracy(logistic_regression(w, train_data), train_label)</span><br><span class="line">        accuracy_list.append(accuracy)</span><br><span class="line"></span><br><span class="line">        if accuracy &gt; best_accuracy:</span><br><span class="line">            best_accuracy = accuracy</span><br><span class="line">            best_w = w.copy()</span><br><span class="line"></span><br><span class="line">draw(loss_list, title=&apos;损失值&apos;)</span><br><span class="line">draw(accuracy_list, title=&apos;训练集检测精度&apos;)</span><br><span class="line">print(max(accuracy_list))</span><br><span class="line">print(compute_predict_accuracy(logistic_regression(best_w, test_data), test_label))</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/逻辑回归/lr_small_loss.png" alt></p>
<p><img src="/imgs/逻辑回归/lr_small_accu.png" alt></p>
<h3 id="RuntimeWarning-divide-by-zero-encountered-in-log"><a href="#RuntimeWarning-divide-by-zero-encountered-in-log" class="headerlink" title="RuntimeWarning: divide by zero encountered in log"></a>RuntimeWarning: divide by zero encountered in log</h3><p>计算损失过程中可能会出现精度错误：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data_loss = -1.0 / num_train * np.sum(y_batch * np.log(scores) + (1 - y_batch) * np.log(1 - scores))</span><br></pre></td></tr></table></figure>
<p>修改如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">eplison = 1e-5</span><br><span class="line"></span><br><span class="line">scores = self.logistic_regression(X_batch)</span><br><span class="line">data_loss = -1.0 / num_train * np.sum(y_batch * np.log(np.maximum(scores, eplison)) + (1 - y_batch) * np.log(np.maximum(1 - scores, eplison)))</span><br></pre></td></tr></table></figure>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>逻辑回归二元分类需要注意：</p>
<ol>
<li>标签值的转换（将两类标签转换成<code>0/1</code>数值）</li>
<li>预测值的计算（计算单个预测值就能判断类别）</li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>数学</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>微积分</tag>
        <tag>逻辑回归</tag>
      </tags>
  </entry>
  <entry>
    <title>从numpy到pytorch实现线性回归</title>
    <url>/posts/ca2079f0.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://medium.com/jovian-io/linear-regression-with-pytorch-3dde91d60b50" target="_blank" rel="noopener">Linear Regression and Gradient Descent from scratch in PyTorch</a></p><a id="more"></a>

<p><a href="https://www.jiqizhixin.com/articles/2019-03-15-5" target="_blank" rel="noopener">PyTorch进阶之路（二）：如何实现线性回归</a></p>
<p><a href="https://www.zhujian.tech/posts/ec419bd2.html#more">线性回归</a></p>
<p><a href="https://www.zhujian.tech/posts/dea583b1.html#more">特征缩放</a></p>
<p>首先利用<code>numpy</code>实现梯度下降解决多变量线性回归问题，然后逐步将操作转换成<code>pytorch</code></p>
<p>实现步骤如下：</p>
<ol>
<li>加载训练数据</li>
<li>初始化权重</li>
<li>计算预测结果</li>
<li>计算损失函数</li>
<li>梯度更新</li>
<li>重复<code>3-5</code>步，直到完成迭代次数</li>
<li>绘制损失图</li>
</ol>
<p>多变量线性回归测试数据参考<a href="https://github.com/peedeep/Coursera/blob/master/ex1/ex1data2.txt" target="_blank" rel="noopener">ex1data2.txt</a></p>
<h2 id="numpy实现随机梯度下降"><a href="#numpy实现随机梯度下降" class="headerlink" title="numpy实现随机梯度下降"></a><code>numpy</code>实现随机梯度下降</h2><p>参考：<a href="https://www.zhujian.tech/posts/3c50d4b7.html#more">梯度下降</a></p>
<p><strong>随机梯度下降</strong>实现如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">梯度下降法计算线性回归问题</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_ex1_multi_data():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载多变量数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    path = &apos;../data/coursera2.txt&apos;</span><br><span class="line">    datas = []</span><br><span class="line">    with open(path, &apos;r&apos;) as f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">        for line in lines:</span><br><span class="line">            datas.append(line.strip().split(&apos;,&apos;))</span><br><span class="line">    data_arr = np.array(datas)</span><br><span class="line">    data_arr = data_arr.astype(np.float)</span><br><span class="line"></span><br><span class="line">    X = data_arr[:, :2]</span><br><span class="line">    Y = data_arr[:, 2]</span><br><span class="line">    return X, Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw_loss(loss_list):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    绘制损失函数值</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    plt.plot(loss_list)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def init_weight(size):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    初始化权重，使用均值为0,方差为1的标准正态分布</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return np.random.normal(loc=0.0, scale=1.0, size=size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_loss(w, x, y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算损失值</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    n = y.shape[0]</span><br><span class="line">    return (x.dot(w) - y).T.dot(x.dot(w) - y) / n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def using_stochastic_gradient_descent():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    随机梯度下降</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x, y = load_ex1_multi_data()</span><br><span class="line">    extend_x = np.insert(x, 0, values=np.ones(x.shape[0]), axis=1)</span><br><span class="line">    w = init_weight(extend_x.shape[1])</span><br><span class="line">    # print(w)</span><br><span class="line">    print(w.shape)</span><br><span class="line"></span><br><span class="line">    # 打乱数据</span><br><span class="line">    np.random.shuffle(extend_x)</span><br><span class="line">    print(extend_x.shape)</span><br><span class="line">    print(y.shape)</span><br><span class="line"></span><br><span class="line">    n = y.shape[0]</span><br><span class="line">    epoches = 10</span><br><span class="line">    alpha = 1e-8</span><br><span class="line">    loss_list = []</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j in range(n):</span><br><span class="line">            temp = w - alpha * (extend_x[j].dot(w) - y[j]) * extend_x[j].T / 2</span><br><span class="line">            w = temp</span><br><span class="line">            loss_list.append(compute_loss(w, extend_x, y))</span><br><span class="line">    draw_loss(loss_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    using_stochastic_gradient_descent()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/从numpy到pytorch实现线性回归/numpy_sgd.png" alt></p>
<h2 id="pytorch实现批量梯度下降"><a href="#pytorch实现批量梯度下降" class="headerlink" title="pytorch实现批量梯度下降"></a><code>pytorch</code>实现批量梯度下降</h2><p><code>pytorch</code>使用<code>tensor</code>作为数据保存结构，使用函数<code>from_numpy</code>可以将<code>numpy array</code>数组转换成<code>tensor</code>类型</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">torch.from_numpy(X), torch.from_numpy(Y)</span><br></pre></td></tr></table></figure>
<p>使用<code>torch.randn</code>可以生成符合标准正态分布的随机数组，用于生成权重和偏置值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">torch.randn(h, 1, requires_grad=True, dtype=torch.double), torch.randn(1, requires_grad=True,                                                                                  dtype=torch.double)</span><br></pre></td></tr></table></figure>
<p><code>pytorch</code>内置了<code>autograd</code>包，计算预测结果和损失函数后，调用函数<code>backward()</code>就能够自动计算出梯度</p>
<p>首先需要开启权重和偏置值的梯度开关，然后在调用函数后进行梯度更新</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">with torch.no_grad():</span><br><span class="line">      w -= w.grad * lr</span><br><span class="line">      b -= b.grad * lr</span><br><span class="line">      w.grad.zero_()</span><br><span class="line">      b.grad.zero_()</span><br></pre></td></tr></table></figure>
<p>使用<code>torch.no_grad</code>能够保证梯度更新过程中不再计算梯度值，计算完成后需要将梯度归零，避免下次叠加</p>
<p>使用<code>pytorch</code>实现<strong>批量梯度下降</strong>计算多变量线性回归问题</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">梯度下降法计算线性回归问题</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_ex1_multi_data():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载多变量数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    path = &apos;../data/coursera2.txt&apos;</span><br><span class="line">    datas = []</span><br><span class="line">    with open(path, &apos;r&apos;) as f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">        for line in lines:</span><br><span class="line">            datas.append(line.strip().split(&apos;,&apos;))</span><br><span class="line">    data_arr = np.array(datas)</span><br><span class="line">    data_arr = data_arr.astype(np.float)</span><br><span class="line"></span><br><span class="line">    X = data_arr[:, :2]</span><br><span class="line">    Y = data_arr[:, 2]</span><br><span class="line"></span><br><span class="line">    return torch.from_numpy(X), torch.from_numpy(Y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def init_weight(h):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    初始化权重，使用均值为0,方差为1的标准正态分布</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return torch.randn(h, 1, requires_grad=True, dtype=torch.double), torch.randn(1, requires_grad=True,</span><br><span class="line">                                                                                  dtype=torch.double)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def predict_result(w, b, x):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    预测结果</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return x.mm(w) + b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_loss(w, b, x, y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算损失值 MSE</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    diff = y - predict_result(w, b, x)</span><br><span class="line">    return torch.sum(diff * diff) / diff.numel()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw_loss(loss_list):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    绘制损失函数值</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    plt.plot(loss_list)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def using_batch_gradient_descent():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    批量梯度下降</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x, y = load_ex1_multi_data()</span><br><span class="line">    w, b = init_weight(x.shape[1])</span><br><span class="line"></span><br><span class="line">    epoches = 20</span><br><span class="line">    lr = 1e-7</span><br><span class="line">    loss_list = []</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        # 计算损失值</span><br><span class="line">        loss = compute_loss(w, b, x, y)</span><br><span class="line">        # 保存损失值</span><br><span class="line">        loss_list.append(loss)</span><br><span class="line">        # 反向更新</span><br><span class="line">        loss.backward()</span><br><span class="line">        # 梯度更新</span><br><span class="line">        with torch.no_grad():</span><br><span class="line">            w -= w.grad * lr</span><br><span class="line">            b -= b.grad * lr</span><br><span class="line">            w.grad.zero_()</span><br><span class="line">            b.grad.zero_()</span><br><span class="line">    draw_loss(loss_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    using_batch_gradient_descent()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/从numpy到pytorch实现线性回归/pytorch_batch.png" alt></p>
<h2 id="pytorch实现随机梯度下降"><a href="#pytorch实现随机梯度下降" class="headerlink" title="pytorch实现随机梯度下降"></a><code>pytorch</code>实现随机梯度下降</h2><p><code>pytorch</code>提供了许多类和函数用于计算，下面实现<strong>随机梯度下降</strong>解决多变量线性回归</p>
<p>首先在<code>numpy</code>数组转换成<code>pytorch tensor</code>类型前先打乱数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 打乱数据</span><br><span class="line">indexs = np.arange(X.shape[0])</span><br><span class="line">np.random.shuffle(indexs)</span><br><span class="line">X = X[indexs]</span><br><span class="line">Y = Y[indexs]</span><br></pre></td></tr></table></figure>
<p><code>pytorch.nn</code>包提供了类<code>Linear</code>用于线性计算</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 定义线性模型</span><br><span class="line">model = nn.Linear(x.size()[1], 1)</span><br><span class="line"># 获取初始权重和偏置值</span><br><span class="line">w = model.weight</span><br><span class="line">b = model.bias</span><br><span class="line"># 计算预测结果，计算损失值</span><br><span class="line">diff = y - model(x)</span><br></pre></td></tr></table></figure>
<p><code>pytorch.nn.function</code>包提供了函数<code>mse_loss</code>用于计算均方误差</p>
<p>也可以使用包装类<code>nn.MSELoss</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 损失函数</span><br><span class="line">loss_fn = F.mse_loss</span><br><span class="line"># 计算损失值</span><br><span class="line">loss = loss_fn(model(x), y)</span><br><span class="line"># 或者</span><br><span class="line"># 损失函数</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"># 计算损失值</span><br><span class="line">loss = criterion(model(x), y)</span><br></pre></td></tr></table></figure>
<p><code>pytorch.optim</code>提供了类<code>SGD</code>用于计算随机梯度下降</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 定义优化器</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=2e-7, momentum=0.9)</span><br><span class="line"># 清空梯度</span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"># 计算梯度</span><br><span class="line">loss.backward()</span><br><span class="line"># 更新</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure>
<p>实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">梯度下降法计算线性回归问题</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import torch.optim as optim</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_ex1_multi_data():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载多变量数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    path = &apos;../data/coursera2.txt&apos;</span><br><span class="line">    datas = []</span><br><span class="line">    with open(path, &apos;r&apos;) as f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">        for line in lines:</span><br><span class="line">            datas.append(line.strip().split(&apos;,&apos;))</span><br><span class="line">    data_arr = np.array(datas)</span><br><span class="line">    data_arr = data_arr.astype(np.float)</span><br><span class="line"></span><br><span class="line">    X = data_arr[:, :2]</span><br><span class="line">    Y = data_arr[:, 2]</span><br><span class="line">    </span><br><span class="line">    # 打乱数据</span><br><span class="line">    indexs = np.arange(X.shape[0])</span><br><span class="line">    np.random.shuffle(indexs)</span><br><span class="line">    X = X[indexs]</span><br><span class="line">    Y = Y[indexs]</span><br><span class="line"></span><br><span class="line">    return torch.from_numpy(X).float(), torch.from_numpy(Y).float()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw_loss(loss_list):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    绘制损失函数值</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    plt.plot(loss_list)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def using_stochastic_gradient_descent():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    随机梯度下降</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x, y = load_ex1_multi_data()</span><br><span class="line"></span><br><span class="line">    # 定义线性模型</span><br><span class="line">    model = nn.Linear(x.size()[1], 1)</span><br><span class="line">    # 获取初始权重和偏置值</span><br><span class="line">    w = model.weight</span><br><span class="line">    b = model.bias</span><br><span class="line"></span><br><span class="line">    # 损失函数</span><br><span class="line">    criterion = nn.MSELoss()</span><br><span class="line">    # 定义优化器</span><br><span class="line">    optimizer = optim.SGD(model.parameters(), lr=1e-10, momentum=0.9)</span><br><span class="line"></span><br><span class="line">    epoches = 10</span><br><span class="line">    loss_list = []</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j, item in enumerate(x, 0):</span><br><span class="line">            # 计算损失值</span><br><span class="line">            loss = criterion(model(item), y[j])</span><br><span class="line">            # 清空梯度</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            # 计算梯度</span><br><span class="line">            loss.backward()</span><br><span class="line">            # 更新</span><br><span class="line">            optimizer.step()</span><br><span class="line">            # 保存损失值</span><br><span class="line">            loss_list.append(loss)</span><br><span class="line">    draw_loss(loss_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    using_stochastic_gradient_descent()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/从numpy到pytorch实现线性回归/pytorch_stochastic.png" alt></p>
<h2 id="pytorch实现小批量梯度下降"><a href="#pytorch实现小批量梯度下降" class="headerlink" title="pytorch实现小批量梯度下降"></a><code>pytorch</code>实现小批量梯度下降</h2><p>实际训练过程中最常使用的梯度下降方法是小批量梯度下降，</p>
<p><code>pytorch</code>提供了类<code>torch.utils.data.TensorDataset</code>以及<code>torch.utils.data.DataLoader</code>来实现数据的加载、打乱和批量化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">batch_size = 8</span><br><span class="line">data_ts = TensorDataset(x, y)</span><br><span class="line">data_loader = DataLoader(data_ts, batch_size=batch_size, shuffle=True)</span><br><span class="line">for j, item in enumerate(data_loader, 0):</span><br><span class="line">    inputs, targets = item</span><br><span class="line">    # 计算损失值</span><br><span class="line">    loss = criterion(model(inputs), targets)</span><br></pre></td></tr></table></figure>
<p>实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">梯度下降法计算线性回归问题</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from torch.utils.data import TensorDataset</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_ex1_multi_data():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载多变量数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    path = &apos;../data/coursera2.txt&apos;</span><br><span class="line">    datas = []</span><br><span class="line">    with open(path, &apos;r&apos;) as f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">        for line in lines:</span><br><span class="line">            datas.append(line.strip().split(&apos;,&apos;))</span><br><span class="line">    data_arr = np.array(datas)</span><br><span class="line">    data_arr = data_arr.astype(np.float)</span><br><span class="line"></span><br><span class="line">    X = data_arr[:, :2]</span><br><span class="line">    Y = data_arr[:, 2]</span><br><span class="line"></span><br><span class="line">    return torch.from_numpy(X).float(), torch.from_numpy(Y).float()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw_loss(loss_list):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    绘制损失函数值</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    plt.plot(loss_list)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def using_small_batch_gradient_descent():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    小批量梯度下降</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x, y = load_ex1_multi_data()</span><br><span class="line"></span><br><span class="line">    batch_size = 8</span><br><span class="line">    data_ts = TensorDataset(x, y)</span><br><span class="line">    data_loader = DataLoader(data_ts, batch_size=batch_size, shuffle=True)</span><br><span class="line"></span><br><span class="line">    # 定义线性模型</span><br><span class="line">    model = nn.Linear(x.size()[1], 1)</span><br><span class="line">    # 获取初始权重和偏置值</span><br><span class="line">    w = model.weight</span><br><span class="line">    b = model.bias</span><br><span class="line"></span><br><span class="line">    # 损失函数</span><br><span class="line">    criterion = nn.MSELoss()</span><br><span class="line">    # 定义优化器</span><br><span class="line">    optimizer = optim.SGD(model.parameters(), lr=1e-10, momentum=0.9)</span><br><span class="line"></span><br><span class="line">    epoches = 200</span><br><span class="line">    loss_list = []</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j, item in enumerate(data_loader, 0):</span><br><span class="line">            # print(item)</span><br><span class="line">            inputs, targets = item</span><br><span class="line">            # 计算损失值</span><br><span class="line">            loss = criterion(model(inputs), targets)</span><br><span class="line">            # 清空梯度</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            # 计算梯度</span><br><span class="line">            loss.backward()</span><br><span class="line">            # 更新</span><br><span class="line">            optimizer.step()</span><br><span class="line">            # 保存损失值</span><br><span class="line">            loss_list.append(loss)</span><br><span class="line">    draw_loss(loss_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    using_small_batch_gradient_descent()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/从numpy到pytorch实现线性回归/pytorch_small_batch.png" alt></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><code>pytorch</code>使用到的类库如下所示</p>
<p><img src="/imgs/从numpy到pytorch实现线性回归/torch-class.png" alt></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title>梯度下降</title>
    <url>/posts/3c50d4b7.html</url>
    <content><![CDATA[<p>参考：<a href="https://www.zhihu.com/topic/19650497/hot" target="_blank" rel="noopener">梯度下降</a></p><p>梯度下降是求解函数最小值的算法，也称为最速下降法，它通过梯度更新不断的逼近最优解</p><p>常用的比喻是下山问题，通过计算梯度能够找到函数值变化最快的地方，通过步长决定收敛的速度</p><a id="more"></a>


<p>梯度下降方法包括批量梯度下降、随机梯度下降和小批量梯度下降，下面通过梯度下降计算多变量线性回归问题</p>
<h2 id="多变量线性回归"><a href="#多变量线性回归" class="headerlink" title="多变量线性回归"></a>多变量线性回归</h2><p>参考<a href="https://www.zhujian.tech/posts/ec419bd2.html#more">线性回归</a></p>
<script type="math/tex; mode=display">
Y=X\cdot W</script><p>其中</p>
<script type="math/tex; mode=display">
Y_{m\times 1}=\begin{bmatrix}
y_{1}\\ 
y_{2}\\ 
...\\ 
y_{m}
\end{bmatrix}</script><script type="math/tex; mode=display">
X_{m\times (n+1)}=\begin{bmatrix}
x_{10} & x_{11} & ... & x_{1n}\\ 
x_{20} & x_{21} & ... & x_{2n}\\ 
... & ... & ... & ...\\ 
x_{m0} & x_{m1} & ... & x_{mn}
\end{bmatrix}
=\begin{bmatrix}
1 & x_{11} & ... & x_{1n}\\ 
1 & x_{21} & ... & x_{2n}\\ 
... & ... & ... & ...\\ 
1 & x_{m1} & ... & x_{mn}
\end{bmatrix}</script><script type="math/tex; mode=display">
W_{(n+1)\times 1}=
\begin{bmatrix}
w_{0} \\ w_{1} \\ ... \\ w_{n}
\end{bmatrix}</script><h2 id="多变量测试数据"><a href="#多变量测试数据" class="headerlink" title="多变量测试数据"></a>多变量测试数据</h2><p>使用<code>UCI</code>提供的计算机硬件数据集<a href="http://archive.ics.uci.edu/ml/datasets/Computer+Hardware" target="_blank" rel="noopener">machine-data</a>，其包含<code>10</code>类数据</p>
<ol>
<li>vendor name: 厂商名</li>
<li>Model Name: 型号名</li>
<li>MYCT: 机器周期(/ns)</li>
<li>MMIN: 主存最小值(/KB)</li>
<li>MMAX: 主存最大值(/KB)</li>
<li>CACH: 缓存大小(/KB)</li>
<li>CHMIN: 通道最小值</li>
<li>CHMAX: 通道最大值</li>
<li>PRP: 相对性能</li>
<li>ERP: cpu相对性能 </li>
</ol>
<p>使用第<code>3-8</code>项作为训练数据，使用第<code>9</code>项作为真实数据进行训练</p>
<h2 id="批量梯度下降"><a href="#批量梯度下降" class="headerlink" title="批量梯度下降"></a>批量梯度下降</h2><p>批量梯度下降(<code>batch gradient descent</code>)每次迭代将所有样本数据都加入计算，其损失函数<code>MSE</code>如下：</p>
<script type="math/tex; mode=display">
J(\theta) = \frac{1}{N}\cdot \sum_{j=1}^{N}(h(x_{j};\theta)-y_{j})^{2}</script><script type="math/tex; mode=display">
\Rightarrow J(\theta) = \frac{1}{N} (X\cdot W-Y)^T\cdot(X\cdot W -Y)</script><p>批量求导如下</p>
<script type="math/tex; mode=display">
\frac{\varphi }{\varphi w_{i}}J(\theta) = \frac{1}{N} \sum_{j=1}^{N}(h(x_{j};\theta)-y_{j})\cdot x_{j,i})</script><script type="math/tex; mode=display">
\Rightarrow \frac{\varphi }{\varphi w_{i}}J(\theta) = \frac{1}{N} X[i]^T\cdot (X\cdot W - Y)</script><script type="math/tex; mode=display">
\Rightarrow \frac{\varphi }{\varphi w}J(\theta) = \frac{1}{N} X^T\cdot (X\cdot W - Y)</script><p>其中$x_{j,i}$表示第$j$行第$i$列，$X[i]$表示第$i$列</p>
<h2 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h2><p>随机梯度下降(<code>stochastic gradient descent</code>)每次更新仅使用一条数据，其损失函数<code>MSE</code>如下：</p>
<script type="math/tex; mode=display">
J(\theta,j) = (h(x_{j};\theta)-y_{j})^{2}</script><p>批量求导如下</p>
<script type="math/tex; mode=display">
\frac{\varphi }{\varphi w_{i}}J(\theta) = \frac{1}{2} (h(x_{j};\theta)-y_{j})\cdot x_{j,i}</script><script type="math/tex; mode=display">
\Rightarrow \frac{\varphi }{\varphi w}J(\theta) = \frac{1}{2}(h(x_{j};\theta)-y_{j})\cdot X[j]^T</script><p>其中$x_{j,i}$表示第$j$行第$i$列，$X[j]$表示第$j$行</p>
<p><strong>在训练之前应该打乱训练集数据，以避免数据顺序对算法结果造成影响</strong></p>
<h2 id="小批量随机梯度下降"><a href="#小批量随机梯度下降" class="headerlink" title="小批量随机梯度下降"></a>小批量随机梯度下降</h2><p>小批量梯度下降(<code>small batch gradient descent</code>)介于批量和随机梯度下降之间，每次更新使用给定数量的训练数据来更新参数，其损失函数<code>MSE</code>如下：</p>
<script type="math/tex; mode=display">
J(\theta,i:j) = \frac{1}{j-i} \sum_{k=1}^{j-i}(h(x_{k};\theta)-y_{k})^{2}</script><p>小批量求导如下</p>
<script type="math/tex; mode=display">
\frac{\varphi }{\varphi w_{l}}J(\theta) = \frac{1}{j-i}\sum_{k=1}^{j-i} (h(x_{k};\theta)-y_{k})\cdot x_{k,l}</script><script type="math/tex; mode=display">
\Rightarrow \frac{\varphi }{\varphi w}J(\theta) = \frac{1}{j-i}X[i:j]^T\cdot (X[i:j]\cdot W-Y[i:j])</script><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>使用<code>numpy</code>实现了批量梯度下降和随机梯度下降方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-4-16 下午3:38</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">梯度下降法计算线性回归问题</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_ex1_multi_data():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载多变量数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    path = &apos;../data/coursera2.txt&apos;</span><br><span class="line">    datas = []</span><br><span class="line">    with open(path, &apos;r&apos;) as f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">        for line in lines:</span><br><span class="line">            datas.append(line.strip().split(&apos;,&apos;))</span><br><span class="line">    data_arr = np.array(datas)</span><br><span class="line">    data_arr = data_arr.astype(np.float)</span><br><span class="line"></span><br><span class="line">    X = data_arr[:, :2]</span><br><span class="line">    Y = data_arr[:, 2]</span><br><span class="line">    return X, Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_machine_data():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载计算机硬件数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data = np.loadtxt(&apos;../data/machine.data&apos;, delimiter=&apos;,&apos;, dtype=np.str)</span><br><span class="line">    # print(data)</span><br><span class="line"></span><br><span class="line">    x = data[:, 2:8].astype(np.float)</span><br><span class="line">    y = data[:, 8].astype(np.float)</span><br><span class="line">    # print(x)</span><br><span class="line">    # print(y)</span><br><span class="line"></span><br><span class="line">    return x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def draw_loss(loss_list):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    绘制损失函数值</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    plt.plot(loss_list)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def init_weight(size):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    初始化权重，使用均值为0,方差为1的标准正态分布</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return np.random.normal(loc=0.0, scale=1.0, size=size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_loss(w, x, y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    计算损失值</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    n = y.shape[0]</span><br><span class="line">    return (x.dot(w) - y).T.dot(x.dot(w) - y) / n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def using_batch_gradient_descent():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    批量梯度下降</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x, y = load_machine_data()</span><br><span class="line">    extend_x = np.insert(x, 0, values=np.ones(x.shape[0]), axis=1)</span><br><span class="line">    w = init_weight(extend_x.shape[1])</span><br><span class="line">    # print(w)</span><br><span class="line"></span><br><span class="line">    n = y.shape[0]</span><br><span class="line">    epoches = 50</span><br><span class="line">    alpha = 1e-9</span><br><span class="line">    loss_list = []</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        temp = w - alpha * extend_x.T.dot(extend_x.dot(w) - y) / n</span><br><span class="line">        w = temp</span><br><span class="line">        loss_list.append(compute_loss(w, extend_x, y))</span><br><span class="line">    draw_loss(loss_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def using_stochastic_gradient_descent():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    随机梯度下降</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x, y = load_machine_data()</span><br><span class="line">    extend_x = np.insert(x, 0, values=np.ones(x.shape[0]), axis=1)</span><br><span class="line">    w = init_weight(extend_x.shape[1])</span><br><span class="line">    # print(w)</span><br><span class="line">    print(w.shape)</span><br><span class="line"></span><br><span class="line">    # 打乱数据</span><br><span class="line">    np.random.shuffle(extend_x)</span><br><span class="line">    print(extend_x.shape)</span><br><span class="line">    print(y.shape)</span><br><span class="line"></span><br><span class="line">    n = y.shape[0]</span><br><span class="line">    epoches = 20</span><br><span class="line">    alpha = 1e-9</span><br><span class="line">    loss_list = []</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j in range(n):</span><br><span class="line">            temp = w - alpha * (extend_x[j].dot(w) - y[j]) * extend_x[j].T / 2</span><br><span class="line">            w = temp</span><br><span class="line">            loss_list.append(compute_loss(w, extend_x, y))</span><br><span class="line">    draw_loss(loss_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def using_small_batch_gradient_descent():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    小批量梯度下降</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x, y = load_machine_data()</span><br><span class="line">    extend_x = np.insert(x, 0, values=np.ones(x.shape[0]), axis=1)</span><br><span class="line">    w = init_weight(extend_x.shape[1])</span><br><span class="line">    # print(w)</span><br><span class="line">    print(w.shape)</span><br><span class="line"></span><br><span class="line">    # 打乱数据</span><br><span class="line">    np.random.shuffle(extend_x)</span><br><span class="line">    print(extend_x.shape)</span><br><span class="line">    print(y.shape)</span><br><span class="line"></span><br><span class="line">    # 批量大小</span><br><span class="line">    batch_size = 16</span><br><span class="line"></span><br><span class="line">    n = y.shape[0]</span><br><span class="line">    epoches = 20</span><br><span class="line">    alpha = 5e-9</span><br><span class="line">    loss_list = []</span><br><span class="line">    for i in range(epoches):</span><br><span class="line">        for j in list(range(0, n, batch_size)):</span><br><span class="line">            temp = w - alpha * extend_x[j:j + batch_size].T.dot(</span><br><span class="line">                extend_x[j:j + batch_size].dot(w) - y[j:j + batch_size]) / batch_size</span><br><span class="line">            w = temp</span><br><span class="line">            loss_list.append(compute_loss(w, extend_x, y))</span><br><span class="line">    draw_loss(loss_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # using_batch_gradient_descent()</span><br><span class="line">    using_stochastic_gradient_descent()</span><br><span class="line">    # using_small_batch_gradient_descent()</span><br></pre></td></tr></table></figure>
<p>批量梯度下降损失图</p>
<p><img src="/imgs/梯度下降/batch.png" alt></p>
<p>随机梯度下降损失图</p>
<p><img src="/imgs/梯度下降/stochastic.png" alt></p>
<p>小批量随机梯度下降损失图</p>
<p><img src="/imgs/梯度下降/small_batch.png" alt></p>
<h2 id="3种梯度下降比较"><a href="#3种梯度下降比较" class="headerlink" title="3种梯度下降比较"></a>3种梯度下降比较</h2><p>参考：</p>
<p><a href="https://www.cnblogs.com/lliuye/p/9451903.html" target="_blank" rel="noopener">批量梯度下降(BGD)、随机梯度下降(SGD)以及小批量梯度下降(MBGD)的理解</a></p>
<p><a href="https://blog.csdn.net/sofuzi/article/details/80882521" target="_blank" rel="noopener">三种梯度下降的方式：批量梯度下降、小批量梯度下降、随机梯度下降</a></p>
<ul>
<li>批量梯度下降<ul>
<li>优点：每次更新需要计算所有样本，从而得到的梯度更具有代表性，所以损失值收敛速度最快</li>
<li>缺点：由于每次梯度更新都需要计算所有样本，对于大样本数据训练需要更多的训练时间和训练资源</li>
</ul>
</li>
<li>随机梯度下降<ul>
<li>优点：每次更新仅需单个样本数据参与，权重更新速度快</li>
<li>缺点：计算的梯度不一定符合整体最优路径，需要更多的迭代才能完成收敛</li>
</ul>
</li>
<li>小批量梯度下降：结合批量梯度下降和随机梯度下降的优点，小批量样本计算得到的梯度更接近全局样本，同时提高梯度计算和权重更新速度</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>最优化</category>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>梯度下降</tag>
      </tags>
  </entry>
  <entry>
    <title>标签页测试</title>
    <url>/posts/5213c80b.html</url>
    <content><![CDATA[<p>参考：<a href="https://hexo-guide.readthedocs.io/zh_CN/latest/theme/[NexT]%E6%A0%87%E7%AD%BE%E9%A1%B5%E8%AE%BE%E7%BD%AE.html" target="_blank" rel="noopener">[NexT]标签页设置</a></p><p>指定标签块名</p><div class="tabs" id="标签块"><ul class="nav-tabs"><li class="tab active"><a href="#标签块-1">标签块 1</a></li><li class="tab"><a href="#标签块-2">标签块 2</a></li><li class="tab"><a href="#标签块-3">标签块 3</a></li></ul><div class="tab-content"><div class="tab-pane active" id="标签块-1"><p><strong>标签页1</strong></p></div><div class="tab-pane" id="标签块-2"><p><strong>标签页2</strong></p></div><div class="tab-pane" id="标签块-3"><p><strong>标签页3</strong></p></div></div></div><p>指定标签块名+起始标签页+标签页名</p><a id="more"></a>



<div class="tabs" id="标签块2"><ul class="nav-tabs"><li class="tab"><a href="#标签块2-1">Tab 1</a></li><li class="tab active"><a href="#标签块2-2">Tab 2</a></li><li class="tab"><a href="#标签块2-3">Tab 3</a></li></ul><div class="tab-content"><div class="tab-pane" id="标签块2-1"><p><strong>This is Tab 1.</strong></p></div><div class="tab-pane active" id="标签块2-2"><p><strong>This is Tab 2.</strong></p></div><div class="tab-pane" id="标签块2-3"><p><strong>This is Tab 3.</strong></p></div></div></div>
<p>指定标签块名+起始标签页+<code>FontAwesome</code>符号</p>
<div class="tabs" id="标签块3"><ul class="nav-tabs"><li class="tab active"><a href="#标签块3-1"><i class="fa fa-book" style="text-align: center;"></i></a></li><li class="tab"><a href="#标签块3-2"><i class="fa fa-bold" style="text-align: center;"></i></a></li><li class="tab"><a href="#标签块3-3"><i class="fa fa-amazon" style="text-align: center;"></i></a></li></ul><div class="tab-content"><div class="tab-pane active" id="标签块3-1"><p><strong>This is Tab 1.</strong></p></div><div class="tab-pane" id="标签块3-2"><p><strong>This is Tab 2.</strong></p></div><div class="tab-pane" id="标签块3-3"><p><strong>This is Tab 3.</strong></p></div></div></div>
<p>子标签块设置</p>
<div class="tabs" id="tags"><ul class="nav-tabs"><li class="tab"><a href="#tags-1">Tags 1</a></li><li class="tab"><a href="#tags-2">Tags 2</a></li><li class="tab active"><a href="#tags-3">Tags 3</a></li></ul><div class="tab-content"><div class="tab-pane" id="tags-1"><p><strong>This is Tab 1.</strong></p></div><div class="tab-pane" id="tags-2"><p><strong>This is Tab 2.</strong></p></div><div class="tab-pane active" id="tags-3"><p><strong>This is Tab 3.</strong></p>
<div class="tabs" id="sub-tabs"><ul class="nav-tabs"><li class="tab active"><a href="#sub-tabs-1">Sub Tabs 1</a></li><li class="tab"><a href="#sub-tabs-2">Sub Tabs 2</a></li><li class="tab"><a href="#sub-tabs-3">Sub Tabs 3</a></li></ul><div class="tab-content"><div class="tab-pane active" id="sub-tabs-1"><p><strong>This is Sub Tab 1.</strong></p></div><div class="tab-pane" id="sub-tabs-2"><p><strong>This is Sub Tab 2.</strong></p></div><div class="tab-pane" id="sub-tabs-3"><p><strong>This is Sub Tab 3.</strong></p></div></div></div></div></div></div>
<p>嵌套子标签块设置</p>
<div class="tabs" id="tags-in-tags"><ul class="nav-tabs"><li class="tab"><a href="#tags-in-tags-1">Tags in Tags 1</a></li><li class="tab"><a href="#tags-in-tags-2">Tags in Tags 2</a></li><li class="tab active"><a href="#tags-in-tags-3">Tags in Tags 3</a></li></ul><div class="tab-content"><div class="tab-pane" id="tags-in-tags-1"><p><strong>This is Tab 1.</strong></p></div><div class="tab-pane" id="tags-in-tags-2"><p><strong>This is Tab 2.</strong></p></div><div class="tab-pane active" id="tags-in-tags-3"><p><strong>This is Tab 3.</strong></p>
<div class="tabs" id="sub-tabs-in-tags"><ul class="nav-tabs"><li class="tab active"><a href="#sub-tabs-in-tags-1">Sub Tabs in Tags 1</a></li><li class="tab"><a href="#sub-tabs-in-tags-2">Sub Tabs in Tags 2</a></li><li class="tab"><a href="#sub-tabs-in-tags-3">Sub Tabs in Tags 3</a></li></ul><div class="tab-content"><div class="tab-pane active" id="sub-tabs-in-tags-1"><p><strong>This is Sub Tab 1.</strong></p></div><div class="tab-pane" id="sub-tabs-in-tags-2"><p><strong>This is Sub Tab 2.</strong></p></div><div class="tab-pane" id="sub-tabs-in-tags-3"><p><strong>This is Sub Tab 3.</strong></p>
<div class="tabs" id="sub-sub-tabs"><ul class="nav-tabs"><li class="tab active"><a href="#sub-sub-tabs-1">Sub-Sub Tabs 1</a></li><li class="tab"><a href="#sub-sub-tabs-2">Sub-Sub Tabs 2</a></li><li class="tab"><a href="#sub-sub-tabs-3">Sub-Sub Tabs 3</a></li></ul><div class="tab-content"><div class="tab-pane active" id="sub-sub-tabs-1"><p><strong>This is Sub-Sub Tab 1 of Sub Tab 3.</strong></p></div><div class="tab-pane" id="sub-sub-tabs-2"><p><strong>This is Sub-Sub Tab 2 of Sub Tab 3.</strong></p></div><div class="tab-pane" id="sub-sub-tabs-3"><p><strong>This is Sub-Sub Tab 3 of Sub Tab 3.</strong></p></div></div></div></div></div></div></div></div></div>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>tab</tag>
        <tag>NexT</tag>
      </tags>
  </entry>
  <entry>
    <title>正态分布</title>
    <url>/posts/6824c6e3.html</url>
    <content><![CDATA[<p>参考：<a href="https://baike.baidu.com/item/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83" target="_blank" rel="noopener">正态分布</a></p><p>正态分布（<code>normal distribution</code>），也称为常态分布，高斯分布（<code>gaussian distribution</code>），是连续随机变量概率分布的一种，自然界中大量现象符合正态分布，比如身高/体重/成绩/收入/寿命</p><a id="more"></a>

<h3 id="一维正态分布"><a href="#一维正态分布" class="headerlink" title="一维正态分布"></a>一维正态分布</h3><p>若随机变量$X$服从一个位置参数（数学期望）为$\mu$、尺度参数（方差）为$\sigma $的概率分布，且其概率密度函数为</p>
<script type="math/tex; mode=display">
f(x)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)</script><p>则这个随机变量就称为正态随机变量，正态随机变量服从的分布就称为正态分布，记作$X \sim N\left(\mu, \sigma^{2}\right)$</p>
<h3 id="标准正态分布"><a href="#标准正态分布" class="headerlink" title="标准正态分布"></a>标准正态分布</h3><p>当$\mu =0, \sigma =1$的正态分布称为标准正态分布</p>
<h4 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h4><p><a href="http://www.ruanyifeng.com/blog/2017/08/normal-distribution.html" target="_blank" rel="noopener">正态分布为什么常见？</a></p>
<p><a href="https://baike.baidu.com/item/%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86" target="_blank" rel="noopener">中心极限定理</a></p>
<p><a href="https://www.zhihu.com/topic/20009708/intro" target="_blank" rel="noopener">中心极限定理</a></p>
<ul>
<li><p><strong>期望值$\mu$决定了概率密度函数的分布位置</strong>，离$\mu$近的值概率大，反之概率小</p>
</li>
<li><p>正态分布以$\mu$为对称轴，左右完全对称；正态分布的期望、均数、中位数和总数都是$\mu$</p>
</li>
<li><p><strong>方差$\sigma$决定了分布幅度大小（离散程度）</strong>，$\sigma$越大，数据分布越分散，曲线越扁平；反之，数据越集中，曲线越廋高</p>
</li>
<li><p>通常称发生概率小于5%的事件几乎不可能发生，在$\left (  \mu-3\cdot \sigma,\mu+3\cdot \sigma \right )$区间外的概率小于千分之三，所以基本上把区间$\left (  \mu-3\cdot \sigma,\mu+3\cdot \sigma \right )$称为随机变量x实际可能的取值范围，称为正态分布的$3\sigma$原则</p>
</li>
<li>中心极限定理：多个独立分布的随机变量的和的均值服从正态分布</li>
</ul>
<h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>参考<a href="https://stackoverflow.com/questions/10138085/python-pylab-plot-normal-distribution" target="_blank" rel="noopener">python pylab plot normal distribution</a>，标准正态分布如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import scipy.stats as stats</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    mu = 0</span><br><span class="line">    variance = 1</span><br><span class="line">    </span><br><span class="line">    x = np.linspace(-10, 10, 100)</span><br><span class="line">    plt.scatter(x, stats.norm.pdf(x, mu, variance), s=3)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/正态分布/normal_distribution.png" alt></p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>概率论</tag>
        <tag>统计学</tag>
      </tags>
  </entry>
  <entry>
    <title>特征缩放</title>
    <url>/posts/dea583b1.html</url>
    <content><![CDATA[<p>参考：<a href="https://blog.csdn.net/pipisorry/article/details/52247379" target="_blank" rel="noopener">数据标准化/归一化normalization</a></p><p>在多变量回归或分类问题上，需要保证这些变量的取值范围具有同一尺度</p><a id="more"></a>

<p>原因一：<strong>确保大尺度变量不会左右分类器的分类结果</strong>。如果分类器利用结果变量的距离来计算损失函数，那么小尺度变量的变化会被忽略，大尺度变量会决定分类效果<br>原因二：<strong>帮助梯度下降算法收敛更快</strong>。参考<a href="https://blog.csdn.net/runnerxin/article/details/78551025" target="_blank" rel="noopener">机器学习—特征缩放/均值归一化</a>，从损失函数等值线图可知，变量在同一尺度下能够更快的通过梯度下降算法收敛</p>
<p>常用的特征缩放方法包括标准化（或称为规范化）和区间缩放</p>
<h3 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h3><p>标准化方法就是将数据变换为均值为<code>0</code>，方差为<code>1</code>的标准正态分布。标准化公式如下</p>
<script type="math/tex; mode=display">
x_{i}'=\frac{x_{i}-\mu_{i}}{s_{i}}</script><p>其中$x_{i}$是第$i$个属性的特征向量，$x_{i}’$是变换后的特征向量，$\mu_{i}$是第$i$个属性的均值，$s_{i}$是第$i$个属性的标准差</p>
<p><strong>要求：变量服从正态分布</strong></p>
<h3 id="区间缩放"><a href="#区间缩放" class="headerlink" title="区间缩放"></a>区间缩放</h3><p>将特征值缩放到某个特定大小的区间，比如<code>[0,1]</code>，计算公式如下：</p>
<script type="math/tex; mode=display">
x_{i}'=\frac{x_{i}-min(x_{i})}{max_{x_{i}}-min_{x_{i}}}</script><p>其中$x_{i}$是第$i$个属性的特征向量，$x_{i}’$是变换后的特征向量，函数$max()$和$min()$用于求该属性的最大最小值</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>最优化</category>
      </categories>
      <tags>
        <tag>标准化</tag>
      </tags>
  </entry>
  <entry>
    <title>线性回归</title>
    <url>/posts/ec419bd2.html</url>
    <content><![CDATA[<p>参考：</p><p>《机器学习基础 原理、算法与实践》第二章 线性回归</p><p><a href="http://baijiahao.baidu.com/s?id=1602127602901158968&amp;wfr=spider&amp;for=pc" target="_blank" rel="noopener">Python 机器学习：线性回归</a></p><p>主要内容如下：</p><a id="more"></a>



<ol>
<li>回归和分类的区别</li>
<li>线性回归</li>
<li>最小二乘法</li>
<li>梯度下降法</li>
</ol>
<h2 id="回归和分类"><a href="#回归和分类" class="headerlink" title="回归和分类"></a>回归和分类</h2><p>参考：</p>
<p><a href="https://www.jiqizhixin.com/articles/2017-12-15-2" target="_blank" rel="noopener">区分识别机器学习中的分类与回归</a></p>
<p><a href="https://www.zhihu.com/question/21329754" target="_blank" rel="noopener">分类与回归区别是什么？</a></p>
<p>回归和分类一样，都是对变量进行预测</p>
<p>回归是对<strong>连续型变量</strong>进行预测，回归预测建模是指建立输入变量<code>X</code>映射到<strong>连续输出变量Y</strong>的映射函数<code>f</code></p>
<p>分类是对<em>离散型或连续型变量</em>进行预测，分类预测建模是指建立输入变量<code>X</code>映射到<strong>离散输出变量Y</strong>的映射函数<code>f</code></p>
<p>比如，预测天气温度是回归问题，预测天气是下雨还是晴天就是分类问题</p>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>线性回归（<code>linear regression</code>）是以线性模型来建模自变量和因变量之间关系的方法</p>
<script type="math/tex; mode=display">
y=h(x;\theta)</script><p>其中$x$是自变量，$y$是因变量，$\theta$是模型参数</p>
<p>如果自变量$x$只有一个，那么这种问题称为单变量线性回归（或称为一元线性回归）；如果自变量$x$表示多个，那么成为多变量线性回归（或称为多元线性回归）</p>
<h3 id="单变量线性回归"><a href="#单变量线性回归" class="headerlink" title="单变量线性回归"></a>单变量线性回归</h3><p>单变量线性问题可转换为求解二维平面上的直线问题</p>
<p>模型计算公式如下：</p>
<script type="math/tex; mode=display">
y=w_{1}x+w_{0}</script><p>参数集合$\theta = \left \{  w_{0},w_{1} \right \}$</p>
<p>在学习过程中，需要判断参数$w_{0}$和$w_{1}$是否满足要求，即是否和所有数据点接近。使用<code>均方误差（mean square error，简称MSE）</code>来评估预测值和实际数据点的接近程度，模型评估公式如下：</p>
<script type="math/tex; mode=display">
J(w_{0},w_{1})=\frac{1}{N}\sum_{i=1}^{N}(h(x_{i};\theta) - y_{i})^{2}</script><p>其中$y_{i}$表示真实数据，$h$表示估计值，$J$表示损失值</p>
<h3 id="多变量线性回归"><a href="#多变量线性回归" class="headerlink" title="多变量线性回归"></a>多变量线性回归</h3><p>多变量线性回归计算公式如下：</p>
<script type="math/tex; mode=display">
\left\{\begin{matrix}
y_{1}=w_{0}+w_{1}\cdot x_{11}+...+w_{n}\cdot x_{1n}\\ 
y_{2}=w_{0}+w_{1}\cdot x_{21}+...+w_{n}\cdot x_{2n}\\ 
...\\ 
y_{m}=w_{0}+w_{1}\cdot x_{m1}+...+w_{n}\cdot x_{mn}
\end{matrix}\right.</script><p>参数$m$表示有$m$个等式，参数$n$表示每一组变量有$n$个参数。设$x_{0}=1$，计算公式如下：</p>
<script type="math/tex; mode=display">
\left\{\begin{matrix}
y_{1}=w_{0}\cdot x_{10}+w_{1}\cdot x_{11}+...+w_{n}\cdot x_{1n}\\ 
y_{2}=w_{0}\cdot x_{20}+w_{1}\cdot x_{21}+...+w_{n}\cdot x_{2n}\\ 
...\\ 
y_{m}=w_{0}\cdot x_{m0}+w_{1}\cdot x_{m1}+...+w_{n}\cdot x_{mn}
\end{matrix}\right.</script><p>此时每组参数个数增加为$n+1$，其向量化公式如下：</p>
<script type="math/tex; mode=display">
Y=X\cdot W</script><p>其中</p>
<script type="math/tex; mode=display">
Y_{m\times 1}=\begin{bmatrix}
y_{1}\\ 
y_{2}\\ 
...\\ 
y_{m}
\end{bmatrix}</script><script type="math/tex; mode=display">
X_{m\times (n+1)}=\begin{bmatrix}
x_{10} & x_{11} & ... & x_{1n}\\ 
x_{20} & x_{21} & ... & x_{2n}\\ 
... & ... & ... & ...\\ 
x_{m0} & x_{m1} & ... & x_{mn}
\end{bmatrix}
=\begin{bmatrix}
1 & x_{11} & ... & x_{1n}\\ 
1 & x_{21} & ... & x_{2n}\\ 
... & ... & ... & ...\\ 
1 & x_{m1} & ... & x_{mn}
\end{bmatrix}</script><script type="math/tex; mode=display">
W_{(n+1)\times 1}=
\begin{bmatrix}
w_{0} \\ w_{1} \\ ... \\ w_{n}
\end{bmatrix}</script><p>同样使用均方误差作为损失函数</p>
<script type="math/tex; mode=display">
J(W)=\frac{1}{N}\sum_{i=1}^{N}(h(x_{i};W) - y_{i})^{2}</script><h2 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h2><p>参考：</p>
<p><a href="https://zhuanlan.zhihu.com/p/31146740" target="_blank" rel="noopener">机器学习数学：最小二乘法</a></p>
<p><a href="https://baike.baidu.com/item/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95" target="_blank" rel="noopener">最小二乘法</a></p>
<p>利用最小二乘法（<code>least square method</code>）计算线性回归问题的参数，它通过<strong>最小化误差的平方和</strong>来求取目标函数的最优值，这样进一步转换为求取损失函数$J$的最小值，当$J$得到最小值时，参数偏导数一定为<code>0</code></p>
<script type="math/tex; mode=display">
loss=N*J=\sum_{i=1}^{N}(h(x_{i}:\theta) - y_{i})^{2}</script><p>有两种方式进行最小二乘法的计算，使用<strong>几何方式</strong>计算单变量线性回归问题，使用<strong>矩阵方式</strong>计算多变量线性回归问题</p>
<h3 id="几何计算"><a href="#几何计算" class="headerlink" title="几何计算"></a>几何计算</h3><p>当$J$得到最小值时，$w_{0}$和$w_{1}$的偏导数一定为<code>0</code>，所以参数$w_{0}$和$w_{1}$的计算公式如下：</p>
<script type="math/tex; mode=display">
\frac{\varphi J}{\varphi w_{0}}
=\frac{\varphi }{\varphi w_{0}}\frac{1}{N} \sum_{i=1}^{N}(h(x_{i})-y_{i})^{2}
=\frac{\varphi }{\varphi w_{0}}\frac{1}{N} \sum_{i=1}^{N}(w_{0}+w_{1}\cdot x_{i}-y_{i})^{2}</script><script type="math/tex; mode=display">
=\frac{2}{N} \sum_{i=1}^{N}(w_{0}+w_{1}\cdot x_{i}-y_{i})
=2\cdot w_{0}+\frac{2}{N} \sum_{i=1}^{N}(w_{1}\cdot x_{i}-y_{i})</script><script type="math/tex; mode=display">
\frac{\varphi J}{\varphi w_{0}}=0 
\Rightarrow 
w_{0}=-\frac{1}{N}\sum_{i=1}^{N}(w_{1}\cdot x_{i}-y_{i})
=\frac{1}{N}(\sum_{i=1}^{N}y_{i}-\sum_{i=1}^{N}w_{1}\cdot x_{i})
=\bar{y}-w_{1}\cdot \bar{x}</script><script type="math/tex; mode=display">
\frac{\varphi J}{\varphi w_{1}}
=\frac{\varphi }{\varphi w_{1}}\frac{1}{N} \sum_{i=1}^{N}(h(x_{i})-y_{i})^{2}
=\frac{\varphi }{\varphi w_{1}}\frac{1}{N} \sum_{i=1}^{N}(w_{0}+w_{1}\cdot x_{i}-y_{i})^{2}</script><script type="math/tex; mode=display">
=\frac{2}{N} \sum_{i=1}^{N}(w_{0}+w_{1}\cdot x_{i}-y_{i})\cdot x_{i}
=\frac{2\cdot w_{0}}{N}\sum_{i=1}^{N}x_{i}+\frac{2\cdot w_{1}}{N}\sum_{i=1}^{N}x_{i}\cdot x_{i}-\frac{2}{N}\sum_{i=1}^{N}x_{i}\cdot y_{i}</script><script type="math/tex; mode=display">
=2\cdot w_{0}\cdot \bar{x}+2\cdot w_{1}\cdot \bar{x^{2}}-2\cdot \bar{x\cdot y}</script><script type="math/tex; mode=display">
\frac{\varphi J}{\varphi w_{1}}=0,  w_{0}=\bar{y}-w_{1}\cdot \bar{x}
\Rightarrow
\bar{x}\cdot \bar{y}-w_{1}\cdot \bar{x}^{2}+w_{1}\cdot \bar{x^{2}}-\bar{x\cdot y}=0
\Rightarrow
w_{1}=\frac{\bar{x\cdot y} - \bar{x}\cdot \bar{y}}{\bar{x^{2}}-\bar{x}^{2}}</script><p>最终得到的$w_{0}$和$w_{1}$的计算公式如下：</p>
<script type="math/tex; mode=display">
w_{0}=\bar{y}-w_{1}\cdot \bar{x}</script><script type="math/tex; mode=display">
w_{1}=\frac{\bar{x\cdot y} - \bar{x}\cdot \bar{y}}{\bar{x^{2}}-\bar{x}^{2}}</script><ul>
<li>参数$\bar{y}$表示真实结果的均值</li>
<li>参数$\bar{x}$表示输入变量的均值</li>
<li>参数$\bar{x\cdot y}$表示输入变量和真实结果的乘积的均值</li>
<li>其他变量以此类推</li>
</ul>
<h3 id="矩阵计算"><a href="#矩阵计算" class="headerlink" title="矩阵计算"></a>矩阵计算</h3><p>参考：<a href="https://zhuanlan.zhihu.com/p/33899560" target="_blank" rel="noopener">最小二乘法线性回归：矩阵视角</a></p>
<p>基本矩阵运算如下：</p>
<script type="math/tex; mode=display">
(X\pm Y)^T = X^T\pm Y^T</script><script type="math/tex; mode=display">
(X\cdot Y)^{T}=Y^{T}\cdot X^{T}</script><script type="math/tex; mode=display">
(A^T)^T=A</script><script type="math/tex; mode=display">
\left | A^{T} \right |=\left | A \right |</script><p>矩阵求导如下：</p>
<script type="math/tex; mode=display">
\frac{\varphi (\theta ^{T}\cdot X)}{\varphi \theta}=X</script><script type="math/tex; mode=display">
\frac{\varphi (X^{T}\cdot \theta )}{\varphi \theta}=X</script><script type="math/tex; mode=display">
\frac{\varphi (\theta ^{T}\cdot \theta )}{\varphi \theta}=\theta</script><script type="math/tex; mode=display">
\frac{\varphi (\theta ^{T}\cdot C\cdot \theta )}{\varphi \theta}=2\cdot C\cdot \theta</script><p>对多变量线性线性回归问题进行计算，</p>
<script type="math/tex; mode=display">
J(W)
=\frac{1}{N}\cdot \sum_{i=1}^{N}(h(x_{i};W)-y_{i})^2
=\frac{1}{N}(X\cdot W-Y)^{T}\cdot (X\cdot W -Y)</script><script type="math/tex; mode=display">
=\frac{1}{N}((X\cdot W)^T-Y^T)\cdot (X\cdot W-Y))
=\frac{1}{N}(W^T\cdot X^T-Y^T)\cdot (X\cdot W-Y))</script><script type="math/tex; mode=display">
=\frac{1}{N}(W^T\cdot X^{T}\cdot X\cdot W-W^T\cdot X^{T}\cdot Y-Y^{T}\cdot X\cdot W+Y^{T}\cdot Y)</script><p>其中，$W^T\cdot X^{T}\cdot Y$是$Y^{T}\cdot X\cdot W$的转置，计算结果均为$1\times 1$的标量，所以大小相等，上式计算如下：</p>
<script type="math/tex; mode=display">
J(W)=\frac{1}{N}(W^T\cdot X^{T}\cdot X\cdot W-2\cdot W^T\cdot X^{T}\cdot Y+Y^{T}\cdot Y)</script><p>求解$\frac{\varphi J(W)}{\varphi W}=0$</p>
<script type="math/tex; mode=display">
\frac{\varphi J(W)}{\varphi W}=\frac{1}{N}\cdot X^{T}\cdot X\cdot W-\frac{1}{N}\cdot X^{T}\cdot Y=0</script><script type="math/tex; mode=display">
\Rightarrow X^{T}\cdot X\cdot W=X^{T}\cdot Y</script><script type="math/tex; mode=display">
\Rightarrow W=(X^{T}\cdot X)^{-1}\cdot X^{T}\cdot Y</script><p><strong>$X^{T}\cdot X$必须是非奇异矩阵，满足$\left | X^{T}\cdot X \right |\neq 0$，才能保证可逆</strong></p>
<p>对于矩阵的秩，有以下定理</p>
<ol>
<li>对于$n$阶矩阵$A$，当且仅当$\left | A \right | \neq 0$时，$R(A_{n})=n$，称$A$为满秩矩阵</li>
<li>$R(A^T)=R(A)$</li>
<li>$R(AB)\leq min \left \{ R(A), R(B)\right \}$</li>
<li>设$A$为$m\times n$矩阵，则$0\leq (A)\leq min \left \{ m,n \right \}$</li>
</ol>
<p>所以矩阵$X$的秩$R(X)$需要为$n+1$（通常样本数量$m$大于变量数量$n+1$）时，才能保证能够使用最小二乘法的矩阵方式求解线性回归问题</p>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>单边量线性回归测试数据参考[线性回归最小二乘法和梯度下降法]的<a href="https://www.math.muni.cz/~kolacek/docs/frvs/M7222/data/AutoInsurSweden.txt" target="_blank" rel="noopener">瑞典汽车保险数据集</a></p>
<p>多变量线性回归测试数据参考<code>coursera</code>的<a href="https://github.com/peedeep/Coursera/blob/master/ex1/ex1data2.txt" target="_blank" rel="noopener">ex1data2.txt</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-4-16 上午10:04</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">最小二乘法计算线性回归问题</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">from mpl_toolkits.mplot3d import Axes3D</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_sweden_data():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载单变量数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    path = &apos;../data/sweden.txt&apos;</span><br><span class="line">    res = None</span><br><span class="line">    with open(path, &apos;r&apos;) as f:</span><br><span class="line">        line = f.readline()</span><br><span class="line">        res = np.array(line.strip().split(&apos; &apos;)).reshape((-1, 2))</span><br><span class="line">        # print(res)</span><br><span class="line">    x = []</span><br><span class="line">    y = []</span><br><span class="line">    for i, item in enumerate(res, 0):</span><br><span class="line">        item[1] = str(item[1]).replace(&apos;,&apos;, &apos;.&apos;)</span><br><span class="line">        # print(&apos;%d %.3f&apos; % (int(item[0]), float(item[1])))</span><br><span class="line">        x.append(int(item[0]))</span><br><span class="line">        y.append(float(item[1]))</span><br><span class="line">    return np.array(x), np.array(y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_ex1_multi_data():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载多变量数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    path = &apos;../data/coursera2.txt&apos;</span><br><span class="line">    datas = []</span><br><span class="line">    with open(path, &apos;r&apos;) as f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">        for line in lines:</span><br><span class="line">            datas.append(line.strip().split(&apos;,&apos;))</span><br><span class="line">    data_arr = np.array(datas)</span><br><span class="line">    data_arr = data_arr.astype(np.float)</span><br><span class="line"></span><br><span class="line">    X = data_arr[:, :2]</span><br><span class="line">    Y = data_arr[:, 2]</span><br><span class="line">    return X, Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def least_square_loss_v1(x, y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    最小二乘法，几何运算</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    X = np.array(x)</span><br><span class="line">    Y = np.array(y)</span><br><span class="line">    muX = np.mean(X)</span><br><span class="line">    muY = np.mean(Y)</span><br><span class="line">    muXY = np.mean(X * Y)</span><br><span class="line">    muXX = np.mean(X * X)</span><br><span class="line"></span><br><span class="line">    w1 = (muXY - muX * muY) / (muXX - muX ** 2)</span><br><span class="line">    w0 = muY - w1 * muX</span><br><span class="line">    return w0, w1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def least_square_loss_v2(x, y):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    最小二乘法，矩阵运算</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    extend_x = np.insert(x, 0, values=np.ones(x.shape[0]), axis=1)</span><br><span class="line">    w = np.linalg.inv(extend_x.T.dot(extend_x)).dot(extend_x.T).dot(y)</span><br><span class="line">    return w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_single_variable_linear_regression():</span><br><span class="line">    x, y = load_sweden_data()</span><br><span class="line">    w0, w1 = least_square_loss_v1(x, y)</span><br><span class="line"></span><br><span class="line">    y2 = w1 * x + w0</span><br><span class="line"></span><br><span class="line">    plt.scatter(x, y)</span><br><span class="line">    plt.plot(x, y2)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_multi_variable_linear_regression():</span><br><span class="line">    x, y = load_ex1_multi_data()</span><br><span class="line">    # 计算权重</span><br><span class="line">    w = least_square_loss_v2(x, y)</span><br><span class="line">    print(w)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # compute_single_variable_linear_regression()</span><br><span class="line">    compute_multi_variable_linear_regression()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/线性回归/sweden.png" alt></p>
<h3 id="适用范围"><a href="#适用范围" class="headerlink" title="适用范围"></a>适用范围</h3><p>参考：</p>
<p><a href="https://zhuanlan.zhihu.com/p/38128785" target="_blank" rel="noopener">最小二乘法（least sqaure method）</a></p>
<p><a href="https://www.zhihu.com/question/24095027" target="_blank" rel="noopener">在进行线性回归时，为什么最小二乘法是最优方法？</a></p>
<p>最小二乘法直接进行计算就能求出解，操作简洁，最适用于计算单变量线性回归问题</p>
<p>而对于多变量线性回归问题，使用最小二乘法计算需要考虑计算效率，因为$X^T\cdot X$的逆矩阵计算代价很大，同时需要考虑可逆问题，所以更推荐梯度下降算法来解决多变量线性回归问题</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文学习了线性回归模型，利用最小二乘法（<em>最小化误差的平方和</em>）实现单边量/多变量线性数据的训练和预测</p>
<p>在训练过程中，线性回归模型使用线性映射进行前向计算，利用均方误差方法进行损失值的计算</p>
<ul>
<li>对于单变量线性回归问题，适用于最小二乘法的几何计算</li>
<li>对于多变量线性回归问题，如果变量维数不大同时满足$\left | X^{T}\cdot X \right |\neq 0$且$R(X) = n+1$的情况，使用最小二乘法的矩阵计算；否则，利用梯度下降方式进行权重更新</li>
</ul>
<p>线性回归模型更适用于回归问题，可以使用逻辑回归模型进行分类</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>编程</category>
        <category>编程语言</category>
        <category>机器学习</category>
        <category>代码库</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>matplotlib</tag>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title>[数据集]cifar-100</title>
    <url>/posts/adb6e880.html</url>
    <content><![CDATA[<p><a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">cifar-100数据集</a>解析和<a href="https://www.zhuajin.tech/posts/43d7ec86.html" target="_blank" rel="noopener">cifar-10数据集解析</a>类似，区别在于<code>cifar-100</code>共<code>20</code>个超类（<code>superclass</code>），<code>100</code>个子类，所以每张图像有两个标签：超类标签（<code>coarse label</code>）和子类标签（<code>fine label</code>）</p><a id="more"></a>
<p><img src="/imgs/cifar-100数据集解析/100-classes.png" alt></p>
<h2 id="文件解析"><a href="#文件解析" class="headerlink" title="文件解析"></a>文件解析</h2><p>下载<a href="https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz" target="_blank" rel="noopener">python压缩包</a>，解压后里面有<code>3</code>个文件：<code>meta/test/train</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def print_keys():</span><br><span class="line">    data_list = [&apos;meta&apos;, &apos;test&apos;, &apos;train&apos;]</span><br><span class="line">    data_dir = &apos;/home/zj/data/cifar-100-python/&apos;</span><br><span class="line"></span><br><span class="line">    for item in data_list:</span><br><span class="line">        data_path = os.path.join(data_dir, item)</span><br><span class="line">        data = unpickle(data_path)</span><br><span class="line"></span><br><span class="line">        print(item, list(data.keys()))</span><br></pre></td></tr></table></figure>
<p>每个文件都是一个字典结构，依次输出文件的键</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">meta [b&apos;fine_label_names&apos;, b&apos;coarse_label_names&apos;]</span><br><span class="line">test [b&apos;filenames&apos;, b&apos;batch_label&apos;, b&apos;fine_labels&apos;, b&apos;coarse_labels&apos;, b&apos;data&apos;]</span><br><span class="line">train [b&apos;filenames&apos;, b&apos;batch_label&apos;, b&apos;fine_labels&apos;, b&apos;coarse_labels&apos;, b&apos;data&apos;]</span><br></pre></td></tr></table></figure>
<p>在元信息文件、训练文件和测试文件中，相比<code>cifar-10</code>数据集多个一个标签信息</p>
<h2 id="图像解析"><a href="#图像解析" class="headerlink" title="图像解析"></a>图像解析</h2><p>按以下结构保存图像数据：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── test</span><br><span class="line">    ├── coarse_labels</span><br><span class="line">        └── fine_labels</span><br><span class="line">└── train</span><br><span class="line">    ├── coarse_labels</span><br><span class="line">       └── fine_labels</span><br></pre></td></tr></table></figure>
<p>实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def unpickle(file):</span><br><span class="line">    with open(file, &apos;rb&apos;) as fo:</span><br><span class="line">        dict = pickle.load(fo, encoding=&apos;bytes&apos;)</span><br><span class="line">    return dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def write_img(data, coarse_labels, fine_labels, filenames, isTrain=True):</span><br><span class="line">    res_data_dir = &apos;/home/zj/data/decompress_cifar_100&apos;</span><br><span class="line"></span><br><span class="line">    if isTrain:</span><br><span class="line">        data_dir = os.path.join(res_data_dir, &apos;train&apos;)</span><br><span class="line">    else:</span><br><span class="line">        data_dir = os.path.join(res_data_dir, &apos;test&apos;)</span><br><span class="line"></span><br><span class="line">    if not os.path.exists(data_dir):</span><br><span class="line">        os.mkdir(data_dir)</span><br><span class="line"></span><br><span class="line">    N = len(coarse_labels)</span><br><span class="line">    for i in range(N):</span><br><span class="line">        coarse_cate_dir = os.path.join(data_dir, str(coarse_labels[i]))</span><br><span class="line">        if not os.path.exists(coarse_cate_dir):</span><br><span class="line">            os.mkdir(coarse_cate_dir)</span><br><span class="line">        fine_cate_dir = os.path.join(coarse_cate_dir, str(fine_labels[i]))</span><br><span class="line">        if not os.path.exists(fine_cate_dir):</span><br><span class="line">            os.mkdir(fine_cate_dir)</span><br><span class="line">        img_path = os.path.join(fine_cate_dir, str(filenames[i], encoding=&apos;utf-8&apos;))</span><br><span class="line"></span><br><span class="line">        img = data[i].reshape(3, 32, 32)</span><br><span class="line">        img = np.transpose(img, (1, 2, 0))</span><br><span class="line">        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)</span><br><span class="line">        cv2.imwrite(img_path, img)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decompress_img():</span><br><span class="line">    data_list = [&apos;test&apos;, &apos;train&apos;]</span><br><span class="line">    data_dir = &apos;/home/zj/data/cifar-100-python/&apos;</span><br><span class="line"></span><br><span class="line">    for item in data_list:</span><br><span class="line">        data_dir = os.path.join(data_dir, item)</span><br><span class="line">        di = unpickle(data_dir)</span><br><span class="line"></span><br><span class="line">        batch_label = str(di.get(b&apos;batch_label&apos;), encoding=&apos;utf-8&apos;)</span><br><span class="line">        filenames = di.get(b&apos;filenames&apos;)</span><br><span class="line">        fine_labels = di.get(b&apos;fine_labels&apos;)</span><br><span class="line">        coarse_labels = di.get(b&apos;coarse_labels&apos;)</span><br><span class="line">        data = di.get(b&apos;data&apos;)</span><br><span class="line"></span><br><span class="line">        if &apos;train&apos; in batch_label:</span><br><span class="line">            write_img(data, coarse_labels, fine_labels, filenames)</span><br><span class="line">        else:</span><br><span class="line">            write_img(data, coarse_labels, fine_labels, filenames, isTrain=False)</span><br></pre></td></tr></table></figure>
<h2 id="图像展示"><a href="#图像展示" class="headerlink" title="图像展示"></a>图像展示</h2><p>随机读取<code>100</code>张图像显示如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    data_dir = &apos;/home/zj/da</span><br><span class="line">文件解析</span><br><span class="line"></span><br><span class="line">far-100-python/train&apos;</span><br><span class="line"></span><br><span class="line">    di = unpickle(data_dir)</span><br><span class="line">文件解析</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    batch_label = str(di.get(b&apos;batch_label&apos;), encoding=&apos;utf-8&apos;)</span><br><span class="line">    filenames = di.get(b&apos;filenames&apos;)</span><br><span class="line">    fine_labels = di.get(b&apos;fine_labels&apos;)</span><br><span class="line">    coarse_labels = di.get(b&apos;coarse_labels&apos;)</span><br><span class="line">    data = di.get(b&apos;data&apos;)</span><br><span class="line"></span><br><span class="line">    N = 10</span><br><span class="line">    W = 32</span><br><span class="line">    H = 32</span><br><span class="line">    ex = np.zeros((H * N, W * N, 3))</span><br><span class="line">    for i in range(N):</span><br><span class="line">        for j in range(N):</span><br><span class="line">            img = data[i * N + j].reshape(3, H, W)</span><br><span class="line">            img = np.transpose(img, (1, 2, 0))</span><br><span class="line">            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)</span><br><span class="line"></span><br><span class="line">            ex[i * H:(i + 1) * H, j * W:(j + 1) * W] = img</span><br><span class="line">    cv2.imwrite(&apos;cifar-100.png&apos;, ex)</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/cifar-100数据集解析/cifar-100.png" alt></p>
]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据</category>
        <category>代码库</category>
        <category>数据集</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
        <tag>numpy</tag>
        <tag>pickle</tag>
        <tag>cifar100</tag>
      </tags>
  </entry>
  <entry>
    <title>[数据集]cifar-10</title>
    <url>/posts/43d7ec86.html</url>
    <content><![CDATA[<p><code>cifar-10</code>数据集保存<code>10</code>类，每类<code>6000</code>张图像。其中<code>50000</code>张训练图像和<code>10000</code>张测试图像</p><p>训练图像保存在<code>5</code>个文件中，每个文件有<code>10000</code>张图像，测试图像保存在一个文件，训练和测试图像都以随机顺序保存</p><a id="more"></a>

<p>官网：<a href="http://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">The CIFAR-10 dataset</a></p>
<p><code>cifar-10</code>提供了使用不同语言生成的压缩包，包括<code>python/matlab/c</code></p>
<h2 id="python解析"><a href="#python解析" class="headerlink" title="python解析"></a><code>python</code>解析</h2><p>训练文件命名为<code>data_batch_1/data_batch_2/data_batch_3/data_batch_4/data_batch_5</code></p>
<p>测试文件命名为<code>test_batch</code></p>
<p>另外还有一个元数据文件<code>batches.meta</code>，保存了标签名对应的类名，比如<code>label_names[0] == &quot;airplane&quot;, label_names[1] == &quot;automobile&quot;</code></p>
<p><code>python</code>版压缩包使用<code>pickle</code>模块进行保存，解析程序如下，返回一个<code>dict</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def unpickle(file):</span><br><span class="line">    import pickle</span><br><span class="line">    with open(file, &apos;rb&apos;) as fo:</span><br><span class="line">        dict = pickle.load(fo, encoding=&apos;bytes&apos;)</span><br><span class="line">    return dict</span><br></pre></td></tr></table></figure>
<p>以测试集文件为例，其包含以下键值对</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dict_keys([b&apos;batch_label&apos;, b&apos;labels&apos;, b&apos;data&apos;, b&apos;filenames&apos;])</span><br></pre></td></tr></table></figure>
<p>其中<code>b&#39;labels&#39;</code>保存类别标签（<code>0-9</code>），<code>b&#39;data&#39;</code>保存对应图像数据，<code>b&#39;filenames&#39;</code>保存图像文件名</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    data_dir = &apos;/home/zj/data/cifar-10-batches-py/&apos;</span><br><span class="line">    test_data_dir = data_dir + &apos;test_batch&apos;</span><br><span class="line">    di = unpickle(test_data_dir)</span><br><span class="line">    # 打印所有键值</span><br><span class="line">    print(di.keys())</span><br><span class="line"></span><br><span class="line">    batch_label = di.get(b&apos;batch_label&apos;)</span><br><span class="line">    filenames = di.get(b&apos;filenames&apos;)</span><br><span class="line">    labels = di.get(b&apos;labels&apos;)</span><br><span class="line">    data = di.get(b&apos;data&apos;)</span><br><span class="line"></span><br><span class="line">    print(batch_label)</span><br><span class="line">    print(filenames[0])</span><br><span class="line">    print(labels[0])</span><br><span class="line">    print(data[0])</span><br><span class="line"></span><br><span class="line">dict_keys([b&apos;batch_label&apos;, b&apos;labels&apos;, b&apos;data&apos;, b&apos;filenames&apos;])</span><br><span class="line">b&apos;testing batch 1 of 1&apos;</span><br><span class="line">b&apos;domestic_cat_s_000907.png&apos;</span><br><span class="line">3</span><br><span class="line">[158 159 165 ... 124 129 110]</span><br></pre></td></tr></table></figure>
<h2 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h2><p>键<code>b&#39;data&#39;</code>保存了图像数据，其值类型是<code>numpy.ndarray</code>，每一行都保存了<code>32x32</code>大小图像数据</p>
<p>其中前<code>1024</code>个字节是红色分量值，中间<code>1024</code>个字节是绿色分量值，最后<code>1024</code>个字节是蓝色分量值</p>
<p>解析程序如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def unpickle(file):</span><br><span class="line">    import pickle</span><br><span class="line">    with open(file, &apos;rb&apos;) as fo:</span><br><span class="line">        dict = pickle.load(fo, encoding=&apos;bytes&apos;)</span><br><span class="line">    return dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def convert_data_to_img(data):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    转换数据为图像</span><br><span class="line">    :param data: 3072维</span><br><span class="line">    :return: img</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    num = 1024</span><br><span class="line">    red = data[:num]</span><br><span class="line">    green = data[num:(num * 2)]</span><br><span class="line">    blue = data[(num * 2):]</span><br><span class="line"></span><br><span class="line">    img = np.ndarray((32, 32, 3))</span><br><span class="line">    for i in range(32):</span><br><span class="line">        for j in range(32):</span><br><span class="line">            img[i, j, 0] = blue[i * 32 + j]</span><br><span class="line">            img[i, j, 1] = green[i * 32 + j]</span><br><span class="line">            img[i, j, 2] = red[i * 32 + j]</span><br><span class="line"></span><br><span class="line">    return img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    data_dir = &apos;/home/zj/data/cifar-10-batches-py/&apos;</span><br><span class="line">    test_data_dir = data_dir + &apos;test_batch&apos;</span><br><span class="line">    di = unpickle(test_data_dir)</span><br><span class="line"></span><br><span class="line">    filenames = di.get(b&apos;filenames&apos;)</span><br><span class="line">    data = di.get(b&apos;data&apos;)</span><br><span class="line"></span><br><span class="line">    filename = str(filenames[0], encoding=&apos;utf-8&apos;)</span><br><span class="line">    img = convert_data_to_img(data[0])</span><br><span class="line"></span><br><span class="line">    cv.imwrite(filename, img)</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/cifar-10数据集解析/domestic_cat_s_000907.png" alt></p>
<h2 id="解压代码"><a href="#解压代码" class="headerlink" title="解压代码"></a>解压代码</h2><p>完整解压代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># @Time    : 19-6-5 下午8:20</span><br><span class="line"># @Author  : zj</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import pickle</span><br><span class="line">import os</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">data_list = [&apos;data_batch_1&apos;, &apos;data_batch_2&apos;, &apos;data_batch_3&apos;, &apos;data_batch_4&apos;, &apos;data_batch_5&apos;, &apos;test_batch&apos;]</span><br><span class="line"></span><br><span class="line">res_data_dir = &apos;/home/zj/data/decompress_cifar_10&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def unpickle(file):</span><br><span class="line">    with open(file, &apos;rb&apos;) as fo:</span><br><span class="line">        dict = pickle.load(fo, encoding=&apos;bytes&apos;)</span><br><span class="line">    return dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def write_img(data, labels, filenames, isTrain=True):</span><br><span class="line">    if isTrain:</span><br><span class="line">        data_dir = os.path.join(res_data_dir, &apos;train&apos;)</span><br><span class="line">    else:</span><br><span class="line">        data_dir = os.path.join(res_data_dir, &apos;test&apos;)</span><br><span class="line"></span><br><span class="line">    if not os.path.exists(data_dir):</span><br><span class="line">        os.mkdir(data_dir)</span><br><span class="line"></span><br><span class="line">    N = len(labels)</span><br><span class="line">    for i in range(N):</span><br><span class="line">        cate_dir = os.path.join(data_dir, str(labels[i]))</span><br><span class="line">        if not os.path.exists(cate_dir):</span><br><span class="line">            os.mkdir(cate_dir)</span><br><span class="line">        img_path = os.path.join(cate_dir, str(filenames[i], encoding=&apos;utf-8&apos;))</span><br><span class="line"></span><br><span class="line">        # r = data[i][:1024].reshape(32, 32)</span><br><span class="line">        # g = data[i][1024:2048].reshape(32, 32)</span><br><span class="line">        # b = data[i][2048:].reshape(32, 32)</span><br><span class="line">        # img = cv2.merge((b, g, r))</span><br><span class="line"></span><br><span class="line">        img = data[i].reshape(3, 32, 32)</span><br><span class="line">        img = np.transpose(img, (1, 2, 0))</span><br><span class="line">        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)</span><br><span class="line">        cv2.imwrite(img_path, img)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line"></span><br><span class="line">    for item in data_list:</span><br><span class="line">        data_dir = &apos;/home/zj/data/cifar-10-batches-py/&apos;</span><br><span class="line">        data_dir = os.path.join(data_dir, item)</span><br><span class="line">        di = unpickle(data_dir)</span><br><span class="line"></span><br><span class="line">        batch_label = str(di.get(b&apos;batch_label&apos;), encoding=&apos;utf-8&apos;)</span><br><span class="line">        filenames = di.get(b&apos;filenames&apos;)</span><br><span class="line">        labels = di.get(b&apos;labels&apos;)</span><br><span class="line">        data = di.get(b&apos;data&apos;)</span><br><span class="line"></span><br><span class="line">        if &apos;train&apos; in batch_label:</span><br><span class="line">            write_img(data, labels, filenames)</span><br><span class="line">        else:</span><br><span class="line">            write_img(data, labels, filenames, isTrain=False)</span><br></pre></td></tr></table></figure>
<h2 id="读取图像"><a href="#读取图像" class="headerlink" title="读取图像"></a>读取图像</h2><p>读取解压后的图像并显示，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    data_dir = &apos;/home/zj/data/cifar-10-batches-py/test_batch&apos;</span><br><span class="line"></span><br><span class="line">    di = unpickle(data_dir)</span><br><span class="line"></span><br><span class="line">    batch_label = str(di.get(b&apos;batch_label&apos;), encoding=&apos;utf-8&apos;)</span><br><span class="line">    filenames = di.get(b&apos;filenames&apos;)</span><br><span class="line">    labels = di.get(b&apos;labels&apos;)</span><br><span class="line">    data = di.get(b&apos;data&apos;)</span><br><span class="line"></span><br><span class="line">    N = 10</span><br><span class="line">    W = 32</span><br><span class="line">    H = 32</span><br><span class="line">    ex = np.zeros((H * N, W * N, 3))</span><br><span class="line">    for i in range(N):</span><br><span class="line">        for j in range(N):</span><br><span class="line">            img = data[i * N + j].reshape(3, H, W)</span><br><span class="line">            img = np.transpose(img, (1, 2, 0))</span><br><span class="line">            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)</span><br><span class="line"></span><br><span class="line">            ex[i * H:(i + 1) * H, j * W:(j + 1) * W] = img</span><br><span class="line">    plt.imshow(ex.astype(np.uint8), cmap=&apos;gray&apos;)</span><br><span class="line">    plt.axis(&apos;off&apos;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/cifar-10数据集解析/mix.png" alt></p>
]]></content>
      <categories>
        <category>编程</category>
        <category>编程语言</category>
        <category>数据</category>
        <category>代码库</category>
        <category>数据集</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
        <tag>numpy</tag>
        <tag>cifar10</tag>
        <tag>pickle</tag>
      </tags>
  </entry>
  <entry>
    <title>[pycharm]远程编译</title>
    <url>/posts/a6c06fb8.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://zhuanlan.zhihu.com/p/38330654" target="_blank" rel="noopener">教程 | 使用 PyCharm 连接服务器进行远程开发和调试</a></p><p><a href="https://www.jetbrains.com/help/pycharm/creating-a-remote-server-configuration.html" target="_blank" rel="noopener">Creating a Remote Server Configuration</a></p><a id="more"></a>


<p>当前使用笔记本进行开发，想要利用服务器加快编译和运行速度</p>
<p>新建<code>PyCharm</code>工程，点击菜单栏<code>File-&gt;Settings</code>，打开设置窗口</p>
<p>点击左侧窗格<code>Project-&gt;Project Interpreter</code></p>
<p><img src="/imgs/pycharm-远程编译/project-interpreter.png" alt></p>
<p>点击右上角的齿轮按钮<code>-&gt;Add</code>，弹出<code>Add Pycharm Interpreter</code>窗口</p>
<p><img src="/imgs/pycharm-远程编译/gear-button.png" alt></p>
<p>选择<code>SSH Interpreter</code>，在右侧添加<code>Host</code>和<code>Username</code>，然后点击<code>Next</code></p>
<p><img src="/imgs/pycharm-远程编译/add-interpreter.png" alt></p>
<p>填入服务器中<code>python</code>解释器的位置，默认会将本地<code>pycharm</code>工程同步到服务器<code>tmp</code>路径下，点击<code>Finish</code>按钮，即完成创建</p>
<p><img src="/imgs/pycharm-远程编译/select-interpreter.png" alt></p>
<p>等待一段时间，将本地工程先上传到远程服务器，同时更新解释器，就可以使用远程解释器进行运算了</p>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>pycharm</tag>
      </tags>
  </entry>
  <entry>
    <title>jupyter-notebook远程登录</title>
    <url>/posts/5e96fc4f.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://jupyter-notebook.readthedocs.io/en/latest/public_server.html#notebook-server-security" target="_blank" rel="noopener">Running a notebook server</a></p><p><a href="https://blog.csdn.net/simple_the_best/article/details/77005400" target="_blank" rel="noopener">设置 jupyter notebook 可远程访问</a></p><a id="more"></a>


<p><code>jupyter notebook</code>是一个基于客户端-服务器架构的<code>web</code>应用，但是默认仅能运行在本地，可以通过配置开放远程服务器端口</p>
<p>本文实现单用户远程访问功能，如果要实现多用户访问，参考<a href="https://jupyterhub.readthedocs.io/en/latest/" target="_blank" rel="noopener">JupyterHub</a></p>
<h2 id="生成配置文件"><a href="#生成配置文件" class="headerlink" title="生成配置文件"></a>生成配置文件</h2><p>使用参数<code>--generate-config</code>生成配置文件<code>jupyter_notebook_config.py</code>，存储在<code>~/.jupyter</code>文件夹</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ jupyter notebook --generate-config</span><br><span class="line">Writing default config to: /home/zj/.jupyter/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure>
<h2 id="修改监听ip地址"><a href="#修改监听ip地址" class="headerlink" title="修改监听ip地址"></a>修改监听<code>ip</code>地址</h2><p>修改服务器监听<code>ip</code>地址</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## The IP address the notebook server will listen on.</span><br><span class="line">#c.NotebookApp.ip = &apos;localhost&apos;</span><br></pre></td></tr></table></figure>
<p>默认为<code>localhost</code>（就是本地），允许所有<code>ip</code>地址访问</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">c.NotebookApp.ip = &apos;*&apos;</span><br></pre></td></tr></table></figure>
<h2 id="远程登录"><a href="#远程登录" class="headerlink" title="远程登录"></a>远程登录</h2><p>在远程服务器修改完配置文件后，启动<code>jupyter</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ jupyter notebook</span><br><span class="line">[W 11:13:25.418 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.</span><br><span class="line">[I 11:13:25.423 NotebookApp] Serving notebooks from local directory: /home/zj/software/tutorial</span><br><span class="line">[I 11:13:25.423 NotebookApp] 0 active kernels </span><br><span class="line">[I 11:13:25.424 NotebookApp] The Jupyter Notebook is running at: http://[all ip addresses on your system]:8888/?token=e78e227ffb28ede99b5b7d576459335fd265e886d834ec32</span><br><span class="line">[I 11:13:25.424 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).</span><br><span class="line">[W 11:13:25.424 NotebookApp] No web browser found: could not locate runnable browser.</span><br><span class="line">[C 11:13:25.424 NotebookApp] </span><br><span class="line">    </span><br><span class="line">    Copy/paste this URL into your browser when you connect for the first time,</span><br><span class="line">    to login with a token:</span><br><span class="line">        http://localhost:8888/?token=e78e227ffb28ede99b5b7d576459335fd265e886d834ec32</span><br><span class="line">[I 11:13:41.883 NotebookApp] 302 GET / (192.168.0.140) 0.94ms</span><br><span class="line">[I 11:13:41.915 NotebookApp] 302 GET /tree? (192.168.0.140) 1.24ms</span><br></pre></td></tr></table></figure>
<p>在本地浏览器输入<code>远程IP:8888</code>，就能进入页面，还需要输入<code>token</code>（<em>在输入日志中</em>）</p>
<p><img src="/imgs/jupyter-notebook远程登录/jupyter-token-login.png" alt></p>
<h2 id="密码设置"><a href="#密码设置" class="headerlink" title="密码设置"></a>密码设置</h2><p>可以进行密码设置以加强安全性</p>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>jupyter-notebook</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins]反向代理出错</title>
    <url>/posts/adc5ce0c.html</url>
    <content><![CDATA[<p>将<code>Jenkins</code>架设在局域网服务器上，使用内网穿透技术映射<code>Jenkins</code>端口，打开页面，提示错误</p><blockquote>
<p>It appears that your reverse proxy set up is broken</p>
</blockquote><a id="more"></a>

<p>参考：<a href="https://blog.csdn.net/fxy0325/article/details/88131947" target="_blank" rel="noopener">It appears that your reverse proxy set up is broken解决</a></p>
<p>进入配置系统页面(<code>Manage Jenkins-&gt;Configure System</code>)，找到<code>Jenkins Location</code>小节</p>
<p><img src="/imgs/Jenkins-反向代理出错/jenkins-location.png" alt></p>
<p>修改<code>Jenkins URL</code>为当前公网地址即可</p>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins][github]webhook连接</title>
    <url>/posts/341b6b1e.html</url>
    <content><![CDATA[<p>默认<code>Jenkins</code>已安装好<code>github</code>插件<a href="http://wiki.jenkins-ci.org/display/JENKINS/Github+Plugin" target="_blank" rel="noopener">Github plugin</a></p><p><img src="/imgs/Jenkins-github-webhook连接/github-plugin.png" alt></p><p>使用<code>WebHook</code>方式进行<code>github</code>的配置，过程如下：</p><a id="more"></a>


<ol>
<li>获取<code>Jenkins WebHook URL</code></li>
<li>配置<code>github</code>仓库<code>WebHook</code></li>
<li>新建<code>jenkins</code>工程并配置<code>github</code>仓库</li>
<li>推送修改到<code>github</code>，触发<code>jenkins</code>工程</li>
</ol>
<h2 id="获取Jenkins-WebHook-URL"><a href="#获取Jenkins-WebHook-URL" class="headerlink" title="获取Jenkins WebHook URL"></a>获取<code>Jenkins WebHook URL</code></h2><p>点击左侧菜单栏<code>-&gt;Manage Jenkins-&gt;Configure System</code>，在<code>GitHub</code>小节点击<code>Advanced</code>选项<code>-&gt;Override Hook URL</code></p>
<p><img src="/imgs/Jenkins-github-webhook连接/github-webhook.png" alt></p>
<h2 id="配置github仓库WebHook"><a href="#配置github仓库WebHook" class="headerlink" title="配置github仓库WebHook"></a>配置<code>github</code>仓库<code>WebHook</code></h2><p>进入<code>github</code>仓库<code>Settings</code>页面，选择<code>Webhooks-&gt;Add webhook</code>，添加<code>URL</code>，<code>Content type</code>选择<code>application/json</code>格式</p>
<p><img src="/imgs/Jenkins-github-webhook连接/add-webhook.png" alt></p>
<h2 id="新建jenkins工程并配置"><a href="#新建jenkins工程并配置" class="headerlink" title="新建jenkins工程并配置"></a>新建<code>jenkins</code>工程并配置</h2><p>新建<code>Freestyle</code>工程<code>github_test</code>，进入配置页面</p>
<p>在<code>General</code>小节，添加<code>Github project</code>地址</p>
<p><img src="/imgs/Jenkins-github-webhook连接/config-general.png" alt></p>
<p>在<code>Source Code Management</code>小节，选择<code>Git</code>并添加<code>Github project</code>地址（<em>相同就好了</em>）</p>
<p><img src="/imgs/Jenkins-github-webhook连接/config-source-code-management.png" alt></p>
<p>在<code>Build Triggers</code>小节，选择<code>GitHub hook trigger for GITScm polling</code>选项</p>
<p><img src="/imgs/Jenkins-github-webhook连接/config-build-triggers.png" alt></p>
<p>在<code>Build</code>小节，添加脚本如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 输出信息</span><br><span class="line">echo &quot;hello github&quot;</span><br><span class="line"># 当前路径</span><br><span class="line">pwd</span><br><span class="line"># 当前文件信息</span><br><span class="line">ls -al</span><br></pre></td></tr></table></figure>
<p>最后点击<code>Save</code>按钮</p>
<h2 id="触发构建"><a href="#触发构建" class="headerlink" title="触发构建"></a>触发构建</h2><p><code>Jenkins</code>工程<code>github_test</code>的控制台输出如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">。。。</span><br><span class="line">。。。</span><br><span class="line">[github_test] $ /bin/sh -xe /tmp/jenkins5404470649999101259.sh</span><br><span class="line">+ echo hello github</span><br><span class="line">hello github</span><br><span class="line">+ pwd</span><br><span class="line">/home/ubuntu/.jenkins/workspace/github_test</span><br><span class="line">+ ls -al</span><br><span class="line">total 96</span><br><span class="line">drwxrwxr-x  3 ubuntu ubuntu  4096 3月  25 14:56 .</span><br><span class="line">drwxrwxr-x 15 ubuntu ubuntu  4096 3月  25 14:47 ..</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu     7 3月  25 14:56 coding.txt</span><br><span class="line">drwxrwxr-x  8 ubuntu ubuntu  4096 3月  25 14:56 .git</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu    11 3月  25 14:56 github.txt</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu    14 3月  25 14:56 .gitignore</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu   492 3月  25 14:56 .gitmessage</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu    15 3月  25 14:56 hello.txt</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu     0 3月  25 14:56 hihihi.txt</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu    33 3月  25 14:56 hi.txt</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu 57146 3月  25 14:56 package-lock.json</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu   100 3月  25 14:56 README.md</span><br><span class="line">Finished: SUCCESS</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins][ssh]coding连接</title>
    <url>/posts/6185d82f.html</url>
    <content><![CDATA[<p>参考：<a href="https://open.coding.net/ci/jenkins/" target="_blank" rel="noopener">使用 Jenkins 构建 Coding 项目</a></p><p>使用步骤如下：</p><ol>
<li>在<code>Jenkins</code>安装<code>coding</code>插件</li>
<li>在<code>Jenkins</code>配置<code>Credentials</code>，设置<code>ssh</code>私钥</li>
<li>新建工程，配置<code>coding</code>仓库地址以及<code>coding</code>触发器</li>
<li>在<code>coding</code>仓库设置<code>webhook</code></li>
<li>推送修改到<code>coding</code>仓库，触发<code>jenkins</code>构建</li>
</ol><a id="more"></a>


<h2 id="安装Coding-Webhook-Plugin"><a href="#安装Coding-Webhook-Plugin" class="headerlink" title="安装Coding Webhook Plugin"></a>安装<code>Coding Webhook Plugin</code></h2><p>默认没有安装<code>coding</code>插件，点击左侧菜单栏<code>-&gt;Manage Jenkins-&gt;Manage Plugins</code></p>
<p><img src="/imgs/Jenkins-ssh-coding连接/manage-plugins.png" alt></p>
<p>选择<code>Available</code>类别，在<code>Filter</code>框输入<code>coding</code>进行过滤，选中<code>Coding Webhook Plugin</code>后进行安装，重启</p>
<p><img src="/imgs/Jenkins-ssh-coding连接/coding-plugin.png" alt></p>
<h2 id="私钥设置"><a href="#私钥设置" class="headerlink" title="私钥设置"></a>私钥设置</h2><p>选择左侧菜单栏<code>-&gt;Credentials-&gt;System-&gt;Global credentials(unrestricted)</code></p>
<p><img src="/imgs/Jenkins-ssh-coding连接/global-credentials.png" alt></p>
<p>选择左侧菜单栏<code>-&gt;Add Credentials</code></p>
<p><img src="/imgs/Jenkins-ssh-coding连接/add-credentials.png" alt></p>
<p><code>Kind</code>（类型）选择<code>SSH Username with privary key</code>，然后输入<code>Username</code>（自定义）和<code>privary key</code>（私钥）以及<code>Passphrase</code>（口令，如果有的话），点击<code>OK</code>按钮即可</p>
<p><img src="/imgs/Jenkins-ssh-coding连接/create-ssh-credential.png" alt></p>
<h2 id="工程配置"><a href="#工程配置" class="headerlink" title="工程配置"></a>工程配置</h2><p>新建<code>Freestyle</code>工程<code>coding_test</code>，在<code>Source Code Management</code>(源码管理)部分配置<code>Git</code>仓库，同时添加之前设置的<code>credential</code></p>
<p><img src="/imgs/Jenkins-ssh-coding连接/source-code-management.png" alt></p>
<p>在<code>Build Triggers</code>(构建触发器)部分选择<code>Coding</code>构建（<strong>在这里可以查询到<code>webhook url</code></strong>）</p>
<p><img src="/imgs/Jenkins-ssh-coding连接/coding-trigger.png" alt></p>
<p>在<code>Build</code>(构建)部分添加脚本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 输出信息</span><br><span class="line">echo &quot;hello coding&quot;</span><br><span class="line"># 当前路径</span><br><span class="line">pwd</span><br><span class="line"># 当前文件信息</span><br><span class="line">ls -al</span><br></pre></td></tr></table></figure>
<p><img src="/imgs/Jenkins-ssh-coding连接/build-script.png" alt></p>
<p>最后点击<code>Save</code>按钮保存配置</p>
<h2 id="webhook设置"><a href="#webhook设置" class="headerlink" title="webhook设置"></a><code>webhook</code>设置</h2><p>进入<code>Coding</code>仓库页面，选择设置<code>-&gt;WebHook</code>，点击新建<code>WebHook</code>按钮</p>
<p><img src="/imgs/Jenkins-ssh-coding连接/coding-webhook.png" alt></p>
<p>添加<code>URL</code>，其他设置默认即可</p>
<h2 id="触发构建"><a href="#触发构建" class="headerlink" title="触发构建"></a>触发构建</h2><p>在本地下载<code>coding</code>仓库，修改后推送到<code>coding</code>仓库，<code>Jenkins</code>自动进行构建，控制台输出如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">...</span><br><span class="line">[coding_test] $ /bin/sh -xe /tmp/jenkins865426060185704403.sh</span><br><span class="line">+ echo hello jenkins</span><br><span class="line">hello jenkins</span><br><span class="line">+ pwd</span><br><span class="line">/home/ubuntu/.jenkins/workspace/coding_test</span><br><span class="line">+ ls -al</span><br><span class="line">total 96</span><br><span class="line">drwxrwxr-x  3 ubuntu ubuntu  4096 3月  25 10:09 .</span><br><span class="line">drwxrwxr-x 11 ubuntu ubuntu  4096 3月  25 09:40 ..</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu     7 3月  25 10:09 coding.txt</span><br><span class="line">drwxrwxr-x  8 ubuntu ubuntu  4096 3月  25 10:09 .git</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu    11 3月  25 10:09 github.txt</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu    14 3月  25 10:09 .gitignore</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu   492 3月  25 10:09 .gitmessage</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu    15 3月  25 10:09 hello.txt</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu     0 3月  25 10:09 hihihi.txt</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu    33 3月  25 10:09 hi.txt</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu 57146 3月  25 10:09 package-lock.json</span><br><span class="line">-rw-rw-r--  1 ubuntu ubuntu   100 3月  25 10:09 README.md</span><br><span class="line">Finished: SUCCESS</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>[Jenkins]freestyle工程</title>
    <url>/posts/fddee3e1.html</url>
    <content><![CDATA[<p><code>Jenkins</code>提供了多种模型来进行自动化操作，最基础的就是<code>freestyle</code>工程</p><p>操作步骤如下：</p><ol>
<li>在本地新建<code>git</code>仓库</li>
<li>创建<code>Jenkins Freestyle</code>工程，绑定<code>git</code>仓库，执行构建脚本</li>
<li><code>git</code>仓库添加文件</li>
<li>手动触发<code>Jenkins</code>工程进行构建</li>
</ol><a id="more"></a>


<h2 id="新建freestyle工程"><a href="#新建freestyle工程" class="headerlink" title="新建freestyle工程"></a>新建<code>freestyle</code>工程</h2><p>选择左侧菜单栏<code>-&gt;New Item</code>，输入项目名，选择工程类型为<code>Freestyle project</code>，点击<code>OK</code>按钮即完成新建</p>
<p><img src="/imgs/Jenkins-freestyle工程/item-type-freestyle.png" alt></p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>完成新建项目后会跳往配置页面，也可在项目页面选择左侧菜单栏<code>-&gt;Configure</code></p>
<p>配置页面有<code>6</code>个部分</p>
<ol>
<li><code>General</code></li>
<li><code>Source Code Management</code></li>
<li><code>Build Triggers</code></li>
<li><code>Build Environment</code></li>
<li><code>Build</code></li>
<li><code>Post-build Actions</code></li>
</ol>
<p><em>配置完成点击<code>Save</code>或<code>Apply</code>按钮</em></p>
<h3 id="绑定git仓库"><a href="#绑定git仓库" class="headerlink" title="绑定git仓库"></a>绑定<code>git</code>仓库</h3><p>选择<code>Source Code Management-&gt;Git</code>，输入本地仓库地址</p>
<p><img src="/imgs/Jenkins-freestyle工程/git-setting.png" alt></p>
<h3 id="设置运行脚本"><a href="#设置运行脚本" class="headerlink" title="设置运行脚本"></a>设置运行脚本</h3><p>选择<code>Build-&gt;Add build step-&gt;Execute Shell</code>，使用<code>Linux</code>命令进行接下来的构建</p>
<p><img src="/imgs/Jenkins-freestyle工程/build-script.png" alt></p>
<p>当前测试脚本如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 输出信息</span><br><span class="line">echo &quot;hello jenkins&quot;</span><br><span class="line"># 当前路径</span><br><span class="line">pwd</span><br><span class="line"># 当前文件信息</span><br><span class="line">ls -al</span><br></pre></td></tr></table></figure>
<h2 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h2><p><code>git</code>仓库添加修改后，选择项目页面左侧菜单栏<code>-&gt;Build Now</code>，会在左侧下方<code>Build History</code>栏中显示新的构建，比如<code>#1</code></p>
<p>点击本次构建，跳转到构建页面后选择左侧菜单栏<code>-&gt;Console Output</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">。。。</span><br><span class="line">。。。</span><br><span class="line">[freestyle-test] $ /bin/sh -xe /tmp/jenkins191262132818038393.sh</span><br><span class="line">+ echo hello jenkins</span><br><span class="line">hello jenkins</span><br><span class="line">+ pwd</span><br><span class="line">/home/zj/.jenkins/workspace/freestyle-test</span><br><span class="line">+ ls -al</span><br><span class="line">总用量 16</span><br><span class="line">drwxrwxr-x 3 zj zj 4096 3月  23 15:16 .</span><br><span class="line">drwxrwxr-x 4 zj zj 4096 3月  23 15:16 ..</span><br><span class="line">drwxrwxr-x 8 zj zj 4096 3月  23 15:22 .git</span><br><span class="line">-rw-rw-r-- 1 zj zj   19 3月  23 15:16 hi.txt</span><br><span class="line">Finished: SUCCESS</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins安装</title>
    <url>/posts/5d15ec84.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://jenkins.io/doc/#about-this-documentation" target="_blank" rel="noopener">Jenkins User Documentation</a></p><p><a href="https://jenkins.io/zh/doc/book/installing/" target="_blank" rel="noopener">安装Jenkins </a></p><h2 id="什么是Jenkins？"><a href="#什么是Jenkins？" class="headerlink" title="什么是Jenkins？"></a>什么是<code>Jenkins</code>？</h2><p><a href="https://jenkins.io/zh/" target="_blank" rel="noopener">Jenkins</a>是一个独立开源的自动化服务器，支持几乎所有语言，支持所有自动化任务，包括构建、测试、交付和部署</p><a id="more"></a>



<h3 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h3><p>硬件上</p>
<ol>
<li>至少<code>256MB</code>内存，推荐<code>512MB</code></li>
<li><code>10GB</code>硬盘空间（用于<code>Jenkins</code>和<code>Docker</code>镜像）</li>
</ol>
<p>软件上</p>
<ol>
<li><code>Java 8</code>，参考：<a href="https://zj-linux-guide.readthedocs.io/zh_CN/latest/tools/[Ubuntu%2016.04]Java%E5%AE%89%E8%A3%85.html" target="_blank" rel="noopener">[Ubuntu 16.04]Java安装</a></li>
<li><code>Docker</code>，参考：<a href="https://docker-guide.readthedocs.io/zh_CN/latest/basic/[Ubuntu%2016.04]%E5%AE%89%E8%A3%85.html" target="_blank" rel="noopener">[Ubuntu 16.04]安装</a></li>
</ol>
<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>有两种下载方式</p>
<ol>
<li>直接下载安装包</li>
<li>通过<code>apt-get</code>安装</li>
</ol>
<h3 id="直接下载"><a href="#直接下载" class="headerlink" title="直接下载"></a>直接下载</h3><p>下载<code>Jetkins</code>: <a href="http://mirrors.jenkins.io/war-stable/latest/jenkins.war" target="_blank" rel="noopener">http://mirrors.jenkins.io/war-stable/latest/jenkins.war</a></p>
<h3 id="apt-get下载"><a href="#apt-get下载" class="headerlink" title="apt-get下载"></a>apt-get下载</h3><p>参考<a href="https://pkg.jenkins.io/debian-stable/" target="_blank" rel="noopener">Jenkins Debian packages</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 添加键</span><br><span class="line">$ wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add -</span><br><span class="line"># 添加源路径</span><br><span class="line">$ deb https://pkg.jenkins.io/debian-stable binary/</span><br><span class="line"># 下载或更新</span><br><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get install jenkins</span><br></pre></td></tr></table></figure>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>运行 </p>
<pre><code>$ java -jar jenkins.war --httpPort=8080
</code></pre><p>如果是本地安装，登录</p>
<pre><code>http://localhost:8080
</code></pre><p>如果是远程安装，登录</p>
<pre><code>http://远程ip:8080
</code></pre><p>输入密码，在命令行信息中会有提示</p>
<pre><code>Jenkins initial setup is required. An admin user has been created and a password generated.
Please use the following password to proceed to installation:

ae096c33c43148c3a65a518b5dbaxxxx

This may also be found at: /home/ubuntu/.jenkins/secrets/initialAdminPassword
</code></pre><p><em><code>Jetkins</code>需要安装额外插件，选择官方建议的插件进行安装</em></p>
<h3 id="重新安装"><a href="#重新安装" class="headerlink" title="重新安装"></a>重新安装</h3><p>删除<code>home</code>目录下的<code>.jenkins</code>文件夹，重新执行命令即可</p>
<h3 id="登录失败"><a href="#登录失败" class="headerlink" title="登录失败"></a>登录失败</h3><p>参考：<a href="https://blog.csdn.net/qq_38318622/article/details/79448018" target="_blank" rel="noopener">jenkins忘记密码问题解决</a></p>
<p>忘记用户名，进入<code>~/.jenkins/users</code>，每个登录用户有一个专属文件夹，以<code>用户名+id</code>命名</p>
<p>忘记密码，进入用户文件夹，修改<code>config.xml</code>文件，修改<code>&lt;passwordHash&gt;</code>属性为</p>
<pre><code>#jbcrypt:$2a$10$MiIVR0rr/UhQBqT.bBq0QehTiQVqgNpUGyWW2nJObaVAM/2xSQdSq
或者
#jbcrypt:$2a$10$3UUvN926tlDQAc4Yo6WnbOOBPvPw8/sqgJoKahwHSACJ.Im4oWZLS
</code></pre><p>上面这个是密码<code>123456</code>的加密版本，重新启动<code>jenkins</code>即可</p>
]]></content>
      <categories>
        <category>工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>你在哪个端开发</title>
    <url>/posts/591ccb13.html</url>
    <content><![CDATA[<p>前几天和同学聊天关于未来工作的场景，聊到具体的研发岗位后发现对于后端开发和服务器开发没有太多概念（我以为后端开发和服务器开发是一回事），打算写一篇文章好好理清其中的关系</p><a id="more"></a>
<h2 id="前端、移动端和客户端"><a href="#前端、移动端和客户端" class="headerlink" title="前端、移动端和客户端"></a>前端、移动端和客户端</h2><p>参考：</p>
<p><a href="https://www.zhihu.com/question/20734984?sort=created" target="_blank" rel="noopener">什么叫前端？</a></p>
<p><a href="https://baike.baidu.com/item/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91" target="_blank" rel="noopener">前端开发</a></p>
<p><a href="https://baike.baidu.com/item/%E7%A7%BB%E5%8A%A8%E5%BC%80%E5%8F%91/11030579" target="_blank" rel="noopener">移动开发</a></p>
<p><a href="https://www.zhihu.com/search?type=content&amp;q=%E7%A7%BB%E5%8A%A8%E5%BC%80%E5%8F%91" target="_blank" rel="noopener">移动开发</a></p>
<p><a href="https://baike.baidu.com/item/%E5%AE%A2%E6%88%B7%E7%AB%AF" target="_blank" rel="noopener">客户端</a></p>
<p>前端开发(<code>frontend development</code>)：在浏览器或内置浏览器引擎的应用上实现用户交互界面，也称为<code>web</code>端开发。使用<code>HTML+CSS</code>构建页面，使用<code>JS</code>实现用户交互</p>
<p>移动端开发(<code>Mobile Development</code>)：在移动手机、平板等便携式终端上开发应用，因为这些应用基本使用无线上网方式，也称为移动互联开发。主要有<code>IOS</code>和<code>Android</code>两个开发平台，有多种应用开发类型，包括原生应用(<code>native app</code>)、混合应用(<code>hybird app</code>)、<code>web</code>应用(<code>web app</code>)</p>
<p>客户端开发(<code>Client Development</code>)：客户端指的是直接面向客户的应用。一般把客户端理解成为<code>C/S</code>中的<code>client</code>，与服务器端相对应，区别于<code>B/S</code>中的<code>browser</code>(浏览器端)，包括桌面应用和移动应用</p>
<p>所以按开发平台（移动/<code>PC</code>）划分，3者的关系如下</p>
<p><img src="/images/你在哪个端开发/前端-移动端-客户端.PNG" alt></p>
<h2 id="后端和服务器端"><a href="#后端和服务器端" class="headerlink" title="后端和服务器端"></a>后端和服务器端</h2><p>参考：<a href="https://zhuanlan.zhihu.com/p/27067255" target="_blank" rel="noopener">什么是后端开发？</a></p>
<p>后端开发(<code>backend development</code>)区别于前端开发，其目的是针对前端页面的请求实现相应的逻辑，比如获取获取数据库数据并反馈给前端，执行识别功能并返回识别结果给前端，所以后端开发的目的不在于可视化，而是专注于逻辑处理。后端开发涉及数据库、服务器、网络等领域。</p>
<p>服务器端开发(<code>server-side development</code>)则区别于客户端开发(<code>C/S</code>)和浏览器端开发(<code>B/S</code>)，其目的也是为客户端和浏览器端提供相应的逻辑服务</p>
<p>所以后端开发和服务器端开发的内容本质上是一样的</p>
]]></content>
      <categories>
        <category>随笔</category>
        <category>软件工程</category>
      </categories>
  </entry>
  <entry>
    <title>敏捷开发</title>
    <url>/posts/ed2e9abb.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://baike.baidu.com/item/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91" target="_blank" rel="noopener">敏捷开发</a></p><p><a href="https://blog.csdn.net/ympzuelx3aiap7q/article/details/79395255" target="_blank" rel="noopener">从业十余年的阿里工程师告诉你，敏捷开发的核心是什么？</a></p><p><a href="https://bbs.csdn.net/topics/390701149" target="_blank" rel="noopener">敏捷开发的优缺点</a></p><h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>将软件项目划分为可独立运行、可相互集成的小项目，分别完成的同时保持软件的可运行</p><a id="more"></a>




<p>小项目迭代开发，以用户需求为核心，根据反馈及时修改开发方向</p>
<p>尽早实现开发原型的交付，在此基础上进一步添加用户需求，强调可持续开发</p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点：</p>
<ul>
<li>给予开发人员足够的自由度，激发开发人员的主观能动性</li>
<li>保证开发过程中软件可运行</li>
<li>以用户需求为核心，及时调整开发方向</li>
<li>模块化开发，保证小项目的独立运行和集成性</li>
</ul>
<p>缺点：</p>
<ul>
<li>快速开发的过程会缺失对文档的管理，如果人员流失过大会造成项目的不可持续</li>
<li>对软件模型的不完备，经常需要更新和变化</li>
</ul>
<h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><p>需求变化大，同时能够深入了解客户需求</p>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>保证开发人员的及时沟通，比如早上的站立会议，每周的团队会议<br>保证文档的管理，除了日/周/月报，季度总结外，还要主要项目模块的开发模型，关键事项</p>
]]></content>
      <categories>
        <category>软件工程</category>
        <category>开发模型</category>
      </categories>
      <tags>
        <tag>敏捷开发</tag>
      </tags>
  </entry>
  <entry>
    <title>螺旋模型</title>
    <url>/posts/8e9d3485.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://baike.baidu.com/item/%E8%9E%BA%E6%97%8B%E6%A8%A1%E5%9E%8B" target="_blank" rel="noopener">螺旋模型</a></p><h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>结合迭代模型和瀑布模型的特点，同时增加风险分析</p><p>开发过程中，首先实现关键功能，然后周期性的进行其他功能的开发。每个开发周期划分为需求定义、风险分析、工程实现和评审共4个阶段</p><a id="more"></a>



<p><img src="/images/螺旋模型/螺旋模型.PNG" alt></p>
<p>在需求定义阶段，分解项目需求，确定需求等级</p>
<p>通过风险分析，将软件项目分解成一个个小项目，确定每个项目的主要风险，以及采取哪种策略来规避风险</p>
<p>通过客户评审来进一步修正计划，进行下一个周期的开发</p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点：</p>
<ul>
<li>能够及时获知市场或客户对于产品的反馈</li>
<li>能够灵活的调整开发步骤</li>
<li>能够规避开发风险</li>
</ul>
<p>缺点：</p>
<ul>
<li>提高开发成本</li>
<li>开发周期长</li>
</ul>
<h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><ol>
<li>高成本复杂项目，通过风险分析，一步步分解项目，进一步规避开发风险</li>
<li>需求不明确项目，能够及时反馈客户需求进行灵活调整</li>
</ol>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ol>
<li>需要客户积极的反馈和参与</li>
<li>需要开发人员拥有足够经验来识别和规避风险</li>
</ol>
]]></content>
      <categories>
        <category>软件工程</category>
        <category>开发模型</category>
      </categories>
      <tags>
        <tag>螺旋模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文写作</title>
    <url>/posts/5cbfbe67.html</url>
    <content><![CDATA[<p>记录一些论文写作相关的工具和使用方法</p><h2 id="文献相关"><a href="#文献相关" class="headerlink" title="文献相关"></a>文献相关</h2><h3 id="文献查询"><a href="#文献查询" class="headerlink" title="文献查询"></a>文献查询</h3><ul>
<li><a href="http://www.cnki.net/" target="_blank" rel="noopener">知网</a></li>
<li><a href="https://arxiv.org/" target="_blank" rel="noopener">预印本数据库</a></li>
<li><a href="http://xueshu.baidu.com/" target="_blank" rel="noopener">百度学术</a></li>
<li><a href="http://ac.scmor.com/" target="_blank" rel="noopener">谷歌学术</a></li>
</ul><h3 id="参考文献编辑"><a href="#参考文献编辑" class="headerlink" title="参考文献编辑"></a>参考文献编辑</h3><a id="more"></a>

<p>使用<a href="http://xueshu.baidu.com/" target="_blank" rel="noopener">百度学术</a>或<a href="https://scholar.google.com/" target="_blank" rel="noopener">google学术</a>进行文献引用格式查询：点击<strong>引用</strong>选项即会弹出标准的引用格式</p>
<p><img src="/imgs/论文写作/LeNet-5.png" alt></p>
<p><img src="/imgs/论文写作/LeNet-5-Ref.png" alt></p>
<p>辅助工具：<code>NoteExpress</code></p>
<h2 id="查重"><a href="#查重" class="headerlink" title="查重"></a>查重</h2><ol>
<li><a href="http://www.paperfree.cn/" target="_blank" rel="noopener">PaperFree</a></li>
</ol>
<h2 id="文档编辑"><a href="#文档编辑" class="headerlink" title="文档编辑"></a>文档编辑</h2><h3 id="word编辑"><a href="#word编辑" class="headerlink" title="word编辑"></a><code>word</code>编辑</h3><ol>
<li>分栏设置：布局-&gt;栏-&gt;两栏</li>
</ol>
<h3 id="公式编辑"><a href="#公式编辑" class="headerlink" title="公式编辑"></a>公式编辑</h3><p><code>MathType</code>：<a href="http://www.xue51.com/soft/9446.html" target="_blank" rel="noopener">MathType7.1破解版</a></p>
<p>问题：<a href="https://jingyan.baidu.com/article/90bc8fc8565484f653640ccc.html" target="_blank" rel="noopener">解决MathType安装字体MT Extra的问题</a></p>
<h3 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h3><ol>
<li><code>Visio</code></li>
<li><code>PPT</code></li>
<li><code>xmind</code></li>
</ol>
<p>神经网络在线画图：</p>
<ul>
<li><a href="https://cbovar.github.io/ConvNetDraw/" target="_blank" rel="noopener">ConvNetDraw</a></li>
<li><a href="http://alexlenail.me/NN-SVG/LeNet.html" target="_blank" rel="noopener">NN-SVG</a></li>
</ul>
<p><code>UML</code>在线画图：</p>
<ul>
<li><a href="https://www.draw.io/" target="_blank" rel="noopener">draw.io</a></li>
</ul>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>迭代模型</title>
    <url>/posts/7080d667.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://baike.baidu.com/item/%E8%BF%AD%E4%BB%A3%E6%A8%A1%E5%9E%8B/10705205?fr=aladdin" target="_blank" rel="noopener">迭代模型</a></p><p><a href="https://baike.baidu.com/item/%E8%BF%AD%E4%BB%A3/8415523" target="_blank" rel="noopener">迭代 （科学概念）</a></p><h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>迭代模型不要求一次迭代就完成目标结果，其目的是通过不断迭代来逐渐实现目标</p><a id="more"></a>



<p>每次迭代都可以看成一个小的瀑布模型，经历过需求分析、设计、实现和测试阶段</p>
<p>上一次迭代的成果是下一次迭代的起始；当前迭代的目的是解决上一次迭代遗留的问题以及实现最终目标</p>
<p><img src="/images/迭代模型/迭代模型.PNG" alt></p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点：</p>
<ul>
<li>降低开支风险，每次迭代耗费成本小于完整的软件开发</li>
<li>降低开发风险，能够及时获知市场或客户对于产品的反馈</li>
<li>加快开发进度，各阶段开发人员能够进一步明确问题和工作核心</li>
</ul>
<p>缺点：</p>
<ul>
<li>开发周期长，不断的迭代才能实现更好的目标</li>
</ul>
<h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><ol>
<li>用户或者开发人员对于产品的需求不明确，利用迭代模型开发能保证产品一步步的修正</li>
<li>开发高风险项目，能够允许迭代模型长周期产生的高成本</li>
</ol>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ol>
<li>注重版本管理和文档管理</li>
<li>需要用户不同程度的参与</li>
</ol>
]]></content>
      <categories>
        <category>软件工程</category>
        <category>开发模型</category>
      </categories>
      <tags>
        <tag>迭代模型</tag>
      </tags>
  </entry>
  <entry>
    <title>瀑布模型</title>
    <url>/posts/9d00be46.html</url>
    <content><![CDATA[<p>参考：<a href="https://baike.baidu.com/item/%E7%80%91%E5%B8%83%E6%A8%A1%E5%9E%8B/9817778?fr=aladdin" target="_blank" rel="noopener">瀑布模型</a></p><h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>规划程序开发流程，划分为制定计划、需求分析、软件设计、程序编写、软件测试和运行维护六个阶段</p><a id="more"></a>

<p><img src="/images/瀑布模型/瀑布模型.PNG" alt></p>
<p>发现问题，需要回到上一个阶段进行解决，解决后再进入下一个阶段</p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点：</p>
<ul>
<li>简化工序，将设计和实现分开，便于分工协作</li>
<li>只需要关注一个阶段的任务，完成一个阶段后进入下一阶段</li>
</ul>
<p>缺点：</p>
<ul>
<li>程序固定，不适用于需求经常变化的项目（比如业务开发）</li>
<li>开发模式线性，在流程完成后才能看到开发成果，增大了开发风险</li>
</ul>
<h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><p>瀑布模型适用于产品不复杂，需求明确的软件开发</p>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>划分产品开发阶段，明确产品开发时间</p>
]]></content>
      <categories>
        <category>软件工程</category>
        <category>开发模型</category>
      </categories>
      <tags>
        <tag>瀑布模型</tag>
      </tags>
  </entry>
  <entry>
    <title>什么是软件工程</title>
    <url>/posts/7baadea7.html</url>
    <content><![CDATA[<p>在网上看到一个说法,开发软件就像开发建筑,感觉真的很像.后来又转念一想,工程类学科(比如建筑工程/汽车工程)都有相似的部分</p><a id="more"></a>
<ul>
<li>参与人数众多</li>
<li>高度分工(比如有专门负责视觉UI/有专门负责产品测试/有专门负责产品开发)</li>
<li>追求模块化/结构化</li>
<li>在不同领域有专精(比如开发浏览器/邮箱/搜索引擎/电子商务)</li>
</ul>
<p>软件开发和汽车/建筑开发的区别在于它应用在互联网上,想象的空间无远弗届；同时它的实践性要求更大,有短期的目标,但是很难说有长远目标,根据市场的需求来确定下一个版本的内容  </p>
<p>它的缺点也可能就是开发更容易变形,因为快速开发过程中不断的需求变更导致程序在不断迭代中愈加复杂,最终代码完全失控</p>
<p>软件工程,就是为了制定结构性好,灵活性高的软件开发方法和开发流程.如何调动程序员进行目的明确,组织性高的编程；如何确定出好的评判标准；甚至如何脱离实际内容而抽象出通用的开发流程,这些内容都在不断探索中</p>
<p>待学习的软件开发模型:</p>
<ol>
<li>瀑布模型(<code>waterfall model</code>)</li>
<li>迭代模型(<code>iterative model</code>)</li>
<li>螺旋模型(<code>sprial model</code>)</li>
<li>敏捷开发(<code>agile development</code>)</li>
</ol>
<p>待学习的软件测试模型：</p>
<ol>
<li>单元测试(<code>unit test</code>)</li>
<li>集成测试(<code>integration tes</code>t)</li>
<li>系统测试(<code>system test</code>)</li>
<li>回归测试(<code>regression testing</code>)</li>
</ol>
]]></content>
      <categories>
        <category>随笔</category>
        <category>软件工程</category>
      </categories>
  </entry>
  <entry>
    <title>软件开发流程</title>
    <url>/posts/a6cd9115.html</url>
    <content><![CDATA[<p>经历过几个软件开发，有模块的开发也有产品的开发。这其中并不是每一次都是细分开发过程，但是随着学习的深入，越来越多的自动化操作应用在开发过程中，如果能够更好的细分当前的开发流程，我觉得这会对开发软件有更好的帮助。</p><a id="more"></a>
<p>小结软件开发过程中需要经历的阶段和专用术语</p>
<h2 id="大体划分"><a href="#大体划分" class="headerlink" title="大体划分"></a>大体划分</h2><p>软件开发过程主要包括4个阶段：</p>
<ol>
<li>需求</li>
<li>开发</li>
<li>测试</li>
<li>发布</li>
</ol>
<p>首先针对将要进行的软件进行功能和应用的研究，明确要实现的需求和相应的功能；接下来进行实际的编程开发（也有可能包括硬件的开发）；完成开发后需要进行功能点的测试；最后发布该软件</p>
<p>整个过程并不一定是直线型，即先需求，再开发，再测试，最后发布</p>
<p><img src="/images/软件开发流程/general-division.PNG" alt></p>
<p>相反，往往各个阶段混杂在一起，先开发一部分需求，每开发完成一个需求点就进行测试，测试成功后发布给用户体验；测试发现的问题反馈给开发解决；在发布给用户后，根据用户体验决定是否更新需求</p>
<p><img src="/images/软件开发流程/cross-division.PNG" alt></p>
<h2 id="持续集成、持续部署、持续发布"><a href="#持续集成、持续部署、持续发布" class="headerlink" title="持续集成、持续部署、持续发布"></a>持续集成、持续部署、持续发布</h2><p>参考：</p>
<p><a href="https://www.zhihu.com/question/23444990" target="_blank" rel="noopener">如何理解持续集成、持续交付、持续部署？</a></p>
<p><a href="https://blog.csdn.net/peterxiaoq/article/details/73648732" target="_blank" rel="noopener">如何理解持续集成、持续交付、持续部署？</a></p>
<p>软件开发往往是一个多人协同进行的过程，每一个人负责一部分的功能实现</p>
<p><strong>持续集成（continuous integration）</strong>的概念指的是开发人员完成某一个功能点后马上进行测试，解决测试发现的问题以及是否进一步合并代码</p>
<p>要实现持续集成，需要构建一个自动化测试的环境，代码上传到服务器后，通过钩子（<code>hook</code>）拉取新代码并进行单元测试，发布测试结果并发起合并请求</p>
<p><strong>持续部署（continuous deploy）</strong>的概念指的是测试开发环节的代码并自动部署到生产环节</p>
<p><strong>持续发布（continuous release）</strong>的概念指的是实现新的功能后马上发布给用户体验，如果出现问题也可以更准确的进行定位</p>
<p>这几个术语来自于<a href="https://baike.baidu.com/item/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F" target="_blank" rel="noopener">敏捷开发</a>，强调的是小步快跑的概念，通过自动化工具的辅助进行软件功能的快速迭代，不但能够给予开发成员更加便捷的工作环境，也能让用户更快的体验到新的功能</p>
]]></content>
      <categories>
        <category>软件工程</category>
        <category>开发模型</category>
      </categories>
  </entry>
  <entry>
    <title>文档集合</title>
    <url>/posts/d22ab967.html</url>
    <content><![CDATA[<p><strong><em>停止更新，使用<a href="https://www.zhujian.tech/posts/bd2847bc.html">知识金字塔</a></em></strong></p><p>列出整理成册的文档，以备参考</p><h2 id="计算机基础"><a href="#计算机基础" class="headerlink" title="计算机基础"></a>计算机基础</h2><ol>
<li><a href="https://www.zhujian.tech/posts/fe7e69f4.html">数学</a></li>
<li><a href="https://www.zhujian.tech/posts/ee5b0da5.html">软件工程</a></li>
<li><a href="https://zj-linux-guide.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">Linux Guide</a></li>
</ol><a id="more"></a>


<h2 id="计算机语言"><a href="#计算机语言" class="headerlink" title="计算机语言"></a>计算机语言</h2><ol>
<li><a href="https://zj-sphinx-github-readthedocs.readthedocs.io/en/latest/markdown/Markdown%E4%BD%BF%E7%94%A8-1-%E5%BC%95%E8%A8%80/" target="_blank" rel="noopener">Markdown语法</a></li>
<li><a href="https://zj-sphinx-github-readthedocs.readthedocs.io/en/latest/reStructuredText/reStructuredText-%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/" target="_blank" rel="noopener">reStructuredtext语法</a></li>
<li><a href="https://vscode-guide.readthedocs.io/zh_CN/latest/node/nodeJS%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">nodeJS Guide</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/cplusplus/%E5%AD%A6%E4%B9%A0C++%E4%B9%8B%E8%B7%AF/" target="_blank" rel="noopener">C++11 Standard</a></li>
<li><a href="https://zj-linux-guide.readthedocs.io/zh_CN/latest/shell/dash%E5%92%8Cbash/" target="_blank" rel="noopener">Shell脚本编程</a></li>
</ol>
<h2 id="服务器搭建"><a href="#服务器搭建" class="headerlink" title="服务器搭建"></a>服务器搭建</h2><ol>
<li><a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/nginx/%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">Nginx-Guide</a></li>
<li><a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/tomcat/%E5%85%B3%E4%BA%8ETomcat/" target="_blank" rel="noopener">Tomcat-Guide</a></li>
</ol>
<h2 id="网络处理"><a href="#网络处理" class="headerlink" title="网络处理"></a>网络处理</h2><ol>
<li><a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">网络基础知识</a></li>
<li><a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/net-traversal/%E5%89%8D%E8%A8%80/" target="_blank" rel="noopener">内网穿透</a></li>
<li><a href="https://wall-guide.readthedocs.io/zh/latest/?badge=latest" target="_blank" rel="noopener">翻墙指南</a></li>
<li><a href="https://zj-network-guide.readthedocs.io/zh_CN/latest/ssh/[SSH]%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/" target="_blank" rel="noopener">SSH</a></li>
</ol>
<h2 id="容器与自动化"><a href="#容器与自动化" class="headerlink" title="容器与自动化"></a>容器与自动化</h2><ol>
<li><a href="https://containerization-automation.readthedocs.io/zh_CN/latest/jenkins/" target="_blank" rel="noopener">Jenkins Guide</a></li>
<li><a href="https://containerization-automation.readthedocs.io/zh_CN/latest/?badge=latest" target="_blank" rel="noopener">Docker Guide</a></li>
</ol>
<h2 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h2><ol>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">Image Processing</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/opencv/OpenCV%E6%A6%82%E8%BF%B0/" target="_blank" rel="noopener">OpenCV Learning</a></li>
<li><a href="https://vscode-guide.readthedocs.io/zh_CN/latest/anaconda/%E7%8E%AF%E5%A2%83%E6%9F%A5%E8%AF%A2%EF%BC%8C%E5%AE%89%E8%A3%85%EF%BC%8C%E5%8D%B8%E8%BD%BD%EF%BC%8C%E5%85%8B%E9%9A%86/" target="_blank" rel="noopener">Anaconda Guide</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/pytorch/%E5%BC%95%E8%A8%80/" target="_blank" rel="noopener">PyTorch Guide</a></li>
<li><a href="https://zj-image-processing.readthedocs.io/zh_CN/latest/matplotlib/%E5%BC%95%E8%A8%80/" target="_blank" rel="noopener">Matplotlib-Guide</a></li>
<li><a href="https://www.zhujian.tech/posts/bdfae45b.html">数据集小结</a></li>
</ol>
<h2 id="开发工具"><a href="#开发工具" class="headerlink" title="开发工具"></a>开发工具</h2><ol>
<li><a href="https://vscode-guide.readthedocs.io/zh_CN/latest/?badge=latest" target="_blank" rel="noopener">VSCode使用</a></li>
<li><a href="https://blog-website-building-guide.readthedocs.io/zh_CN/latest/?badge=latest" target="_blank" rel="noopener">博客网站搭建指南</a></li>
<li><a href="https://zj-sphinx-github-readthedocs.readthedocs.io/en/latest/?badge=latest" target="_blank" rel="noopener">MkDocs-Github-Readthedocs</a></li>
<li><a href="https://vscode-guide.readthedocs.io/zh_CN/latest/jupyter/[conda]JupyterLab%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">JupyterLab Guide</a></li>
<li><a href="https://zhujian.tech/posts/f793688d.html" target="_blank" rel="noopener">[PyTorch]Tensorboard使用实践</a></li>
</ol>
<h2 id="版本管理"><a href="#版本管理" class="headerlink" title="版本管理"></a>版本管理</h2><ol>
<li><a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">GIT语法</a></li>
<li><a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/platform/[GitLab]%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">托管平台</a></li>
<li>实现规范<ul>
<li><a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/message/%E5%BC%95%E8%A8%80/" target="_blank" rel="noopener">消息提交规范</a></li>
<li><a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/version/[SEMVER]%E8%AF%AD%E4%B9%89%E7%89%88%E6%9C%AC%E8%A7%84%E8%8C%83/" target="_blank" rel="noopener">语义版本规范</a></li>
<li><a href="https://zj-git-guide.readthedocs.io/zh_CN/latest/readme/%E5%BC%95%E8%A8%80/" target="_blank" rel="noopener">README编写规范</a></li>
<li><a href="https://www.zhujian.tech/posts/c7ee2f15.html">GIT工作流实践</a></li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>方差 标准差</title>
    <url>/posts/3d82a363.html</url>
    <content><![CDATA[<p>方差、标准差都是在概率论(<code>probability</code>)和统计学(<code>statistic</code>)中常用的内容，它们之间彼此联系又互相有差别</p><a id="more"></a>
<hr>
<h2 id="独立性和相关性"><a href="#独立性和相关性" class="headerlink" title="独立性和相关性"></a>独立性和相关性</h2><p>参考：<a href="https://www.zhihu.com/question/22762386" target="_blank" rel="noopener">随机变量的独立性和相关性有什么联系？相关系数为零能说明什么？</a></p>
<p>对于两组随机变量$X$和$Y$而言:</p>
<ul>
<li>如果对$X$的取值不改变对$Y$的取值，反之亦然，那么这两组变量是<strong>独立</strong>的</li>
<li>如果对$X$的取值和对$Y$的取值服从某一函数$f(x,y)=0$，那么称它们是<strong>不独立</strong>的</li>
</ul>
<p>统计学上指相关性为<strong>线性相关</strong>，即$y=ax+b$</p>
<p>所以如果$X$对$Y$的关系是$y=x^{2}$，那么它是没有独立性同时没有相关性</p>
<h4 id="独立同分布"><a href="#独立同分布" class="headerlink" title="独立同分布"></a>独立同分布</h4><p>参考：<a href="https://baike.baidu.com/item/%E7%8B%AC%E7%AB%8B%E5%90%8C%E5%88%86%E5%B8%83/6715110" target="_blank" rel="noopener">独立同分布</a></p>
<p>独立同分布(<code>independent and identically distributed (i.i.d.)</code>)指多组随机变量服从同一分布，但是彼此相互独立</p>
<hr>
<h2 id="数学期望和平均数"><a href="#数学期望和平均数" class="headerlink" title="数学期望和平均数"></a>数学期望和平均数</h2><p>参考：<a href="https://www.zhihu.com/question/25391960" target="_blank" rel="noopener">期望和平均数有什么区别？</a></p>
<p>数学期望又称均值，即所有随机变量的平均数；而平均数是对当前已知样本集进行求和平均的值</p>
<p>数学期望是一个概率论概念，而平均数是一个统计学的概念，当样本集趋近于所有随机变量时，平均数会趋近于数学期望</p>
<p>所以对于总体随机变量而言，它的均值是数学期望；而对于样本随机变量而言，它的均值是平均数</p>
<p>假定总体随机变量为$X$，均值为$\mu$；独立同分布的样本随机变量为$x$，均值为$\overline{x}$。它们之间有以下关系：</p>
<ul>
<li>对于总体随机变量而言，其数学期望$E(X)=\mu$</li>
<li>对于样本随机变量而言，其数学期望$E(x)=\overline{x}$</li>
<li>对于样本均值而言，其数学期望$E(\overline{x})=\mu$</li>
</ul>
<h3 id="均值"><a href="#均值" class="headerlink" title="均值"></a>均值</h3><p>参考：<a href="https://en.wikipedia.org/wiki/Expected_value" target="_blank" rel="noopener">Expected value</a></p>
<p>对于独立分布的随机变量$X/Y$有</p>
<ol>
<li><p>$E[XY]=E[X]E[Y]$</p>
</li>
<li><p>$E[aX]=aE[X]$</p>
</li>
<li><p>$E[X+Y]=E[X]+E[Y]$</p>
</li>
</ol>
<hr>
<h2 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h2><p>参考：</p>
<p><a href="https://en.wikipedia.org/wiki/Variance" target="_blank" rel="noopener">Variance</a></p>
<p><a href="https://baike.baidu.com/item/%E6%96%B9%E5%B7%AE/3108412" target="_blank" rel="noopener">方差</a></p>
<p>方差(<code>variance</code>)指随机变量对其数学期望的平方偏差。用于衡量一组随机变量相对于期望值的离散程度（偏离程度），值多大，表示其分布越广</p>
<p>常用数学符号：$\sigma ^ { 2 }$、$s^{2}$、$Var(X)$、$D(x)$，方差计算公式：</p>
<script type="math/tex; mode=display">
D ( X ) = \mathrm { E } \left[ ( X - \mu ) ^ { 2 } \right]</script><p>其中$X$是随机变量，$\mu$是均值，计算如下</p>
<script type="math/tex; mode=display">
\mu=E[X]</script><p><strong>离散随机变量</strong>的方差公式：</p>
<script type="math/tex; mode=display">
D( X ) = \frac { 1 } { N } \sum _ { i = 1 } ^ { N } \left( x _ { i } - \mu \right) ^ { 2 }</script><p>其中$D(X)$指离散方差，$X$是一组随机变量，$\mu$是均值，$N$指变量个数</p>
<p>均值$\mu$的计算公式如下：</p>
<script type="math/tex; mode=display">
\mu = \frac { 1 } { N } \sum _ { i = 1 } ^ { N} x _ { i }</script><h3 id="基本属性"><a href="#基本属性" class="headerlink" title="基本属性"></a>基本属性</h3><p>下面介绍一些关于方差/协方差的基本属性</p>
<h4 id="方差-1"><a href="#方差-1" class="headerlink" title="方差"></a>方差</h4><ol>
<li><p>方差值永远大于0：$D ( X ) \geq 0$</p>
</li>
<li><p>如果一组变量均为同一值，那么其方差为0，换句话说，如果方差为0，那么这组随机变量为同一值：$P ( X = a ) = 1 \Longleftrightarrow D( X ) = 0$</p>
</li>
<li><p>对随机变量增加一个数，不改变方差值：$D ( X + a ) = D( X )$</p>
</li>
<li><p>对随机变量同乘以一个数，相当于对方差乘以该值平方：$D( a X ) = a ^ { 2 } D( X )$</p>
</li>
<li><p>两组随机变量和的方差可通过各组方差以及协方差计算得到：</p>
<script type="math/tex; mode=display">
 D ( a X + b Y ) = a ^ { 2 } D ( X ) + b ^ { 2 } D ( Y ) + 2 a b \operatorname { Cov } ( X , Y )</script><script type="math/tex; mode=display">
 D ( a X - b Y ) = a ^ { 2 }D ( X ) + b ^ { 2 } D ( Y ) - 2 a b \operatorname { Cov } ( X , Y )</script><p> 其中$Cov(<em>,</em>)$是协方差，对于$N$组随机变量${X_{1},X_{2},…,X_{N}}$的和的方差如下：</p>
<script type="math/tex; mode=display">
 D(\sum_{i=1}^{n}X_{i})=\sum_{i,j=1}^{n}Cov(X_{i},X_{j})=\sum_{i=1}^{N}D(X_{i})+\sum_{i\neq j}Cov(X_{i},X_{j})</script></li>
</ol>
<h4 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h4><p>变量$X/Y$属于同一组独立分布的随机变量，那么有</p>
<script type="math/tex; mode=display">\operatorname { Cov } \left( X _ { i } , X _ { j } \right) = 0 , \forall ( i \neq j )</script><p>所以对于独立分布的随机变量$X_{1},X_{2},…,X_{N}$有</p>
<script type="math/tex; mode=display">
D(\sum_{i=1}^{n}X_{i})=\sum_{i=1}^{N}D(X_{i})</script><h4 id="不相关变量和的方差"><a href="#不相关变量和的方差" class="headerlink" title="不相关变量和的方差"></a>不相关变量和的方差</h4><p>参考：<a href="https://en.wikipedia.org/wiki/Variance#Sum_of_uncorrelated_variables_(Bienaym%C3%A9_formula" target="_blank" rel="noopener">Sum of uncorrelated variables (Bienaymé formula)</a>)</p>
<p>对于不相关分布的随机变量$X$，其和的方差等同于方差的和</p>
<script type="math/tex; mode=display">
\operatorname { Var } \left( \sum _ { i = 1 } ^ { n } X _ { i } \right) = \sum _ { i = 1 } ^ { n } \operatorname { Var } \left( X _ { i } \right)</script><p>所以计算均值的方差等同于方差除以随机变量数目</p>
<script type="math/tex; mode=display">
\operatorname { Var } ( \overline { X } ) = \operatorname { Var } \left( \frac { 1 } { n } \sum _ { i = 1 } ^ { n } X _ { i } \right) = \frac { 1 } { n ^ { 2 } } \sum _ { i = 1 } ^ { n } \operatorname { Var } \left( X _ { i } \right) = \frac { 1 } { n ^ { 2 } } n \sigma ^ { 2 } = \frac { \sigma ^ { 2 } } { n }</script><h3 id="总体方差和样本方差"><a href="#总体方差和样本方差" class="headerlink" title="总体方差和样本方差"></a>总体方差和样本方差</h3><p>参考：</p>
<p><a href="https://blog.csdn.net/zxyhhjs2017/article/details/79149111" target="_blank" rel="noopener">统计学—-之样本方差与总体方差的区别</a></p>
<p><a href="https://wenku.baidu.com/view/8422e2516bd97f192279e973.html" target="_blank" rel="noopener">样本方差与总体方差的区别</a></p>
<p><a href="https://blog.csdn.net/yangzhenzhen/article/details/73244592" target="_blank" rel="noopener">样本方差的无偏估计与（n-1）的由来</a></p>
<p><a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator" target="_blank" rel="noopener">Bias of an estimator</a></p>
<p>通过统计所有随机变量来计算其偏离平均值的平方偏差称为总体方差(<code>population variance</code>)</p>
<p>通过计算样本集得到的方差称为样本方差(<code>sample variance</code>)</p>
<p>在很多情况下，总体随机变量的采集无法实现，通常使用样本集来代替，即使用样本方差来作为总体方差估计(<code>estimate</code>)</p>
<p>假定以下数学符号：</p>
<ul>
<li>总体均值：$\mu$</li>
<li>总体方差：$\sigma ^{2}$</li>
<li>总体随机变量：$X=(x_{1},x_{2},…,x_{N})$</li>
<li>样本均值：$\overline { x }$</li>
<li>样本方差：$s^{2}$</li>
<li>样本随机变量：$X=(x_{1},x_{2},…,x_{n})$</li>
</ul>
<h4 id="总体方差计算公式"><a href="#总体方差计算公式" class="headerlink" title="总体方差计算公式"></a>总体方差计算公式</h4><script type="math/tex; mode=display">
\mu=\frac{1}{N}\sum_{i=1}^{N}x_{i}</script><script type="math/tex; mode=display">
\sigma ^{2} =\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\mu)^{2}=\frac{1}{N}\sum_{i=1}^{N}(x_{i}^{2}-2x_{i}\mu +\mu^{2})</script><script type="math/tex; mode=display">
=\frac{1}{N}\sum_{i=1}^{N}x_{i}^{2}-\frac{2}{N}\sum_{i=1}^{N}x_{i}\mu+\frac{1}{N}\mu^{2}
=\frac{1}{N}\sum_{i=1}^{N}x_{i}^{2}-2\mu(\frac{1}{N}\sum_{i=1}^{N}x_{i})+\mu^{2}</script><script type="math/tex; mode=display">
=\frac{1}{N}\sum_{i=1}^{N}x_{i}^{2}-2\mu^{2}+\mu^{2}
=\frac{1}{N}\sum_{i=1}^{N}x_{i}^{2}-\mu^{2}
=E[X^{2}]-(E[X])^{2}</script><p>由上式也可推导出如下公式：</p>
<script type="math/tex; mode=display">
E[X^{2}]=\sigma ^{2}+\mu^{2}</script><h4 id="样本方差计算公式"><a href="#样本方差计算公式" class="headerlink" title="样本方差计算公式"></a>样本方差计算公式</h4><script type="math/tex; mode=display">
\overline {x}=\frac{1}{N}\sum_{i=1}^{N}x_{i}</script><script type="math/tex; mode=display">
s^{2}=\frac{1}{n}\sum_{i=1}^{n}(x_{i}-\overline {x})^{2}</script><p>但是上述样本方差计算公式是一个有偏差(<code>biased</code>)的总体方差估计，证明如下：</p>
<script type="math/tex; mode=display">
s^{2}=\frac{1}{n}\sum_{i=1}^{n}[(x_{i}-\overline {x})^{2}]=\frac{1}{n}\sum_{i=1}^{n}[((x_{i}-\mu)-(\overline {x}-\mu))^{2}]</script><script type="math/tex; mode=display">
=\frac{1}{n}\sum_{i=1}^{n}[(x_{i}-\mu)^{2}-2(x_{i}-\mu)(\overline {x}-\mu)+(\overline {x}-\mu)^{2}]</script><script type="math/tex; mode=display">
=\frac{1}{n}\sum_{i=1}^{n}(x_{i}-\mu)^{2}-\frac{2}{n}\sum_{i=1}^{n}(x_{i}-\mu)(\overline {x}-\mu)+\frac{1}{n}\sum_{i=1}^{n}(\overline {x}-\mu)^{2}</script><p>其中$\mu$和$\overline { x }$是常量，所以上述公式转换为</p>
<script type="math/tex; mode=display">
s^{2}=\frac{1}{n}\sum_{i=1}^{n}(x_{i}-\mu)^{2}-2(\frac{1}{n}\sum_{i=1}^{n}x_{i}-\mu)(\bar{x}-\mu)+(\bar{x}-\mu)^{2}</script><script type="math/tex; mode=display">
=\frac{1}{n}\sum_{i=1}^{n}(x_{i}-\mu)^{2}-2(\bar{x}-\mu)(\bar{x}-\mu)+(\bar{x}-\mu)^{2}</script><script type="math/tex; mode=display">
=\frac{1}{n}\sum_{i=1}^{n}(x_{i}-\mu)^{2}-(\bar{x}-\mu)^{2} \leq \frac{1}{n}\sum_{i=1}^{n}(x_{i}-\mu)^{2}</script><p>样本方差一直小于等于总体方差，为得到正确的总体方差的无偏估计，需要对有偏的样本方差公式乘以一个缩放因子</p>
<p>假定存在$n$组独立同分布的随机变量$X={X_{1},X_{2},…,X_{n}}$，每个随机变量均值和方差为$\mu$和$\sigma ^{2}$，那么</p>
<script type="math/tex; mode=display">
E(s^{2})=\sigma ^{2}</script><script type="math/tex; mode=display">
E(\overline X)=\mu</script><p>计算如下：</p>
<script type="math/tex; mode=display">
E[s^{2}]=E[\frac{1}{n}\sum_{i=1}^{n}(X_{i}-\overline {X})^{2}]=E[\frac{1}{n}\sum_{i=1}^{n}(X_{i}-\frac{1}{n}\sum_{j=1}^{n}X_{j})^{2}]</script><script type="math/tex; mode=display">
=E[\frac{1}{n}\sum_{i=1}^{n}(X_{i}^{2}-\frac{2}{n}X_{i}\sum_{j=1}^{n}X_{j}+\frac{1}{n^{2}}\sum_{j=1}^{n}\sum_{k=1}^{n}X_{j}X_{k})]</script><script type="math/tex; mode=display">
=E[\frac{1}{n}\sum_{i=1}^{n}(X_{i}^{2}-\frac{2}{n}X_{i}^{2}-\frac{2}{n}X_{i}\sum_{j=1,j\neq i}^{n}X_{j}+\frac{1}{n^{2}}\sum_{j=1}^{n}X_{j}^{2}+\frac{1}{n^{2}}\sum_{j=1}^{n}\sum_{k=1,k\neq j}^{n}X_{j}X_{k})]</script><script type="math/tex; mode=display">
=\frac{1}{n}\sum_{i=1}^{n}(\frac{n-2}{n}E[X_{i}^{2}]-\frac{2}{n}E[X_{i}\sum_{j=1,j\neq i}^{n}X_{j}]+\frac{1}{n^{2}}E[\sum_{j=1}^{n}X_{j}^{2}]+\frac{1}{n^{2}}E[\sum_{j=1}^{n}\sum_{k=1,k\neq j}^{n}X_{j}X_{k}])</script><p>因为随机变量$X$是独立同分布，所以</p>
<script type="math/tex; mode=display">
E[X_{i}^{2}]=D(X_{i})+(E[X_{i}])^{2}=\sigma ^{2}+\mu^{2}</script><script type="math/tex; mode=display">
E[X_{i}\sum_{j=1,j\neq i}^{n}X_{j}]=E[X_{i}]\sum_{j=1,j\neq i}^{n}E[X_{j}]=\mu \cdot(n-1)\cdot\mu=(n-1)\mu^{2}</script><script type="math/tex; mode=display">
E[\sum_{j=1}^{n}X_{j}^{2}]=\sum_{j=1}^{n}E[X_{j}^{2}]=\sum_{j=1}^{n}(D(X_{j})+(E[X_{j}])^{2})=n(\sigma ^{2}+\mu^{2})</script><script type="math/tex; mode=display">
E[\sum_{j=1}^{n}\sum_{k=1,k\neq j}^{n}X_{j}X_{k}]=\sum_{j=1}^{n}\sum_{k=1,k\neq j}^{n}E[X_{j}]E[X_{k}]=n\cdot (n-1) \cdot \mu \cdot \mu=n(n-1)\mu^{2}</script><p>所以上述公式转换为</p>
<script type="math/tex; mode=display">
E[s^{2}]=\frac{1}{n}\sum_{i=1}^{n}(\frac{n-2}{n}(\sigma ^{2}+\mu^{2})-\frac{2(n-1)}{n}\mu^{2}+\frac{1}{n}(\sigma ^{2}+\mu^{2})+\frac{n-1}{n}\mu^{2})=\frac{n-1}{n}\sigma^{2}</script><p>可以通过贝塞尔校正(<code>Bessel Correction</code>)方法来修正原先的样本方差计算公式得到一个无偏(<code>unbiased</code>)的估计，即对样本方差再乘以一个因子$n/(n-1)$，那么</p>
<script type="math/tex; mode=display">
\frac{n}{n-1}E[s^{2}]=\frac{n}{n-1}\cdot\frac{n-1}{n}\sigma^{2}=\sigma^{2}</script><p>所以<strong>无偏样本方差</strong>公式为</p>
<script type="math/tex; mode=display">
s^{2} = \frac{1}{n-1}\sum_{i=1}^{n}(x_{i}-\overline x)^{2}</script><hr>
<h2 id="标准差"><a href="#标准差" class="headerlink" title="标准差"></a>标准差</h2><p>参考：</p>
<p><a href="https://en.wikipedia.org/wiki/Standard_deviation" target="_blank" rel="noopener">Standard deviation</a></p>
<p><a href="https://baike.baidu.com/item/%E6%A0%87%E5%87%86%E5%B7%AE/1415772" target="_blank" rel="noopener">标准差</a></p>
<p><a href="https://www.zhihu.com/question/20534502" target="_blank" rel="noopener">有了方差为什么需要标准差？</a></p>
<p><a href="https://blog.csdn.net/Leyvi_Hsing/article/details/54022612" target="_blank" rel="noopener">方差、标准差、均方差、均方误差区别总结</a></p>
<p>标准差(<code>standard deviation</code>)，又称为均方差(<code>Mean square deviation</code>)，是方差的算术平方根，用$\sigma$表示</p>
<p>标准差用于衡量数据的离散程度，数值越低表示数据点分布更接近期望值</p>
<p>方差是数据偏离平均值距离的平方，而标准差是方差的算术平方根，所以标准差的单位和数据一致，易于直观理解</p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>概率论</tag>
        <tag>统计学</tag>
      </tags>
  </entry>
  <entry>
    <title>充分条件 必要条件</title>
    <url>/posts/507c1b79.html</url>
    <content><![CDATA[<p>参考：</p><p><a href="https://en.wikipedia.org/wiki/Necessity_and_sufficiency" target="_blank" rel="noopener">Necessity and sufficiency</a></p><p><a href="https://baike.baidu.com/item/%E5%85%85%E5%88%86%E5%BF%85%E8%A6%81%E6%9D%A1%E4%BB%B6" target="_blank" rel="noopener">充分必要条件</a></p><p><a href="https://www.zhihu.com/question/30469121" target="_blank" rel="noopener">充分条件和必要条件怎么区分 ？</a></p><p>充分条件(<code>sufficient condition</code>)和必要条件(<code>necessary condition</code>)是逻辑上用于描述表达式(<code>statement</code>)之间或日常生活中用于描述事务(<code>affair</code>)之间的条件关系或隐含关系的术语</p><a id="more"></a>




<p>假设$A$为条件，$B$为结论</p>
<h3 id="充分条件"><a href="#充分条件" class="headerlink" title="充分条件"></a>充分条件</h3><p>如果$A$只是$B$的其中一种证明方式，也就是说$A$为真能推导出$B$为真，但是其他条件为真也能推导出$B$为真，那么称<strong>A为B的充分条件</strong></p>
<script type="math/tex; mode=display">
\left\{\begin{matrix}
A_{1}\Rightarrow B\\ 
A_{2}\Rightarrow B\\ 
A_{3}\Rightarrow B
\end{matrix}\right.</script><h3 id="必要条件"><a href="#必要条件" class="headerlink" title="必要条件"></a>必要条件</h3><p>如果$A$是$B$的证明过程的一部分，$A$为真不足以证明$B$为真，但是$B$为真一定能证明$A$为真，那么称<strong>A为B的必要条件</strong></p>
<script type="math/tex; mode=display">
A_{1}+A_{2}+A_{3}\Rightarrow B</script><h3 id="相互关系"><a href="#相互关系" class="headerlink" title="相互关系"></a>相互关系</h3><ul>
<li>如果$A$能推导出$B$，$B$不能推导出$A$，那么称<strong>A是B的充分不必要条件</strong>($A$ $\subseteq$ $B$)</li>
<li>如果$A$能推导出$B$，$B$能推导出$A$，那么称<strong>A是B的充分必要条件</strong>($A=B$)</li>
<li>如果$A$不能推导出$B$，$B$能推导出$A$，那么称<strong>A是B的必要不充分条件</strong>($B\subseteq A$)</li>
<li>如果$A$不能推导出$B$，$B$不能推导出$A$，那么称<strong>A是B的既不充分也不必要条件</strong>($A\nsubseteq B, B\nsubseteq A$)</li>
</ul>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>概率论</tag>
        <tag>统计学</tag>
      </tags>
  </entry>
  <entry>
    <title>从CSDN到Hexo</title>
    <url>/posts/359e7c3c.html</url>
    <content><![CDATA[<p>从文档写作开始,经历了多个平台的实践</p><p>最开始在<code>CSDN</code>上进行博客写作，到现在利用<code>Hexo</code>自建博客网站，中间还通过<code>sphinx+github+readthedocs</code>进行文档管理</p><a id="more"></a>

<p>不同的写作平台和写作方式有长处也有短处，小结一下</p>
<h2 id="CSDN"><a href="#CSDN" class="headerlink" title="CSDN"></a><code>CSDN</code></h2><p>持续时间:<code>2015</code>年<code>4</code>月-至今</p>
<p>最开始接触的就是<code>CSDN</code>，因为之前经常会在上面查阅资料，所以后来就注册了帐号开始写作</p>
<p><code>15</code>年刚考上研究生,开始写博客的目的就是为了毕业的时候可以展示我的学习成果,但是后来在坚持写文章的过程中,发现写作的好处非常明显</p>
<p>有一种说法是写出一篇完整的文章能够理解至少<code>90%</code>的知识点，而且还能够通过理清这个知识点相关的问题进一步发散到其他知识点；以此同时,在往后的查阅和复习过程中能够给你快速的提示</p>
<p>刚开始的<code>CSDN</code>使用富文本编辑器进行写作，后来也支持了<code>Markdown</code>编辑器，中间也推出了博客专栏,专门用于系列文章的整合。但是相较于后面的写作方式，对于文章的编辑修改操作比较繁琐，也不利于系列文章的发布，对图像、数学公式等功能的支持也不是很完善.</p>
<p>小结：在<code>CSDN</code>发布的博客比较倾向于单篇文章，较少的图像和数学公式</p>
<h2 id="sphinx-github-readthedocs"><a href="#sphinx-github-readthedocs" class="headerlink" title="sphinx+github+readthedocs"></a><code>sphinx+github+readthedocs</code></h2><p>持续时间: <code>2018</code>年<code>12</code>月-至今</p>
<p>写作一段时间后,发现有些内容比较复杂,需要用很长的文字+图片+公式+代码去解释,这样的内容需要很长一段时间进行编辑.如果都在一篇文章里,会导致阅读性大大降低；如果分成多篇文章,中间很可能会穿插其他文档,打断阅读的连贯性.</p>
<p>为此苦恼了一段时间,偶然的情况下发现<code>sphinx</code>,能够生成<code>html</code>文档，这种方式对于系列文章的发布真的是福音；再结合<code>github</code>进行远程存储，<code>readthedocs</code>进行远程发布，真真的是一个好字</p>
<p>不过经过一段时间的写作之后，发现其中还是有一个问题:</p>
<p><code>sphinx</code>默认使用<code>reStructuredText</code>语法进行写作，虽然支持<code>Markdown</code>语法(使用<code>CommonMark</code>语法)，但是在一些额外功能(比如数学公式、表格)的支持上并没有很完善，虽然可以利用<code>pandoc</code>将<code>md</code>转换成<code>rst</code>，但是对于数学公式的渲染还是有问题</p>
<p>小结：<code>sphinx</code>适合于发布系列文章，较少的数学公式</p>
<h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a><code>Hexo</code></h2><p>持续时间: <code>2019</code>年<code>1</code>月-至今</p>
<p>现在利用<code>Hexo</code>进行个人博客网站的建设</p>
<ol>
<li>对于页面有更强的自定义权限</li>
<li>没有广告的干扰</li>
<li>能够快速的进行文章的编辑和发布</li>
</ol>
<p>个人觉得的一个不方便之处就是它提供了许多快捷方式（比如块引用/代码引用）来辅助<code>markdown</code>的编写，不利于文章的移植，同时<code>hexo</code>对于资源文件的地址处理也有别于一般<code>markdown</code>的编写习惯</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>math test</title>
    <url>/posts/931e2563.html</url>
    <content><![CDATA[<p>Simple inline $a = b + c$.</p><script type="math/tex; mode=display">
\frac{\partial u}{\partial t}
= h^2 \left( \frac{\partial^2 u}{\partial x^2} +
\frac{\partial^2 u}{\partial y^2} +
\frac{\partial^2 u}{\partial z^2}\right)</script>]]></content>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/posts/4a17b156.html</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><a id="more"></a>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
